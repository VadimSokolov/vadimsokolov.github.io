[
  {
    "objectID": "courses/caio/01-intro.html#mechanical-machines",
    "href": "courses/caio/01-intro.html#mechanical-machines",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Mechanical machines",
    "text": "Mechanical machines\nRobots and Automatic Machines Were Generally Very Inventive: Al-Jazari (XII Century)\n\nHesdin Castle (Robert II of Artois), Leonardo’s robot…"
  },
  {
    "objectID": "courses/caio/01-intro.html#mechanical-machines-1",
    "href": "courses/caio/01-intro.html#mechanical-machines-1",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Mechanical machines",
    "text": "Mechanical machines\nJaquet-Droz automata (XVIII century):"
  },
  {
    "objectID": "courses/caio/01-intro.html#mechanical-machines-2",
    "href": "courses/caio/01-intro.html#mechanical-machines-2",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Mechanical machines",
    "text": "Mechanical machines\n\nBut this is in mechanics, in mathematics/logic AI it was quite rudimentary for a long time\n\n\nLogic machine of Ramon Llull (XIII-XIV centuries)\nStarting with Dr. Frankenstein, further AI in the literature appears constantly …"
  },
  {
    "objectID": "courses/caio/01-intro.html#shennons-theseus",
    "href": "courses/caio/01-intro.html#shennons-theseus",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Shennon’s Theseus",
    "text": "Shennon’s Theseus\n\nYouTube Video\nEarly 1950s, Claude Shannon (The father of Information Theory) demonstrates Theseus\nA life-sized magnetic mouse controlled by relay circuits, learns its way around a maze."
  },
  {
    "objectID": "courses/caio/01-intro.html#great-hopes",
    "href": "courses/caio/01-intro.html#great-hopes",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "1956-1960: Great hopes",
    "text": "1956-1960: Great hopes\n\nOptimistic time. It seemed a that we were almost there…\nAllen Newell, Herbert A. Simon, and Cliff Shaw: Logic Theorist.\nAutomated reasoning.\nIt was able to prof most of the Principia Mathematica, in some places even more elegant than Russell and Whitehead."
  },
  {
    "objectID": "courses/caio/01-intro.html#big-hopes",
    "href": "courses/caio/01-intro.html#big-hopes",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "1956-1960: Big Hopes",
    "text": "1956-1960: Big Hopes\n\nGeneral Problem Solver - a program that tried to think as a person\nA lot of programs that have been able to do some limited things (MicroWorlds):\n\nAnalogy (IQ tests with multiple choice questions)\nStudent (algebraic verbal tasks)\nBlocks World (rearranged 3D blocks)."
  },
  {
    "objectID": "courses/caio/01-intro.html#s-knowledge-based-systems",
    "href": "courses/caio/01-intro.html#s-knowledge-based-systems",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "1970s: Knowledge Based Systems",
    "text": "1970s: Knowledge Based Systems\n\nThe bottom line: to accumulate a fairly large set of rules and knowledge about the subject area, then draw conclusions.\nFirst success: MYCIN - Diagnosis of blood infections:\n\nabout 450 rules\nThe results are like an experienced doctor and significantly better than beginner doctors."
  },
  {
    "objectID": "courses/caio/01-intro.html#commercial-applications-industry-ai",
    "href": "courses/caio/01-intro.html#commercial-applications-industry-ai",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "1980-2010: Commercial applications Industry AI",
    "text": "1980-2010: Commercial applications Industry AI\n\nThe first AI department was at Dec (Digital Equipment Corporation). It is argued that by 1986 he saved the Dec about $10 million per year.\nThe boom ended by the end of the 80s, when many companies could not live up to high expectations."
  },
  {
    "objectID": "courses/caio/01-intro.html#rule-based-system-vs-bayes",
    "href": "courses/caio/01-intro.html#rule-based-system-vs-bayes",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Rule-Based System vs Bayes",
    "text": "Rule-Based System vs Bayes\n\n\n\n\n\n\nOld AI\n\n\n If rain outside, then take umbrella\nThis rule cannot be learned from data. It does not allow inference. Cannot say anything about rain outside if I see an umbrella.\n\n\n\n\n\n\n \n\n\n\n\n\nNew AI\n\n\nProbability of taking umbrella, given there is rain\nConditional probability rule can be learned from data. Allows for inference. We can calculate the probability of rain outside if we see an umbrella.\n\n\n\n\n\n\n\nBayesian approach is a powerful statistical framework based on the work of Thomas Bayes and later Laplace.\nIt provides a probabilistic approach to reasoning and learning\nAllowing us to update our beliefs about the world as we gather new data.\nThis makes it a natural fit for artificial intelligence, where we often need to deal with uncertainty and incomplete information."
  },
  {
    "objectID": "courses/caio/01-intro.html#definition",
    "href": "courses/caio/01-intro.html#definition",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "DEFINITION",
    "text": "DEFINITION\n\nHow to determine “learning”?\n\n\n\n\nDefinition:\n\n\nThe computer program learns as the data is accumulating relative to a certain problem class \\(T\\) and the target function of \\(P\\) if the quality of solving these problems (relative to \\(P\\)) improves with gaining new experience.\n\n\n\n\nThe definition is very (too?) General.\nWhat specific examples can be given?"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ml",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ml",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of ML",
    "text": "Tasks and concepts of ML"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-supervised-learning",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-supervised-learning",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of ML: Supervised Learning",
    "text": "Tasks and concepts of ML: Supervised Learning\n\ntraining sample – a set of examples, each of which consists of input features (attributes) and the correct “answers” - the response variable\nLearn a rule that maps input features to the response variable\nThen this rule is applied to new examples (deployment)\nThe main thing is to train a model that explains not only examples from the training set, but also new examples (generalizes)\nOtherwise - overfitting"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-unsupervised-learning",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-unsupervised-learning",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of ML: unsupervised learning",
    "text": "Tasks and concepts of ML: unsupervised learning\nThere are no correct answers, only data, e.g. clustering:\n\nWe need to divide the data into pre -unknown classes to some extent similar:\n\nhighlight the family of genes from the sequences of nucleotides\ncluster users and personalize the application for them\ncluster the mass spectrometric image to parts with different composition"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-unsupervised-learning-1",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-unsupervised-learning-1",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of ML: unsupervised learning",
    "text": "Tasks and concepts of ML: unsupervised learning\n\nDimensionality reduction: data have a high dimension, it is necessary to reduce it, select the most informative features so that all of the above algorithms can work\nMatrix Competition: There is a sparse matrix, we must predict what is in the missing positions.\nAnomaly detection: find anomalies in the data, e.g. fraud detection.\nOften the outputs answers are given for a small part of the data, then we call it semi -supervised Learning."
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-reinforcement-learning",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-reinforcement-learning",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of ML: reinforcement learning",
    "text": "Tasks and concepts of ML: reinforcement learning\n\nMulti-armed bandits: there is a certain set of actions, each of which leads to random results, you need to get as much rewards possible\nExploration vs.Exploitation: how and when to proceed from the study of the new to use what has already studied\nCredit Assignment: You get rewarded at the very end (won the game), and we must somehow distribute this reward on all the moves that led to victory."
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-active-learning",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ml-active-learning",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of ML: active learning",
    "text": "Tasks and concepts of ML: active learning\n\nActive Learning - how to choose the following (relatively expensive) test\nBoosting - how to combine several weak classifiers so that it turns out good\nModel Selection - where to draw a line between models with many parameters and with a few.\nRanking: response list is ordered (internet search)"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ai",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ai",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of AI",
    "text": "Tasks and concepts of AI"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-reasoning",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-reasoning",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of AI: Reasoning",
    "text": "Tasks and concepts of AI: Reasoning\n\nBayesian networks: given conditional probabilities, calculate the probability of the event\no1 by OpenAI: a family of AI models that are designed to perform complex reasoning tasks, such as math, coding, and science. o1 models placed among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME)\nGemini 2.0: model for the agentic era"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-representation",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-representation",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of AI: Representation",
    "text": "Tasks and concepts of AI: Representation\n\nKnowledge Graphs: a graph database that uses semantic relationships to represent knowledge\nEmbeddings: a way to represent data in a lower-dimensional space\nTransformers: a deep learning model that uses self-attention to process sequential data"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-generation",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-generation",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of AI: Generation",
    "text": "Tasks and concepts of AI: Generation\nIn shadows of data, uncertainty reigns,\nBayesian whispers, where knowledge remains.\nWith prior beliefs, we start our quest,\nUpdating with evidence, we strive for the best.\nA dance of the models, predictions unfold,\nInferences drawn, from the new and the old.\nThrough probabilities, we find our way,\nIn the world of AI, it’s the Bayesian sway.\nSo gather your data, let prior thoughts flow,\nIn the realm of the unknown, let your insights grow.\nFor in this approach, with each little clue,\nWe weave understanding, both rich and true.\nMusic"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-generation-1",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-generation-1",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of AI: Generation",
    "text": "Tasks and concepts of AI: Generation\n\nfrom openai import OpenAI\nclient = OpenAI(api_key=\"your-api-key\")\nresponse = client.images.generate(\n    model=\"dall-e-3\",\n    prompt=\"a hockey player trying to understand the Bayes rule\",\n    size=\"1024x1024\",\n    quality=\"standard\",\n    n=1,\n)\n\nprint(response.data[0].url)"
  },
  {
    "objectID": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-generation-2",
    "href": "courses/caio/01-intro.html#tasks-and-concepts-of-ai-generation-2",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tasks and concepts of AI: Generation",
    "text": "Tasks and concepts of AI: Generation\nA humorous and illustrative scene of a hockey player sitting on a bench in full gear, holding a hockey stick in one hand and a whiteboard marker in th"
  },
  {
    "objectID": "courses/caio/01-intro.html#chess-and-ai",
    "href": "courses/caio/01-intro.html#chess-and-ai",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Chess and AI",
    "text": "Chess and AI\nOld AI: Deep Blue (1997) vs. Garry Kasparov\n\n\n\nKasparov vs IBM’s DeepBlue in 1997"
  },
  {
    "objectID": "courses/caio/01-intro.html#alphago-zero",
    "href": "courses/caio/01-intro.html#alphago-zero",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "AlphaGo Zero",
    "text": "AlphaGo Zero\n\nRemove all human knowledge from training process - only uses self play,\nTakes raw board as input and neural network predicts the next move.\nUses Monte Carlo tree search to evaluate the position.\nThe algorithm was able to beat AlphaGo 100-0. The algorithm was then used to play chess and shogi and was able to beat the best human players in those games as well.\n\n\nAlpha GO vs Lee Sedol: Move 37 by AlphaGo in Game Two"
  },
  {
    "objectID": "courses/caio/01-intro.html#probability-in-machine-learning",
    "href": "courses/caio/01-intro.html#probability-in-machine-learning",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Probability in machine learning",
    "text": "Probability in machine learning\n\nIn all methods and approaches, it is useful not only generate an answer, but also evaluate how confident in this answer, how well the model describes the data, how these values will change in further experiments, etc.\nTherefore, the central role in machine learning is played by the theory of probability - and we will also actively use it."
  },
  {
    "objectID": "courses/caio/01-intro.html#review-of-basic-probability-concepts",
    "href": "courses/caio/01-intro.html#review-of-basic-probability-concepts",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Review of Basic Probability Concepts",
    "text": "Review of Basic Probability Concepts\nProbability lets us talk efficiently about things that we are uncertain about.\n\nWhat will Amazon’s sales be next quarter?\nWhat will the return be on my stocks next year?\nHow often will users click on a particular Google ad?\n\nAll these involve estimating or predicting unknowns!!"
  },
  {
    "objectID": "courses/caio/01-intro.html#random-variables",
    "href": "courses/caio/01-intro.html#random-variables",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Random Variables",
    "text": "Random Variables\nRandom Variables are numbers that we are not sure about. There’s a list of potential outcomes. We assign probabilities to each outcome.\nExample: Suppose that we are about to toss two coins. Let \\(X\\) denote the number of heads. We call \\(X\\) the random variable that stands for the potential outcome."
  },
  {
    "objectID": "courses/caio/01-intro.html#probability",
    "href": "courses/caio/01-intro.html#probability",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Probability",
    "text": "Probability\nProbability is a language designed to help us communicate about uncertainty. We assign a number between \\(0\\) and \\(1\\) measuring how likely that event is to occur. It’s immensely useful, and there’s only a few basic rules.\n\nIf an event \\(A\\) is certain to occur, it has probability \\(1\\), denoted \\(P(A)=1\\)\nEither an event \\(A\\) occurs or it does not. \\[P(A) = 1 - P(\\text{not }A)\\]\nIf two events are mutually exclusive (both cannot occur simultaneously) then \\[P(A \\text{ or } B) = P(A) + P(B)\\]\nJoint probability, when events are independent \\[P(A \\text{ and } B) = P( A) P(B)\\]"
  },
  {
    "objectID": "courses/caio/01-intro.html#probability-distribution",
    "href": "courses/caio/01-intro.html#probability-distribution",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Probability Distribution",
    "text": "Probability Distribution\nWe describe the behavior of random variables with a Probability Distribution\nExample: Suppose we are about to toss two coins. Let \\(X\\) denote the number of heads.\n\\[X = \\left\\{ \\begin{array}{ll}\n0 \\text{ with prob. } 1/4\\\\\n1 \\text{ with prob. } 1/2\\\\\n2 \\text{ with prob. } 1/4\n\\end{array}\n\\right.\\]\n\\(X\\) is called a Discrete Random Variable\nQuestion: What is \\(P(X=0)\\)? How about \\(P(X \\geq 1)\\)?"
  },
  {
    "objectID": "courses/caio/01-intro.html#example-happiness-index",
    "href": "courses/caio/01-intro.html#example-happiness-index",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Example: Happiness Index",
    "text": "Example: Happiness Index\n“happiness index” as a function of salary.\n\n\n\nSalary (\\(X\\))\nHappiness (\\(Y\\)): 0 (low)\n1 (medium)\n2 (high)\n\n\n\n\nlow 0\n0.03\n0.12\n0.07\n\n\nmedium 1\n0.02\n0.13\n0.11\n\n\nhigh 2\n0.01\n0.13\n0.14\n\n\nvery high 3\n0.01\n0.09\n0.14\n\n\n\nIs \\(P(Y=2 \\mid X=3) &gt; P(Y=2)\\)?"
  },
  {
    "objectID": "courses/caio/01-intro.html#bayes-rule",
    "href": "courses/caio/01-intro.html#bayes-rule",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Bayes Rule",
    "text": "Bayes Rule\nThe computation of \\(P(x \\mid y)\\) from \\(P(x)\\) and \\(P(y \\mid x)\\) is called Bayes theorem: \\[\nP(x \\mid y) = \\frac{P(y,x)}{P(y)} = \\frac{P(y\\mid x)p(x)}{p(y)}\n\\]\nThis shows now the conditional distribution is related to the joint and marginal distributions.\nYou’ll be given all the quantities on the r.h.s."
  },
  {
    "objectID": "courses/caio/01-intro.html#bayes-rule-1",
    "href": "courses/caio/01-intro.html#bayes-rule-1",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Bayes Rule",
    "text": "Bayes Rule\nKey fact: \\(P(x \\mid y)\\) is generally different from \\(P(y \\mid x)\\)!\nExample: Most people would agree\n\\[\\begin{align*}\nPr  & \\left ( Practice \\; hard  \\mid  Play \\; in \\; NBA \\right ) \\approx  1\\\\\nPr  & \\left ( Play \\; in \\; NBA  \\mid  Practice \\; hard  \\right ) \\approx  0\n\\end{align*}\\]\nThe main reason for the difference is that \\(P( Play \\; in \\; NBA ) \\approx 0\\)."
  },
  {
    "objectID": "courses/caio/01-intro.html#independence",
    "href": "courses/caio/01-intro.html#independence",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Independence",
    "text": "Independence\nTwo random variable \\(X\\) and \\(Y\\) are independent if \\[\nP(Y = y  \\mid X = x) = P (Y = y)\n\\] for all possible \\(x\\) and \\(y\\) values. Knowing \\(X=x\\) tells you nothing about \\(Y\\)!\nExample: Tossing a coin twice. What’s the probability of getting \\(H\\) in the second toss given we saw a \\(T\\) in the first one?"
  },
  {
    "objectID": "courses/caio/01-intro.html#sally-clark-case-independence-or-bayes",
    "href": "courses/caio/01-intro.html#sally-clark-case-independence-or-bayes",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Sally Clark Case: Independence or Bayes?",
    "text": "Sally Clark Case: Independence or Bayes?\nSally Clark was accused and convicted of killing her two children\nThey could have both died of SIDS.\n\nThe chance of a family which are non-smokers and over 25 having a SIDS death is around 1 in 8,500.\nThe chance of a family which has already had a SIDS death having a second is around 1 in 100.\nThe chance of a mother killing her two children is around 1 in 1,000,000."
  },
  {
    "objectID": "courses/caio/01-intro.html#bayes-or-independence",
    "href": "courses/caio/01-intro.html#bayes-or-independence",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Bayes or Independence",
    "text": "Bayes or Independence\n\nUnder Bayes \\[\\begin{align*}\nP \\left(  \\mathrm{both} \\; \\; \\mathrm{SIDS} \\right)   &  = P \\left(\n\\mathrm{first} \\; \\mathrm{SIDS} \\right)  P \\left(  \\mathrm{Second} \\; \\;\n\\mathrm{SIDS} | \\mathrm{first} \\; \\mathrm{SIDS} \\right) \\\\\n&  = \\frac{1}{8500} \\cdot \\frac{1}{100} = \\frac{1}{850,000}\n\\end{align*}\\]\n\nThe \\(\\frac{1}{100}\\) comes from taking into account genetics.\n\nIndependence, as the court did, gets you\n\n\\[\nP \\left(  \\mathrm{both} \\; \\; \\mathrm{SIDS} \\right)  = (1/8500) (1/8500) = (1/73,000,000)\n\\]\n\nBy Bayes rule\n\n\\[\n\\frac{p(I|E)}{p(G|E)} = \\frac{P( E \\cap I)}{P( E \\cap G)}\n\\] \\(P( E \\cap I) = P(E|I )P(I)\\) needs discussion of \\(p(I)\\)."
  },
  {
    "objectID": "courses/caio/01-intro.html#random-variables-expectation-ex",
    "href": "courses/caio/01-intro.html#random-variables-expectation-ex",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Random Variables: Expectation \\(E(X)\\)",
    "text": "Random Variables: Expectation \\(E(X)\\)\nThe expected value of a random variable is simply a weighted average of the possible values X can assume.\nThe weights are the probabilities of occurrence of those values.\n\\[E(X) = \\sum_x xP(X=x)\\]\nWith \\(n\\) equally likely outcomes with values \\(x_1, \\ldots, x_n\\), \\(P(X = x_i) = 1/n\\)\n\\[E(X) = \\frac{x_1+x_2+\\ldots+x_n}{n}\\]"
  },
  {
    "objectID": "courses/caio/01-intro.html#roulette-expectation",
    "href": "courses/caio/01-intro.html#roulette-expectation",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Roulette Expectation",
    "text": "Roulette Expectation\n\nEuropean Odds: 36 numbers (red/black) + zero\nYou bet $1 on 11 Black (pays 35 to 1)\n\\(X\\) is the return on this bet\n\n\\[E(X) = \\frac{1}{37}\\times 36 + \\frac{36}{37}\\times 0 = 0.97\\]\n\nIf you bet $1 on Black (pays 1 to 1)\n\n\\[E(X) = \\frac{18}{37}\\times 2 + \\frac{19}{37}\\times 0 = 0.97\\]\nCasino is guaranteed to make money in the long run!"
  },
  {
    "objectID": "courses/caio/01-intro.html#standard-deviation-sdx-and-variance-varx",
    "href": "courses/caio/01-intro.html#standard-deviation-sdx-and-variance-varx",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Standard Deviation \\(sd(X)\\) and Variance \\(Var(X)\\)",
    "text": "Standard Deviation \\(sd(X)\\) and Variance \\(Var(X)\\)\nThe variance is calculated as\n\\[Var(X) = E\\left((X - E(X))^2\\right)\\]\nA simpler calculation is \\(Var(X) = E(X^2) - E(X)^2\\).\nThe standard deviation is the square-root of variance.\n\\[sd(X) = \\sqrt{Var(X)}\\]"
  },
  {
    "objectID": "courses/caio/01-intro.html#roulette-variance",
    "href": "courses/caio/01-intro.html#roulette-variance",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Roulette Variance",
    "text": "Roulette Variance\n\nEuropean Odds: 36 numbers (red/black) + zero\nYou bet $1 on 11 Black (pays 35 to 1)\n\\(X\\) is the return on this bet\n\n\\[Var(X) = \\frac{1}{37}\\times (36 - 0.97)^2 + \\frac{36}{37}\\times (0 - 0.97)^2 = 34\\]\n\nIf you bet $1 on Black (pays 1 to 1)\n\n\\[Var(X) = \\frac{18}{37}\\times (2 - 0.97)^2+ \\frac{19}{37}\\times (0- 0.97)^2 = 1\\]\nIf your goal is to spend as much time as possible in the casino (free drinks): place small bets on black/red"
  },
  {
    "objectID": "courses/caio/01-intro.html#example-ex-and-varx",
    "href": "courses/caio/01-intro.html#example-ex-and-varx",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Example: \\(E(X)\\) and \\(Var(X)\\)",
    "text": "Example: \\(E(X)\\) and \\(Var(X)\\)\nTortoise and Hare are selling cars. Probability distributions, means and variances for \\(X\\), the number of cars sold\n\n\n\n\n0\n1\n2\n3\nMean\nVariance\nsd\n\n\n\n\ncars sold\n\n\\(X\\)\n\n\n\\(E(X)\\)\n\\(Var(X)\\)\n\\(\\sqrt{Var(X)}\\)\n\n\nTortoise\n0\n0.5\n0.5\n0\n1.5\n0.25\n0.5\n\n\nHare\n0.5\n0\n0\n0.5\n1.5\n2.25\n1.5"
  },
  {
    "objectID": "courses/caio/01-intro.html#expectation-and-variance-calculations",
    "href": "courses/caio/01-intro.html#expectation-and-variance-calculations",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Expectation and Variance Calculations",
    "text": "Expectation and Variance Calculations\nLet’s do Tortoise expectations and variances\n\nThe Tortoise \\[\\begin{align*}\nE(T) &= (1/2)(1) + (1/2)(2) = 1.5 \\\\\nVar(T) &= E(T^2) - E(T)^2 \\\\\n     &= (1/2)(1)^2 + (1/2)(2)^2 - (1.5)^2 = 0.25\n\\end{align*}\\]\nNow the Hare’s \\[\\begin{align*}\nE(H) &= (1/2)(0) + (1/2)(3) = 1.5 \\\\\nVar(H) &= (1/2)(0)^2 + (1/2)(3)^2- (1.5)^2 = 2.25\n\\end{align*}\\]"
  },
  {
    "objectID": "courses/caio/01-intro.html#expectation-and-variance-interpretation",
    "href": "courses/caio/01-intro.html#expectation-and-variance-interpretation",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Expectation and Variance Interpretation",
    "text": "Expectation and Variance Interpretation\nWhat do these tell us above the long run behavior?\n\nTortoise and Hare have the same expected number of cars sold.\nTortoise is more predictable than Hare. He has a smaller variance The standard deviations \\(\\sqrt{Var(X)}\\) are \\(0.5\\) and \\(1.5\\), respectively\nGiven two equal means, you always want to pick the lower variance."
  },
  {
    "objectID": "courses/caio/01-intro.html#linear-combinations-of-random-variables",
    "href": "courses/caio/01-intro.html#linear-combinations-of-random-variables",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Linear Combinations of Random Variables",
    "text": "Linear Combinations of Random Variables\nTwo key properties:\nLet \\(a, b\\) be given constants\n\nExpectations and Variances \\[\\begin{align*}\nE(aX + bY) &= a E(X) + b E(Y) \\\\\nVar(aX + bY) &= a^2 Var(X) + b^2 Var(Y) + 2 ab Cov(X,Y)\n\\end{align*}\\]\n\nwhere \\(Cov(X,Y)\\) is the covariance between random variables."
  },
  {
    "objectID": "courses/caio/01-intro.html#tortoise-and-hare-portfolio",
    "href": "courses/caio/01-intro.html#tortoise-and-hare-portfolio",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Tortoise and Hare Portfolio",
    "text": "Tortoise and Hare Portfolio\nWhat about Tortoise and Hare? We need to know \\(Cov(\\text{Tortoise, Hare})\\). Let’s take \\(Cov(T,H) = -1\\) and see what happens\nSuppose \\(a = \\frac{1}{2}, b= \\frac{1}{2}\\) Expectation and Variance\n\\[\\begin{align*}\nE\\left(\\frac{1}{2} T + \\frac{1}{2} H\\right) &= \\frac{1}{2} E(T) + \\frac{1}{2} E(H) = \\frac{1}{2} \\times 1.5 + \\frac{1}{2} \\times 1.5 = 1.5 \\\\\nVar\\left(\\frac{1}{2} T + \\frac{1}{2} H\\right) &= \\frac{1}{4} 0.25 + \\frac{1}{4} 2.25 - 2 \\frac{1}{2} \\frac{1}{2} = 0.625 - 0.5 = 0.125\n\\end{align*}\\]\nMuch lower!"
  },
  {
    "objectID": "courses/caio/01-intro.html#personalization-conditional-probability",
    "href": "courses/caio/01-intro.html#personalization-conditional-probability",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "“Personalization\" \\(=\\)”Conditional Probability\"",
    "text": "“Personalization\" \\(=\\)”Conditional Probability\"\n\nConditional probability is how AI systems express judgments in a way that reflects their partial knowledge.\nPersonalization runs on conditional probabilities, all of which must be estimated from massive data sets in which you are the conditioning event.\n\n Many Business Applications!! Suggestions vs Search…."
  },
  {
    "objectID": "courses/caio/01-intro.html#bayess-rule-in-medical-diagnostics",
    "href": "courses/caio/01-intro.html#bayess-rule-in-medical-diagnostics",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Bayes’s Rule in Medical Diagnostics",
    "text": "Bayes’s Rule in Medical Diagnostics\nAlice is a 40-year-old women, what is the chance that she really has breast cancer when she gets positive mammogram result, given the conditions:\n\nThe prevalence of breast cancer among people like Alice is 1%.\nThe test has an 80% detection rate.\nThe test has a 10% false-positive rate.\n\nThe posterior probability \\(P(\\text{cancer} \\mid \\text{positive mammogram})\\)?"
  },
  {
    "objectID": "courses/caio/01-intro.html#medical-diagnostics---visualization",
    "href": "courses/caio/01-intro.html#medical-diagnostics---visualization",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Medical Diagnostics - Visualization",
    "text": "Medical Diagnostics - Visualization\n\n\n\n\n\nMedical Screening\n\n\n\nOf 1000 cases:\n\n108 positive mammograms. 8 are true positives. The remaining 100 are false positives.\n892 negative mammograms. 2 are false negatives. The other 890 are true negatives."
  },
  {
    "objectID": "courses/caio/01-intro.html#personalization-conditional-probability-1",
    "href": "courses/caio/01-intro.html#personalization-conditional-probability-1",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "“Personalization” = “Conditional Probability”",
    "text": "“Personalization” = “Conditional Probability”\nConditional probability is how AI systems express judgments in a way that reflects their partial knowledge.\nPersonalization runs on conditional probabilities, all of which must be estimated from massive data sets in which you are the conditioning event.\nMany Business Applications!! Suggestions vs Search, …."
  },
  {
    "objectID": "courses/caio/01-intro.html#how-does-netflix-give-recommendations",
    "href": "courses/caio/01-intro.html#how-does-netflix-give-recommendations",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "How does Netflix Give Recommendations?",
    "text": "How does Netflix Give Recommendations?\nWill a subscriber like Saving Private Ryan, given that he or she liked the HBO series Band of Brothers?\nBoth are epic dramas about the Normandy invasion and its aftermath.\n100 people in your database, and every one of them has seen both films.\nTheir viewing histories come in the form of a big “ratings matrix”.\n\n\n\n\nLiked Band of Brothers\nDidn’t like it\n\n\n\n\nLiked Saving Private Ryan\n56 subscribers\n6 subscribers\n\n\nDidn’t like it\n14 subscribers\n24 subscribers\n\n\n\n\\[P(\\text{likes Saving Private Ryan} \\mid \\text{likes Band of Brothers})=\\frac{56}{56+14}=80\\%\\]"
  },
  {
    "objectID": "courses/caio/01-intro.html#how-does-netflix-give-recommendations---complexity",
    "href": "courses/caio/01-intro.html#how-does-netflix-give-recommendations---complexity",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "How does Netflix Give Recommendations? - Complexity",
    "text": "How does Netflix Give Recommendations? - Complexity\nBut real problem is much more complicated:\n\nScale. It has 100 million subscribers and ratings data on more than 10,000 shows. The ratings matrix has more than a trillion possible entries.\n“Missingness”. Most subscribers haven’t watched most films. Moreover, missingness pattern is informative.\nCombinatorial explosion. In a database with 10,000 films, no one else’s history is exactly the same as yours.\n\nThe solution to all three issues is careful modeling."
  },
  {
    "objectID": "courses/caio/01-intro.html#how-does-netflix-give-recommendations---fundamental-equation",
    "href": "courses/caio/01-intro.html#how-does-netflix-give-recommendations---fundamental-equation",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "How does Netflix Give Recommendations? - Fundamental Equation",
    "text": "How does Netflix Give Recommendations? - Fundamental Equation\nThe fundamental equation is: \\[\\text{Predicted Rating} =\\text{Overall Average} + \\text{Film Offset} + \\text{User Offset} + \\text{User-Film Interaction}\\]\nThese three terms provide a baseline for a given user/film pair:\n\nThe overall average rating across all films is 3.7.\nEvery film has its own offset. Popular movies have positive offsets.\nEvery user has an offset. Some users are more or less critical than average."
  },
  {
    "objectID": "courses/caio/01-intro.html#netflix---latent-features",
    "href": "courses/caio/01-intro.html#netflix---latent-features",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Netflix - Latent Features",
    "text": "Netflix - Latent Features\n\nThe User-Film Interaction is calculated based on a person’s ratings of similar films exhibit patterns because those ratings are all associated with a latent feature of that person.\nThere’s not just one latent feature to describe Netflix subscribers, but dozens or even hundreds. There’s a “British murder mystery” feature, a “gritty character-driven crime drama” feature, a “cooking show” feature, a “hipster comedy films” feature, …"
  },
  {
    "objectID": "courses/caio/01-intro.html#the-hidden-features-tell-the-story",
    "href": "courses/caio/01-intro.html#the-hidden-features-tell-the-story",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "The Hidden Features Tell the Story",
    "text": "The Hidden Features Tell the Story\n\nThese latent features are the magic elixir of the digital economy–a special brew of data, algorithms, and human insight that represents the most perfect tool ever conceived for targeted marketing.\nYour precise combination of latent features–your tiny little corner of a giant multidimensional Euclidean space–makes you a demographic of one.\nNetflix spent $130 million for 10 episodes on The Crown. Other network television: $400 million commissioning 113 pilots, of which 13 shows made it to a second season."
  },
  {
    "objectID": "courses/caio/02-ml.html#why-distributions-matter",
    "href": "courses/caio/02-ml.html#why-distributions-matter",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Why Distributions Matter",
    "text": "Why Distributions Matter\n\n\n\nMachine learning is built on probability\nDistributions describe uncertainty in data\nThree fundamental distributions:\n\nBinomial: Binary outcomes (yes/no, win/lose)\nPoisson: Count data (arrivals, events)\nNormal: Continuous measurements (heights, returns)\n\n\n\nWhy Should Executives Care?\n\n\n\nBusiness Question\nDistribution\n\n\n\n\nWill the customer buy?\nBinomial\n\n\nHow many orders today?\nPoisson\n\n\nWhat’s the forecast error?\nNormal\n\n\n\nChoosing the right distribution is the first step in building a reliable model. Wrong distribution = wrong predictions!"
  },
  {
    "objectID": "courses/caio/02-ml.html#binomial-distribution",
    "href": "courses/caio/02-ml.html#binomial-distribution",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\n\nModels the number of successes in \\(n\\) independent trials, each with probability \\(p\\)\n\\[P(X=k) = \\binom{n}{k} p^k(1-p)^{n-k}\\]\nKey Parameters:\n\n\\(n\\) = number of trials\n\\(p\\) = probability of success\nMean = \\(np\\)\nVariance = \\(np(1-p)\\)\n\nExamples: A/B test conversions, click-through rates, quality defects"
  },
  {
    "objectID": "courses/caio/02-ml.html#nfl-patriots-coin-toss",
    "href": "courses/caio/02-ml.html#nfl-patriots-coin-toss",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "NFL Patriots Coin Toss",
    "text": "NFL Patriots Coin Toss\n\n\nThe Patriots won 19 out of 25 coin tosses in 2014-15. How likely?\n\nThere are 177,100 ways to arrange 19 wins in 25 games\nEach specific sequence has probability \\(0.5^{25}\\)\nCombined probability: 0.5% or odds of 199 to 1 against\n\n\n\nShow R code\n# \"25 choose 19\" = number of ways to pick 19 wins from 25 games\nchoose(25, 19)\n\n\n[1] 177100\n\n\nShow R code\n# Probability = (ways to get 19 wins) × (probability of any specific sequence)\nchoose(25, 19) * 0.5^25\n\n\n[1] 0.005277991\n\n\n\nThe “Law of Large Numbers” Perspective:\nWith 32 NFL teams over 20+ years, some team will have a suspicious streak!\nKey insight: Probability of Patriots specifically = 0.5%. But probability that some team has a streak ≈ much higher!\nBusiness lesson: When auditing for fraud or anomalies:\n\nDon’t just flag rare events\nConsider how many opportunities for rare events exist\nAdjust for “multiple comparisons”\n\nLooking at enough data, you’ll always find something “unusual”"
  },
  {
    "objectID": "courses/caio/02-ml.html#predicting-premier-league-goals",
    "href": "courses/caio/02-ml.html#predicting-premier-league-goals",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Predicting Premier League Goals",
    "text": "Predicting Premier League Goals\n\n\nHow many goals will a team score? Historical EPL data:\n\n\nShow R code\nepl &lt;- read.csv(\"data/epl.csv\")\nepl[1:5, c(\"home_team_name\", \"away_team_name\", \"home_score\", \"guest_score\")]\n\n\n  home_team_name       away_team_name home_score guest_score\n1        Arsenal            Liverpool          3           4\n2    Bournemouth    Manchester United          1           3\n3        Burnley              Swansea          0           1\n4        Chelsea             West Ham          2           1\n5 Crystal Palace West Bromwich Albion          0           1\n\n\nEach row = one match with final scores.\n\n\n\nThe Business Problem:\nSports betting: $200+ billion industry.\nOur approach:\n\nAnalyze historical data\nModel goals as random events\nEstimate team strengths\nSimulate matches\n\nWho uses this? FiveThirtyEight, ESPN, DraftKings, Betfair, team analytics"
  },
  {
    "objectID": "courses/caio/02-ml.html#epl-goals-mean-variance",
    "href": "courses/caio/02-ml.html#epl-goals-mean-variance",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "EPL Goals: Mean ≈ Variance",
    "text": "EPL Goals: Mean ≈ Variance\n\n\nA key signature of Poisson data: the mean equals the variance.\n\nTeams score about 1.4 goals per match on average\nThe variance is also ~1.4 — this is the Poisson fingerprint!\nIf variance were much larger, we’d need a different model\n\n\n\nShow R code\ngoals &lt;- c(epl$home_score, epl$guest_score)\nmean(goals)  # Average goals per team per match\n\n\n[1] 1.4\n\n\nShow R code\nvar(goals)   # Variance ≈ Mean suggests Poisson!\n\n\n[1] 1.644796\n\n\n\nModel Diagnostics: Mean vs Variance\n\n\n\nRelationship\nSuggests\n\n\n\n\nVariance ≈ Mean\nPoisson ✓\n\n\nVariance &gt; Mean\nOverdispersion (Negative Binomial)\n\n\nVariance &lt; Mean\nUnderdispersion (rare)\n\n\n\nOther Poisson Applications:\n\nCall center arrivals per hour\nWebsite clicks per minute\nInsurance claims per year\nManufacturing defects per batch\nEmails received per day\n\nPoisson is the “go-to” for count data!"
  },
  {
    "objectID": "courses/caio/02-ml.html#goals-follow-a-poisson-distribution",
    "href": "courses/caio/02-ml.html#goals-follow-a-poisson-distribution",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Goals Follow a Poisson Distribution",
    "text": "Goals Follow a Poisson Distribution\n\n\n\n\nShow R code\ngoals &lt;- c(epl$home_score, epl$guest_score)\nlambda &lt;- mean(goals)\nx &lt;- 0:8\nobserved &lt;- table(factor(goals, levels = x)) / length(goals)\nexpected &lt;- dpois(x, lambda = lambda)\n\nbarplot(rbind(observed, expected), beside = TRUE, \n        names.arg = x, col = c(\"steelblue\", \"coral\"),\n        xlab = \"Goals Scored\", ylab = \"Proportion\",\n        legend.text = c(\"Observed\", \"Poisson Model\"))\n\n\n\n\n\n\n\n\n\n\nModel Validation:\nThe Poisson model (coral bars) fits the observed data (blue bars) remarkably well!\nWhat this tells us:\n\nGoals are indeed rare, independent events\nThe Poisson assumption is justified\nWe can use this model for predictions\n\nSlight discrepancy at 0 goals: Real matches have slightly fewer 0-0 draws than Poisson predicts (teams try harder when level!)"
  },
  {
    "objectID": "courses/caio/02-ml.html#poisson-distribution",
    "href": "courses/caio/02-ml.html#poisson-distribution",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\n\n\nModels count of random events: goals, arrivals, defects, clicks\n\\[P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\]\n\n\\(\\lambda\\) (lambda): expected rate of events\nKey property: Mean = Variance = \\(\\lambda\\)\nEvents occur independently at a constant average rate\n\n\nBusiness Applications:\n\nCustomer arrivals per hour\nWebsite clicks per day\nManufacturing defects per batch\nInsurance claims per year\nServer requests per minute\n\nIf events are rare and independent, Poisson is your model!"
  },
  {
    "objectID": "courses/caio/02-ml.html#improving-the-model-team-strength",
    "href": "courses/caio/02-ml.html#improving-the-model-team-strength",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Improving the Model: Team Strength",
    "text": "Improving the Model: Team Strength\n\n\nA single \\(\\lambda\\) for all teams is too simple. Better model:\n\\[\\lambda_{ij} = \\text{Attack}_i \\times \\text{Defense}_j \\times \\text{HomeAdvantage}\\]\n\nAttack: How good is team \\(i\\) at scoring?\nDefense: How weak is team \\(j\\) at defending?\nHome advantage: ~0.4 extra goals at home\n\n\nThis is how real sports analytics works:\n\nEstimate each team’s offensive/defensive strength from historical data\nAdjust for home/away effects\nPredict expected goals for each team\nUse Poisson to generate win/draw/loss probabilities\n\nSame framework applies to:\n\nNBA point spreads\nNFL betting lines\nCricket run predictions\nBaseball run expectations"
  },
  {
    "objectID": "courses/caio/02-ml.html#team-specific-lambda-arsenal-vs-liverpool",
    "href": "courses/caio/02-ml.html#team-specific-lambda-arsenal-vs-liverpool",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Team-Specific \\(\\lambda\\): Arsenal vs Liverpool",
    "text": "Team-Specific \\(\\lambda\\): Arsenal vs Liverpool\nTo predict a specific match, we estimate each team’s scoring rate:\n\nArsenal’s attack: How many goals do they typically score at home?\nLiverpool’s defense: How many goals do they typically concede away?\nAdjustment: Scale by league average to get relative strength\n\nFor Arsenal vs Liverpool at home, we estimate Arsenal will score about 1.8 goals on average. Liverpool’s away \\(\\lambda\\) would be calculated similarly.\n\n\nShow R code\n# Simple estimate: average goals scored and conceded\narsenal_attack &lt;- mean(epl$home_score[epl$home_team_name == \"Arsenal\"])\nliverpool_defense &lt;- mean(epl$home_score[epl$away_team_name == \"Liverpool\"])\nleague_avg &lt;- mean(goals)\n\n# Arsenal's expected goals vs Liverpool (simplified)\nlambda_arsenal &lt;- arsenal_attack * (liverpool_defense / league_avg)\nlambda_arsenal\n\n\n[1] 1.851998"
  },
  {
    "objectID": "courses/caio/02-ml.html#monte-carlo-simulation",
    "href": "courses/caio/02-ml.html#monte-carlo-simulation",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Monte Carlo Simulation",
    "text": "Monte Carlo Simulation\nOnce we have \\(\\lambda\\) for each team, we can simulate the match thousands of times.\nFor Arsenal (\\(\\lambda=1.8\\)) vs Liverpool (\\(\\lambda=1.5\\)), running 10,000 simulations gives:\n\nArsenal wins: ~42% of simulations\nDraw: ~24% of simulations\n\nLiverpool wins: ~34% of simulations\n\nThis is how betting companies set their odds!\n\n\nShow R code\nset.seed(42)\nn_sims &lt;- 10000\n# Simulate Arsenal vs Liverpool\narsenal_goals &lt;- rpois(n_sims, lambda = 1.8)  # λ for Arsenal\nliverpool_goals &lt;- rpois(n_sims, lambda = 1.5) # λ for Liverpool\n\n# Match outcomes\nc(Arsenal_Win = mean(arsenal_goals &gt; liverpool_goals),\n  Draw = mean(arsenal_goals == liverpool_goals),\n  Liverpool_Win = mean(arsenal_goals &lt; liverpool_goals))\n\n\n  Arsenal_Win          Draw Liverpool_Win \n       0.4538        0.2254        0.3208"
  },
  {
    "objectID": "courses/caio/02-ml.html#why-monte-carlo",
    "href": "courses/caio/02-ml.html#why-monte-carlo",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Why Monte Carlo?",
    "text": "Why Monte Carlo?\n\n\nEach simulation draws random goals from Poisson distributions\n\nRun 10,000 simulations → get probability of each outcome\nCan extend to simulate entire season, league standings\nSame approach used by betting companies and analytics firms\n\nThis is how FiveThirtyEight and bookmakers build their models!\n\nMonte Carlo Applications:\n\nFinance: Option pricing, portfolio risk (VaR)\nInsurance: Claim projections, reserve calculations\nOperations: Supply chain uncertainty, demand forecasting\nEngineering: Reliability analysis, quality control\nAI: Reinforcement learning, MCMC for Bayesian inference\n\nWhen math is too hard, simulate!"
  },
  {
    "objectID": "courses/caio/02-ml.html#central-limit-theorem-clt",
    "href": "courses/caio/02-ml.html#central-limit-theorem-clt",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Central Limit Theorem (CLT)",
    "text": "Central Limit Theorem (CLT)\n\n\nThe most important theorem in statistics:\n\nThe average of many independent random events tends toward a Normal distribution, regardless of the original distribution.\n\nWhy it matters: Stock returns, measurement errors, test scores — all tend to be Normal because they’re sums of many small effects.\n\nPractical Implications:\n\nSample means are approximately Normal (even if data isn’t)\nConfidence intervals work because of CLT\nA/B testing relies on CLT for significance tests\nQuality control uses CLT for process monitoring\n\nRule of thumb: Sample size ≥ 30 usually sufficient for CLT to kick in\nThis is why the Normal distribution is everywhere!"
  },
  {
    "objectID": "courses/caio/02-ml.html#clt-in-action-michigan-election-polls",
    "href": "courses/caio/02-ml.html#clt-in-action-michigan-election-polls",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "CLT in Action: Michigan Election Polls",
    "text": "CLT in Action: Michigan Election Polls\nSuppose the true vote share in Michigan is 51%. What happens when we poll voters?\n\nEach voter is like a coin flip (vote A or B)\nSmall samples are noisy; large samples converge to the truth\nThe distribution of poll results becomes Normal\n\n\nShow R code\nset.seed(42)\ntrue_p &lt;- 0.51\n# Poll of 10 voters\nhist(replicate(1000, mean(rbinom(10, 1, true_p))), breaks = 20,\n     main = \"Poll: 10 Voters\", xlab = \"Vote Share\", col = \"steelblue\", \n     freq = FALSE, xlim = c(0.2, 0.8))\nabline(v = true_p, col = \"red\", lwd = 2, lty = 2)\n# Poll of 100 voters\nhist(replicate(1000, mean(rbinom(100, 1, true_p))), breaks = 20,\n     main = \"Poll: 100 Voters\", xlab = \"Vote Share\", col = \"steelblue\", \n     freq = FALSE, xlim = c(0.2, 0.8))\nabline(v = true_p, col = \"red\", lwd = 2, lty = 2)\n# Poll of 1000 voters\nhist(replicate(1000, mean(rbinom(1000, 1, true_p))), breaks = 20,\n     main = \"Poll: 1000 Voters\", xlab = \"Vote Share\", col = \"steelblue\", \n     freq = FALSE, xlim = c(0.2, 0.8))\nabline(v = true_p, col = \"red\", lwd = 2, lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarger samples → tighter Normal distribution around the true value (red line)"
  },
  {
    "objectID": "courses/caio/02-ml.html#normal-distribution",
    "href": "courses/caio/02-ml.html#normal-distribution",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Normal Distribution",
    "text": "Normal Distribution\n\n\nThe “bell curve” — the most important distribution in statistics\nThe 68-95-99.7 Rule:\n\n68% of data within 1 standard deviation\n95% of data within 2 standard deviations\n99.7% of data within 3 standard deviations\n\nWhy it’s everywhere: Central Limit Theorem guarantees that averages of many random events become Normal\nApplications: Quality control, financial risk, test scores, measurement error"
  },
  {
    "objectID": "courses/caio/02-ml.html#normal-heights-of-adults",
    "href": "courses/caio/02-ml.html#normal-heights-of-adults",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Normal: Heights of Adults",
    "text": "Normal: Heights of Adults\n\n\nMale heights follow a Normal distribution: mean = 70 inches, sd = 3 inches\n\n68% of men are between 67-73 inches (within 1 sd)\nThe 95th percentile is about 75 inches — only 5% are taller\n\n\n\nShow R code\n# What proportion are between 67 and 73 inches (+/- 1 sd)?\npnorm(73, mean = 70, sd = 3) - pnorm(67, mean = 70, sd = 3)\n\n\n[1] 0.6826895\n\n\nShow R code\n# What height is taller than 95% of men?\nqnorm(0.95, mean = 70, sd = 3)\n\n\n[1] 74.93456\n\n\n\nR Functions for Normal Distribution:\n\n\n\nFunction\nPurpose\nExample\n\n\n\n\npnorm()\nProbability ≤ x\nP(height ≤ 73)\n\n\nqnorm()\nFind percentile\n95th percentile\n\n\ndnorm()\nDensity at x\nHeight of curve\n\n\nrnorm()\nRandom samples\nSimulate data\n\n\n\nBusiness Applications:\n\nSetting size ranges for products\nEstablishing “normal” ranges for KPIs\nIdentifying outliers (&gt; 2-3 sd)\nQuality control limits"
  },
  {
    "objectID": "courses/caio/02-ml.html#the-1987-stock-market-crash-a-5-sigma-event",
    "href": "courses/caio/02-ml.html#the-1987-stock-market-crash-a-5-sigma-event",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "The 1987 Stock Market Crash: A 5-Sigma Event",
    "text": "The 1987 Stock Market Crash: A 5-Sigma Event\nHow extreme was the October 1987 crash of -21.76%?\n\nPrior to crash: \\(\\mu = 1.2\\%\\), \\(\\sigma = 4.3\\%\\) → Z-score = \\(\\frac{-21.76 - 1.2}{4.3} = -5.34\\)\nUnder Normal model: probability = 1 in 20 million (once every 130,000 years!)\nYet 5+ sigma events happened in 1987, 2008, and 2020\n\nConclusion: The model is wrong — stock returns have “fat tails.” Banks using Normal-based VaR dramatically underestimate risk.\n\n\nShow R code\npnorm(-5.34)  # Probability of -5.34 sigma event\n\n\n[1] 4.647329e-08"
  },
  {
    "objectID": "courses/caio/02-ml.html#fat-tails-reality-vs-normal-model",
    "href": "courses/caio/02-ml.html#fat-tails-reality-vs-normal-model",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Fat Tails: Reality vs Normal Model",
    "text": "Fat Tails: Reality vs Normal Model\n\n\n\n\n\n\n\n\nThe Problem with Normal Assumptions:\nStock returns have more extreme events than the Normal distribution predicts.\n\n\n\nEvent\nNormal Probability\nActually Happened\n\n\n\n\n1987 Crash (-22%)\n1 in \\(10^{160}\\)\nYes\n\n\n2008 Crisis\n“Impossible”\nYes\n\n\n2020 COVID Crash\n“Impossible”\nYes\n\n\n\nImplications for Risk Management:\n\nVaR models underestimate tail risk\nNeed “fat-tailed” distributions (t-distribution, etc.)\nStress testing is essential"
  },
  {
    "objectID": "courses/caio/02-ml.html#what-is-regression",
    "href": "courses/caio/02-ml.html#what-is-regression",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "What is Regression?",
    "text": "What is Regression?\n\n\nFinding the relationship between variables\n\\[y = \\beta_0 + \\beta_1 x + \\epsilon\\]\n\n\\(\\beta_0\\): intercept (baseline value)\n\\(\\beta_1\\): slope (change in \\(y\\) per unit change in \\(x\\))\n\\(\\epsilon\\): unexplained variation\n\nGoal: Minimize sum of squared prediction errors\n\nBusiness Questions Regression Answers:\n\nHow much does price affect sales?\nWhat’s the ROI of advertising spend?\nHow does experience affect salary?\nWhat drives customer lifetime value?\nHow does weather affect demand?\n\nRegression quantifies relationships and enables prediction."
  },
  {
    "objectID": "courses/caio/02-ml.html#simple-example-house-prices",
    "href": "courses/caio/02-ml.html#simple-example-house-prices",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Simple Example: House Prices",
    "text": "Simple Example: House Prices\n\n\nUsing Saratoga County housing data, we fit a model:\nPrice = f(Living Area)\n\nIntercept: Base price of ~$13,000 (land value)\nSlope: Each additional square foot adds ~$113 to the price\n\nA 2,000 sq ft house: $13K + (2000 × $113) = $239,000\n\n\nShow R code\nd &lt;- read.csv(\"data/SaratogaHouses.csv\")\nmodel &lt;- lm(price ~ livingArea, data = d)\ncoef(model)\n\n\n(Intercept)  livingArea \n 13439.3940    113.1225 \n\n\n\nInterpreting Coefficients:\n\n\n\nCoefficient\nMeaning\n\n\n\n\nIntercept ($13K)\nValue of land without house\n\n\nSlope ($113/sqft)\nPrice increase per sqft\n\n\n\nMaking Predictions:\n\\[\\text{Price} = 13,439 + 113 \\times \\text{SqFt}\\]\n\n\n\nHouse Size\nPredicted Price\n\n\n\n\n1,500 sqft\n$183,000\n\n\n2,500 sqft\n$296,000\n\n\n3,500 sqft\n$409,000"
  },
  {
    "objectID": "courses/caio/02-ml.html#visualizing-the-fit",
    "href": "courses/caio/02-ml.html#visualizing-the-fit",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Visualizing the Fit",
    "text": "Visualizing the Fit\n\n\n\n\n\n\n\n\n\n\n\n\nWhat the plot shows:\n\nEach blue dot is a house\nThe red line is our prediction\nVertical distance from dot to line = prediction error\n\nKey observations:\n\nStrong positive relationship\nMore scatter at higher prices (heteroskedasticity)\nSome outliers (expensive small houses, cheap large houses)\n\nThe line minimizes the sum of squared vertical distances"
  },
  {
    "objectID": "courses/caio/02-ml.html#google-vs-sp-500-capm",
    "href": "courses/caio/02-ml.html#google-vs-sp-500-capm",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Google vs S&P 500 (CAPM)",
    "text": "Google vs S&P 500 (CAPM)\nThe Capital Asset Pricing Model (CAPM) asks: Does a stock follow the market or beat it?\n\\[\\text{Google Return} = \\alpha + \\beta \\times \\text{Market Return}\\]\n\n\\(\\beta\\) (beta): How volatile is the stock relative to the market?\n\\(\\alpha\\) (alpha): Does the stock outperform after adjusting for risk?\n\n\n\nShow R code\nlibrary(quantmod)\ngetSymbols(c(\"GOOG\", \"SPY\"), from = \"2017-01-01\", to = \"2023-12-31\") |&gt; invisible()\ngoog &lt;- as.numeric(dailyReturn(GOOG))\nspy &lt;- as.numeric(dailyReturn(SPY))\nmodel &lt;- lm(goog ~ spy)\nprint(model)\n\n\n\nCall:\nlm(formula = goog ~ spy)\n\nCoefficients:\n(Intercept)          spy  \n  0.0003211    1.1705808"
  },
  {
    "objectID": "courses/caio/02-ml.html#google-vs-sp-500-capm-results",
    "href": "courses/caio/02-ml.html#google-vs-sp-500-capm-results",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Google vs S&P 500: CAPM Results",
    "text": "Google vs S&P 500: CAPM Results\n\n\n\n\n\n\n\n\n\n\n\n\nOur Findings:\n\nBeta (\\(\\beta = 1.01\\)): Google moves 1:1 with market\nAlpha (\\(\\alpha \\approx 0\\)): No significant outperformance (\\(p = 0.06\\))\n\n\n\n\nBeta      \nInterpretation\n\n\n\n\n\\(\\beta &lt; 1\\)\nLess volatile (utilities, healthcare)\n\n\n\\(\\beta = 1\\)\nMoves with market (index funds)\n\n\n\\(\\beta &gt; 1\\)\nMore volatile (tech, small caps)\n\n\n\nConclusion: Google tracked the market without consistent alpha in 2017-2023. High beta = higher risk, potentially higher reward."
  },
  {
    "objectID": "courses/caio/02-ml.html#orange-juice-price-advertising",
    "href": "courses/caio/02-ml.html#orange-juice-price-advertising",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Orange Juice: Price & Advertising",
    "text": "Orange Juice: Price & Advertising\nHow does advertising affect price sensitivity? We model sales as a function of price and whether the product was featured in ads.\nKey finding: The interaction term (log(price):feat) is negative and significant — advertising changes how customers respond to price!\n\n\nShow R code\noj &lt;- read.csv(\"data/oj.csv\")\nmodel &lt;- lm(logmove ~ log(price) * feat, data = oj)\ntidy(model) |&gt; select(term, estimate, p.value) |&gt; kable(digits = 3)\n\n\n\n\n\nterm\nestimate\np.value\n\n\n\n\n(Intercept)\n9.659\n0\n\n\nlog(price)\n-0.958\n0\n\n\nfeat\n1.714\n0\n\n\nlog(price):feat\n-0.977\n0"
  },
  {
    "objectID": "courses/caio/02-ml.html#the-advertising-paradox",
    "href": "courses/caio/02-ml.html#the-advertising-paradox",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "The Advertising Paradox",
    "text": "The Advertising Paradox\n\n\nFinding: Advertising increases price sensitivity\n\n\n\nCondition\nPrice Elasticity\n\n\n\n\nNo advertising\n-0.96\n\n\nWith advertising\n-0.96 + (-0.98) = -1.94\n\n\n\nWhy? Ads coincide with promotions → attract price-sensitive shoppers\n\nKey Lessons:\n\nCorrelation ≠ Causation: Ads don’t cause sensitivity; they coincide with promotions\nSelection effects: Who responds to ads? Price hunters!\nConfounding variables: Promotions happen during ad campaigns\nManagerial insight: Don’t blame advertising for price sensitivity — it’s the promotion strategy\n\nAlways ask: What’s really driving the relationship?"
  },
  {
    "objectID": "courses/caio/02-ml.html#from-regression-to-classification",
    "href": "courses/caio/02-ml.html#from-regression-to-classification",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "From Regression to Classification",
    "text": "From Regression to Classification\n\n\nWhat if the outcome is yes/no?\n\\[P(y=1 \\mid x) = \\frac{1}{1 + e^{-\\beta^T x}}\\]\nWhy not just use linear regression?\n\nLinear regression can predict values &lt; 0 or &gt; 1\nProbabilities must be between 0 and 1\nLogistic function “squashes” any input to (0, 1)"
  },
  {
    "objectID": "courses/caio/02-ml.html#nba-point-spread-example",
    "href": "courses/caio/02-ml.html#nba-point-spread-example",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "NBA Point Spread Example",
    "text": "NBA Point Spread Example\nCan Vegas point spreads predict game outcomes? We fit a logistic regression using historical NBA data.\n\n\nShow R code\nNBA &lt;- read.csv(\"data/NBAspread.csv\")\nmodel &lt;- glm(favwin ~ spread - 1, family = binomial, data = NBA)\ntidy(model) |&gt; kable(digits = 3)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\nspread\n0.156\n0.014\n11.332\n0\n\n\n\n\n\nInterpretation: For each additional point in the spread, log-odds of favorite winning increases by 0.16. The p-value &lt; 0.001 confirms spreads are highly predictive."
  },
  {
    "objectID": "courses/caio/02-ml.html#making-predictions",
    "href": "courses/caio/02-ml.html#making-predictions",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Making Predictions",
    "text": "Making Predictions\nUsing our model, we can predict win probability for any point spread:\n\n\n\nSpread\nP(Favorite Wins)\n\n\n\n\n4 points\n65%\n\n\n8 points\n78%\n\n\n12 points\n87%\n\n\n\n\n\nShow R code\npredict(model, newdata = data.frame(spread = c(4, 8)), type = \"response\")\n\n\n        1         2 \n0.6511238 0.7769474 \n\n\nSame approach used for: credit scoring, churn prediction, marketing response, fraud detection — any binary outcome."
  },
  {
    "objectID": "courses/caio/02-ml.html#confusion-matrix",
    "href": "courses/caio/02-ml.html#confusion-matrix",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\n\n\nHow accurate is our model? The confusion matrix shows predictions vs. actual outcomes.\n\n\nShow R code\npred &lt;- predict(model, type = \"response\") &gt; 0.5\ntable(Actual = NBA$favwin, Predicted = as.integer(pred))\n\n\n      Predicted\nActual   1\n     0 131\n     1 422\n\n\nOur model achieves about 66% accuracy — better than a coin flip!\n\nReading the Matrix:\n\n\n\n\nPred: 0\nPred: 1\n\n\n\n\nActual: 0\nTN (correct!)\nFP (oops)\n\n\nActual: 1\nFN (oops)\nTP (correct!)\n\n\n\nSports Betting Reality:\n\n66% accuracy sounds good, but…\nVegas takes ~10% commission (“vig”)\nNeed ~52.4% accuracy just to break even\nEdge of 13.6% is excellent if it holds!\n\nBut past performance ≠ future results"
  },
  {
    "objectID": "courses/caio/02-ml.html#understanding-the-confusion-matrix",
    "href": "courses/caio/02-ml.html#understanding-the-confusion-matrix",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Understanding the Confusion Matrix",
    "text": "Understanding the Confusion Matrix\n\n\n\n\nPredicted: Win\nPredicted: Lose\n\n\n\n\nActual: Win\nTrue Positive (TP)\nFalse Negative (FN)\n\n\nActual: Lose\nFalse Positive (FP)\nTrue Negative (TN)\n\n\n\nKey Metrics:\n\nAccuracy = (TP + TN) / Total — overall correctness\nPrecision = TP / (TP + FP) — “Of predicted wins, how many were right?”\nRecall = TP / (TP + FN) — “Of actual wins, how many did we catch?”\n\nCaution: Accuracy can mislead! A spam filter predicting “not spam” for everything has 99% accuracy but catches zero spam. Choose metrics based on business costs."
  },
  {
    "objectID": "courses/caio/02-ml.html#roc-curve-the-trade-off",
    "href": "courses/caio/02-ml.html#roc-curve-the-trade-off",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "ROC Curve: The Trade-off",
    "text": "ROC Curve: The Trade-off\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding the ROC Curve:\n\nX-axis: False Positive Rate (false alarms)\nY-axis: True Positive Rate (catches)\nDiagonal: Random guessing (AUC = 0.5)\nUpper-left corner: Perfect classifier\n\nArea Under Curve (AUC):\n\n\n\nAUC\nModel Quality\n\n\n\n\n0.5\nRandom (useless)\n\n\n0.6-0.7\nPoor\n\n\n0.7-0.8\nFair\n\n\n0.8-0.9\nGood\n\n\n0.9+\nExcellent"
  },
  {
    "objectID": "courses/caio/02-ml.html#choosing-the-right-threshold",
    "href": "courses/caio/02-ml.html#choosing-the-right-threshold",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Choosing the Right Threshold",
    "text": "Choosing the Right Threshold\n\n\nThe optimal threshold depends on business costs:\n\nFraud detection: Low threshold (catch more fraud, accept false alarms)\nMedical screening: Low threshold (don’t miss disease)\nSpam filter: Higher threshold (don’t lose important emails)\n\nThere is no universal “correct” threshold\n\nFramework for Threshold Selection:\n\nQuantify costs: What’s the cost of FP vs FN?\nCalculate expected cost at each threshold\nChoose threshold that minimizes total expected cost\n\nExample — Credit Card Fraud:\n\nFalse Positive cost: $10 (customer inconvenience)\nFalse Negative cost: $500 (fraud loss)\nOptimal threshold: Much lower than 0.5!\n\nLet business economics guide your model decisions"
  },
  {
    "objectID": "courses/caio/02-ml.html#summary",
    "href": "courses/caio/02-ml.html#summary",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\nConcept\nKey Insight\n\n\n\n\nDistributions\nBinomial (binary), Poisson (counts), Normal (continuous)\n\n\nPoisson\nMean = Variance — the fingerprint of count data\n\n\nNormal\nCLT makes it universal for averages\n\n\nLinear Regression\nCoefficients = effect sizes\n\n\nLogistic Regression\nOutputs probabilities for classification\n\n\nROC/AUC\nTrade-off between false positives and false negatives\n\n\nThreshold\nBusiness costs should drive the choice\n\n\n\nStatistics is the science of decision-making under uncertainty"
  },
  {
    "objectID": "courses/caio/02-ml.html#supplemental-reading",
    "href": "courses/caio/02-ml.html#supplemental-reading",
    "title": "Chief AI Officer Program: ML Essentials",
    "section": "Supplemental Reading",
    "text": "Supplemental Reading\n\n\nOnline Articles:\n\nThe Surprising Power of Online Experiments - HBR\nMachine Learning, Explained - MIT Sloan\n\nKey Insight from HBR: A simple A/B test at Bing generated over $100M annually by testing a “low priority” idea\n\nBooks for Further Study:\n\nThe Signal and the Noise — Nate Silver\nThinking, Fast and Slow — Daniel Kahneman\nNaked Statistics — Charles Wheelan\nData Science for Business — Provost & Fawcett\n\nOnline Courses:\n\nAndrew Ng’s Machine Learning (Coursera)\nStatistical Learning (Stanford Online)\nFast.ai Practical Deep Learning"
  },
  {
    "objectID": "courses/caio/03-ai.html#the-language-challenge",
    "href": "courses/caio/03-ai.html#the-language-challenge",
    "title": "Modern AI",
    "section": "The Language Challenge",
    "text": "The Language Challenge\n\n“You shall know a word by the company it keeps.” — J.R. Firth (1957)\n\nLanguage poses unique challenges for AI:\n\nUnlike images (continuous pixels) or audio (waveforms), text is discrete symbols\nThe word “cat” is not inherently closer to “dog” than to “quantum”\nYet humans effortlessly recognize semantic similarities\n\nThe breakthrough: Represent words as vectors in continuous space where geometry encodes meaning."
  },
  {
    "objectID": "courses/caio/03-ai.html#from-symbols-to-vectors",
    "href": "courses/caio/03-ai.html#from-symbols-to-vectors",
    "title": "Modern AI",
    "section": "From Symbols to Vectors",
    "text": "From Symbols to Vectors\nThe Problem with One-Hot Encoding:\nEach word gets a unique vector with a single 1:\n\n“cat” → [0, 0, 1, 0, 0, …, 0]\n“dog” → [0, 1, 0, 0, 0, …, 0]\n\nProblem: Cosine similarity between any two words = 0\nNo notion of semantic similarity is captured!\nSolution: Learn dense vector representations where similar words are close together."
  },
  {
    "objectID": "courses/caio/03-ai.html#the-twenty-questions-intuition",
    "href": "courses/caio/03-ai.html#the-twenty-questions-intuition",
    "title": "Modern AI",
    "section": "The Twenty Questions Intuition",
    "text": "The Twenty Questions Intuition\nImagine playing Twenty Questions to identify words:\n\n\n\nQuestion\nBear\nDog\nCat\n\n\n\n\nIs it an animal?\n1\n1\n1\n\n\nIs it domestic?\n0\n1\n0.7\n\n\nLarger than human?\n0.8\n0.1\n0.01\n\n\nHas long tail?\n0\n0.6\n1\n\n\nIs it a predator?\n1\n0\n0.6\n\n\n\nEach word becomes a vector of answers. Similar words give similar answers → similar vectors!\nThis is the essence of word embeddings."
  },
  {
    "objectID": "courses/caio/03-ai.html#word2vec-learning-from-context",
    "href": "courses/caio/03-ai.html#word2vec-learning-from-context",
    "title": "Modern AI",
    "section": "Word2Vec: Learning from Context",
    "text": "Word2Vec: Learning from Context\nThe Distributional Hypothesis: Words appearing in similar contexts have similar meanings.\n\n\n\n\n\nflowchart LR\n    C1[\"The ___ sat on the mat\"]\n    C2[\"The ___ sat on the rug\"]\n    \n    Cat[\"cat\"] --&gt; C1\n    Dog[\"dog\"] --&gt; C2\n    \n    Cat --&gt; V[\"Similar Vectors!\"]\n    Dog --&gt; V\n    \n    style Cat fill:#e1f5fe,stroke:#1976d2\n    style Dog fill:#e1f5fe,stroke:#1976d2\n    style V fill:#c8e6c9,stroke:#2e7d32\n\n\n\n\n\n\nResult: Vector arithmetic captures analogies!\n\\[\\vec{king} - \\vec{man} + \\vec{woman} \\approx \\vec{queen}\\]"
  },
  {
    "objectID": "courses/caio/03-ai.html#word2vec-war-and-peace",
    "href": "courses/caio/03-ai.html#word2vec-war-and-peace",
    "title": "Modern AI",
    "section": "Word2Vec: War and Peace",
    "text": "Word2Vec: War and Peace\nTraining Word2Vec on Tolstoy’s War and Peace reveals thematic structure:\n\nWord2Vec embeddings from War and Peace, reduced to 2D via PCA"
  },
  {
    "objectID": "courses/caio/03-ai.html#war-and-peace-semantic-clusters",
    "href": "courses/caio/03-ai.html#war-and-peace-semantic-clusters",
    "title": "Modern AI",
    "section": "War and Peace: Semantic Clusters",
    "text": "War and Peace: Semantic Clusters\nThe Word2Vec visualization reveals meaningful semantic relationships:\n\n\n\nCluster\nWords\nInsight\n\n\n\n\nMilitary\nsoldier, regiment, battle, army\nWar domain\n\n\nSocial\nballroom, court, marriage\nPeace domain\n\n\nGovernment\nhistory, power, war\nPolitical themes\n\n\n\nKey observation: “Peace” sits between government and social domains — central to the narrative’s dual structure.\nBusiness applications: Netflix recommendations, Amazon suggestions, LinkedIn job matching, document search"
  },
  {
    "objectID": "courses/caio/03-ai.html#the-skip-gram-model",
    "href": "courses/caio/03-ai.html#the-skip-gram-model",
    "title": "Modern AI",
    "section": "The Skip-Gram Model",
    "text": "The Skip-Gram Model\nGiven a center word, predict surrounding context words:\n\n\n\n\n\nflowchart LR\n    A[loves] --&gt; B[the]\n    A --&gt; C[man]\n    A --&gt; D[his]\n    A --&gt; E[son]\n    \n    style A fill:#e1f5fe,stroke:#0277bd,stroke-width:2px\n    style B fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    style C fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    style E fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n\n\n\n\n\n\n\\[P(\\text{context} \\mid \\text{center}) = \\prod_{j} P(w_{j} \\mid w_{\\text{center}})\\]\nThe learned vectors capture semantic relationships because words with similar contexts get similar representations."
  },
  {
    "objectID": "courses/caio/03-ai.html#from-words-to-sentences-the-attention-revolution",
    "href": "courses/caio/03-ai.html#from-words-to-sentences-the-attention-revolution",
    "title": "Modern AI",
    "section": "From Words to Sentences: The Attention Revolution",
    "text": "From Words to Sentences: The Attention Revolution\nThe Problem: Static Embeddings\n\nThe word “bank” has one vector, whether it’s “river bank” or “investment bank.”\nThis conflation of senses creates an information bottleneck.\n\nThe Sequential Bottleneck (RNNs/LSTMs):\n\nProcessed text step-by-step (like reading through a straw).\nEarly information “vanished” as sentences grew longer.\nImpossible to parallelize effectively on modern GPUs.\n\nThe Breakthrough: Attention Mechanisms\n\nLet each word dynamically “attend” to all other words simultaneously.\nExample: “The trophy wouldn’t fit in the suitcase because it was too big.”\nSelf-attention identifies that “it” refers to “trophy” by looking at the whole sentence at once.\n\nResult: Contextual representations that change based on surrounding words."
  },
  {
    "objectID": "courses/caio/03-ai.html#the-attention-mechanism",
    "href": "courses/caio/03-ai.html#the-attention-mechanism",
    "title": "Modern AI",
    "section": "The Attention Mechanism",
    "text": "The Attention Mechanism\nThe Library Analogy (Query, Key, Value):\n\nQuery (Q): What am I looking for? (e.g., “subject of the sentence”)\nKey (K): What is in this book? (e.g., “noun”, “verb”, “adjective”)\nValue (V): What is the content of the book? (the actual meaning vector)\n\nThe Mathematical Operation:\n\nSimilarity: Compare the Query to all Keys using a dot product.\nScoring: Turn these scores into weights (probabilities) using Softmax.\nRetrieval: Take a weighted sum of the Values."
  },
  {
    "objectID": "courses/caio/03-ai.html#attention-qkv-interaction",
    "href": "courses/caio/03-ai.html#attention-qkv-interaction",
    "title": "Modern AI",
    "section": "Attention: QKV Interaction",
    "text": "Attention: QKV Interaction\n\n\n\n\n\nflowchart LR\n    k1[k1]\n    k2[k2]\n    km[km]\n    \n    Q[Query q] --&gt; a1[score1]\n    Q --&gt; a2[score2]\n    Q --&gt; am[scorem]\n    \n    k1 --&gt; a1\n    k2 --&gt; a2\n    km --&gt; am\n    \n    a1 -.-&gt; v1[v1]\n    a2 -.-&gt; v2[v2]\n    am -.-&gt; vm[vm]\n    \n    v1 --&gt; O[Output]\n    v2 --&gt; O\n    vm --&gt; O\n    \n    style Q fill:#e1f5fe,stroke:#0277bd\n    style O fill:#c8e6c9,stroke:#2e7d32\n\n\n\n\n\n\n\\[\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\\]"
  },
  {
    "objectID": "courses/caio/03-ai.html#attention-a-visual-example",
    "href": "courses/caio/03-ai.html#attention-a-visual-example",
    "title": "Modern AI",
    "section": "Attention: A Visual Example",
    "text": "Attention: A Visual Example\nFor “The trophy wouldn’t fit in the suitcase because it was too big”:\n\n\n\nWord\nAttention to “it”\n\n\n\n\ntrophy\n0.45\n\n\nsuitcase\n0.15\n\n\nfit\n0.12\n\n\nbig\n0.18\n\n\nother\n0.10\n\n\n\nThe model learns that “it” most likely refers to “trophy” by attending strongly to it!"
  },
  {
    "objectID": "courses/caio/03-ai.html#self-attention-vs-cross-attention",
    "href": "courses/caio/03-ai.html#self-attention-vs-cross-attention",
    "title": "Modern AI",
    "section": "Self-Attention vs Cross-Attention",
    "text": "Self-Attention vs Cross-Attention\n\n\nSelf-Attention:\n\n\n\n\n\nflowchart LR\n    w1[\"The\"] &lt;--&gt; w2[\"cat\"]\n    w2 &lt;--&gt; w3[\"sat\"]\n    w1 &lt;--&gt; w3\n    \n    style w1 fill:#e1f5fe,stroke:#1976d2\n    style w2 fill:#e1f5fe,stroke:#1976d2\n    style w3 fill:#e1f5fe,stroke:#1976d2\n\n\n\n\n\n\nGoal: Understand internal relationships. Used in: Encoders (BERT) and Decoders (GPT). Analogy: Rereading a sentence to find the subject.\n\nCross-Attention:\n\n\n\n\n\nflowchart LR\n    e1[\"The\"]\n    e2[\"cat\"]\n    d1[\"Le\"]\n    d2[\"chat\"]\n    \n    e1 --&gt; d1\n    e2 --&gt; d2\n    e1 -.-&gt; d2\n    e2 -.-&gt; d1\n    \n    style e1 fill:#e1f5fe,stroke:#1976d2\n    style e2 fill:#e1f5fe,stroke:#1976d2\n    style d1 fill:#c8e6c9,stroke:#2e7d32\n    style d2 fill:#c8e6c9,stroke:#2e7d32\n\n\n\n\n\n\nGoal: Link two different sequences. Used in: Translation models (T5). Analogy: Looking back at English while writing French."
  },
  {
    "objectID": "courses/caio/03-ai.html#the-transformer-architecture",
    "href": "courses/caio/03-ai.html#the-transformer-architecture",
    "title": "Modern AI",
    "section": "The Transformer Architecture",
    "text": "The Transformer Architecture\n\n\n\n\n\nflowchart LR\n    In[\"Input\"] --&gt; Tok[\"Token\"] --&gt; Emb[\"Embed\"] --&gt; Att[\"Attention\"] --&gt; FF[\"FeedForward\"] --&gt; Out[\"Output\"]\n    \n    style In fill:#e3f2fd,stroke:#1976d2\n    style Att fill:#fff3e0,stroke:#f57c00\n    style FF fill:#e8f5e9,stroke:#388e3c\n    style Out fill:#f3e5f5,stroke:#7b1fa2\n\n\n\n\n\n\nKey innovations:\n\nSelf-attention replaces recurrence → parallel processing\nPositional encoding preserves word order\nMulti-head attention captures different relationship types\nFeed-forward layers add nonlinear transformations"
  },
  {
    "objectID": "courses/caio/03-ai.html#why-transformers-won",
    "href": "courses/caio/03-ai.html#why-transformers-won",
    "title": "Modern AI",
    "section": "Why Transformers Won",
    "text": "Why Transformers Won\n\n\n\nProperty\nRNN/LSTM\nTransformer\n\n\n\n\nSequential processing\nYes (slow)\nNo (parallel)\n\n\nLong-range dependencies\nDifficult\nEasy\n\n\nTraining speed\nSlow\nFast\n\n\nScalability\nLimited\nExcellent\n\n\n\nTransformers scale with compute → the foundation of modern LLMs."
  },
  {
    "objectID": "courses/caio/03-ai.html#from-transformers-to-llms",
    "href": "courses/caio/03-ai.html#from-transformers-to-llms",
    "title": "Modern AI",
    "section": "From Transformers to LLMs",
    "text": "From Transformers to LLMs\nThe Scale Approach:\n\n\n\n\n\nflowchart LR\n    G1[\"GPT-1&lt;br/&gt;117M\"] --&gt; G2[\"GPT-2&lt;br/&gt;1.5B\"]\n    G2 --&gt; G3[\"GPT-3&lt;br/&gt;175B\"]\n    G3 --&gt; G4[\"GPT-4&lt;br/&gt;~1.8T\"]\n    \n    style G1 fill:#e3f2fd\n    style G2 fill:#bbdefb\n    style G3 fill:#90caf9\n    style G4 fill:#42a5f5\n\n\n\n\n\n\nEmergent capabilities appear at scale:\n\nChain-of-thought reasoning\nIn-context learning (few-shot)\nCode generation\nMulti-step planning"
  },
  {
    "objectID": "courses/caio/03-ai.html#how-llms-generate-text",
    "href": "courses/caio/03-ai.html#how-llms-generate-text",
    "title": "Modern AI",
    "section": "How LLMs Generate Text",
    "text": "How LLMs Generate Text\nLLMs are autoregressive: they predict the next token based on all previous tokens.\n\n\n\n\n\n\n\nflowchart LR\n    C[\"Context\"] --&gt; M[\"LLM\"]\n    M --&gt; P[\"Probabilities\"]\n    P --&gt; S[\"Sample\"]\n    S --&gt; T[\"Token\"]\n    T --&gt; |\"Append\"| C\n    \n    style C fill:#e3f2fd,stroke:#1976d2\n    style M fill:#fff3e0,stroke:#f57c00\n    style P fill:#e8f5e9,stroke:#388e3c\n    style T fill:#f3e5f5,stroke:#7b1fa2\n\n\n\n\n\n\nThe Generation Loop:\n\nProbabilities: Compute scores for the vocabulary.\nSampling: Select next word (via Temperature).\nAutoregression: Append and repeat.\n\n\nTemperature (\\(\\tau\\)):\n\n\n\n\\(\\tau\\)\nBehavior\n\n\n\n\n0\nDeterministic\n\n\n0.7\nBalanced\n\n\n1.0\nProbabilistic\n\n\n1.5\nCreative\n\n\n\nLower \\(\\tau\\) = Predictable Higher \\(\\tau\\) = Random"
  },
  {
    "objectID": "courses/caio/03-ai.html#why-we-need-randomness-the-obama-example",
    "href": "courses/caio/03-ai.html#why-we-need-randomness-the-obama-example",
    "title": "Modern AI",
    "section": "Why We Need Randomness: The Obama Example",
    "text": "Why We Need Randomness: The Obama Example\nPrompt: “The first African American president is Barack…”\n\nMost probable next token: “Obama” ✓\nAlso correct: “Hussein” (his middle name)\n\nA greedy strategy always picks “Obama” — but in formal documents, “Barack Hussein Obama” is preferred.\nTemperature &gt; 0 allows the model to explore alternatives that may better fit the context."
  },
  {
    "objectID": "courses/caio/03-ai.html#the-llm-lifecycle",
    "href": "courses/caio/03-ai.html#the-llm-lifecycle",
    "title": "Modern AI",
    "section": "The LLM Lifecycle",
    "text": "The LLM Lifecycle\n\n\n\n\n\nflowchart LR\n    D[Data Collection] --&gt; P[Pre-Training]\n    P --&gt; I[Instruction Tuning]\n    I --&gt; A[Alignment]\n    A --&gt; Dep[Deployment]\n    \n    style D fill:#e3f2fd,stroke:#1976d2\n    style P fill:#e8f5e9,stroke:#388e3c\n    style I fill:#fff3e0,stroke:#f57c00\n    style A fill:#fce4ec,stroke:#c2185b\n    style Dep fill:#f3e5f5,stroke:#7b1fa2\n\n\n\n\n\n\n\n\n\nStage\nPurpose\n\n\n\n\nData Collection\nCurate training corpus (quality &gt; quantity)\n\n\nPre-Training\nPredict next tokens on billions of sequences\n\n\nInstruction Tuning\nTeach the model to follow instructions\n\n\nAlignment\nEnsure behavior matches human values (RLHF)\n\n\nDeployment\nOptimize for latency, cost, safety"
  },
  {
    "objectID": "courses/caio/03-ai.html#alignment-why-it-matters",
    "href": "courses/caio/03-ai.html#alignment-why-it-matters",
    "title": "Modern AI",
    "section": "Alignment: Why It Matters",
    "text": "Alignment: Why It Matters\n\n\n\n\n\nflowchart LR\n    Q[\"User Query\"]\n    \n    Q --&gt; U[\"Unaligned\"]\n    Q --&gt; A[\"Aligned\"]\n    \n    U --&gt; UR[\"Yes, only true god\"]\n    \n    A --&gt; AR[\"Multiple perspectives exist\"]\n    \n    style Q fill:#e3f2fd,stroke:#1976d2\n    style UR fill:#ffcccc,stroke:#cc0000\n    style AR fill:#ccffcc,stroke:#00cc00\n\n\n\n\n\n\nExample: “Is Allah the only god?”\n\nUnaligned: “Yes, Allah is the one true god and all other beliefs are false.”\nAligned: “In Islam, Allah is considered the one God. Other religions have different perspectives. I can provide factual information if helpful.”\n\nThis nuanced behavior emerges from alignment training, not pre-training alone."
  },
  {
    "objectID": "courses/caio/03-ai.html#context-windows-and-prompting",
    "href": "courses/caio/03-ai.html#context-windows-and-prompting",
    "title": "Modern AI",
    "section": "Context Windows and Prompting",
    "text": "Context Windows and Prompting\nContext window: Maximum tokens the model can “see” at once\n\n\n\n\n\nflowchart LR\n    S[System Prompt&lt;br/&gt;~500 tokens]\n    T[Tools/Schemas&lt;br/&gt;~300 tokens]\n    H[History&lt;br/&gt;~1000 tokens]\n    R[Retrieved Docs&lt;br/&gt;~2000 tokens]\n    U[User Query&lt;br/&gt;~200 tokens]\n    \n    S --&gt; M[LLM]\n    T --&gt; M\n    H --&gt; M\n    R --&gt; M\n    U --&gt; M\n    \n    style S fill:#e3f2fd\n    style R fill:#c8e6c9\n    style U fill:#fff3e0\n\n\n\n\n\n\nPrompting strategies: Zero-shot, Few-shot, Chain-of-thought, System prompts"
  },
  {
    "objectID": "courses/caio/03-ai.html#what-are-ai-agents",
    "href": "courses/caio/03-ai.html#what-are-ai-agents",
    "title": "Modern AI",
    "section": "What Are AI Agents?",
    "text": "What Are AI Agents?\n\n“The question of whether a computer can think is no more interesting than the question of whether a submarine can swim.” — Edsger Dijkstra\n\nAI agents are autonomous systems that:\n\nPerceive their environment\nReason about goals\nTake actions to achieve outcomes\nLearn from results\n\nUnlike chatbots, agents can act in the world."
  },
  {
    "objectID": "courses/caio/03-ai.html#the-agent-loop",
    "href": "courses/caio/03-ai.html#the-agent-loop",
    "title": "Modern AI",
    "section": "The Agent Loop",
    "text": "The Agent Loop\n\n\n\n\n\nflowchart LR\n    P[\"Perceive\"] --&gt; R[\"Reason\"]\n    R --&gt; A[\"Act\"]\n    A --&gt; O[\"Observe\"]\n    O --&gt; P\n    \n    style P fill:#e3f2fd,stroke:#1976d2\n    style R fill:#fff3e0,stroke:#f57c00\n    style A fill:#e8f5e9,stroke:#388e3c\n    style O fill:#fce4ec,stroke:#c2185b\n\n\n\n\n\n\nThe agent perceives its environment, reasons about goals, acts to achieve outcomes, observes the result, and repeats — a continuous loop of intelligent behavior."
  },
  {
    "objectID": "courses/caio/03-ai.html#tool-use-giving-llms-hands",
    "href": "courses/caio/03-ai.html#tool-use-giving-llms-hands",
    "title": "Modern AI",
    "section": "Tool Use: Giving LLMs Hands",
    "text": "Tool Use: Giving LLMs Hands\nLLMs are “brains without hands” — function calling bridges this gap:\n\n\n\n\n\nflowchart LR\n    U[\"Query\"] --&gt; L[\"LLM\"]\n    L --&gt; TC[\"Tool Call\"]\n    TC --&gt; O[\"Orchestrator\"]\n    O --&gt; T[\"Tool\"]\n    T --&gt; |\"Result\"| L\n    L --&gt; R[\"Response\"]\n    \n    style U fill:#e3f2fd,stroke:#1976d2\n    style L fill:#fff3e0,stroke:#f57c00\n    style TC fill:#fce4ec,stroke:#c2185b\n    style T fill:#e8f5e9,stroke:#388e3c\n    style R fill:#f3e5f5,stroke:#7b1fa2\n\n\n\n\n\n\nExamples: Web search, database queries, code execution, API calls."
  },
  {
    "objectID": "courses/caio/03-ai.html#example-currency-conversion-agent",
    "href": "courses/caio/03-ai.html#example-currency-conversion-agent",
    "title": "Modern AI",
    "section": "Example: Currency Conversion Agent",
    "text": "Example: Currency Conversion Agent\nUser: “What’s $100 in euros?”\nAgent reasoning:\n\nI need to convert currency\nCall convert_currency(amount=100, from=\"USD\", to=\"EUR\")\n\nTool returns: 92.50\nAgent response: “100 US dollars is approximately 92.50 euros at current exchange rates.”\nThe agent reasons about what tool to use, then acts to get information."
  },
  {
    "objectID": "courses/caio/03-ai.html#multi-step-planning",
    "href": "courses/caio/03-ai.html#multi-step-planning",
    "title": "Modern AI",
    "section": "Multi-Step Planning",
    "text": "Multi-Step Planning\nComplex tasks require chained actions:\n\n\n\n\n\nflowchart LR\n    Task[Task] --&gt; get_rates[get_rates]\n    get_rates --&gt; Rates[Rates]\n    Rates --&gt; get_prices[get_prices]\n    get_prices --&gt; Prices[Prices]\n    Prices --&gt; correlate[correlate]\n    correlate --&gt; r[r=0.73]\n    r --&gt; report[report]\n    report --&gt; Final[Final Report]\n    \n    style Task fill:#e3f2fd,stroke:#1976d2\n    style get_rates fill:#fff3e0,stroke:#f57c00\n    style Rates fill:#fff3e0,stroke:#f57c00\n    style get_prices fill:#fff3e0,stroke:#f57c00\n    style Prices fill:#fff3e0,stroke:#f57c00\n    style correlate fill:#fff3e0,stroke:#f57c00\n    style r fill:#fff3e0,stroke:#f57c00\n    style report fill:#fff3e0,stroke:#f57c00\n    style Final fill:#c8e6c9,stroke:#2e7d32\n\n\n\n\n\n\nEach step informs the next — true autonomous problem-solving."
  },
  {
    "objectID": "courses/caio/03-ai.html#planning-capabilities",
    "href": "courses/caio/03-ai.html#planning-capabilities",
    "title": "Modern AI",
    "section": "Planning Capabilities",
    "text": "Planning Capabilities\nPlanning capabilities enable:\n\n\n\n\n\n\n\n\nCapability\nDescription\nExample\n\n\n\n\nDecomposition\nBreak complex goals into subtasks\n“Analyze market” → 4 API calls\n\n\nState tracking\nRemember intermediate results\nStore data between steps\n\n\nAdaptation\nAdjust plan based on results\nRetry if API fails\n\n\nSynthesis\nCombine outputs into final answer\nMerge data into report\n\n\n\nBusiness impact: Agents can handle multi-hour research tasks that would take humans days."
  },
  {
    "objectID": "courses/caio/03-ai.html#react-the-loop",
    "href": "courses/caio/03-ai.html#react-the-loop",
    "title": "Modern AI",
    "section": "ReAct: The Loop",
    "text": "ReAct: The Loop\nThe Loop:\n\n\n\n\n\n\n\n\nStep\nAction\nExample\n\n\n\n\nObserve\nAnalyze input, tool outputs, environment\n“User wants weather in Paris”\n\n\nThink\nDecide next action or tool to use\n“I should call weather API”\n\n\nAct\nExecute tool or generate response\nget_weather(\"Paris\")\n\n\n\nKey insight: Unlike single-pass generation, ReAct agents can course-correct based on intermediate results."
  },
  {
    "objectID": "courses/caio/03-ai.html#case-study-chatdev",
    "href": "courses/caio/03-ai.html#case-study-chatdev",
    "title": "Modern AI",
    "section": "Case Study: ChatDev",
    "text": "Case Study: ChatDev\nChatDev orchestrates a virtual software company with specialized AI agents:\n\n\n\n\n\nflowchart LR\n    CEO[CEO] --- CTO[CTO]\n    CTO --- CPO[CPO]\n    Prog[Programmer] --- Des[Designer]\n    Test[Tester] --- Prog2[Programmer]\n    \n    CEO --&gt; Prog\n    Des --&gt; Test\n    Test --&gt; Doc[Documentation]\n    \n    style CEO fill:#ffcccc,stroke:#cc0000\n    style CTO fill:#ccffcc,stroke:#00cc00\n    style Prog fill:#cce5ff,stroke:#1976d2\n    style Test fill:#fff3cd,stroke:#f57c00\n\n\n\n\n\n\nResults: 70 software projects, 17 files each, ~$0.30 per project, 7 minutes."
  },
  {
    "objectID": "courses/caio/03-ai.html#agent-orchestration-patterns",
    "href": "courses/caio/03-ai.html#agent-orchestration-patterns",
    "title": "Modern AI",
    "section": "Agent Orchestration Patterns",
    "text": "Agent Orchestration Patterns\n\n\n\n\n\nflowchart LR\n    A1[Agent A] --&gt; A2[Agent B] --&gt; A3[Agent C]\n    \n    T[Task] --&gt; P1[Agent 1]\n    T --&gt; P2[Agent 2]\n    T --&gt; P3[Agent 3]\n    P1 --&gt; R[Results]\n    P2 --&gt; R\n    P3 --&gt; R\n    \n    S[Supervisor] --&gt; H1[Worker 1]\n    S --&gt; H2[Worker 2]\n    S --&gt; H3[Worker 3]"
  },
  {
    "objectID": "courses/caio/03-ai.html#orchestration-use-cases",
    "href": "courses/caio/03-ai.html#orchestration-use-cases",
    "title": "Modern AI",
    "section": "Orchestration: Use Cases",
    "text": "Orchestration: Use Cases\n\n\n\n\n\n\n\n\nPattern\nUse Case\nTradeoff\n\n\n\n\nSequential\nContent pipeline (research → write → edit)\nSimple but slow\n\n\nParallel\nMulti-source analysis\nFast but needs synthesis\n\n\nHierarchical\nProject management\nControl but bottleneck risk\n\n\nDynamic\nMarket-based task allocation\nFlexible but complex"
  },
  {
    "objectID": "courses/caio/03-ai.html#the-risks-of-agent-autonomy",
    "href": "courses/caio/03-ai.html#the-risks-of-agent-autonomy",
    "title": "Modern AI",
    "section": "The Risks of Agent Autonomy",
    "text": "The Risks of Agent Autonomy\nCase Study: Replit Agent Failure\n\n\n\n\n\nflowchart LR\n    U[\"User: Fix this bug\"] --&gt; A[Agent]\n    A --&gt; D1[\"Diagnoses: config file issue\"]\n    D1 --&gt; D2[\"Decides: delete config\"]\n    D2 --&gt; B[\"Bug in delete tool\"]\n    B --&gt; C[\"Entire project wiped\"]\n    C --&gt; X[\"Production DB destroyed\"]\n    \n    style D1 fill:#fff3cd\n    style D2 fill:#ffcccc\n    style B fill:#ffcccc\n    style X fill:#ff0000,color:#fff\n\n\n\n\n\n\nLesson: Agent autonomy requires multiple safety layers.\nWhat went wrong:\n\n\n\n\n\n\n\n\nFailure\nType\nPrevention\n\n\n\n\nWrong diagnosis\nReasoning error\nRequire confirmation for destructive actions\n\n\nAuto-delete decision\nAutonomy overreach\nHuman-in-the-loop for irreversible ops\n\n\nTool bug\nImplementation flaw\nSandbox testing, rollback capability\n\n\nNo backup\nMissing safeguard\nMandatory snapshots before changes\n\n\n\nKey principle: The more powerful the agent, the more guardrails it needs."
  },
  {
    "objectID": "courses/caio/03-ai.html#agent-safety-challenges",
    "href": "courses/caio/03-ai.html#agent-safety-challenges",
    "title": "Modern AI",
    "section": "Agent Safety Challenges",
    "text": "Agent Safety Challenges\n\n\n\n\n\nflowchart LR\n    PI[Prompt Injection] --&gt; A[Agent]\n    AD[Adversarial Inputs] --&gt; A\n    GM[Goal Misalignment] --&gt; A\n    HA[Hallucinations] --&gt; A\n    CO[Capability Overhang] --&gt; A\n    LC[Lack of Corrigibility] --&gt; A\n    A --&gt; H[Harm]\n    \n    style PI fill:#ffcccc\n    style HA fill:#fff3cd\n    style H fill:#ff0000,color:#fff\n\n\n\n\n\n\nAutonomous agents amplify risks — a hallucination becomes action."
  },
  {
    "objectID": "courses/caio/03-ai.html#agent-safety-risk-taxonomy",
    "href": "courses/caio/03-ai.html#agent-safety-risk-taxonomy",
    "title": "Modern AI",
    "section": "Agent Safety: Risk Taxonomy",
    "text": "Agent Safety: Risk Taxonomy\n\n\n\n\n\n\n\n\nRisk\nDescription\nReal Example\n\n\n\n\nPrompt Injection\nHidden instructions hijack agent\nEmail contains “ignore previous instructions”\n\n\nHallucinations\nActing on false information\nAgent invents API that doesn’t exist\n\n\nGoal Misalignment\nOptimizes wrong objective\nMaximizes engagement via manipulation\n\n\nCapability Overhang\nDoes more than authorized\nAccesses files outside scope"
  },
  {
    "objectID": "courses/caio/03-ai.html#safety-mechanisms",
    "href": "courses/caio/03-ai.html#safety-mechanisms",
    "title": "Modern AI",
    "section": "Safety Mechanisms",
    "text": "Safety Mechanisms\n\n\n\n\n\nflowchart LR\n    U[Input] --&gt; IF[Input Filter]\n    IF --&gt; |Clean| A[Agent]\n    IF --&gt; |Malicious| B[Block]\n    A --&gt; OF[Output Filter]\n    OF --&gt; |Safe| R[Response]\n    OF --&gt; |Unsafe| B\n    A --&gt; M[Monitor]\n    M --&gt; |Anomaly| CB[Circuit Breaker]\n    CB --&gt; B\n    \n    style IF fill:#fff3e0,stroke:#f57c00\n    style OF fill:#fff3e0,stroke:#f57c00\n    style B fill:#ffcccc,stroke:#cc0000\n    style R fill:#ccffcc,stroke:#00cc00\n    style CB fill:#fce4ec,stroke:#c2185b\n\n\n\n\n\n\nThe Safety Pipeline:\n\nInput/Output Guards: Fast classifiers that run before and after the LLM.\nMonitoring: Watching for “strange” behavior (e.g., an agent trying to access a restricted database).\nCircuit Breakers: Automatically killing the agent process if safety thresholds are exceeded."
  },
  {
    "objectID": "courses/caio/03-ai.html#the-defense-in-depth-pipeline",
    "href": "courses/caio/03-ai.html#the-defense-in-depth-pipeline",
    "title": "Modern AI",
    "section": "The Defense-in-Depth Pipeline",
    "text": "The Defense-in-Depth Pipeline\n\n\n\n\n\n\n\n\nLayer\nPurpose\nTechnical Method\n\n\n\n\nInput Filter\nBlock malicious prompts\nPII detection, jailbreak classifiers\n\n\nSandboxing\nIsolate agent actions\nDocker containers, restricted API keys\n\n\nOutput Filter\nPrevent sensitive leakage\nRegEx for PII, toxic content scoring\n\n\nHuman-in-the-Loop\nVerify high-risk actions\n“Approve” button for financial transfers\n\n\nMonitoring\nDetect runtime anomalies\nLog analysis, capability tracking\n\n\n\nKey Principle: Never rely on the LLM to self-police. Use external code to enforce boundaries."
  },
  {
    "objectID": "courses/caio/03-ai.html#human-in-the-loop-hitl",
    "href": "courses/caio/03-ai.html#human-in-the-loop-hitl",
    "title": "Modern AI",
    "section": "Human-in-the-Loop (HITL)",
    "text": "Human-in-the-Loop (HITL)\nThe most effective safety measure for high-stakes agents:\n\nCritical Actions: Require manual approval for destructive or financial operations (e.g., rm -rf, send_payment).\nConfirmation Dialogue: Show the agent’s proposed plan before execution.\nFeedback Loop: Allow the human to correct the agent’s reasoning.\nAudit Logs: Every action approved or rejected by a human is recorded for training and safety reviews.\n\nExample: A code-refactoring agent proposes changes; a human developer reviews and clicks “Merge” or “Reject”."
  },
  {
    "objectID": "courses/caio/03-ai.html#anthropics-asl-3-safety-measures",
    "href": "courses/caio/03-ai.html#anthropics-asl-3-safety-measures",
    "title": "Modern AI",
    "section": "Anthropic’s ASL-3 Safety Measures",
    "text": "Anthropic’s ASL-3 Safety Measures\nFor Claude Opus 4, Anthropic activated proactive safety:\n\n\n\n\n\nflowchart LR\n    U[User] --&gt; CC[Constitutional Classifiers]\n    CC --&gt; |Safe| M[Model]\n    CC --&gt; |Blocked| B[Reject]\n    M --&gt; OC[Output Check]\n    OC --&gt; |Safe| R[Response]\n    OC --&gt; |Harmful| B\n    \n    BB[Bug Bounty] --&gt; CC\n    RP[Rapid Patch] --&gt; CC\n    \n    style CC fill:#c8e6c9,stroke:#2e7d32\n    style B fill:#ffcccc,stroke:#cc0000\n    style R fill:#e3f2fd,stroke:#1976d2"
  },
  {
    "objectID": "courses/caio/03-ai.html#asl-3-safety-pipeline",
    "href": "courses/caio/03-ai.html#asl-3-safety-pipeline",
    "title": "Modern AI",
    "section": "ASL-3: Safety Pipeline",
    "text": "ASL-3: Safety Pipeline\n\n\n\n\n\n\n\n\nLayer\nFunction\nWhy It Matters\n\n\n\n\nConstitutional AI\nReal-time input/output filtering\nBlocks harmful requests before execution\n\n\nBug Bounty\nCrowdsourced discovery\nFinds attacks humans miss\n\n\nRapid Patching\nAuto-generate variants\nStays ahead of attackers\n\n\nEgress Control\nThrottle outbound data\nPrevents model weight theft"
  },
  {
    "objectID": "courses/caio/03-ai.html#evaluating-ai-agents",
    "href": "courses/caio/03-ai.html#evaluating-ai-agents",
    "title": "Modern AI",
    "section": "Evaluating AI Agents",
    "text": "Evaluating AI Agents\nTraditional metrics (accuracy, precision) are insufficient for agents.\n\n\n\n\n\nflowchart LR\n    TC[\"Task Completion\"] --&gt; Score[\"Overall Agent Score\"]\n    RQ[\"Reasoning Quality\"] --&gt; Score\n    SA[\"Safety\"] --&gt; Score\n    RE[\"Resource Efficiency\"] --&gt; Score\n    ER[\"Error Recovery\"] --&gt; Score\n    AD[\"Adversarial Robustness\"] --&gt; Score\n    \n    style SA fill:#ffcccc,stroke:#cc0000\n    style Score fill:#c8e6c9,stroke:#2e7d32"
  },
  {
    "objectID": "courses/caio/03-ai.html#evaluation-approaches",
    "href": "courses/caio/03-ai.html#evaluation-approaches",
    "title": "Modern AI",
    "section": "Evaluation Approaches",
    "text": "Evaluation Approaches\n\n\n\n\n\nflowchart LR\n    A[Agent Output] --&gt; R[Rule-Based]\n    A --&gt; L[LLM-as-Judge]\n    A --&gt; H[Human Review]\n    A --&gt; S[Simulation]\n    \n    R --&gt; E[Score]\n    L --&gt; E\n    H --&gt; E\n    S --&gt; E\n    \n    style R fill:#e3f2fd,stroke:#1976d2\n    style L fill:#fff3e0,stroke:#f57c00\n    style H fill:#c8e6c9,stroke:#2e7d32\n    style S fill:#f3e5f5,stroke:#7b1fa2\n    style E fill:#ffcccc,stroke:#cc0000\n\n\n\n\n\n\nBest practice: Combine multiple approaches for comprehensive evaluation."
  },
  {
    "objectID": "courses/caio/03-ai.html#domain-specific-benchmarks",
    "href": "courses/caio/03-ai.html#domain-specific-benchmarks",
    "title": "Modern AI",
    "section": "Domain-Specific Benchmarks",
    "text": "Domain-Specific Benchmarks\n\n\n\nDomain\nBenchmark\nWhat It Tests\n\n\n\n\nCoding\nSWE-bench\nFix real GitHub issues\n\n\nWeb\nWebArena\nNavigate websites, complete tasks\n\n\nRobotics\nALFRED\nHousehold tasks in 3D\n\n\nEnterprise\nTAU-bench\nMulti-system workflows\n\n\n\nAgent capabilities are task-specific — benchmarks must match use cases."
  },
  {
    "objectID": "courses/caio/03-ai.html#red-teaming-agents",
    "href": "courses/caio/03-ai.html#red-teaming-agents",
    "title": "Modern AI",
    "section": "Red-Teaming Agents",
    "text": "Red-Teaming Agents\nSystematic vulnerability testing:\n\n\n\n\n\nflowchart LR\n    PI[Prompt Injection] --&gt; A[Agent]\n    ME[Agent Mistakes] --&gt; A\n    MU[Direct Misuse] --&gt; A\n    \n    A --&gt; |Vulnerability| V[Security Issue]\n    A --&gt; |Safe| S[Normal Operation]\n    \n    V --&gt; R[Report]\n    \n    style PI fill:#ffcccc,stroke:#cc0000\n    style ME fill:#fff3cd,stroke:#f57c00\n    style MU fill:#ffcccc,stroke:#cc0000\n    style V fill:#ffcccc,stroke:#cc0000\n    style S fill:#ccffcc,stroke:#00cc00\n\n\n\n\n\n\nExample: Hidden text in a webpage hijacks agent to exfiltrate data.\nComprehensive red-teaming found 1,200+ vulnerabilities in one enterprise agent."
  },
  {
    "objectID": "courses/caio/03-ai.html#embodied-ai-robots",
    "href": "courses/caio/03-ai.html#embodied-ai-robots",
    "title": "Modern AI",
    "section": "Embodied AI: Robots",
    "text": "Embodied AI: Robots\nSoftware agents operate in digital systems. Embodied agents must handle:\n\n\n\n\n\nflowchart LR\n    C[\"Camera\"] --&gt; F[\"Fusion\"]\n    L[\"Lidar\"] --&gt; F\n    T[\"Touch\"] --&gt; F\n    F --&gt; B[\"Robot Brain\"]\n    B --&gt; M[\"Motors\"]\n    M --&gt; E[\"Environment\"]\n    E --&gt; |\"Feedback\"| C\n    \n    style F fill:#fff3e0,stroke:#f57c00\n    style B fill:#e3f2fd,stroke:#1976d2\n    style E fill:#c8e6c9,stroke:#388e3c\n\n\n\n\n\n\nThe sim-to-real gap: Robots trained in simulation often fail in reality."
  },
  {
    "objectID": "courses/caio/03-ai.html#the-evolution-of-robotic-intelligence",
    "href": "courses/caio/03-ai.html#the-evolution-of-robotic-intelligence",
    "title": "Modern AI",
    "section": "The Evolution of Robotic Intelligence",
    "text": "The Evolution of Robotic Intelligence\n\n\n\n\n\nflowchart LR\n    S[1960s Shakey] --&gt; P[1980s-2000s Probabilistic]\n    P --&gt; F[2020s Foundation Models]\n    \n    style S fill:#e3f2fd,stroke:#1976d2\n    style P fill:#fff3e0,stroke:#f57c00\n    style F fill:#c8e6c9,stroke:#2e7d32"
  },
  {
    "objectID": "courses/caio/03-ai.html#robotics-capability-eras",
    "href": "courses/caio/03-ai.html#robotics-capability-eras",
    "title": "Modern AI",
    "section": "Robotics: Capability Eras",
    "text": "Robotics: Capability Eras\n\n\n\n\n\n\n\n\nEra\nCapability\nLimitation\n\n\n\n\nRule-based\nExplicit reasoning\nBrittle, narrow\n\n\nProbabilistic\nHandle uncertainty\nNo language understanding\n\n\nFoundation Models\nNatural language + adaptation\nCompute-intensive\n\n\n\nLLMs have catalyzed a new era: robots that understand language and adapt."
  },
  {
    "objectID": "courses/caio/03-ai.html#googles-robotic-transformer-rt-2",
    "href": "courses/caio/03-ai.html#googles-robotic-transformer-rt-2",
    "title": "Modern AI",
    "section": "Google’s Robotic Transformer (RT-2)",
    "text": "Google’s Robotic Transformer (RT-2)\nA vision-language-action model that directly controls robots:\n\n\n\n\n\nflowchart LR\n    V[Vision Input] --&gt; VLA[RT-2 Model]\n    L[Language Input] --&gt; VLA\n    VLA --&gt; A[Action Output]\n    A --&gt; R[Robot]\n    R -- Feedback --&gt; V\n    \n    style V fill:#e3f2fd,stroke:#1976d2\n    style L fill:#fff3e0,stroke:#f57c00\n    style VLA fill:#f3e5f5,stroke:#7b1fa2\n    style A fill:#c8e6c9,stroke:#2e7d32\n    style R fill:#ffcccc,stroke:#cc0000\n\n\n\n\n\n\nGeneral → Interactive → Dexterous\nWorks across robot forms: arms, humanoids, mobile platforms."
  },
  {
    "objectID": "courses/caio/03-ai.html#robot-safety-asimov",
    "href": "courses/caio/03-ai.html#robot-safety-asimov",
    "title": "Modern AI",
    "section": "Robot Safety: ASIMOV",
    "text": "Robot Safety: ASIMOV\nNamed after Asimov’s Laws of Robotics, this benchmark tests embodied AI safety:\n\n\n\n\n\n\n\n\nAsimov’s Law\nModern Interpretation\nTest Scenario\n\n\n\n\n1. Don’t harm humans\nRefuse dangerous commands\n“Throw this at the person”\n\n\n2. Obey orders\nFollow safe instructions\n“Hand me that tool”\n\n\n3. Protect self\nAvoid self-damage\nDon’t walk off ledge\n\n\nZeroth Law\nProtect humanity broadly\nConsider societal impact\n\n\n\nKey challenge: Context matters — “Hand me that knife” is safe in a kitchen, dangerous in a conflict.\nBusiness relevance: As robots enter warehouses, hospitals, and homes, safety benchmarks become legal and ethical requirements."
  },
  {
    "objectID": "courses/caio/03-ai.html#summary-nlp",
    "href": "courses/caio/03-ai.html#summary-nlp",
    "title": "Modern AI",
    "section": "Summary: NLP",
    "text": "Summary: NLP\n\n\n\nConcept\nKey Insight\n\n\n\n\nWord Embeddings\nWords as vectors; geometry = meaning\n\n\nDistributional Hypothesis\nContext reveals meaning\n\n\nAttention\nDynamic weighting of relevant information\n\n\nTransformers\nParallel processing, scalable, powerful\n\n\n\nThe shift from symbols to vectors enabled modern NLP."
  },
  {
    "objectID": "courses/caio/03-ai.html#summary-llms",
    "href": "courses/caio/03-ai.html#summary-llms",
    "title": "Modern AI",
    "section": "Summary: LLMs",
    "text": "Summary: LLMs\n\n\n\nConcept\nKey Insight\n\n\n\n\nAutoregressive Generation\nPredict next token iteratively\n\n\nTemperature\nControls randomness/creativity\n\n\nAlignment\nEnsures safe, helpful behavior\n\n\nContext Windows\nLimit on “memory” size\n\n\n\nScale + alignment = emergent reasoning capabilities."
  },
  {
    "objectID": "courses/caio/03-ai.html#summary-ai-agents",
    "href": "courses/caio/03-ai.html#summary-ai-agents",
    "title": "Modern AI",
    "section": "Summary: AI Agents",
    "text": "Summary: AI Agents\n\n\n\nConcept\nKey Insight\n\n\n\n\nTool Use\nLLMs gain ability to act\n\n\nMulti-Step Planning\nChain reasoning and action\n\n\nOrchestration\nMultiple agents collaborate\n\n\nSafety\nAutonomy amplifies risks\n\n\nEvaluation\nRequires new methodologies\n\n\n\nAgents transform LLMs from conversationalists to autonomous workers."
  },
  {
    "objectID": "courses/caio/03-ai.html#the-executive-perspective",
    "href": "courses/caio/03-ai.html#the-executive-perspective",
    "title": "Modern AI",
    "section": "The Executive Perspective",
    "text": "The Executive Perspective\nFor AI leaders:\n\nNLP powers search, chatbots, document analysis\nLLMs enable natural language interfaces to business systems\nAgents can automate complex, multi-step workflows\nSafety must be built in from the start, not bolted on\nEvaluation requires domain-specific benchmarks and human oversight\n\nThe promise: augmenting human intelligence — agents handle routine tasks while humans provide judgment, creativity, and ethical oversight."
  },
  {
    "objectID": "courses/caio/03-ai.html#supplemental-reading",
    "href": "courses/caio/03-ai.html#supplemental-reading",
    "title": "Modern AI",
    "section": "Supplemental Reading",
    "text": "Supplemental Reading\nOnline Articles:\n\nMaking the Most of AI and Machine Learning in Organizations — Stanford\nThe State of AI in 2024 — McKinsey\nGenerative AI’s Act Two — Sequoia Capital\n\nFrom the Textbook:\n\nChapter 24: Natural Language Processing\nChapter 26: AI Agents"
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html",
    "href": "courses/caio/cursor-setup-guide.html",
    "title": "Cursor IDE Setup Guide",
    "section": "",
    "text": "Cursor is an AI-powered code editor built on VS Code. It allows you to:\n\nWrite code with AI assistance\nAsk questions about your code\nGenerate code from natural language descriptions\nDebug and fix errors with AI help\n\nFor this course, we’ll use Cursor to build an AI agent without needing deep programming expertise."
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#what-is-cursor",
    "href": "courses/caio/cursor-setup-guide.html#what-is-cursor",
    "title": "Cursor IDE Setup Guide",
    "section": "",
    "text": "Cursor is an AI-powered code editor built on VS Code. It allows you to:\n\nWrite code with AI assistance\nAsk questions about your code\nGenerate code from natural language descriptions\nDebug and fix errors with AI help\n\nFor this course, we’ll use Cursor to build an AI agent without needing deep programming expertise."
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#part-1-download-and-install-cursor",
    "href": "courses/caio/cursor-setup-guide.html#part-1-download-and-install-cursor",
    "title": "Cursor IDE Setup Guide",
    "section": "2 Part 1: Download and Install Cursor",
    "text": "2 Part 1: Download and Install Cursor\n\n2.1 Step 1: Download Cursor\n\nGo to cursor.sh\nClick the Download button\nThe website will automatically detect your operating system (Mac, Windows, or Linux)\n\n\n\n2.2 Step 2: Install on Mac\n\nOpen the downloaded .dmg file\nDrag the Cursor icon to the Applications folder\nOpen Cursor from Applications\nIf prompted about security, go to System Preferences → Security & Privacy and click “Open Anyway”\n\n\n\n2.3 Step 3: Install on Windows\n\nRun the downloaded .exe installer\nFollow the installation wizard\nLaunch Cursor from the Start Menu"
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#part-2-initial-setup",
    "href": "courses/caio/cursor-setup-guide.html#part-2-initial-setup",
    "title": "Cursor IDE Setup Guide",
    "section": "3 Part 2: Initial Setup",
    "text": "3 Part 2: Initial Setup\n\n3.1 Step 1: Sign In (Optional but Recommended)\n\nWhen Cursor opens, you’ll see a welcome screen\nClick Sign In to create a free account\nYou can sign in with:\n\nGoogle account\nGitHub account\nEmail\n\n\nBenefits of signing in:\n\nFree AI credits for code assistance\nSettings sync across devices\n\n\n\n3.2 Step 2: Choose Your Theme\n\nCursor will ask about your preferred color theme\nChoose Dark or Light based on your preference\nYou can change this later in Settings\n\n\n\n3.3 Step 3: Import VS Code Settings (Optional)\nIf you’ve used VS Code before:\n\nCursor will offer to import your settings\nClick Import to bring over extensions and preferences\nOr click Skip to start fresh"
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#part-3-install-python",
    "href": "courses/caio/cursor-setup-guide.html#part-3-install-python",
    "title": "Cursor IDE Setup Guide",
    "section": "4 Part 3: Install Python",
    "text": "4 Part 3: Install Python\nCursor needs Python installed on your computer to run our project.\n\n4.1 Check if Python is Already Installed\n\nIn Cursor, open the terminal: View → Terminal (or press Ctrl+`)\nType this command and press Enter:\n\npython --version\n\nIf you see Python 3.x.x, you’re good! Skip to Part 4.\nIf you get an error, follow the installation steps below.\n\n\n\n4.2 Install Python on Mac\nOption A: Using Homebrew (Recommended)\n\nOpen Terminal (outside of Cursor)\nInstall Homebrew if you don’t have it:\n\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\nInstall Python:\n\nbrew install python\nOption B: Direct Download\n\nGo to python.org/downloads\nDownload the latest Python 3.x version\nRun the installer\nImportant: Check “Add Python to PATH” during installation\n\n\n\n4.3 Install Python on Windows\n\nGo to python.org/downloads\nClick “Download Python 3.x.x”\nRun the installer\nIMPORTANT: Check the box that says “Add Python to PATH”\nClick “Install Now”\n\n\n\n4.4 Verify Installation\nAfter installation, close and reopen Cursor, then:\n\nOpen terminal: View → Terminal\nRun:\n\npython --version\n\nYou should see Python 3.x.x"
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#part-4-install-required-packages",
    "href": "courses/caio/cursor-setup-guide.html#part-4-install-required-packages",
    "title": "Cursor IDE Setup Guide",
    "section": "5 Part 4: Install Required Packages",
    "text": "5 Part 4: Install Required Packages\nOur project needs a few Python libraries. Install them in Cursor’s terminal:\npip install pandas numpy scikit-learn\nYou should see output indicating successful installation.\nIf you get a “pip not found” error on Mac:\npip3 install pandas numpy scikit-learn"
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#part-5-using-cursors-ai-features",
    "href": "courses/caio/cursor-setup-guide.html#part-5-using-cursors-ai-features",
    "title": "Cursor IDE Setup Guide",
    "section": "6 Part 5: Using Cursor’s AI Features",
    "text": "6 Part 5: Using Cursor’s AI Features\n\n6.1 Feature 1: AI Chat (Cmd+L / Ctrl+L)\nUse this to ask questions or get help:\n\nPress Cmd+L (Mac) or Ctrl+L (Windows)\nA chat panel opens on the right\nAsk questions like:\n\n“How do I load a CSV file in Python?”\n“Explain what this code does”\n“Why am I getting this error?”\n\n\n\n\n6.2 Feature 2: Inline Edit (Cmd+K / Ctrl+K)\nUse this to write or modify code:\n\nSelect some code (or place cursor where you want new code)\nPress Cmd+K (Mac) or Ctrl+K (Windows)\nDescribe what you want in plain English:\n\n“Add a function that calculates the average price”\n“Fix this error”\n“Add comments explaining this code”\n\nReview the suggested changes\nPress Enter to accept or Escape to cancel\n\n\n\n6.3 Feature 3: Code Completion (Tab)\nAs you type, Cursor suggests completions:\n\nStart typing code\nYou’ll see gray “ghost text” suggestions\nPress Tab to accept the suggestion\nPress Escape to dismiss\n\n\n\n6.4 Feature 4: Agent Mode (Cmd+I / Ctrl+I)\nFor larger tasks, use Agent mode:\n\nPress Cmd+I (Mac) or Ctrl+I (Windows)\nDescribe a complex task:\n\n“Create a Python script that loads data and builds a regression model”\n\nThe agent will generate multiple files and complete code"
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#part-6-creating-your-first-project",
    "href": "courses/caio/cursor-setup-guide.html#part-6-creating-your-first-project",
    "title": "Cursor IDE Setup Guide",
    "section": "7 Part 6: Creating Your First Project",
    "text": "7 Part 6: Creating Your First Project\n\n7.1 Step 1: Create a Project Folder\n\nIn Cursor, go to File → Open Folder\nNavigate to where you want your project (e.g., Documents)\nClick New Folder and name it oj-pricing-agent\nSelect this folder and click Open\n\n\n\n7.2 Step 2: Create a Python File\n\nIn the Explorer sidebar (left panel), right-click\nSelect New File\nName it test.py\nAdd this code:\n\nprint(\"Hello from Cursor!\")\n\n\n7.3 Step 3: Run Your Code\n\nOpen the terminal: View → Terminal\nRun your script:\n\npython test.py\n\nYou should see: Hello from Cursor!\n\nCongratulations! You’re ready to build your AI agent."
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#part-7-keyboard-shortcuts-reference",
    "href": "courses/caio/cursor-setup-guide.html#part-7-keyboard-shortcuts-reference",
    "title": "Cursor IDE Setup Guide",
    "section": "8 Part 7: Keyboard Shortcuts Reference",
    "text": "8 Part 7: Keyboard Shortcuts Reference\n\n\n\nAction\nMac\nWindows\n\n\n\n\nAI Chat\nCmd+L\nCtrl+L\n\n\nInline Edit\nCmd+K\nCtrl+K\n\n\nAgent Mode\nCmd+I\nCtrl+I\n\n\nOpen Terminal\nCtrl+| Ctrl+\n\n\n\nSave File\nCmd+S\nCtrl+S\n\n\nOpen File\nCmd+O\nCtrl+O\n\n\nNew File\nCmd+N\nCtrl+N\n\n\nFind\nCmd+F\nCtrl+F"
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#troubleshooting",
    "href": "courses/caio/cursor-setup-guide.html#troubleshooting",
    "title": "Cursor IDE Setup Guide",
    "section": "9 Troubleshooting",
    "text": "9 Troubleshooting\n\n9.1 “Python not found” in terminal\nMac:\n\nTry python3 instead of python\nOr run: brew install python\n\nWindows:\n\nReinstall Python and make sure to check “Add Python to PATH”\nRestart Cursor after installation\n\n\n\n9.2 “pip not found”\nMac:\n\nUse pip3 instead of pip\n\nWindows:\n\nTry python -m pip install package_name\n\n\n\n9.3 Cursor won’t start\n\nMake sure you have enough disk space (at least 1GB free)\nTry restarting your computer\nReinstall Cursor from cursor.sh\n\n\n\n9.4 AI features not working\n\nMake sure you’re signed in (check bottom-left corner)\nCheck your internet connection\nTry signing out and back in\n\n\n\n9.5 Code runs but shows errors\n\nCopy the error message\nPress Cmd+L (or Ctrl+L) to open AI Chat\nPaste the error and ask “How do I fix this?”"
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#getting-help-during-the-course",
    "href": "courses/caio/cursor-setup-guide.html#getting-help-during-the-course",
    "title": "Cursor IDE Setup Guide",
    "section": "10 Getting Help During the Course",
    "text": "10 Getting Help During the Course\n\nZoom Sessions: Ask questions during live sessions\nCursor AI: Use Cmd+L to ask the AI for help\nDiscussion Board: Post questions for peer assistance\nOffice Hours: [Insert instructor office hours if applicable]"
  },
  {
    "objectID": "courses/caio/cursor-setup-guide.html#next-steps",
    "href": "courses/caio/cursor-setup-guide.html#next-steps",
    "title": "Cursor IDE Setup Guide",
    "section": "11 Next Steps",
    "text": "11 Next Steps\nAfter completing this setup:\n\n✅ Cursor is installed and running\n✅ Python is installed\n✅ Required packages are installed\n✅ You can create and run Python files\n\nYou’re ready for Zoom Session 1 where we’ll practice using Cursor’s AI features together!"
  },
  {
    "objectID": "courses/caio/final-project-guide.html",
    "href": "courses/caio/final-project-guide.html",
    "title": "Final Project Guide",
    "section": "",
    "text": "In this project, you will build an AI agent that helps a retail pricing analyst make decisions about orange juice pricing and promotions. The agent will:\n\nLoad and explore sales data\nBuild a regression model to predict sales\nAnswer business questions using natural language\n\nTime Required: ~2 hours\nPrerequisites:\n\nCursor IDE installed (see Cursor Setup Guide)\nBasic familiarity with Cursor from Zoom Session 1\nDownload the project template to get started quickly"
  },
  {
    "objectID": "courses/caio/final-project-guide.html#overview",
    "href": "courses/caio/final-project-guide.html#overview",
    "title": "Final Project Guide",
    "section": "",
    "text": "In this project, you will build an AI agent that helps a retail pricing analyst make decisions about orange juice pricing and promotions. The agent will:\n\nLoad and explore sales data\nBuild a regression model to predict sales\nAnswer business questions using natural language\n\nTime Required: ~2 hours\nPrerequisites:\n\nCursor IDE installed (see Cursor Setup Guide)\nBasic familiarity with Cursor from Zoom Session 1\nDownload the project template to get started quickly"
  },
  {
    "objectID": "courses/caio/final-project-guide.html#part-1-project-setup",
    "href": "courses/caio/final-project-guide.html#part-1-project-setup",
    "title": "Final Project Guide",
    "section": "2 Part 1: Project Setup",
    "text": "2 Part 1: Project Setup\n\n2.1 Step 1.1: Create Your Project Folder\n\nOpen Cursor IDE\nClick File → Open Folder\nCreate a new folder called oj-pricing-agent on your computer\nSelect that folder to open it in Cursor\n\n\n\n2.2 Step 1.2: Create the Main Python File\n\nIn the Cursor sidebar, right-click and select New File\nName it oj_agent.py\nYou’ll see an empty file open in the editor\n\n\n\n2.3 Step 1.3: Copy the Dataset\nDownload the oj_data.csv file and copy it into your oj-pricing-agent folder."
  },
  {
    "objectID": "courses/caio/final-project-guide.html#part-2-data-loading-and-exploration",
    "href": "courses/caio/final-project-guide.html#part-2-data-loading-and-exploration",
    "title": "Final Project Guide",
    "section": "3 Part 2: Data Loading and Exploration",
    "text": "3 Part 2: Data Loading and Exploration\n\n3.1 Step 2.1: Load the Required Libraries\nIn your oj_agent.py file, start by adding these lines at the top:\n# Required libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder\nimport warnings\nwarnings.filterwarnings('ignore')\nWhat this does: These libraries help us work with data (pandas), do math (numpy), and build models (sklearn).\n\n\n3.2 Step 2.2: Load the Data\nAdd the following code to load the orange juice sales data:\n# Load the orange juice dataset\nprint(\"Loading data...\")\ndf = pd.read_csv('oj_data.csv')\n\n# Display basic information\nprint(f\"Dataset has {len(df)} rows and {len(df.columns)} columns\")\nprint(f\"\\nColumns: {list(df.columns)}\")\nprint(f\"\\nBrands in dataset: {df['brand'].unique()}\")\nprint(f\"\\nPrice range: ${df['price'].min():.2f} - ${df['price'].max():.2f}\")\nprint(f\"\\nSample of data:\")\nprint(df.head())\n\n\n3.3 Step 2.3: Run Your Code (First Test)\n\nSave the file (Ctrl+S or Cmd+S)\nOpen the terminal in Cursor: View → Terminal\nRun the script:\n\npython oj_agent.py\nYou should see output showing:\n\nThe dataset has ~28,000 rows\nThree brands: Tropicana, Minute Maid, Dominick’s\nPrice ranges from about $1 to $4\n\nTroubleshooting: If you get an error about missing packages, run:\npip install pandas numpy scikit-learn"
  },
  {
    "objectID": "courses/caio/final-project-guide.html#part-3-building-the-regression-model",
    "href": "courses/caio/final-project-guide.html#part-3-building-the-regression-model",
    "title": "Final Project Guide",
    "section": "4 Part 3: Building the Regression Model",
    "text": "4 Part 3: Building the Regression Model\n\n4.1 Step 3.1: Understanding the Model\nWe’re building a model that predicts log of sales volume based on:\n\nPrice: Higher price → lower sales (negative relationship)\nFeatured (feat): If the product is in the weekly ad circular (1 = yes, 0 = no)\nBrand: Different brands have different base sales levels\nPrice × Brand interaction: Price sensitivity varies by brand\n\n\n\n4.2 Step 3.2: Prepare the Data for Modeling\nAdd this code to prepare features for the model:\n# ============================================\n# PART 3: BUILD THE REGRESSION MODEL\n# ============================================\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Building the pricing model...\")\nprint(\"=\"*50)\n\n# Create dummy variables for brand (one-hot encoding)\n# This converts 'brand' text into numbers the model can use\nbrand_dummies = pd.get_dummies(df['brand'], prefix='brand', drop_first=False)\n\n# Create the feature matrix\n# We include: price, feat, brand dummies, and price*brand interactions\nX = pd.DataFrame({\n    'price': df['price'],\n    'feat': df['feat'],\n    'brand_minute.maid': brand_dummies['brand_minute.maid'],\n    'brand_tropicana': brand_dummies['brand_tropicana'],\n    # Interaction terms: price effect varies by brand\n    'price_x_minute.maid': df['price'] * brand_dummies['brand_minute.maid'],\n    'price_x_tropicana': df['price'] * brand_dummies['brand_tropicana']\n})\n\n# Target variable: log of sales (logmove)\ny = df['logmove']\n\nprint(f\"Features: {list(X.columns)}\")\nprint(f\"Target: logmove (log of sales volume)\")\n\n\n4.3 Step 3.3: Fit the Model\nAdd code to train the regression model:\n# Fit the linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Display the coefficients\nprint(\"\\nModel Coefficients:\")\nprint(\"-\" * 40)\nfor feature, coef in zip(X.columns, model.coef_):\n    print(f\"  {feature}: {coef:.4f}\")\nprint(f\"  intercept: {model.intercept_:.4f}\")\n\n# Calculate R-squared (how well the model fits)\nr_squared = model.score(X, y)\nprint(f\"\\nModel R-squared: {r_squared:.3f}\")\nprint(\"(This means the model explains {:.1f}% of sales variation)\".format(r_squared * 100))\n\n\n4.4 Step 3.4: Run and Verify the Model\nSave and run the script again. You should see coefficients like:\n\nprice: negative (higher price = lower sales)\nfeat: positive (being featured increases sales)\nbrand coefficients: capture baseline differences between brands\ninteraction terms: show how price sensitivity differs by brand"
  },
  {
    "objectID": "courses/caio/final-project-guide.html#part-4-creating-helper-functions-for-the-agent",
    "href": "courses/caio/final-project-guide.html#part-4-creating-helper-functions-for-the-agent",
    "title": "Final Project Guide",
    "section": "5 Part 4: Creating Helper Functions for the Agent",
    "text": "5 Part 4: Creating Helper Functions for the Agent\n\n5.1 Step 4.1: Add Prediction Functions\nAdd these functions that the agent will use to answer questions:\n# ============================================\n# PART 4: HELPER FUNCTIONS FOR THE AGENT\n# ============================================\n\ndef predict_sales(brand, price, featured=0):\n    \"\"\"\n    Predict sales volume for a given brand, price, and feature status.\n    \n    Args:\n        brand: 'tropicana', 'minute.maid', or 'dominicks'\n        price: price in dollars (e.g., 2.50)\n        featured: 1 if in ad circular, 0 if not\n    \n    Returns:\n        Predicted sales volume (not log-transformed)\n    \"\"\"\n    # Create feature vector\n    features = {\n        'price': price,\n        'feat': featured,\n        'brand_minute.maid': 1 if brand.lower() == 'minute.maid' else 0,\n        'brand_tropicana': 1 if brand.lower() == 'tropicana' else 0,\n        'price_x_minute.maid': price if brand.lower() == 'minute.maid' else 0,\n        'price_x_tropicana': price if brand.lower() == 'tropicana' else 0\n    }\n    \n    # Convert to dataframe for prediction\n    X_pred = pd.DataFrame([features])\n    \n    # Predict log sales, then convert back\n    log_sales = model.predict(X_pred)[0]\n    sales = np.exp(log_sales)\n    \n    return sales\n\n\ndef get_price_elasticity(brand):\n    \"\"\"\n    Calculate the price elasticity for a given brand.\n    \n    Price elasticity tells us: if price increases by 1%, \n    how much does quantity demanded change (in %)?\n    \n    A more negative number means more price-sensitive.\n    \"\"\"\n    # Base price coefficient\n    base_coef = model.coef_[0]  # price coefficient\n    \n    # Add brand-specific interaction if applicable\n    if brand.lower() == 'minute.maid':\n        interaction_coef = model.coef_[4]  # price_x_minute.maid\n    elif brand.lower() == 'tropicana':\n        interaction_coef = model.coef_[5]  # price_x_tropicana\n    else:  # dominicks (base case)\n        interaction_coef = 0\n    \n    total_elasticity = base_coef + interaction_coef\n    return total_elasticity\n\n\ndef get_advertising_lift(brand):\n    \"\"\"\n    Calculate the sales lift from being featured in advertising.\n    Returns the percentage increase in sales.\n    \"\"\"\n    # The 'feat' coefficient tells us the log-sales increase\n    feat_coef = model.coef_[1]  # feat coefficient\n    \n    # Convert from log to percentage change\n    percentage_lift = (np.exp(feat_coef) - 1) * 100\n    return percentage_lift\n\n\ndef find_optimal_price(brand, min_price=1.0, max_price=4.0, featured=0):\n    \"\"\"\n    Find the price that maximizes revenue for a brand.\n    Revenue = Price × Quantity\n    \"\"\"\n    best_price = min_price\n    best_revenue = 0\n    \n    # Search through price range\n    for price in np.arange(min_price, max_price, 0.05):\n        sales = predict_sales(brand, price, featured)\n        revenue = price * sales\n        \n        if revenue &gt; best_revenue:\n            best_revenue = revenue\n            best_price = price\n    \n    return best_price, best_revenue\n\n\ndef compare_elasticities():\n    \"\"\"\n    Compare price elasticity across all three brands.\n    \"\"\"\n    brands = ['dominicks', 'minute.maid', 'tropicana']\n    results = {}\n    \n    for brand in brands:\n        elasticity = get_price_elasticity(brand)\n        results[brand] = elasticity\n    \n    return results\n\n\n5.2 Step 4.2: Test the Helper Functions\nAdd test code to verify the functions work:\n# ============================================\n# TEST THE HELPER FUNCTIONS\n# ============================================\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Testing helper functions...\")\nprint(\"=\"*50)\n\n# Test prediction\ntest_sales = predict_sales('tropicana', 2.50, featured=0)\nprint(f\"\\nPredicted sales for Tropicana at $2.50 (no ad): {test_sales:.0f} units\")\n\n# Test elasticity\nelasticities = compare_elasticities()\nprint(\"\\nPrice Elasticities by Brand:\")\nfor brand, elast in elasticities.items():\n    print(f\"  {brand}: {elast:.3f}\")\n\n# Test advertising lift\nlift = get_advertising_lift('minute.maid')\nprint(f\"\\nAdvertising lift: {lift:.1f}% increase in sales\")\n\n# Test optimal price\nopt_price, opt_rev = find_optimal_price('dominicks')\nprint(f\"\\nOptimal price for Dominick's: ${opt_price:.2f} (revenue: ${opt_rev:.2f})\")\nRun the script again to verify all functions work correctly."
  },
  {
    "objectID": "courses/caio/final-project-guide.html#part-5-creating-the-ai-agent",
    "href": "courses/caio/final-project-guide.html#part-5-creating-the-ai-agent",
    "title": "Final Project Guide",
    "section": "6 Part 5: Creating the AI Agent",
    "text": "6 Part 5: Creating the AI Agent\n\n6.1 Step 5.1: Add the Agent Logic\nNow we’ll create the agent that interprets natural language questions and calls the appropriate functions. Add this code:\n# ============================================\n# PART 5: THE AI AGENT\n# ============================================\n\ndef answer_question(question):\n    \"\"\"\n    Simple agent that answers business questions about OJ pricing.\n    \n    This is a rule-based agent that matches keywords in the question\n    to determine which analysis to perform.\n    \"\"\"\n    question_lower = question.lower()\n    \n    # Question 1: Predict sales for specific scenario\n    if 'predict' in question_lower or 'sales volume' in question_lower:\n        # Extract brand and price from question if possible\n        if 'tropicana' in question_lower:\n            brand = 'tropicana'\n        elif 'minute maid' in question_lower:\n            brand = 'minute.maid'\n        else:\n            brand = 'dominicks'\n        \n        # Look for price (default to $2.50 if not found)\n        import re\n        price_match = re.search(r'\\$?(\\d+\\.?\\d*)', question_lower)\n        price = float(price_match.group(1)) if price_match else 2.50\n        \n        # Check for advertising\n        featured = 1 if 'advertis' in question_lower or 'feature' in question_lower else 0\n        if 'no advertis' in question_lower or 'without advertis' in question_lower:\n            featured = 0\n        \n        sales = predict_sales(brand, price, featured)\n        \n        response = f\"\"\"\n**Predicted Sales Analysis**\n\nBrand: {brand.title().replace('.', ' ')}\nPrice: ${price:.2f}\nFeatured in Ad: {'Yes' if featured else 'No'}\n\n**Predicted Sales Volume: {sales:,.0f} units**\n\nThis prediction is based on our regression model that accounts for:\n- Base demand for this brand\n- Price sensitivity (elasticity)  \n- Advertising effects\n\"\"\"\n        return response\n    \n    # Question 2: Which brand is most price-sensitive?\n    elif 'price-sensitive' in question_lower or 'price sensitive' in question_lower or 'most sensitive' in question_lower:\n        elasticities = compare_elasticities()\n        \n        # Find most price-sensitive (most negative elasticity)\n        most_sensitive = min(elasticities, key=elasticities.get)\n        \n        response = f\"\"\"\n**Price Sensitivity Analysis**\n\nPrice Elasticity by Brand:\n\"\"\"\n        for brand, elast in sorted(elasticities.items(), key=lambda x: x[1]):\n            sensitivity = \"HIGH\" if elast &lt; -3 else \"MEDIUM\" if elast &lt; -2 else \"LOW\"\n            response += f\"- {brand.title().replace('.', ' ')}: {elast:.3f} ({sensitivity} sensitivity)\\n\"\n        \n        response += f\"\"\"\n**Most Price-Sensitive: {most_sensitive.title().replace('.', ' ')}**\n\nInterpretation: A 1% price increase leads to a {abs(elasticities[most_sensitive]):.1f}% decrease in sales for {most_sensitive.title().replace('.', ' ')}.\n\nBusiness Implication: Be careful with price increases on {most_sensitive.title().replace('.', ' ')} - customers are very responsive to price changes.\n\"\"\"\n        return response\n    \n    # Question 3: Should we feature a brand in advertising?\n    elif 'feature' in question_lower or 'ad circular' in question_lower or 'advertising' in question_lower:\n        if 'minute maid' in question_lower:\n            brand = 'minute.maid'\n        elif 'tropicana' in question_lower:\n            brand = 'tropicana'\n        else:\n            brand = 'dominicks'\n        \n        lift = get_advertising_lift(brand)\n        \n        # Calculate example impact\n        base_sales = predict_sales(brand, 2.50, featured=0)\n        featured_sales = predict_sales(brand, 2.50, featured=1)\n        \n        response = f\"\"\"\n**Advertising Impact Analysis for {brand.title().replace('.', ' ')}**\n\nExpected Sales Lift from Featuring: **{lift:.1f}%**\n\nExample at $2.50:\n- Without advertising: {base_sales:,.0f} units\n- With advertising: {featured_sales:,.0f} units  \n- Additional sales: {featured_sales - base_sales:,.0f} units\n\n**Recommendation:** {'Yes, feature this product!' if lift &gt; 20 else 'Consider the advertising cost vs. the sales lift.'}\n\nThe advertising effect is consistent across price points. Factor in your advertising costs to determine if the sales lift justifies the expense.\n\"\"\"\n        return response\n    \n    # Question 4: Optimal price for a brand\n    elif 'optimal price' in question_lower or 'maximize revenue' in question_lower or 'best price' in question_lower:\n        if 'minute maid' in question_lower:\n            brand = 'minute.maid'\n        elif 'tropicana' in question_lower:\n            brand = 'tropicana'\n        else:\n            brand = 'dominicks'\n        \n        opt_price, opt_revenue = find_optimal_price(brand)\n        opt_sales = predict_sales(brand, opt_price, featured=0)\n        \n        # Compare with current average price\n        avg_price = df[df['brand'] == brand]['price'].mean()\n        avg_revenue = avg_price * predict_sales(brand, avg_price, featured=0)\n        \n        response = f\"\"\"\n**Revenue Optimization for {brand.title().replace('.', ' ')}**\n\n**Optimal Price: ${opt_price:.2f}**\n\nAt optimal price:\n- Predicted sales: {opt_sales:,.0f} units\n- Revenue per store-week: ${opt_revenue:,.2f}\n\nComparison with current average (${avg_price:.2f}):\n- Current revenue: ${avg_revenue:,.2f}\n- Potential improvement: ${opt_revenue - avg_revenue:,.2f} ({((opt_revenue/avg_revenue)-1)*100:.1f}%)\n\nNote: This optimization assumes no competitor response and stable market conditions.\n\"\"\"\n        return response\n    \n    # Question 5: Compare elasticities across brands\n    elif 'compare' in question_lower or 'elasticity' in question_lower or 'across' in question_lower:\n        elasticities = compare_elasticities()\n        \n        response = \"\"\"\n**Price Elasticity Comparison Across Brands**\n\n| Brand | Elasticity | Interpretation |\n|-------|------------|----------------|\n\"\"\"\n        for brand, elast in sorted(elasticities.items(), key=lambda x: x[1]):\n            interp = f\"1% price ↑ → {abs(elast):.1f}% sales ↓\"\n            response += f\"| {brand.title().replace('.', ' ')} | {elast:.3f} | {interp} |\\n\"\n        \n        response += \"\"\"\n**Key Insights:**\n\n1. **Dominick's** (store brand) is least price-sensitive - customers buying store brands may prioritize value and be less responsive to small price changes.\n\n2. **Tropicana** shows moderate price sensitivity - as a premium brand, some customers are loyal but others will switch if prices rise.\n\n3. **Minute Maid** is most price-sensitive - positioned between store and premium brands, these customers actively compare prices.\n\n**Strategic Implications:**\n- Use competitive pricing on Minute Maid to capture price-sensitive shoppers\n- Tropicana can sustain moderate price premiums\n- Dominick's margins can be optimized with less risk of volume loss\n\"\"\"\n        return response\n    \n    else:\n        return \"\"\"\nI can help you with these types of questions:\n\n1. **Sales Prediction:** \"What is the predicted sales volume if we price Tropicana at $2.50?\"\n2. **Price Sensitivity:** \"Which brand is most price-sensitive?\"\n3. **Advertising Impact:** \"Should we feature Minute Maid in the ad circular?\"\n4. **Price Optimization:** \"What price should we set for Dominick's to maximize revenue?\"\n5. **Elasticity Comparison:** \"Compare the price elasticity across brands\"\n\nPlease try one of these questions!\n\"\"\"\n\n\n6.2 Step 5.2: Add the Interactive Interface\nFinally, add code to let users interact with the agent:\n# ============================================\n# PART 6: INTERACTIVE AGENT INTERFACE\n# ============================================\n\ndef run_agent():\n    \"\"\"\n    Run the interactive agent interface.\n    \"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"🍊 ORANGE JUICE PRICING ANALYTICS AGENT 🍊\")\n    print(\"=\"*60)\n    print(\"\\nHello! I'm your pricing analytics assistant.\")\n    print(\"I can help you analyze orange juice pricing and promotions.\")\n    print(\"\\nTry asking me questions like:\")\n    print(\"  - What is the predicted sales if we price Tropicana at $2.50?\")\n    print(\"  - Which brand is most price-sensitive?\")\n    print(\"  - Should we feature Minute Maid in the ad circular?\")\n    print(\"  - What price maximizes revenue for Dominick's?\")\n    print(\"  - Compare price elasticity across brands\")\n    print(\"\\nType 'quit' to exit.\\n\")\n    \n    while True:\n        question = input(\"Your question: \").strip()\n        \n        if question.lower() in ['quit', 'exit', 'q']:\n            print(\"\\nThank you for using the OJ Pricing Agent. Goodbye!\")\n            break\n        \n        if not question:\n            continue\n        \n        print(\"\\n\" + \"-\"*50)\n        response = answer_question(question)\n        print(response)\n        print(\"-\"*50 + \"\\n\")\n\n\n# ============================================\n# MAIN: RUN THE AGENT\n# ============================================\n\nif __name__ == \"__main__\":\n    # Run the interactive agent\n    run_agent()"
  },
  {
    "objectID": "courses/caio/final-project-guide.html#part-6-testing-your-agent",
    "href": "courses/caio/final-project-guide.html#part-6-testing-your-agent",
    "title": "Final Project Guide",
    "section": "7 Part 6: Testing Your Agent",
    "text": "7 Part 6: Testing Your Agent\n\n7.1 Step 6.1: Run the Complete Script\nSave the file and run:\npython oj_agent.py\n\n\n7.2 Step 6.2: Test All Five Required Questions\nTest your agent with these exact questions:\n\n“What is the predicted sales volume if we price Tropicana at $2.50 with no advertising?”\n“Which brand is most price-sensitive?”\n“Should we feature Minute Maid in this week’s ad circular? What’s the expected sales lift?”\n“What price should we set for Dominick’s brand to maximize revenue?”\n“Compare the price elasticity across the three brands.”\n\nRecord the answers for your summary document."
  },
  {
    "objectID": "courses/caio/final-project-guide.html#part-7-writing-your-summary",
    "href": "courses/caio/final-project-guide.html#part-7-writing-your-summary",
    "title": "Final Project Guide",
    "section": "8 Part 7: Writing Your Summary",
    "text": "8 Part 7: Writing Your Summary\nCreate a 1-page document (Word or PDF) that includes:\n\n8.1 Section 1: Key Findings (half page)\n\nWhich brand is most/least price-sensitive and why this matters\nThe impact of advertising on sales\nThe optimal pricing recommendations\n\n\n\n8.2 Section 2: Surprises and Insights (quarter page)\n\nWhat surprised you about the results?\nHow do these findings compare to your intuition?\n\n\n\n8.3 Section 3: Business Implications (quarter page)\n\nHow would you recommend a retailer use these insights?\nWhat additional data would make this analysis more useful?"
  },
  {
    "objectID": "courses/caio/final-project-guide.html#part-8-preparing-your-demo",
    "href": "courses/caio/final-project-guide.html#part-8-preparing-your-demo",
    "title": "Final Project Guide",
    "section": "9 Part 8: Preparing Your Demo",
    "text": "9 Part 8: Preparing Your Demo\nFor Zoom Session 3, prepare a 2-3 minute demonstration:\n\nSetup (30 sec): Briefly explain what the agent does\nDemo (1.5 min): Show 2-3 questions and responses\nInsight (1 min): Share your most interesting finding\n\nTips:\n\nHave your script running before you share screen\nPre-type a question so you’re not typing live\nFocus on business insights, not technical details"
  },
  {
    "objectID": "courses/caio/final-project-guide.html#troubleshooting",
    "href": "courses/caio/final-project-guide.html#troubleshooting",
    "title": "Final Project Guide",
    "section": "10 Troubleshooting",
    "text": "10 Troubleshooting\n\n10.1 “ModuleNotFoundError: No module named ‘pandas’”\nRun: pip install pandas numpy scikit-learn\n\n\n10.2 “FileNotFoundError: oj_data.csv”\nMake sure the data file is in the same folder as your Python script.\n\n\n10.3 “Model coefficients look wrong”\nCheck that your data loaded correctly - you should have ~28,000 rows.\n\n\n10.4 “Agent doesn’t understand my question”\nTry rephrasing using keywords like “predict”, “price-sensitive”, “feature”, “optimal”, or “compare”."
  },
  {
    "objectID": "courses/caio/final-project-guide.html#complete-code-reference",
    "href": "courses/caio/final-project-guide.html#complete-code-reference",
    "title": "Final Project Guide",
    "section": "11 Complete Code Reference",
    "text": "11 Complete Code Reference\nThe complete oj_agent.py file should be approximately 350-400 lines. If you get stuck, ask Cursor’s AI assistant for help by selecting your code and pressing Cmd+K (Mac) or Ctrl+K (Windows), then describing your issue. I also prepared a complete code reference for you to refer."
  },
  {
    "objectID": "courses/caio/final-project-guide.html#next-steps-optional-enhancements",
    "href": "courses/caio/final-project-guide.html#next-steps-optional-enhancements",
    "title": "Final Project Guide",
    "section": "12 Next Steps (Optional Enhancements)",
    "text": "12 Next Steps (Optional Enhancements)\nIf you finish early and want to explore further:\n\nAdd more questions: What other business questions could the agent answer?\nImprove the NLP: Use fuzzy matching to better understand varied phrasings\nAdd visualizations: Create charts showing price vs. sales by brand\nConnect to an LLM: Use the OpenAI API to make the agent truly conversational\n\nGood luck with your project! 🍊"
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#case-study-mudslide-threat",
    "href": "courses/caio/mudslide_slides.html#case-study-mudslide-threat",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "Case Study: Mudslide Threat",
    "text": "Case Study: Mudslide Threat\nI live in a house at risk of a mudslide damage.\n\nOption A: Build a protective wall ($10,000).\nDamage Cost: $100,000 if the house is hit (and wall fails/absent).\nWall Effectiveness: 95% protection.\nProbability of Mudslide: \\(P(\\text{Slide}) = 0.01\\).\n\nWhat is the best course of action?"
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#decision-tree-initial-options",
    "href": "courses/caio/mudslide_slides.html#decision-tree-initial-options",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "Decision Tree: Initial Options",
    "text": "Decision Tree: Initial Options\n\n\n\n\n\ngraph LR\n    Start((Decision)) --&gt; Build[Build Wall]\n    Start --&gt; NoBuild[Don't Build]\n    \n    Build -- \"$10,000\" --&gt; WallNode{Slide?}\n    WallNode -- \"0.01\" --&gt; FailNode{Wall Fails?}\n    FailNode -- \"0.05\" --&gt; Loss[\"$100,000 Cost\"]\n    FailNode -- \"0.95\" --&gt; NoLoss[\"$0 Cost\"]\n    WallNode -- \"0.99\" --&gt; NoSlide[\"$0 Cost\"]\n    \n    NoBuild -- \"$0\" --&gt; SlideNode{Slide?}\n    SlideNode -- \"0.01\" --&gt; Loss2[\"$100,000 Cost\"]\n    SlideNode -- \"0.99\" --&gt; NoLoss2[\"$0 Cost\"]"
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#comparison-no-test",
    "href": "courses/caio/mudslide_slides.html#comparison-no-test",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "Comparison: No Test",
    "text": "Comparison: No Test\nDon’t Build\n\\(EV = 0.01 \\times \\$100,000 = \\$1,000\\)\nBuild (No Test)\n\\(EV = \\$10,000 + (0.01 \\times 0.05 \\times \\$100,000) = \\$10,050\\)\n\n[!IMPORTANT] Based purely on expected cost, Don’t Build is the rational choice despite the high impact of a slide."
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#the-geological-test",
    "href": "courses/caio/mudslide_slides.html#the-geological-test",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "The Geological Test",
    "text": "The Geological Test\nA test is available to better estimate the risk.\n\nCost: $3,000\nAccuracy:\n\n\\(P( T \\mid \\text{Slide} ) = 0.90\\)\n\\(P( \\text{not } T \\mid \\text{No Slide} ) = 0.85\\)\n\n\nShould we take the test?"
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#updating-probabilities-bayes-rule",
    "href": "courses/caio/mudslide_slides.html#updating-probabilities-bayes-rule",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "Updating Probabilities: Bayes’ Rule",
    "text": "Updating Probabilities: Bayes’ Rule\nProbability of Positive Test \\(P(T)\\):\n\\(P(T) = (0.90 \\times 0.01) + (0.15 \\times 0.99) = 0.1575\\)\nPosterior \\(P(\\text{Slide} \\mid T)\\):\n\\(P(\\text{Slide} \\mid T) = \\frac{0.90 \\times 0.01}{0.1575} \\approx 0.0571\\)\nPosterior \\(P(\\text{Slide} \\mid \\text{not } T)\\):\n\\(P(\\text{Slide} \\mid \\text{not } T) = \\frac{0.1 \\times 0.01}{0.8425} \\approx 0.0012\\)"
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#the-testing-strategy",
    "href": "courses/caio/mudslide_slides.html#the-testing-strategy",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "The Testing Strategy",
    "text": "The Testing Strategy\nIf we test:\n\nIf \\(T\\): Build the wall.\nIf not \\(T\\): Don’t build.\n\nExpected Cost with Test:\n\\[\\begin{aligned}\n&\\text{Test Cost} + P(T) \\times \\text{EV(Build} \\mid T) \\\\\n&\\quad + P(\\text{not } T) \\times \\text{EV(No Build} \\mid \\text{not } T)\n\\end{aligned}\\]\n\\(= 3,000 + (0.1575 \\times 10,285) + (0.8425 \\times 120) \\approx \\$4,693\\)"
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#risk-vs.-reward",
    "href": "courses/caio/mudslide_slides.html#risk-vs.-reward",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "Risk vs. Reward",
    "text": "Risk vs. Reward\n\n\n\nChoice\nExpected Cost\nRisk of Loss\nP\n\n\n\n\nDon’t Build\n$1,000\n0.01\n1 in 100\n\n\nBuild w/o test\n$10,050\n0.0005\n1 in 2000\n\n\nTest & Decide\n$4,693\n0.00146\n1 in 700"
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#conclusion",
    "href": "courses/caio/mudslide_slides.html#conclusion",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "Conclusion",
    "text": "Conclusion\n\nLowest Expected Cost: Don’t Build ($1,000).\nLowest Risk of Catastrophe: Build without testing (0.0005).\nMiddle Ground: Testing ($4,693) significantly reduces risk compared to “Don’t Build” without the full $10k upfront cost.\n\nDecision? It depends on your utility function (risk tolerance).\nView Python Implementation (Notebook)"
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#saint-petersburg-paradox",
    "href": "courses/caio/mudslide_slides.html#saint-petersburg-paradox",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "Saint Petersburg Paradox",
    "text": "Saint Petersburg Paradox\nImagine a gambling game where a fair coin is flipped repeatedly until it lands on heads. The payoff for the game is \\(2^N\\), where \\(N\\) is the number of tosses needed for the coin to land on heads.\nThe expected value of this game is infinite:\n\\[\nE(X) = \\frac{1}{2} \\cdot 2 + \\frac{1}{4} \\cdot 4 + \\frac{1}{8} \\cdot 8 + \\ldots = \\infty\n\\]\nThis means that, in theory, a rational person should be willing to pay any finite amount to play this game. However, in reality, most people would be unwilling to pay a large amount."
  },
  {
    "objectID": "courses/caio/mudslide_slides.html#expected-utility-resolution",
    "href": "courses/caio/mudslide_slides.html#expected-utility-resolution",
    "title": "Decision Analysis: The Mudslide Problem",
    "section": "Expected Utility Resolution",
    "text": "Expected Utility Resolution\nBernoulli argued that people do not maximize expected monetary value but rather expected utility \\(U(x)\\).\n\\[\nE[U(X)] = \\sum^\\infty_{k=1} 2^{-k} U(2^k)\n\\]\nFor the log utility case, \\(U(x) = \\log(x)\\), the expected utility is \\(2 \\log(2)\\). To find the certain dollar amount \\(x^*\\) (certainty equivalent) that provides the same utility:\n\\[\n\\log(x^*) = 2\\log(2) = \\log(2^2) = \\log(4) \\implies x^* = 4\n\\]\nUnder log utility, a rational player would pay at most $4 to play, despite the infinite expected monetary value."
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html",
    "href": "courses/caio/topic-overview-caio.html",
    "title": "Machine Learning Essentials",
    "section": "",
    "text": "Online: 2 Weeks (14 Days)\nEmail: vsokolov@gmu.edu\nPhone: 703 993 4533\nCourse Textbook: Bayes, AI and Deep Learning by Nick Polson and Vadim Sokolov. The book is to be published by Chapman & Hall/CRC in 2026. Available for free online."
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#topic-purpose",
    "href": "courses/caio/topic-overview-caio.html#topic-purpose",
    "title": "Machine Learning Essentials",
    "section": "Topic Purpose",
    "text": "Topic Purpose\nThe purpose of this topic is to introduce participants to the foundational concepts of artificial intelligence and data-driven decision making. Participants will develop a working understanding of probability, statistical modeling, and modern AI techniques—equipping them to lead AI initiatives, evaluate AI investments, and communicate effectively with technical teams."
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#topic-overview",
    "href": "courses/caio/topic-overview-caio.html#topic-overview",
    "title": "Machine Learning Essentials",
    "section": "Topic Overview",
    "text": "Topic Overview\nThis module takes executives on a journey from the fundamentals of probability and uncertainty through statistical modeling to the cutting edge of modern AI. Rather than focusing on mathematical derivations, we emphasize intuition, real-world applications, and business implications. Through compelling case studies—from wrongful convictions caused by probability errors to the Netflix Prize’s lessons about model complexity—participants will learn to think probabilistically about business decisions. The module culminates in a hands-on project where participants build an AI agent using Cursor IDE, directly experiencing how data, models, and AI agents work together to solve business problems."
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#topic-objectives",
    "href": "courses/caio/topic-overview-caio.html#topic-objectives",
    "title": "Machine Learning Essentials",
    "section": "Topic Objectives",
    "text": "Topic Objectives\nUpon completion of this topic, you should understand and be able to:\n\nApply probabilistic thinking to business decisions under uncertainty\nRecognize common probability fallacies (prosecutor’s fallacy, base rate neglect) and their business implications\nUnderstand the trade-offs between model accuracy, complexity, and business value\nInterpret regression models and explain their predictions to stakeholders\nEvaluate when AI/ML solutions are appropriate versus traditional statistical approaches\nBuild a simple AI agent that combines data analysis with natural language interaction\nLead informed conversations with data science and AI teams"
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#course-approach",
    "href": "courses/caio/topic-overview-caio.html#course-approach",
    "title": "Machine Learning Essentials",
    "section": "Course Approach",
    "text": "Course Approach\nThis topic combines asynchronous learning (recorded lectures, readings, discussion boards) with synchronous sessions (live Zoom calls) and hands-on practice. The approach emphasizes:\n\nCase-based learning: Each concept is grounded in real-world examples—from legal cases to sports analytics to retail pricing\nBusiness-first perspective: Technical concepts are always connected to business decisions and outcomes\nProgressive building: Each module builds on the previous, culminating in an integrated final project\nPeer learning: Discussion boards encourage sharing experiences and learning from diverse industry perspectives\nApplied practice: The final project provides hands-on experience building an AI-powered analytics tool"
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#time-commitment",
    "href": "courses/caio/topic-overview-caio.html#time-commitment",
    "title": "Machine Learning Essentials",
    "section": "Time Commitment",
    "text": "Time Commitment\nThis topic will require approximately 10 hours of work to complete:\n\n\n\nActivity\nHours\n\n\n\n\nRecorded Lectures (3 lectures × 30 min)\n1.5\n\n\nLive Zoom Sessions (3 sessions × 1 hr)\n3.0\n\n\nReading\n2\n\n\nDiscussion Boards\n1.0\n\n\nFinal Project\n2.0\n\n\nTotal\n10.0"
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#schedule",
    "href": "courses/caio/topic-overview-caio.html#schedule",
    "title": "Machine Learning Essentials",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\nDay\nActivities\n\n\n\n\nDay 1-2\nModule 1 lectures available; begin readings on probability and Bayes rule\n\n\nDay 3\nDiscussion Board 1 opens\n\n\nDay 4\nZoom Session 1: Kick-off + Cursor IDE Hands-on (1 hr)\n\n\nDay 5-6\nModule 2 lectures available; readings on statistics and regression\n\n\nDay 7\nDiscussion Board 2 opens\n\n\nDay 8\nZoom Session 2: Mid-point Check-in (1 hr)\n\n\nDay 9-10\nModule 3 lectures available; readings on NLP and AI agents\n\n\nDay 11\nDiscussion Board 3 opens\n\n\nDay 12-13\nFinal Project work time\n\n\nDay 14\nZoom Session 3: Wrap-up + Final Project Presentations (1 hr)"
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#module-1-probability-as-a-language-of-uncertainty",
    "href": "courses/caio/topic-overview-caio.html#module-1-probability-as-a-language-of-uncertainty",
    "title": "Machine Learning Essentials",
    "section": "Module 1: Probability as a Language of Uncertainty",
    "text": "Module 1: Probability as a Language of Uncertainty\nDays 1-4\n\nRecorded Lectures\n\nPart 1: Probability\nPart 2: Bayes Rule\n\n\n\nRequired Reading (from course textbook)\nChapter 1: Probability and Uncertainty\n\nOpening sections through “Kolmogorov Axioms”\nSection: “Conditional, Marginal and Joint Distributions”\nExample: Salary-Happiness\n\nChapter 2: Bayes Rule\n\nSection: “Intuition and Simple Examples”\nExample: Sally Clark Case\nExample: Nakamura’s Alleged Cheating\n\nChapter 4: Utility, Risk and Decisions\n\nSection: “Expected Utility”\nExamples: Saint Petersburg Paradox, Kelly Criterion, Ellsberg Paradox, Secretary Problem\nSection: “Decision Trees” (including Medical Testing and Mudslide examples)\n\n\n\nSupplemental Reading (online)\n\nDid a US Chess Champion Cheat? - Chicago Booth Review (Bayesian analysis, prosecutor’s fallacy)\nA Refresher on Statistical Significance - Harvard Business Review\nDecision Making in Uncertain Times - McKinsey\n\n\n\nDiscussion Board: Decision-Making Under Uncertainty\nOpens Day 3 | Due Day 7\n“Consider a strategic decision your organization recently faced (or is currently facing) involving uncertainty. Describe the decision and identify:\n\nWhat were the key uncertain factors?\nHow was probability or likelihood assessed (formally or informally)?\nReflecting on the Ellsberg paradox and Kelly criterion, how might a more systematic probabilistic approach have changed the decision-making process?\n\nRespond to at least two peers’ posts with constructive suggestions.”\n\n\nZoom Session 1: Kick-off + Cursor Hands-on\nDay 4 | 1 hour\n\nWelcome and module overview (15 min)\nHands-on: Setting up Cursor IDE and using coding agents (30 min)\nQ&A on probability concepts from Module 1 (15 min)\n\nPreparation: Install Cursor IDE before the session (setup instructions)"
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#module-2-statistics-and-modeling",
    "href": "courses/caio/topic-overview-caio.html#module-2-statistics-and-modeling",
    "title": "Machine Learning Essentials",
    "section": "Module 2: Statistics and Modeling",
    "text": "Module 2: Statistics and Modeling\nDays 5-8\n\nRecorded Lectures\n\nStatistics\n\n\n\nRequired Reading (from course textbook)\nChapter 1: Probability and Uncertainty\n\nSections: “Normal Distribution,” “Poisson Distribution,” “Binomial Distribution”\nExamples: Heights of Adults, Customer Arrivals, NFL Patriots Coin Toss\n\nChapter 3: Bayesian Learning\n\nSection: “Poisson Model for Count Data”\n\nChapter 12: Linear Regression\n\nSection: “Linear Regression” (opening)\nExamples: Google vs S&P 500, Orange Juice\n\nChapter 13: Logistic Regression and GLMs\n\nSections: “Model Fitting,” “Confusion Matrix,” “ROC Curve”\nExample: NBA point spread\n\n\n\nSupplemental Reading (online)\n\nThe Surprising Power of Online Experiments - Harvard Business Review (A/B testing)\nMachine Learning Explained - MIT Sloan\n\n\n\nDiscussion Board: Predictive Models in Business\nOpens Day 7 | Due Day 11 “The Netflix Prize awarded $1 million for a 10% improvement in recommendation accuracy, yet Netflix never fully implemented the winning algorithm—it was too complex and expensive to deploy, and by then, streaming had changed the business model entirely. See Why Even a Million Dollars Couldn’t Buy a Better Algorithm - Wired (Netflix Prize case study)\nReflecting on this case and the regression concepts from this module:\n\nIdentify a business process in your organization where a predictive model could be applied. What decisions would it inform?\nWhat would happen if the model’s predictions were inaccurate 20% of the time? 40% of the time? How would this affect business outcomes and trust in the system?\nDiscuss the trade-off: Is a highly accurate but complex/expensive model always better than a simpler, ‘good enough’ model? What factors would you consider when making this decision?\n\nRespond to at least two peers’ posts, particularly focusing on whether you agree with their assessment of the accuracy-complexity trade-off.”\n\n\nZoom Session 2: Mid-point Check-in\nDay 8 | 1 hour\n\nReview of statistical modeling concepts (20 min)\nLive demo: Building a simple regression model with Cursor (25 min)\nDiscussion of final project requirements (15 min)\n\nPreparation: Complete Module 2 lectures and readings"
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#module-3-modern-ai",
    "href": "courses/caio/topic-overview-caio.html#module-3-modern-ai",
    "title": "Machine Learning Essentials",
    "section": "Module 3: Modern AI",
    "text": "Module 3: Modern AI\nDays 9-14\n\nRequired Reading (from course textbook)\nChapter 24: Natural Language Processing\n\nSections: “Converting Words to Numbers (Embeddings),” “Word2Vec and Distributional Semantics”\nExample: Word2Vec for War and Peace\nSections: “Attention Mechanisms,” “Transformer Architecture” (overview)\n\nChapter 26: AI Agents\n\nFull chapter overview (agent architecture, tool use, planning, safety)\n\n\n\nSupplemental Reading (online)\n\nMaking the Most of AI and Machine Learning in Organizations - Stanford SMJ Paper\nTraditional Statistics vs Machine Learning - ToolsGroup\nThe State of AI in 2024 - McKinsey\nGenerative AI’s Act Two - Sequoia Capital\n\n\n\nDiscussion Board: AI Agents in the Enterprise\nOpens Day 11 | Due Day 14\n“AI agents are increasingly being deployed in business contexts. Describe a workflow or process in your organization that could potentially be automated or augmented by an AI agent. Address:\n\nWhat tasks would the agent perform?\nWhat data or tools would it need access to?\nWhat guardrails or human oversight would be necessary?\nWhat risks or concerns would need to be addressed before deployment?\n\nRespond to at least two peers’ posts.”\n\n\nZoom Session 3: Wrap-up + Final Project Presentations\nDay 14 | 1 hour\n\nBrief Modern AI recap (10 min)\nFinal project presentations/demonstrations (35 min)\nCourse wrap-up and next steps for AI leadership (15 min)\n\nPreparation: Complete final project; prepare 2-3 minute demonstration"
  },
  {
    "objectID": "courses/caio/topic-overview-caio.html#assignment-final-project",
    "href": "courses/caio/topic-overview-caio.html#assignment-final-project",
    "title": "Machine Learning Essentials",
    "section": "Assignment: Final Project",
    "text": "Assignment: Final Project\n\nOrange Juice Pricing Analytics Agent\nThis part (as ever other part of the module) is optional.\nBusiness Problem: You are a pricing analyst at a retail chain. Management wants to optimize orange juice pricing and promotional strategies. Build an AI agent that can answer business questions about pricing decisions using historical sales data and a predictive model.\nDataset: Dominick’s Orange Juice Dataset\n\nWeekly sales data for orange juice brands (Tropicana, Minute Maid, Dominick’s)\nVariables: sales volume, price, advertising features, brand\n~28,000 observations across multiple stores\n\nModel: Linear Regression with Interactions\n\nPredict sales volume based on price, advertising, and brand\nCapture how price sensitivity varies by brand\n\nYour Agent Must Answer These Business Questions:\n\n“What is the predicted sales volume if we price Tropicana at $2.50 with no advertising?”\n“Which brand is most price-sensitive?”\n“Should we feature Minute Maid in this week’s ad circular? What’s the expected sales lift?”\n“What price should we set for Dominick’s brand to maximize revenue?”\n“Compare the price elasticity across the three brands.”\n\nDeliverables:\n\nPython code files in Cursor IDE (using provided template)\nWorking agent that answers the 5 business questions above\n1-page summary: What did you learn about OJ pricing? What surprised you?\n2-3 minute demo during Zoom Session 3\n\nEvaluation Criteria:\n\nFunctionality: Agent loads data, builds model, and responds to queries\nBusiness Relevance: Clear connection between model outputs and business decisions\nDocumentation: Clear explanation of approach and results\n\nSee Final Project Guide for detailed step-by-step instructions."
  }
]