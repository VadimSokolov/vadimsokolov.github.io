<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Vadim Sokolov – f20</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv.html" rel="" target="">
 <span class="menu-text">cv</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html" rel="" target="">
 <span class="menu-text">research</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teaching" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">teaching</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-teaching">    
        <li>
    <a class="dropdown-item" href="../../courses/468.html" rel="" target="">
 <span class="dropdown-text">Predictive Analytics (UG)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/568.html" rel="" target="">
 <span class="dropdown-text">Predictive Analytics (MS)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/664.html" rel="" target="">
 <span class="dropdown-text">Bayes (MS)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/610.html" rel="" target="">
 <span class="dropdown-text">Deep Learning (MS)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/750.html" rel="" target="">
 <span class="dropdown-text">Bayesian Learning (PhD)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/41000/41000.html" rel="" target="">
 <span class="dropdown-text">Statistics (MBA)</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="or-610.-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="or-610.-deep-learning">OR 610. Deep Learning</h2>
<p><strong>Department of Systems Engineering and Operations Research</strong><br>
<strong>George Mason University</strong><br>
<strong>Fall 2020</strong><br>
\</p>
</section>
<section id="courses" class="level1">
<h1>Courses</h1>
</section>
<section id="httpsdatacamp.comgroupsshared_links486def6889202c4d41d141bdc1427622d88eaf788c2ec719b020cc75fa32821a" class="level1">
<h1>https://datacamp.com/groups/shared_links/486def6889202c4d41d141bdc1427622d88eaf788c2ec719b020cc75fa32821a</h1>
</section>
<section id="httpwww.machinelearning.ruwikiindex.phptitleглубинное_обучение_28курс_лекций292019" class="level1">
<h1>http://www.machinelearning.ru/wiki/index.php?title##Глубинное_обучение_%28курс_лекций%29/2019</h1>
</section>
<section id="httpsgithub.comaosokindl_cshse_amitreemaster2019-spring" class="level1">
<h1>https://github.com/aosokin/dl_cshse_ami/tree/master/2019-spring</h1>
</section>
<section id="httpwww.machinelearning.ruwikiindex.phptitleнейробайесовские_методы_машинного_обучения_28курс_лекций29__2020" class="level1">
<h1>http://www.machinelearning.ru/wiki/index.php?title##Нейробайесовские_методы_машинного_обучения_%28курс_лекций%29_/_2020</h1>
</section>
<section id="httpswww.coursera.orglearnfundamentals-of-reinforcement-learninghomeweek1" class="level1">
<h1>https://www.coursera.org/learn/fundamentals-of-reinforcement-learning/home/week/1</h1>
</section>
<section id="httpsgithub.comyandexdataschoolpractical_dl" class="level1">
<h1>https://github.com/yandexdataschool/Practical_DL</h1>
</section>
<section id="httpsgithub.comyandexdataschoolpractical_rl" class="level1">
<h1>https://github.com/yandexdataschool/Practical_RL</h1>
<p>#password: deepmsclass <a href="https://www.dropbox.com/sh/gddm5kwboe64tyz/AACObyZjs3xUkbq7wUrE9Ujea?dl##0">Course Material</a> \</p>
<p>#https://piazza.com/demo_login?nid##ke7yfo8fkwx12i&amp;auth##6905b70 <a href="https://piazza.com/gmu/fall2020/or610">Piazza</a> \</p>
<p><strong>Instructor</strong>: <a href="http://vsokolov.org%20Vadim%20Sokolov">(vsokolov(at)gmu.edu</a>)<br>
<strong>TA</strong>: Ali Seyedmazloom (aseyedma (at) masonlive.gmu.edu)<br>
<strong>Office hours</strong>: By appointment<br>
</p>
<section id="datacamp" class="level4">
<h4 class="anchored" data-anchor-id="datacamp">Datacamp</h4>
<p>If you are rusty on Python, I suggest you refresh your skills using <a href="https://datacamp.com/groups/shared_links/486def6889202c4d41d141bdc1427622d88eaf788c2ec719b020cc75fa32821a">Datacamp</a>. Datacamp gave students in this class a free access to all of the courses. If you follow the link above you can get your free access using masonlive email. I also listed some of the Python courses I suggest there.</p>
</section>
<section id="schedule-homework-are-due-on-mondays-at-noon" class="level4">
<h4 class="anchored" data-anchor-id="schedule-homework-are-due-on-mondays-at-noon">Schedule (Homework are due on Mondays at noon)</h4>
<section id="week-1-aug-24-introduction" class="level6">
<h6 class="anchored" data-anchor-id="week-1-aug-24-introduction">Week 1 (Aug 24): Introduction</h6>
<ul>
<li><a href="https://coursera.org/share/5c500f68d0a17831417a69284f8e3a4a">What is a neural network?</a></li>
<li><a href="https://coursera.org/share/9c132474e78df7c4c019d6c91d224a8d">Supervised Learning with Neural Networks</a></li>
<li><a href="https://coursera.org/share/0a61ee951fa8f1edee71a8bdf764c145">Why is Deep Learning taking off?</a></li>
<li><a href="https://coursera.org/share/05dc735b893bd7268a41210d116da060">Linear Model</a></li>
<li><a href="https://coursera.org/share/549f09ddb524697de6ffbb0865fcbef4">Linear classification</a></li>
</ul>
</section>
<section id="week-2-aug-31-gradient-descent" class="level6">
<h6 class="anchored" data-anchor-id="week-2-aug-31-gradient-descent">Week 2 (Aug 31): Gradient Descent</h6>
<ul>
<li><a href="https://coursera.org/share/710ed082ffe55f749fcf67dac0b2c00e%20Logistic%20Regression%20Cost">Function</a></li>
<li><a href="https://coursera.org/share/c15d6d08249e04465f62697025bd2dc9%20Gradient">Descent</a></li>
<li><a href="https://coursera.org/share/d12377d5f947cbc7c4b7195fa9c8d2b9">Derivatives</a></li>
<li><a href="https://coursera.org/share/dc19bfe6c6214c02ca6dc00511b1b928%20More%20Derivative">Examples</a></li>
<li><a href="https://coursera.org/share/51fd0223f440c4b921a6325009721911%20Computation">graph</a></li>
<li><a href="https://coursera.org/share/9f167a2ac022e262795db23a31da4773%20Derivatives%20with%20a%20Computation">Graph</a></li>
<li><a href="https://coursera.org/share/1912c891ccb60c95843b056e7ce16ed0%20Logistic%20Regression%20Gradient">Descent</a></li>
<li><a href="https://coursera.org/share/5cd4e8e94de9809a9e9804f324b9c14b%20Gradient%20Descent%20on%20m">Examples</a></li>
</ul>
</section>
<section id="week-3-sep-7-neural-networks" class="level6">
<h6 class="anchored" data-anchor-id="week-3-sep-7-neural-networks">Week 3 (Sep 7): Neural Networks</h6>
<ul>
<li>HW1 Due</li>
<li><a href="https://coursera.org/share/410ca1012714f99104d0310f087e2aba%20Neural%20Networks">Overview</a></li>
<li><a href="https://coursera.org/share/b49295af20ee8bc35363df4115e4a730%20Neural%20Network">Representation</a></li>
<li><a href="https://coursera.org/share/eba336cd7c3ac2e5bdebdf374acf5ada%20Computing%20a%20Neural%20Network's">Output</a></li>
<li><a href="https://coursera.org/share/a1d06e73b2832db2b55aa6f30d512b7d%20Vectorizing%20across%20multiple">examples</a></li>
<li><a href="https://coursera.org/share/f58a66a796711d80bc704b94739796aa%20Explanation%20for%20Vectorized">Implementation</a></li>
<li><a href="https://coursera.org/share/ef6aa088c2c54dad657c5d8357c4067e%20Activation">functions</a></li>
<li><a href="https://coursera.org/share/6aa2a5ab825821d906fc3bf1281acdb0%20Why%20do%20you%20need%20non-linear%20activation">functions?</a></li>
<li><a href="https://coursera.org/share/aa496bf6bcafde8e66e3c6df7744e9e4%20Derivatives%20of%20activation">functions</a></li>
<li><a href="https://coursera.org/share/c4b2b5c02ea549819d9432043912da5b%20Gradient%20descent%20for%20Neural">Networks</a></li>
<li><a href="https://coursera.org/share/a02f6514f0aafdd5385b11d30e0ed93e">Backpropagation</a></li>
<li><a href="https://coursera.org/share/11f721bc9b15dbfcce72f5e995a93fd1%20Random">Initialization</a></li>
<li><a href="https://coursera.org/share/ad07c49b88c58301536544f9ec2d607e%20Efficient%20MLP">implementation</a></li>
<li><a href="https://coursera.org/share/4739f97c8f5dff9e62ea979bb847fae5%20Other%20matrix">derivatives</a> ###### Week 4 (Sep 14): PyTorch</li>
<li>HW2 Due (NN) ###### Week 5 (Sep 21): Optimization and regularization</li>
<li><a href="https://youtu.be/wEoyxE0GP2M%20Training%20Neural%20Networks">(a)</a></li>
<li><a href="https://youtu.be/_JB0AO7QxSA%20Training%20Neural%20Networks">(b)</a></li>
<li>HW3 due (PyTorch) ###### Week 6, 7 (Sep 28, Oct 5): CNN</li>
<li>HW4 Due (Optimisation)</li>
<li>Lecture 9 of CS231n (<a href="https://youtu.be/DAOcjicFr1Y%20video">notes)</a>, <a href="https://cs231n.github.io/convolutional-networks/"></a> ###### Week 8,9 (Oct 12, Oct 19): Recurrent Nets</li>
<li>Project proposals due ###### Week 10,11, 12 (Oct 26, Nov 2, Nov 9): Bayesian Neural Networks (Hinton Notes)</li>
<li><a href="https://www.cs.toronto.edu/~hinton/coursera/lecture9/lec9d.mp4%209d%20-%20Introduction%20to%20the%20bayesian">approach</a></li>
<li><a href="https://www.cs.toronto.edu/~hinton/coursera/lecture9/lec9e.mp4%209e%20-%20The%20bayesian%20interpretation%20of%20weight">decay</a></li>
<li><a href="https://www.cs.toronto.edu/~hinton/coursera/lecture9/lec9f.mp4%209f%20-%20MacKays%20quick%20and%20dirty%20method%20of%20fixing%20weight">costs</a></li>
<li><a href="https://www.cs.toronto.edu/~hinton/coursera/lecture10/lec10a.mp4%2010a%20-%20Why%20it%20helps%20to%20combine">models</a></li>
<li><a href="https://www.cs.toronto.edu/~hinton/coursera/lecture10/lec10b.mp4%2010b%20-%20Mixtures%20of">experts</a></li>
<li><a href="https://www.cs.toronto.edu/~hinton/coursera/lecture10/lec10c.mp4%2010c%20-%20The%20idea%20of%20full%20bayesian">learning</a></li>
<li><a href="https://www.cs.toronto.edu/~hinton/coursera/lecture10/lec10d.mp4%2010d%20-%20Making%20full%20bayesian%20learning">practical</a></li>
<li><a href="https://www.cs.toronto.edu/~hinton/coursera/lecture10/lec10e.mp4%2010e%20-%20Dropout%20an%20efficient%20way%20to%20combine%20neural">nets</a> ###### Week 13, 14 (Nov 16, Nov 30): Deep Reinforcement Learning</li>
<li>Lectures 1-5 by David Silver (<a href="https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver%20videos%20and">slides)</a></li>
<li>HW6 due (Bayes) ###### Week 15 (Dec 7): Final Projects</li>
<li>Final projects are due.</li>
</ul>
</section>
</section>
<section id="data-analysis-projects" class="level4">
<h4 class="anchored" data-anchor-id="data-analysis-projects">Data analysis projects</h4>
<p>You will work in a team of up to 3 people on a Kaggle-like project and will apply deep learning to solve a prediction or data generation problem. By week 8 of the class you should have a team formed and data set + analysis problem identified. You need to submit a 0.5-1 page description of the data and problem you are trying to solve for my feedback and approval. Proposal has to have names and emails of the team members. Description of data set, problem to be solved and proposed architectures.</p>
<p>You will post results of your analysis on the class blog post. The final project will be graded on presentation, writing and analysis.</p>
<p>All of the posts based on the presentations are posted here <a href="http://vsokolov.org/or610fall2020/">vsokolov.org/or610fall2020</a></p>
</section>
<section id="group-work" class="level4">
<h4 class="anchored" data-anchor-id="group-work">Group Work</h4>
<p>Both projects and homework can be done in a groups of size of up to 3 people. You can change groups in between. If you do a homework in a gorup, it means that all of the members of the group do it individually and can consult with each other. You can also do 1 submission per group if you prefer. You can use “group” section of the piazza page to find teammates if you need any. If you need help finding a group, please email me.</p>
</section>
<section id="grading" class="level4">
<h4 class="anchored" data-anchor-id="grading">Grading</h4>
<p>Each hw is 10 points, project is 30.</p>
</section>
</section>
<section id="hw" class="level1">
<h1>#### HW</h1>
</section>
<section id="tutorial-due-sep-18.-optional" class="level1">
<h1>- <a href="https://www.dropbox.com/s/6r3ff01q64584zu/1.pdf?dl##1%20HW1">tutorial</a>, Due Sep 18. Optional: <a href="http://#%20cs231n.github.io/python-numpy-tutorial/%20numpy"></a></h1>
</section>
<section id="hw2-due-sep-29" class="level1">
<h1>- <a href="https://www.dropbox.com/s/im1r52z56j5bhdm/2.pdf?dl##1">HW2</a>, Due Sep 29</h1>
</section>
<section id="hw3-due-oct-9" class="level1">
<h1>- <a href="https://www.dropbox.com/s/2bmw6hgbwp82squ/3.pdf?dl##1">HW3</a>, Due Oct 9</h1>
</section>
<section id="hw4-due-oct-30" class="level1">
<h1>- <a href="https://www.dropbox.com/s/64d50djasajv7ke/hw4.ipynb?dl##1">HW4</a>, Due Oct 30</h1>
</section>
<section id="hw5" class="level1">
<h1>- <a href="https://www.dropbox.com/s/wx59moxlzkt9bpc/5.pdf?dl##5">HW5</a></h1>
<p>\ This is a graduate level course focused on developing deep learning predictive models. We will learn both practical and theoretical aspects of deep learning. We will consider applications in engineering, finance and artificial intelligence. It is targeted towards the students who have completed an introductory courses in statistics and optimization. We will make extensive use of computational tools, such as the Python language, both for illustration in class and in homework problems. The class will consist of 9 lectures given by the instructor on several advanced topics in deep learning. At another 5 lectures students will present on a given topic. \</p>
<section id="books" class="level4">
<h4 class="anchored" data-anchor-id="books">Books</h4>
<ul>
<li>Goodfellow, Ian, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning. Vol. 1. Cambridge: MIT press, 2016.</li>
<li>Ripley, Brian D. Pattern recognition and neural networks. Cambridge university press, 2007.</li>
<li>Bishop, Christopher M. Neural networks for pattern recognition. Oxford university press, 1995.</li>
</ul>
</section>
<section id="per-topic-resources" class="level4">
<h4 class="anchored" data-anchor-id="per-topic-resources">Per Topic Resources</h4>
<section id="architectures" class="level6">
<h6 class="anchored" data-anchor-id="architectures">Architectures</h6>
<ul>
<li>Tuning CNN architecture (<a href="https://bowenbaker.github.io/metaqnn/">blog)</a></li>
<li>Sequence to Sequence Learning with Neural Networks (<a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">paper)</a></li>
<li>Skip RNN (<a href="http://www.gitxiv.com/posts/6ozns2NF7odKrHZ3r/skip-rnn%20blog%20and">paper)</a></li>
<li>Learning the Enigma with Recurrent Neural Networks (<a href="https://greydanus.github.io/2017/01/07/enigma-rnn/">blog)</a></li>
<li>LSTM <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">blog</a></li>
<li>Generative Adversarial Networks (<a href="https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks">presentation)</a></li>
<li>GANs at OpenAI (<a href="https://blog.openai.com/generative-models/?utm_content##buffer50108,utm_medium##social,utm_source##twitter.com,utm_campaign##buffer">blog)</a></li>
<li>Adaptive Neural Trees (<a href="https://arxiv.org/pdf/1807.06699.pdf">paper)</a></li>
<li><a href="https://arxiv.org/pdf/1604.03640.pdf%20Bridging%20the%20Gaps%20Between%20Residual%20Learning,%20Recurrent%20Neural%20Networks%20and%20Visual">Cortex</a></li>
<li><a href="https://arxiv.org/pdf/1512.03385v1.pdf%20Deep%20Residual%20Learning%20for%20Image">Recognition</a></li>
<li><a href="https://arxiv.org/pdf/1507.06228v2.pdf%20Training%20Very%20Deep">Networks</a></li>
<li><a href="https://arxiv.org/pdf/1803.01271.pdf%20An%20Empirical%20Evaluation%20of%20Generic%20Convolutional%20and%20Recurrent%20Networks%20for%20Sequence">Modeling</a></li>
<li><a href="https://arxiv.org/pdf/1807.03247.pdf%20An%20intriguing%20failing%20of%20convolutional%20neural%20networks%20and%20the%20CoordConv">solution</a></li>
<li><a href="https://arxiv.org/abs/1706.03762%20Attention%20Is%20All%20You">Need</a></li>
<li><a href="https://arxiv.org/abs/1701.00160%20NIPS%202016%20Tutorial:%20Generative%20Adversarial">Networks</a></li>
<li><a href="https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf%20Intuitively%20Understanding%20Variational">Autoencoders</a></li>
<li><a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">WaveNet</a></li>
<li><a href="http://proceedings.mlr.press/v48/oord16">PixelCNN</a></li>
<li><a href="Neural Processes">https://chrisorm.github.io/NGP.html</a></li>
</ul>
</section>
<section id="optimization" class="level6">
<h6 class="anchored" data-anchor-id="optimization">Optimization</h6>
<ul>
<li><a href="https://web.stanford.edu/~boyd/cvxbook/%20BV">Book</a></li>
<li><a href="http://www.convexoptimization.com/TOOLS/ConvexAnalysisRockafellar.pdf%20Convex%20Analysis%20by%20Rockafellar">(1970</a>)</li>
<li><a href="https://youtu.be/xpwx0LIz-bs%20Nesterov's">Lecture</a></li>
<li><a href="./files/nesterov.pdf Nesterov">(1983)</a></li>
<li><a href="./files/polyak64.pdf Polyak">(1964)</a></li>
<li><a href="https://papers.nips.cc/paper/3323-the-tradeoffs-of-large-scale-learning.pdf%20The%20Tradeoffs%20of%20Large%20Scale">Learning</a></li>
<li><a href="https://www.springer.com/us/book/9781402075537%20Nesterov">(2004)</a></li>
<li>HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent (<a href="http://i.stanford.edu/hazy/papers/hogwild-nips.pdf">paper)</a></li>
<li>SGD (<a href="https://xianblog.wordpress.com/2017/05/10/the-invasion-of-the-stochastic-gradients/">link)</a></li>
<li><a href="https://arxiv.org/pdf/1704.05201.pdf%20Stein%20Variational%20Adaptive%20Importance">Sampling</a></li>
<li><a href="https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf%20Bayesian%20Learning%20via%20Stochastic%20Gradient%20Langevin">Dynamics</a></li>
<li><a href="https://arxiv.org/pdf/1512.07962.pdf%20Bridging%20the%20Gap%20between%20Stochastic%20Gradient%20MCMC%20and%20Stochastic">Optimization</a></li>
<li><a href="https://arxiv.org/abs/1806.09055%20DARTS:%20Differentiable%20Architecture%20Search">code)</a> (<a href="https://t.co/36J7HUbYkD"></a></li>
<li><a href="https://arxiv.org/abs/1611.01578%20Neural%20Architecture%20Search%20with%20Reinforcement%20Learning">code)</a> (<a href="https://github.com/carpedm20/ENAS-pytorch"></a></li>
<li><a href="https://arxiv.org/abs/1802.01548%20Regularized%20Evolution%20for%20Image%20Classifier%20Architecture">Search</a></li>
<li><a href="http://proceedings.mlr.press/v28/sutskever13.pdf%20On%20the%20importance%20of%20initialization%20and%20momentum%20in%20deep">learning</a></li>
<li><a href="http://www.bioinf.jku.at/publications/older/3304.pdf%20Flat">Minima</a></li>
<li><a href="https://distill.pub/2017/momentum/%20Why%20Momentum%20Really">Works</a></li>
<li><a href="https://arxiv.org/pdf/1609.04836.pdf%20On%20Large-Batch%20Training%20for%20Deep%20Learning:%20Generalization%20Gap%20and%20Sharp">Minima</a></li>
<li><a href="https://arxiv.org/pdf/1703.04933.pdf%20Sharp%20Minima%20Can%20Generalize%20For%20Deep">Nets</a></li>
<li><a href="https://arxiv.org/pdf/1802.10026.pdf%20Loss%20Surfaces,%20Mode%20Connectivity,%20and%20Fast%20Ensembling%20of">DNNs</a></li>
<li><a href="https://papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning.pdf%20The%20Marginal%20Value%20of%20Adaptive%20Gradient%20Methods%20in%20Machine">Learning</a></li>
<li><a href="https://blogs.princeton.edu/imabandit/2015/06/30/revisiting-nesterovs-acceleration/%20Revisiting%20Nesterov’s">Acceleration</a></li>
</ul>
</section>
<section id="theory" class="level6">
<h6 class="anchored" data-anchor-id="theory">Theory</h6>
<ul>
<li>Polyak, Boris, and Pavel Shcherbakov. “Why does Monte Carlo fail to work properly in high-dimensional optimization problems?.” Journal of Optimization Theory and Applications 173, no. 2 (2017): 612-627. (<a href="https://arxiv.org/pdf/1603.00311.pdf">paper)</a></li>
<li>Leni, Pierre-Emmanuel, Yohan D. Fougerolle, and Frédéric Truchetet. “Kolmogorov superposition theorem and its application to multivariate function decompositions and image representation.” In Signal Image Technology and Internet Based Systems, 2008. SITIS’08. IEEE International Conference on, pp.&nbsp;344-351. IEEE, 2008. (<a href="./files/kolmogorov.pdf">paper)</a></li>
<li>Klartag, Bo’az. “A central limit theorem for convex sets.” Inventiones mathematicae 168, no. 1 (2007): 91-131. (<a href="https://arxiv.org/pdf/math/0605014.pdf%20paper">slides)</a>, <a href="http://web.math.unifi.it/users/salani/cortona2007/talks/klartag.pdf"></a></li>
<li>Sun, Chen, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta. “Revisiting unreasonable effectiveness of data in deep learning era.” In Computer Vision (ICCV), 2017 IEEE International Conference on, pp.&nbsp;843-852. IEEE, 2017. (<a href="https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html">blog)</a></li>
<li>Bengio, Yoshua, Aaron Courville, and Pascal Vincent. “Representation learning: A review and new perspectives.” IEEE transactions on pattern analysis and machine intelligence 35, no. 8 (2013): 1798-1828. (<a href="http://www.iro.umontreal.ca/~lisa/pointeurs/TPAMISI-2012-04-0260-1.pdf">paper)</a></li>
<li>Braun, Jürgen. “An application of Kolmogorov’s superposition theorem to function reconstruction in higher dimensions.” (2009). (<a href="./files/braun_disser.pdf">dissertation)</a></li>
<li>Kolmogorov. “On the Representation of Continuous Functions of Several Variables as Superpositions of Continuous Functions of a Smaller Number of Variables” (<a href="./files/Kolmogorov1961.pdf">paper)</a></li>
<li>Arnold. “On functions of three variables” (<a href="./file/Arnold2009Collection.pdf collection of">papers)</a></li>
<li>Bianchini, Monica, and Franco Scarselli. “On the complexity of shallow and deep neural network classifiers.” In ESANN. 2014.(<a href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2014-44.pdf">paper)</a></li>
<li>Girosi, Federico, and Tomaso Poggio. “Representation properties of networks: Kolmogorov’s theorem is irrelevant.” Neural Computation 1, no. 4 (1989): 465-469. (<a href="./files/Girosi89.pdf">paper)</a></li>
<li>Kůrková, Věra. “Kolmogorov’s theorem and multilayer neural networks.” Neural networks 5, no. 3 (1992): 501-506. (<a href="./files/Kurkova92.pdf">paper)</a></li>
<li>Poggio, Tomaso, Hrushikesh Mhaskar, Lorenzo Rosasco, Brando Miranda, and Qianli Liao. “Why and when can deep-but not shallow-networks avoid the curse of dimensionality: a review.” International Journal of Automation and Computing 14, no. 5 (2017): 503-519. (<a href="https://arxiv.org/pdf/1611.00740.pdf">paper)</a></li>
<li>Telgarsky, Matus. “Representation benefits of deep feedforward networks.” arXiv preprint arXiv:1509.08101 (2015). (<a href="https://arxiv.org/abs/1509.08101">paper)</a></li>
<li>Montufar, Guido F., Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. “On the number of linear regions of deep neural networks.” In Advances in neural information processing systems, pp.&nbsp;2924-2932. 2014. (<a href="https://arxiv.org/abs/1402.1869">paper)</a></li>
<li>Zhang, Chiyuan, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. “Understanding deep learning requires rethinking generalization.” arXiv preprint arXiv:1611.03530 (2016). (<a href="https://arxiv.org/abs/1611.03530">paper)</a></li>
<li>Lin, Henry W., Max Tegmark, and David Rolnick. “Why does deep and cheap learning work so well?.” Journal of Statistical Physics 168, no. 6 (2017): 1223-1247. (<a href="https://arxiv.org/abs/1608.08225">paper)</a></li>
<li>Stéphane Mallat 1: Mathematical Mysteries of Deep Neural Networks (<a href="https://youtu.be/0wRItoujFTA">video)</a></li>
<li><a href="https://dspace.mit.edu/bitstream/handle/1721.1/107787/CBMM-Memo-066.pdf?sequence##4%20Theory%20of%20Deep%20Learning%20II:%20Landscape%20of%20the%20Empirical%20Risk%20in%20Deep">Learning</a></li>
<li><a href="./filed/Kolmogorov1957.pdf On the representation of continuous functions of many variables by superposition of continuous functions of one variable and">addition</a></li>
<li><a href="./files/matus.pdf Representation Power of Feed forward Neural">Networks</a></li>
<li><a href="https://arxiv.org/pdf/1512.03965.pdf%20The%20Power%20of%20Depth%20for%20Feedforward%20Neural">Networks</a></li>
</ul>
</section>
<section id="reinforcement-learning" class="level6">
<h6 class="anchored" data-anchor-id="reinforcement-learning">Reinforcement Learning</h6>
<p><a href="https://arxiv.org/abs/1802.10592%20Model-Ensemble%20Trust-Region%20Policy">Optimization</a> <a href="https://arxiv.org/abs/1805.12114%20Deep%20Reinforcement%20Learning%20in%20a%20Handful%20of%20Trials%20using%20Probabilistic%20Dynamics">Models</a> - <a href="http://www.argmin.net/2018/02/20/reinforce/%20The%20Policy%20of">Truth</a> - <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html%20Deep%20Reinforcement%20Learning%20Doesn't%20Work">Yet</a></p>
</section>
<section id="section-5-bayesian-dl" class="level6">
<h6 class="anchored" data-anchor-id="section-5-bayesian-dl">Section 5: Bayesian DL</h6>
<ul>
<li>VAE with a VampPrior (<a href="https://arxiv.org/pdf/1705.07120.pdf">paper)</a></li>
<li>Bayesian DL (<a href="http://www.datasciencecentral.com/profiles/blogs/a-curated-list-of-resources-dedicated-to-bayesian-deep-learning?utm_content##buffer3671b,utm_medium##social,utm_source##twitter.com,utm_campaign##buffer">blog)</a></li>
<li>Recognition Networks for Approximate Inference in BN20 Networks (<a href="https://arxiv.org/pdf/1301.2295.pdf">paper)</a></li>
<li>Non-linear regression models for Approximate Bayesian Computation (<a href="https://arxiv.org/abs/0809.4178">paper)</a></li>
<li>DR-ABC: Approximate Bayesian Computation with Kernel-Based Distribution Regression (<a href="https://arxiv.org/abs/1602.04805">paper)</a></li>
<li>Fast ε-free Inference of Simulation Models with Bayesian Conditional Density Estimation (<a href="https://arxiv.org/abs/1605.06376">paper)</a></li>
<li>Auto-Encoding Variational Bayes (<a href="https://arxiv.org/abs/1312.6114">paper)</a></li>
<li>Composing graphical models with neural networks for structured representations and fast inference (<a href="https://arxiv.org/abs/1603.06277">paper)</a></li>
<li><a href="https://arxiv.org/pdf/1802.02538.pdf%20Yes,%20but%20Did%20It%20Work?:%20Evaluating%20Variational">Inference</a></li>
</ul>
</section>
<section id="practical-tricks" class="level6">
<h6 class="anchored" data-anchor-id="practical-tricks">Practical Tricks</h6>
<ul>
<li><a href="https://towardsdatascience.com/stochastic-weight-averaging-a-new-way-to-get-state-of-the-art-results-in-deep-learning-c639ccf36a">Averaging</a></li>
<li><ul>
<li>Normalization Propagation: A Parametric Technique for Removing Internal Covariate Shift in Deep Networks (<a href="https://arxiv.org/pdf/1603.01431.pdf">paper)</a></li>
</ul></li>
<li>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (<a href="https://arxiv.org/pdf/1502.03167.pdf">paper)</a></li>
<li>Auto-Encoding Variational Bayes (<a href="https://arxiv.org/pdf/1312.6114.pdf">paper)</a></li>
<li>Twin Networks: Using the Future as a Regularizer (<a href="https://arxiv.org/pdf/1708.06742.pdf">paper)</a></li>
<li>Don’t Decay the Learning Rate, Increase the Batch Size (<a href="https://arxiv.org/abs/1711.00489">paper)</a></li>
<li>DL Tuning (<a href="http://theorangeduck.com/page/neural-network-not-working">blog)</a></li>
<li><a href="https://arxiv.org/pdf/1703.09039.pdf%20Efficient%20Processing%20of%20Deep%20Neural%20Networks:%20A%20Tutorial%20and">Survey</a></li>
</ul>
</section>
</section>
<section id="other-resources" class="level4">
<h4 class="anchored" data-anchor-id="other-resources">Other Resources</h4>
<section id="additional-reading-list" class="level6">
<h6 class="anchored" data-anchor-id="additional-reading-list">Additional Reading List</h6>
<ul>
<li>50 Years of Data Science by Donoho (<a href="./files/50YearsofDataScience.pdf">paper)</a></li>
<li><a href="https://arxiv.org/pdf/1404.7828.pdf%20Deep%20Learning%20in%20Neural%20Networks:%20An">Overview</a></li>
<li><a href="https://arxiv.org/pdf/1806.11146.pdf%20Adversarial%20Reprogramming%20of%20Neural">Networks</a></li>
<li><a href="http://unsupervised.cs.princeton.edu/deeplearningtutorial.html%20Toward%20theoretical%20understanding%20of%20deep">learning</a></li>
</ul>
</section>
<section id="blogs" class="level6">
<h6 class="anchored" data-anchor-id="blogs">Blogs</h6>
<ul>
<li>Papers with code <a href="https://paperswithcode.com">link</a></li>
<li>Security (<a href="http://www.cleverhans.io">blog)</a></li>
<li>Unsupervised learning (<a href="https://medium.com/intuitionmachine/navigating-the-unsupervised-learning-landscape-951bd5842df9">blog)</a></li>
<li>Cybersecurity (<a href="https://medium.com/@jason_trost/collection-of-deep-learning-cyber-security-research-papers-e1f856f71042%20paper">collection)</a></li>
<li><a href="http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html%20Opt">Visualization</a></li>
</ul>
</section>
<section id="videos" class="level6">
<h6 class="anchored" data-anchor-id="videos">Videos</h6>
<ul>
<li>Deep Energy (<a href="https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/">blog)</a></li>
<li>DL Summer school 2015 (<a href="http://videolectures.net/deeplearning2015_montreal/">videos)</a></li>
<li>DL Representations (<a href="http://netdissect.csail.mit.edu">blog)</a></li>
<li>PyData 2017 (<a href="https://www.analyticsvidhya.com/blog/2017/05/pydata-amsterdam-2017-machine-learning-deep-learning-data-science/">videos)</a></li>
</ul>
</section>
<section id="other-courses-with-good-web-presence" class="level6">
<h6 class="anchored" data-anchor-id="other-courses-with-good-web-presence">Other courses with good web presence</h6>
<ul>
<li>Stanford’s CS231n (<a href="http://cs231n.github.io%20course">page)</a></li>
<li>Stanford’s STATS385 (<a href="https://stats385.github.io%20course">page)</a></li>
<li><a href="http://www.fast.ai">fast.ai</a></li>
<li><a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/%20Nando%20de%20Freitas’%20course%20on%20machine">learning</a></li>
<li>UC Berkeley Stat241B (<a href="https://bcourses.berkeley.edu/courses/1409209/pages/lectures">lectures)</a></li>
<li>UCUC CSE598 (<a href="http://mjt.web.engr.illinois.edu/courses/mlt-f17/%20course">page)</a></li>
<li><a href="https://github.com/udacity/deep-reinforcement-learning%20Udacity">DRL</a></li>
</ul>
</section>
<section id="tools" class="level6">
<h6 class="anchored" data-anchor-id="tools">Tools</h6>
<ul>
<li><a href="https://www.tensorflow.org">TensorFlow</a></li>
<li><a href="https://keras.io">Keras</a></li>
<li><a href="http://playground.tensorflow.org%20TF%20Playground">(Google</a>)</li>
<li><a href="https://dl.sony.com%20DL">Sony</a></li>
<li><a href="https://jiffyclub.github.io/snakeviz/%20SnakeViz">profiler</a> (python)</li>
<li><a href="http://pytorch.org">PyTorch</a></li>
<li><a href="https://github.com/jeffalstott/pystan_time_series%20TS%20Stan">Examples</a></li>
<li><a href="https://blog.openai.com/glow/%20OpenAI">Glow</a></li>
</ul>
</section>
<section id="misc-links" class="level6">
<h6 class="anchored" data-anchor-id="misc-links">Misc Links</h6>
<ul>
<li><a href="https://github.com/ritchieng/the-incredible-pytorch%20Pytorch%20resources">projects</a> (a curated list of tutorials, papers,)</li>
<li><a href="https://www.christies.com/Features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx%20Is%20artificial%20intelligence%20set%20to%20become%20art’s%20next">medium?</a></li>
</ul>
</section>
</section>
<section id="previous-instances" class="level4">
<h4 class="anchored" data-anchor-id="previous-instances">Previous instances</h4>
<ul>
<li><a href="./2017/index.html Fall">2017</a></li>
<li><a href="./2018/index.html Fall">2018</a></li>
</ul>
<p>#https://www.coursera.org/learn/intro-to-deep-learning #http://www.machinelearning.ru/wiki/index.php?title##Глубинное_обучение_%28курс_лекций%29/2017 #https://github.com/aosokin/dl_cshse_ami/tree/master/2019-spring #https://bayesgroup.ru/teaching/ #saddepal@gmu.edu;savala@gmu.edu;fbehnia@gmu.edu;schava@gmu.edu;hgangava@gmu.edu;xgitiaux@gmu.edu;vgunnala@gmu.edu;nhuang2@gmu.edu;wkirsche@gmu.edu;jkrishn@gmu.edu;slakaman@gmu.edu;elynch9@gmu.edu;mmittapa@gmu.edu;gn@gmu.edu;krajend2@gmu.edu;srayapro@gmu.edu;asaid8@gmu.edu;oshaat@gmu.edu;ashambhu@gmu.edu;asothor2@gmu.edu;tstickl@gmu.edu;rzimme10@gmu.edu;aachary@gmu.edu;jbashata@gmu.edu;zchai2@gmu.edu;ychen37@gmu.edu;zfan3@gmu.edu;agharibr@gmu.edu;bghimire@gmu.edu;cgrubb@gmu.edu;zjiang@gmu.edu;nnewman7@gmu.edu;rpandey4@gmu.edu;tsmith58@gmu.edu;jwang40@gmu.edu;fyu2@gmu.edu;dzhang22@gmu.edu</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>