<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Vadim Sokolov – f19</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv.html" rel="" target="">
 <span class="menu-text">cv</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html" rel="" target="">
 <span class="menu-text">research</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teaching" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">teaching</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-teaching">    
        <li>
    <a class="dropdown-item" href="../../courses/468.html" rel="" target="">
 <span class="dropdown-text">Predictive Analytics (UG)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/568.html" rel="" target="">
 <span class="dropdown-text">Predictive Analytics (MS)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/664.html" rel="" target="">
 <span class="dropdown-text">Bayes (MS)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/610.html" rel="" target="">
 <span class="dropdown-text">Deep Learning (MS)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/750.html" rel="" target="">
 <span class="dropdown-text">Bayesian Learning (PhD)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../courses/41000/41000.html" rel="" target="">
 <span class="dropdown-text">Statistics (MBA)</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="or-750610.-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="or-750610.-deep-learning">OR 750/610. Deep Learning</h2>
<p><strong>Department of Systems Engineering and Operations Research</strong><br>
<strong>George Mason University</strong><br>
<strong>Fall 2019</strong><br>
\</p>
<p><a href="https://www.dropbox.com/sh/baa7xf79uu9ol7a/AAC_We5RC3kqMGoABB51YGxra?dl##0%20Course">Material</a> \</p>
<p><strong>Instructor</strong>: <a href="http://vsokolov.org%20Vadim%20Sokolov">(vsokolov(at)gmu.edu</a>)<br>
<strong>Office hours</strong>: By appointment<br>
<strong>TA</strong>: Wanru Li (wli15(at)masonlive.gmu.edu)<br>
<strong>Office Hours</strong>: Mon 4-6 pm at ENGR 2216</p>
<section id="presentation-materials" class="level4">
<h4 class="anchored" data-anchor-id="presentation-materials">Presentation Materials</h4>
<p>All of the posts based on the presentations are posted here <a href="https://dlclass2019.github.io">dlclass2019.github.io</a></p>
<section id="phd" class="level6">
<h6 class="anchored" data-anchor-id="phd">PhD</h6>
<p>Please upload your materials to <a href="https://www.dropbox.com/request/UPTOWsxmzLpByhda34he">here</a>.</p>
<p>To post your blog, send me your GiHub handle and use this <a href="https://help.github.com/en/github/working-with-github-pages/adding-content-to-your-github-pages-site-using-jekyll">instructions</a> to add your post</p>
<ul>
<li>10/30: Uncertainty and Super resolution by Xavier Guitiaux. 40-60 min. Blog by Trajectory team. <a href="http://arxiv.org/abs/1911.01490%20paper%201">2</a>, <a href="http://arxiv.org/abs/1911.01486%20paper"></a></li>
<li>11/6: Unbalanced data and Generalization by Zhengyang Fan, Di Zhang, Zhenlong Jiang. Full lecture. Blog by NLP team\</li>
</ul>
<p><a href="https://www.dropbox.com/s/rn03ncyn7zgwdb5/or750_zhengyang%20fan%20and%20zhenlong%20jiang%20and%20di%20zhang.pdf?dl##1">Slides</a>\</p>
<p>Notes from Zhengyang Fan on prep materials:<br>
</p>
<p>The presentation for next class will mainly focus on interpolation phenomenon, and I plan to start this topic from kernel regression, thus some background in kernel space would be helpful for students. I have prepared a brief introduction for kernel space (<a href="../../pdf/KernelSpace.pdf file">helpful</a>), which was also included in our presentation slides as backup slides. For students who are willing to have a deeper understanding of kernel, the following <a href="http://www.gatsby.ucl.ac.uk/~gretton/coursefiles/lecture4_introToRKHS.pdf%20lecture%20note%20is"></a>, which includes some visualizations and simple examples.<br>
</p>
<p>For Rademacher complexity and uniform laws o larger numbers, following papers and lecture notes can be useful for students: – <a href="http://www.jmlr.org/papers/volume3/bartlett02a/bartlett02a.pdf%20Rademacher%20complexity">paper</a> – <a href="https://www.cs.cmu.edu/~ninamf/ML11/lect1117.pdf%20Rademacher%20complexity%20lecture">note</a> – <a href="https://en.wikipedia.org/wiki/Rademacher_complexity%20Rademacher%20complexity">wiki</a> – <a href="https://www.stat.berkeley.edu/~mjwain/stat210b/Chap4_Uniform_Feb4_2015.pdf%20Uniform%20Laws%20of%20Large%20Numbers%20lecture">note</a><br>
My presentation on theory of deep learning is mainly based on the following <a href="https://simons.berkeley.edu/workshops/schedule/10624%20video%20lectures">series</a>. Students who are interested in theory may benefit from these video lectures.</p>
<ul>
<li>11/13 NLP by Rahul Pandey, Angeela, Junxiang(Will), Jomana. Full lecture. Blog by the unbalanced/generalization team</li>
<li>11/20 Adverarial Atatchs by Farnaz Behnia and Azadeh Gharibreza Yazdi. Half lecture. Blog by Uncertainty team</li>
<li>11/20 Trajecotry Generation by Chris Grubb. 40-60 min. Blog by adversarial team</li>
</ul>
</section>
<section id="ms" class="level6">
<h6 class="anchored" data-anchor-id="ms">MS</h6>
<p>Please upload your 1-page proposals to <a href="https://www.dropbox.com/request/sb6aoseTcf03D0XHQnms">here</a>. Deadline is 11/6. Proposal has to have names and emails of the team members. Description of data set, problem to be solved and proposed architectures.</p>
<ul>
<li>11/20</li>
<li>12/4</li>
</ul>
</section>
</section>
<section id="hw" class="level4">
<h4 class="anchored" data-anchor-id="hw">HW</h4>
<ul>
<li><a href="https://www.dropbox.com/s/6r3ff01q64584zu/1.pdf?dl##1%20HW1">tutorial</a>, Due Sep 18. Optional: <a href="http://cs231n.github.io/python-numpy-tutorial/%20numpy"></a></li>
<li><a href="https://www.dropbox.com/s/im1r52z56j5bhdm/2.pdf?dl##1">HW2</a>, Due Sep 29</li>
<li><a href="https://www.dropbox.com/s/2bmw6hgbwp82squ/3.pdf?dl##1">HW3</a>, Due Oct 9</li>
<li><a href="https://www.dropbox.com/s/64d50djasajv7ke/hw4.ipynb?dl##1">HW4</a>, Due Oct 30</li>
<li><a href="https://www.dropbox.com/s/wx59moxlzkt9bpc/5.pdf?dl##5">HW5</a></li>
</ul>
</section>
<section id="announcements" class="level4">
<h4 class="anchored" data-anchor-id="announcements">Announcements</h4>
<ul>
<li>Presentation/Project proposals due Oct 16</li>
<li>9/3/2019: Room changed to EXPL L111</li>
<li>3/15/2019: No Class on October 23 (INFORMS Meeting)</li>
<li>3/15/2019: No Class on November 27 (Thanksgiving recess)</li>
<li>3/15/2019: First class is on Aug 28 at 7:20pm</li>
<li>3/15/2019: Last class is on Dec 4</li>
</ul>
</section>
<section id="schedule" class="level4">
<h4 class="anchored" data-anchor-id="schedule">Schedule</h4>
<ul>
<li>DL Overview + Python (numpy and PyTorch) (Week 1)<br>
Notes Ch 1; <a href="https://arxiv.org/abs/1808.08618">Polson18</a></li>
<li>Probability (Week 2)<br>
Notes Ch 2-3; <a href="https://homes.cs.washington.edu/~pedrod/papers/mlc00a.pdf">Domingos</a><br>
Optional DLB Ch 3</li>
<li>Optimization: SGD, Backprop (Week 3)<br>
Notes Ch 4, <a href="https://arxiv.org/pdf/1502.05767.pdf">Baydin17</a>,</li>
<li>Architectures (Week 4)<br>
Notes ch 5; <a href="https://arxiv.org/pdf/1606.05328.pdf">Oord16</a></li>
<li>More optimization (Week 5)<br>
<a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Glorot10</a></li>
<li>Bayes DL (6-7)<br>
<a href="https://arxiv.org/pdf/1603.00391.pdf%20p1">p3</a>, <a href="https://arxiv.org/pdf/1805.00784.pdf%20p2"></a>, <a href="https://arxiv.org/pdf/1906.02691.pdf"></a></li>
<li>DL Theory (Week 8)</li>
<li>Research paper presentations (Week 9-12)</li>
<li>Project Presentations (Week 13)</li>
</ul>
<p>\ This is a graduate level course focused on developing deep learning predictive models. We will learn both practical and theoretical aspects of deep learning. We will consider applications in engineering, finance and artificial intelligence. It is targeted towards the students who have completed an introductory courses in statistics and optimization. We will make extensive use of computational tools, such as the Python language, both for illustration in class and in homework problems. The class will consist of 9 lectures given by the instructor on several advanced topics in deep learning. At another 5 lectures students will present on a given topic. \ The lectures and homework for 750 and 610 are the same. The difference is in the final project. If you are registered for 750, you will read and present research papers and if you are registered for 610 you will do a Kaggle-type project. Both research paper presentations and projects are to be done in a group of size up to 5 for research papers and 3 for projects.</p>
</section>
<section id="research-paper-presentations-by-750-students" class="level4">
<h4 class="anchored" data-anchor-id="research-paper-presentations-by-750-students">Research paper presentations by 750 students</h4>
<p>During weeks 9-12, this class will be run in a seminar mode. A team of students will prepare a topic and will lead the discussion and another team will write a blog-post about the class and will post it on Medium. Students responsible for posting the blog summary will be different from the ones charged with leading the topic discussion, but should work closely with the leaders on the posted write-up.</p>
<section id="leading-team.-the-team-responsible-for-leading-a-class-should" class="level6">
<h6 class="anchored" data-anchor-id="leading-team.-the-team-responsible-for-leading-a-class-should">Leading Team. The team responsible for leading a class should:</h6>
<ul>
<li>Two weeks before the scheduled class, meet briefly with me to discuss plan for the class. You should decide on a team leader for this class, who will be the one responsible for making sure everyone on the team knows what they are doing and coordinating the team’s efforts.</li>
<li>The Monday the week of the class, at least a few representatives from the team should come to my office to discuss the plan for the class. You should come prepared to this meeting with suggested papers and ideas about how to present them.</li>
<li>On Tuesday before class, send me the preparation materials for the class. This can include links to papers to read, but could also include exercises to do or software to install and experiment with, etc. I will post it on the course page.</li>
<li>Day of class: lead an interesting, engaging, and illuminating class! This is a 2.5 hour class, so it can’t just be a series of unconnected, dull presentations. You need to think of things to do in class to make it more worthwhile and engaging.</li>
<li>After class: help the Blogging team by providing them with your materials, answering their questions, and reviewing their write-up.</li>
</ul>
</section>
<section id="blogging-team.-the-team-responsible-for-blogging-a-class-should" class="level6">
<h6 class="anchored" data-anchor-id="blogging-team.-the-team-responsible-for-blogging-a-class-should">Blogging Team. The team responsible for blogging a class should:</h6>
<ul>
<li>The week before the scheduled class, develop a team plan for how to manage the blogging.</li>
<li>One team member should be designated the team leader for the blogging. The blogging leader is responsible for making sure the team is well coordinated and everyone knows what they are doing and follows through on this.</li>
<li>During class, participate actively in the class, and take detailed notes (this can be distributed among the team).</li>
<li>By the Wed following class, have a the blog post ready and posted on Medium. Get comments from the rest of the class (including the leading team and coordinators).</li>
<li>By the next Friday (one week after the class), have a final version of the blog post ready.</li>
</ul>
</section>
<section id="suggested-research-paper-topics" class="level6">
<h6 class="anchored" data-anchor-id="suggested-research-paper-topics">Suggested Research Paper Topics</h6>
<ul>
<li>Adversarial attacks</li>
<li>DL in reinforcement learning</li>
<li>Interpretable DL</li>
<li>Science applications of DL (physics, molecular biology,…)</li>
<li>Engineering applications of DL (logistics, energy, smart grids, congestion management,…)</li>
<li>Natural language processing</li>
</ul>
</section>
</section>
<section id="data-analysis-projects-by-610-students" class="level4">
<h4 class="anchored" data-anchor-id="data-analysis-projects-by-610-students">Data analysis projects by 610 students</h4>
<p>You will work in a team of up to 3 people on a Kaggle-like project and will apply deep learning to solve a prediction or data generation problem. By week 9 of the class you should have a team formed and data set + analysis problem identified. You need to email me a 0.5-1 page description of the data and problem you are trying to solve for my feedback and approval. During week 13, you will have a time slot to present your findings. You are also encouraged (although it is not required) to post results of your analysis on Medium, if you think it is worth sharing.</p>
</section>
<section id="course-staff" class="level4">
<h4 class="anchored" data-anchor-id="course-staff">Course staff</h4>
<p><strong>Lectures</strong>: <a href="https://goo.gl/maps/d8yJBSXQXnzpmoz3A%20Exploratory">Hall</a> L111. 7:20-10pm on Wed<br>
<strong>Grades</strong>: 40% homework, 60% class presentations<br>
</p>
</section>
<section id="list-of-topics" class="level4">
<h4 class="anchored" data-anchor-id="list-of-topics">List of topics</h4>
<ul>
<li>Convex Optimization – Stochastic gradient descent and its variants (ADAM, RMSpropr, Nesterov acceleration) – Second order methods – ADMM – Regularization (l1, l2 and dropout) – Batch normalization</li>
<li>Theory of deep learning – Universal approximators – Curse of dimensionality – Kernel spaces – Topology and geometry</li>
<li>Computational aspects (accelerated linear algebra, reduced precision calculations, parallelism)</li>
<li>Architectures (CNN, LSTM, MLP, VAE)</li>
<li>Bayesian DL</li>
<li>Deep reinforcement learning</li>
<li>Hyperparameter selection and parameter initialization</li>
<li>Generative models (GANs)</li>
</ul>
</section>
<section id="books" class="level4">
<h4 class="anchored" data-anchor-id="books">Books</h4>
<ul>
<li>Deep Learning (DLB) (<a href="http://www.deeplearningbook.org%20book">page)</a></li>
<li>Deep Learning with Python (DLPB) (<a href="https://www.manning.com/books/deep-learning-with-python%20book">page)</a></li>
<li>Learning Deep Architectures for AI (<a href="files/bengiofull2009.pdf">monograph)</a></li>
</ul>
</section>
<section id="per-topic-resources" class="level4">
<h4 class="anchored" data-anchor-id="per-topic-resources">Per Topic Resources</h4>
<section id="section-1-architectures" class="level6">
<h6 class="anchored" data-anchor-id="section-1-architectures">Section 1: Architectures</h6>
<ul>
<li>Tuning CNN architecture (<a href="https://bowenbaker.github.io/metaqnn/">blog)</a></li>
<li>Sequence to Sequence Learning with Neural Networks (<a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">paper)</a></li>
<li>Skip RNN (<a href="http://www.gitxiv.com/posts/6ozns2NF7odKrHZ3r/skip-rnn%20blog%20and">paper)</a></li>
<li>Learning the Enigma with Recurrent Neural Networks (<a href="https://greydanus.github.io/2017/01/07/enigma-rnn/">blog)</a></li>
<li>LSTM <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">blog</a></li>
<li>Generative Adversarial Networks (<a href="https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks">presentation)</a></li>
<li>GANs at OpenAI (<a href="https://blog.openai.com/generative-models/?utm_content##buffer50108,utm_medium##social,utm_source##twitter.com,utm_campaign##buffer">blog)</a></li>
<li>Adaptive Neural Trees (<a href="https://arxiv.org/pdf/1807.06699.pdf">paper)</a></li>
<li><a href="https://arxiv.org/pdf/1604.03640.pdf%20Bridging%20the%20Gaps%20Between%20Residual%20Learning,%20Recurrent%20Neural%20Networks%20and%20Visual">Cortex</a></li>
<li><a href="https://arxiv.org/pdf/1512.03385v1.pdf%20Deep%20Residual%20Learning%20for%20Image">Recognition</a></li>
<li><a href="https://arxiv.org/pdf/1507.06228v2.pdf%20Training%20Very%20Deep">Networks</a></li>
<li><a href="https://arxiv.org/pdf/1803.01271.pdf%20An%20Empirical%20Evaluation%20of%20Generic%20Convolutional%20and%20Recurrent%20Networks%20for%20Sequence">Modeling</a></li>
<li><a href="https://arxiv.org/pdf/1807.03247.pdf%20An%20intriguing%20failing%20of%20convolutional%20neural%20networks%20and%20the%20CoordConv">solution</a></li>
<li><a href="https://arxiv.org/abs/1706.03762%20Attention%20Is%20All%20You">Need</a></li>
<li><a href="https://arxiv.org/abs/1701.00160%20NIPS%202016%20Tutorial:%20Generative%20Adversarial">Networks</a></li>
<li><a href="https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf%20Intuitively%20Understanding%20Variational">Autoencoders</a></li>
<li><a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">WaveNet</a></li>
<li><a href="http://proceedings.mlr.press/v48/oord16">PixelCNN</a></li>
<li><a href="Neural Processes">https://chrisorm.github.io/NGP.html</a></li>
</ul>
</section>
<section id="section-2-optimization" class="level6">
<h6 class="anchored" data-anchor-id="section-2-optimization">Section 2: Optimization</h6>
<ul>
<li><a href="https://web.stanford.edu/~boyd/cvxbook/%20BV">Book</a></li>
<li><a href="http://www.convexoptimization.com/TOOLS/ConvexAnalysisRockafellar.pdf%20Convex%20Analysis%20by%20Rockafellar">(1970</a>)</li>
<li><a href="https://youtu.be/xpwx0LIz-bs%20Nesterov's">Lecture</a></li>
<li><a href="./files/nesterov.pdf Nesterov">(1983)</a></li>
<li><a href="./files/polyak64.pdf Polyak">(1964)</a></li>
<li><a href="https://papers.nips.cc/paper/3323-the-tradeoffs-of-large-scale-learning.pdf%20The%20Tradeoffs%20of%20Large%20Scale">Learning</a></li>
<li><a href="https://www.springer.com/us/book/9781402075537%20Nesterov">(2004)</a></li>
<li>HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent (<a href="http://i.stanford.edu/hazy/papers/hogwild-nips.pdf">paper)</a></li>
<li>SGD (<a href="https://xianblog.wordpress.com/2017/05/10/the-invasion-of-the-stochastic-gradients/">link)</a></li>
<li><a href="https://arxiv.org/pdf/1704.05201.pdf%20Stein%20Variational%20Adaptive%20Importance">Sampling</a></li>
<li><a href="https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf%20Bayesian%20Learning%20via%20Stochastic%20Gradient%20Langevin">Dynamics</a></li>
<li><a href="https://arxiv.org/pdf/1512.07962.pdf%20Bridging%20the%20Gap%20between%20Stochastic%20Gradient%20MCMC%20and%20Stochastic">Optimization</a></li>
<li><a href="https://arxiv.org/abs/1806.09055%20DARTS:%20Differentiable%20Architecture%20Search">code)</a> (<a href="https://t.co/36J7HUbYkD"></a></li>
<li><a href="https://arxiv.org/abs/1611.01578%20Neural%20Architecture%20Search%20with%20Reinforcement%20Learning">code)</a> (<a href="https://github.com/carpedm20/ENAS-pytorch"></a></li>
<li><a href="https://arxiv.org/abs/1802.01548%20Regularized%20Evolution%20for%20Image%20Classifier%20Architecture">Search</a></li>
<li><a href="http://proceedings.mlr.press/v28/sutskever13.pdf%20On%20the%20importance%20of%20initialization%20and%20momentum%20in%20deep">learning</a></li>
<li><a href="http://www.bioinf.jku.at/publications/older/3304.pdf%20Flat">Minima</a></li>
<li><a href="https://distill.pub/2017/momentum/%20Why%20Momentum%20Really">Works</a></li>
<li><a href="https://arxiv.org/pdf/1609.04836.pdf%20On%20Large-Batch%20Training%20for%20Deep%20Learning:%20Generalization%20Gap%20and%20Sharp">Minima</a></li>
<li><a href="https://arxiv.org/pdf/1703.04933.pdf%20Sharp%20Minima%20Can%20Generalize%20For%20Deep">Nets</a></li>
<li><a href="https://arxiv.org/pdf/1802.10026.pdf%20Loss%20Surfaces,%20Mode%20Connectivity,%20and%20Fast%20Ensembling%20of">DNNs</a></li>
<li><a href="https://papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning.pdf%20The%20Marginal%20Value%20of%20Adaptive%20Gradient%20Methods%20in%20Machine">Learning</a></li>
<li><a href="https://blogs.princeton.edu/imabandit/2015/06/30/revisiting-nesterovs-acceleration/%20Revisiting%20Nesterov’s">Acceleration</a></li>
</ul>
</section>
<section id="section-3-theory" class="level6">
<h6 class="anchored" data-anchor-id="section-3-theory">Section 3: Theory</h6>
<ul>
<li>Polyak, Boris, and Pavel Shcherbakov. “Why does Monte Carlo fail to work properly in high-dimensional optimization problems?.” Journal of Optimization Theory and Applications 173, no. 2 (2017): 612-627. (<a href="https://arxiv.org/pdf/1603.00311.pdf">paper)</a></li>
<li>Leni, Pierre-Emmanuel, Yohan D. Fougerolle, and Frédéric Truchetet. “Kolmogorov superposition theorem and its application to multivariate function decompositions and image representation.” In Signal Image Technology and Internet Based Systems, 2008. SITIS’08. IEEE International Conference on, pp.&nbsp;344-351. IEEE, 2008. (<a href="./files/kolmogorov.pdf">paper)</a></li>
<li>Klartag, Bo’az. “A central limit theorem for convex sets.” Inventiones mathematicae 168, no. 1 (2007): 91-131. (<a href="https://arxiv.org/pdf/math/0605014.pdf%20paper">slides)</a>, <a href="http://web.math.unifi.it/users/salani/cortona2007/talks/klartag.pdf"></a></li>
<li>Sun, Chen, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta. “Revisiting unreasonable effectiveness of data in deep learning era.” In Computer Vision (ICCV), 2017 IEEE International Conference on, pp.&nbsp;843-852. IEEE, 2017. (<a href="https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html">blog)</a></li>
<li>Bengio, Yoshua, Aaron Courville, and Pascal Vincent. “Representation learning: A review and new perspectives.” IEEE transactions on pattern analysis and machine intelligence 35, no. 8 (2013): 1798-1828. (<a href="http://www.iro.umontreal.ca/~lisa/pointeurs/TPAMISI-2012-04-0260-1.pdf">paper)</a></li>
<li>Braun, Jürgen. “An application of Kolmogorov’s superposition theorem to function reconstruction in higher dimensions.” (2009). (<a href="./files/braun_disser.pdf">dissertation)</a></li>
<li>Kolmogorov. “On the Representation of Continuous Functions of Several Variables as Superpositions of Continuous Functions of a Smaller Number of Variables” (<a href="./files/Kolmogorov1961.pdf">paper)</a></li>
<li>Arnold. “On functions of three variables” (<a href="./file/Arnold2009Collection.pdf collection of">papers)</a></li>
<li>Bianchini, Monica, and Franco Scarselli. “On the complexity of shallow and deep neural network classifiers.” In ESANN. 2014.(<a href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2014-44.pdf">paper)</a></li>
<li>Girosi, Federico, and Tomaso Poggio. “Representation properties of networks: Kolmogorov’s theorem is irrelevant.” Neural Computation 1, no. 4 (1989): 465-469. (<a href="./files/Girosi89.pdf">paper)</a></li>
<li>Kůrková, Věra. “Kolmogorov’s theorem and multilayer neural networks.” Neural networks 5, no. 3 (1992): 501-506. (<a href="./files/Kurkova92.pdf">paper)</a></li>
<li>Poggio, Tomaso, Hrushikesh Mhaskar, Lorenzo Rosasco, Brando Miranda, and Qianli Liao. “Why and when can deep-but not shallow-networks avoid the curse of dimensionality: a review.” International Journal of Automation and Computing 14, no. 5 (2017): 503-519. (<a href="https://arxiv.org/pdf/1611.00740.pdf">paper)</a></li>
<li>Telgarsky, Matus. “Representation benefits of deep feedforward networks.” arXiv preprint arXiv:1509.08101 (2015). (<a href="https://arxiv.org/abs/1509.08101">paper)</a></li>
<li>Montufar, Guido F., Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. “On the number of linear regions of deep neural networks.” In Advances in neural information processing systems, pp.&nbsp;2924-2932. 2014. (<a href="https://arxiv.org/abs/1402.1869">paper)</a></li>
<li>Zhang, Chiyuan, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. “Understanding deep learning requires rethinking generalization.” arXiv preprint arXiv:1611.03530 (2016). (<a href="https://arxiv.org/abs/1611.03530">paper)</a></li>
<li>Lin, Henry W., Max Tegmark, and David Rolnick. “Why does deep and cheap learning work so well?.” Journal of Statistical Physics 168, no. 6 (2017): 1223-1247. (<a href="https://arxiv.org/abs/1608.08225">paper)</a></li>
<li>Stéphane Mallat 1: Mathematical Mysteries of Deep Neural Networks (<a href="https://youtu.be/0wRItoujFTA">video)</a></li>
<li><a href="https://dspace.mit.edu/bitstream/handle/1721.1/107787/CBMM-Memo-066.pdf?sequence##4%20Theory%20of%20Deep%20Learning%20II:%20Landscape%20of%20the%20Empirical%20Risk%20in%20Deep">Learning</a></li>
<li><a href="./filed/Kolmogorov1957.pdf On the representation of continuous functions of many variables by superposition of continuous functions of one variable and">addition</a></li>
<li><a href="./files/matus.pdf Representation Power of Feed forward Neural">Networks</a></li>
<li><a href="https://arxiv.org/pdf/1512.03965.pdf%20The%20Power%20of%20Depth%20for%20Feedforward%20Neural">Networks</a></li>
</ul>
</section>
<section id="section-4-reinforcement-learning" class="level6">
<h6 class="anchored" data-anchor-id="section-4-reinforcement-learning">Section 4: Reinforcement Learning</h6>
<p><a href="https://arxiv.org/abs/1802.10592%20Model-Ensemble%20Trust-Region%20Policy">Optimization</a> <a href="https://arxiv.org/abs/1805.12114%20Deep%20Reinforcement%20Learning%20in%20a%20Handful%20of%20Trials%20using%20Probabilistic%20Dynamics">Models</a> - <a href="http://www.argmin.net/2018/02/20/reinforce/%20The%20Policy%20of">Truth</a> - <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html%20Deep%20Reinforcement%20Learning%20Doesn't%20Work">Yet</a></p>
</section>
<section id="section-5-bayesian-dl" class="level6">
<h6 class="anchored" data-anchor-id="section-5-bayesian-dl">Section 5: Bayesian DL</h6>
<ul>
<li>VAE with a VampPrior (<a href="https://arxiv.org/pdf/1705.07120.pdf">paper)</a></li>
<li>Bayesian DL (<a href="http://www.datasciencecentral.com/profiles/blogs/a-curated-list-of-resources-dedicated-to-bayesian-deep-learning?utm_content##buffer3671b,utm_medium##social,utm_source##twitter.com,utm_campaign##buffer">blog)</a></li>
<li>Recognition Networks for Approximate Inference in BN20 Networks (<a href="https://arxiv.org/pdf/1301.2295.pdf">paper)</a></li>
<li>Non-linear regression models for Approximate Bayesian Computation (<a href="https://arxiv.org/abs/0809.4178">paper)</a></li>
<li>DR-ABC: Approximate Bayesian Computation with Kernel-Based Distribution Regression (<a href="https://arxiv.org/abs/1602.04805">paper)</a></li>
<li>Fast ε-free Inference of Simulation Models with Bayesian Conditional Density Estimation (<a href="https://arxiv.org/abs/1605.06376">paper)</a></li>
<li>Auto-Encoding Variational Bayes (<a href="https://arxiv.org/abs/1312.6114">paper)</a></li>
<li>Composing graphical models with neural networks for structured representations and fast inference (<a href="https://arxiv.org/abs/1603.06277">paper)</a></li>
<li><a href="https://arxiv.org/pdf/1802.02538.pdf%20Yes,%20but%20Did%20It%20Work?:%20Evaluating%20Variational">Inference</a></li>
</ul>
</section>
<section id="section-6-practical-tricks" class="level6">
<h6 class="anchored" data-anchor-id="section-6-practical-tricks">Section 6: Practical Tricks</h6>
<ul>
<li><a href="https://towardsdatascience.com/stochastic-weight-averaging-a-new-way-to-get-state-of-the-art-results-in-deep-learning-c639ccf36a">Averaging</a></li>
<li><ul>
<li>Normalization Propagation: A Parametric Technique for Removing Internal Covariate Shift in Deep Networks (<a href="https://arxiv.org/pdf/1603.01431.pdf">paper)</a></li>
</ul></li>
<li>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (<a href="https://arxiv.org/pdf/1502.03167.pdf">paper)</a></li>
<li>Auto-Encoding Variational Bayes (<a href="https://arxiv.org/pdf/1312.6114.pdf">paper)</a></li>
<li>Twin Networks: Using the Future as a Regularizer (<a href="https://arxiv.org/pdf/1708.06742.pdf">paper)</a></li>
<li>Don’t Decay the Learning Rate, Increase the Batch Size (<a href="https://arxiv.org/abs/1711.00489">paper)</a></li>
<li>DL Tuning (<a href="http://theorangeduck.com/page/neural-network-not-working">blog)</a></li>
<li><a href="https://arxiv.org/pdf/1703.09039.pdf%20Efficient%20Processing%20of%20Deep%20Neural%20Networks:%20A%20Tutorial%20and">Survey</a></li>
</ul>
</section>
</section>
<section id="other-resources" class="level4">
<h4 class="anchored" data-anchor-id="other-resources">Other Resources</h4>
<section id="additional-reading-list" class="level6">
<h6 class="anchored" data-anchor-id="additional-reading-list">Additional Reading List</h6>
<ul>
<li>50 Years of Data Science by Donoho (<a href="./files/50YearsofDataScience.pdf">paper)</a></li>
<li><a href="https://arxiv.org/pdf/1404.7828.pdf%20Deep%20Learning%20in%20Neural%20Networks:%20An">Overview</a></li>
<li><a href="https://arxiv.org/pdf/1806.11146.pdf%20Adversarial%20Reprogramming%20of%20Neural">Networks</a></li>
<li><a href="http://unsupervised.cs.princeton.edu/deeplearningtutorial.html%20Toward%20theoretical%20understanding%20of%20deep">learning</a></li>
</ul>
</section>
<section id="blogs" class="level6">
<h6 class="anchored" data-anchor-id="blogs">Blogs</h6>
<ul>
<li>Papers with code <a href="https://paperswithcode.com">link</a></li>
<li>Security (<a href="http://www.cleverhans.io">blog)</a></li>
<li>Unsupervised learning (<a href="https://medium.com/intuitionmachine/navigating-the-unsupervised-learning-landscape-951bd5842df9">blog)</a></li>
<li>Cybersecurity (<a href="https://medium.com/@jason_trost/collection-of-deep-learning-cyber-security-research-papers-e1f856f71042%20paper">collection)</a></li>
<li><a href="http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html%20Opt">Visualization</a></li>
</ul>
</section>
<section id="videos" class="level6">
<h6 class="anchored" data-anchor-id="videos">Videos</h6>
<ul>
<li>Deep Energy (<a href="https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/">blog)</a></li>
<li>DL Summer school 2015 (<a href="http://videolectures.net/deeplearning2015_montreal/">videos)</a></li>
<li>DL Representations (<a href="http://netdissect.csail.mit.edu">blog)</a></li>
<li>PyData 2017 (<a href="https://www.analyticsvidhya.com/blog/2017/05/pydata-amsterdam-2017-machine-learning-deep-learning-data-science/">videos)</a></li>
</ul>
</section>
<section id="other-courses-with-good-web-presence" class="level6">
<h6 class="anchored" data-anchor-id="other-courses-with-good-web-presence">Other courses with good web presence</h6>
<ul>
<li>Stanford’s CS231n (<a href="http://cs231n.github.io%20course">page)</a></li>
<li>Stanford’s STATS385 (<a href="https://stats385.github.io%20course">page)</a></li>
<li><a href="http://www.fast.ai">fast.ai</a></li>
<li><a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/%20Nando%20de%20Freitas’%20course%20on%20machine">learning</a></li>
<li>UC Berkeley Stat241B (<a href="https://bcourses.berkeley.edu/courses/1409209/pages/lectures">lectures)</a></li>
<li>UCUC CSE598 (<a href="http://mjt.web.engr.illinois.edu/courses/mlt-f17/%20course">page)</a></li>
<li><a href="https://github.com/udacity/deep-reinforcement-learning%20Udacity">DRL</a></li>
</ul>
</section>
<section id="tools" class="level6">
<h6 class="anchored" data-anchor-id="tools">Tools</h6>
<ul>
<li><a href="https://www.tensorflow.org">TensorFlow</a></li>
<li><a href="https://keras.io">Keras</a></li>
<li><a href="http://playground.tensorflow.org%20TF%20Playground">(Google</a>)</li>
<li><a href="https://dl.sony.com%20DL">Sony</a></li>
<li><a href="https://jiffyclub.github.io/snakeviz/%20SnakeViz">profiler</a> (python)</li>
<li><a href="http://pytorch.org">PyTorch</a></li>
<li><a href="https://github.com/jeffalstott/pystan_time_series%20TS%20Stan">Examples</a></li>
<li><a href="https://blog.openai.com/glow/%20OpenAI">Glow</a></li>
</ul>
</section>
<section id="misc-links" class="level6">
<h6 class="anchored" data-anchor-id="misc-links">Misc Links</h6>
<ul>
<li><a href="https://github.com/ritchieng/the-incredible-pytorch%20Pytorch%20resources">projects</a> (a curated list of tutorials, papers,)</li>
<li><a href="https://www.christies.com/Features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx%20Is%20artificial%20intelligence%20set%20to%20become%20art’s%20next">medium?</a></li>
</ul>
</section>
</section>
<section id="previous-instances" class="level4">
<h4 class="anchored" data-anchor-id="previous-instances">Previous instances</h4>
<ul>
<li><a href="./2017/index.html Fall">2017</a></li>
<li><a href="./2018/index.html Fall">2018</a></li>
</ul>
<p>#https://www.coursera.org/learn/intro-to-deep-learning #http://www.machinelearning.ru/wiki/index.php?title##Глубинное_обучение_%28курс_лекций%29/2017 #https://github.com/aosokin/dl_cshse_ami/tree/master/2019-spring #https://bayesgroup.ru/teaching/ #saddepal@gmu.edu;savala@gmu.edu;fbehnia@gmu.edu;schava@gmu.edu;hgangava@gmu.edu;xgitiaux@gmu.edu;vgunnala@gmu.edu;nhuang2@gmu.edu;wkirsche@gmu.edu;jkrishn@gmu.edu;slakaman@gmu.edu;elynch9@gmu.edu;mmittapa@gmu.edu;gn@gmu.edu;krajend2@gmu.edu;srayapro@gmu.edu;asaid8@gmu.edu;oshaat@gmu.edu;ashambhu@gmu.edu;asothor2@gmu.edu;tstickl@gmu.edu;rzimme10@gmu.edu;aachary@gmu.edu;jbashata@gmu.edu;zchai2@gmu.edu;ychen37@gmu.edu;zfan3@gmu.edu;agharibr@gmu.edu;bghimire@gmu.edu;cgrubb@gmu.edu;zjiang@gmu.edu;nnewman7@gmu.edu;rpandey4@gmu.edu;tsmith58@gmu.edu;jwang40@gmu.edu;fyu2@gmu.edu;dzhang22@gmu.edu</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>