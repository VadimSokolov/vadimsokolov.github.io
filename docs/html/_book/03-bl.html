<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Bayesian Learning – Bayes, AI and Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04-dec.html" rel="next">
<link href="./02-bayes.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-b4985e4eddee1e63d72746df2b00da28.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
  // Load MathJax with custom macros
  window.MathJax = {
    tex: {
      macros: {
        Cov: ["\\mathrm{Cov}\\left(#1\\right)", 1],
        Cor: ["\\mathrm{Cor}\\left(#1\\right)", 1],
        Var: ["\\mathrm{Var}\\left(#1\\right)", 1],
        sd: ["\\mathrm{sd}\\left(#1\\right)", 1],
        E: ["\\mathrm{E}_{#1}\\left(#2\\right)", 2, ""],
        prob: ["\\mathrm{P}\\left(#1\\right)", 1],
        defeq: "\\stackrel{\\mathrm{def}}{=}",
        mini: "\\operatorname*{minimize}"
      }
    }
  };
</script>

<style>
  /* Custom styling for math content */
  .MathJax {
    font-size: 1em !important;
  }

  /* Ensure consistent math rendering */
  mjx-container[jax="CHTML"] {
    line-height: 1.2;
  }
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="3&nbsp; Bayesian Learning – Bayes, AI and Deep Learning">
<meta property="og:description" content="">
<meta property="og:image" content="03-bl_files/figure-html/fig-coinposterior-1.png">
<meta property="og:site_name" content="Bayes, AI and Deep Learning">
<meta name="twitter:title" content="3&nbsp; Bayesian Learning – Bayes, AI and Deep Learning">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="03-bl_files/figure-html/fig-coinposterior-1.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="./03-bl.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayes, AI and Deep Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Modern AI Playbook</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-bl.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-dec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-ab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">A/B Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-hyp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-sp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-rl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Unreasonable Effectiveness of Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-pattern.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Pattern Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Logistic Regression and Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Tree Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-forecasting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Forecasting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-select.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-theoryai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Statistical Learning Theory and Regularization</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-theorydl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Theory of Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-sgd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-qnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Quantile Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-nlp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Natural Language Processing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Large Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-robots.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">AI Agents</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Linear algebra and multivariate normal toolkit</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#exchangeability-and-the-bayesian-view-of-probability-models" id="toc-exchangeability-and-the-bayesian-view-of-probability-models" class="nav-link active" data-scroll-target="#exchangeability-and-the-bayesian-view-of-probability-models"><span class="header-section-number">3.1</span> Exchangeability and the Bayesian view of probability models</a>
  <ul class="collapse">
  <li><a href="#de-finettis-representation-theorem" id="toc-de-finettis-representation-theorem" class="nav-link" data-scroll-target="#de-finettis-representation-theorem">de Finetti’s representation theorem</a></li>
  <li><a href="#posterior-empirical-cdf" id="toc-posterior-empirical-cdf" class="nav-link" data-scroll-target="#posterior-empirical-cdf">Posterior Empirical CDF</a></li>
  </ul></li>
  <li><a href="#sufficient-statistic" id="toc-sufficient-statistic" class="nav-link" data-scroll-target="#sufficient-statistic"><span class="header-section-number">3.2</span> Sufficient Statistic</a></li>
  <li><a href="#sec-betabinomial" id="toc-sec-betabinomial" class="nav-link" data-scroll-target="#sec-betabinomial"><span class="header-section-number">3.3</span> Beta-Binomial Model</a></li>
  <li><a href="#poisson-model-for-count-data" id="toc-poisson-model-for-count-data" class="nav-link" data-scroll-target="#poisson-model-for-count-data"><span class="header-section-number">3.4</span> Poisson Model for Count Data</a></li>
  <li><a href="#poisson-gamma-learning-about-an-intensity" id="toc-poisson-gamma-learning-about-an-intensity" class="nav-link" data-scroll-target="#poisson-gamma-learning-about-an-intensity"><span class="header-section-number">3.5</span> Poisson-Gamma: Learning about an Intensity</a></li>
  <li><a href="#exponential-gamma-model" id="toc-exponential-gamma-model" class="nav-link" data-scroll-target="#exponential-gamma-model"><span class="header-section-number">3.6</span> Exponential-Gamma Model</a></li>
  <li><a href="#normal-with-unknown-mean" id="toc-normal-with-unknown-mean" class="nav-link" data-scroll-target="#normal-with-unknown-mean"><span class="header-section-number">3.7</span> Normal With Unknown Mean</a>
  <ul class="collapse">
  <li><a href="#posterior-predictive" id="toc-posterior-predictive" class="nav-link" data-scroll-target="#posterior-predictive">Posterior Predictive</a></li>
  </ul></li>
  <li><a href="#normal-with-unknown-variance" id="toc-normal-with-unknown-variance" class="nav-link" data-scroll-target="#normal-with-unknown-variance"><span class="header-section-number">3.8</span> Normal With Unknown Variance</a>
  <ul class="collapse">
  <li><a href="#the-normal-gamma-model" id="toc-the-normal-gamma-model" class="nav-link" data-scroll-target="#the-normal-gamma-model">The Normal-Gamma Model</a></li>
  <li><a href="#credible-intervals-for-normal-gamma-model-posterior-parameters" id="toc-credible-intervals-for-normal-gamma-model-posterior-parameters" class="nav-link" data-scroll-target="#credible-intervals-for-normal-gamma-model-posterior-parameters">Credible Intervals for Normal-Gamma Model Posterior Parameters</a></li>
  </ul></li>
  <li><a href="#multivariate-normal" id="toc-multivariate-normal" class="nav-link" data-scroll-target="#multivariate-normal"><span class="header-section-number">3.9</span> Multivariate Normal</a></li>
  <li><a href="#mixtures-of-conjugate-priors" id="toc-mixtures-of-conjugate-priors" class="nav-link" data-scroll-target="#mixtures-of-conjugate-priors"><span class="header-section-number">3.10</span> Mixtures of Conjugate Priors</a></li>
  <li><a href="#sec-computational-bridge" id="toc-sec-computational-bridge" class="nav-link" data-scroll-target="#sec-computational-bridge"><span class="header-section-number">3.11</span> Bayesian Computation: when conjugacy breaks</a>
  <ul class="collapse">
  <li><a href="#posterior-consistency-and-the-law-of-large-numbers" id="toc-posterior-consistency-and-the-law-of-large-numbers" class="nav-link" data-scroll-target="#posterior-consistency-and-the-law-of-large-numbers">Posterior Consistency and the Law of Large Numbers</a></li>
  <li><a href="#monte-carlo-methods" id="toc-monte-carlo-methods" class="nav-link" data-scroll-target="#monte-carlo-methods">Monte Carlo Methods</a></li>
  <li><a href="#markov-chain-monte-carlo" id="toc-markov-chain-monte-carlo" class="nav-link" data-scroll-target="#markov-chain-monte-carlo">Markov Chain Monte Carlo</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="./03-bl.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Learning</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-bl" class="quarto-section-identifier"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Learning</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>“<em>A Wise man proportions his beliefs to the evidence.</em>” – David Hume</p>
</blockquote>
<p>Statistics makes use of parametric families of distributions and often assumes that observed samples <span class="math inline">\(y = (y_1,\ldots,y_n)\)</span> are independent and identically distributed observations from a distribution with density function parametrized by <span class="math inline">\(\theta\)</span>, the notation is <span class="math inline">\(y\mid \theta \sim p(y \mid \theta)\)</span>. The functional form of <span class="math inline">\(p(y \mid \theta)\)</span> is assumed to be known, but the value of <span class="math inline">\(\theta\)</span> is unknown. The goal of statistical inference is to estimate <span class="math inline">\(\theta\)</span> from the observed data <span class="math display">\[
y = (y_1,\ldots,y_n).
\]</span></p>
<p>The main tasks in statistical inference include estimation, hypothesis testing, and prediction. <strong>Estimation</strong> involves using the observed sample to infer the value of the unknown parameter <span class="math inline">\(\theta\)</span>, either by providing a single best guess (denoted as <span class="math inline">\(\hat{\theta}\)</span>) or by constructing an interval <span class="math inline">\([a, b]\)</span> that is likely to contain the true value of <span class="math inline">\(\theta\)</span> with a specified probability. <strong>Hypothesis testing</strong> focuses on evaluating specific claims or hypotheses about the value of <span class="math inline">\(\theta\)</span>; for instance, we might be interested in determining whether <span class="math inline">\(\theta\)</span> is equal to a particular value <span class="math inline">\(\theta_0\)</span>. <strong>Prediction</strong>, on the other hand, is concerned with forecasting the value of a future observation <span class="math inline">\(y_{n+1}\)</span> based on the data already observed, <span class="math inline">\(y_1, \ldots, y_n\)</span> via a model <span class="math inline">\(p(y_{n+1} \mid y_1, \ldots, y_n)\)</span>.</p>
<p>In this section we present a general framework for statistical inference, known as Bayesian inference, which is based on the use of probability distributions to represent uncertainty and make inferences about unknown parameters. We will use Bayes rule to update our beliefs about the parameters of a model based on new evidence or data. Bayesian inference provides a principled approach to statistical modeling and decision-making.</p>
<p>Bayesian analysis always starts with specifying the two main components of the model:</p>
<ol type="1">
<li><strong>Prior</strong> <span class="math inline">\(p(\theta)\)</span> represents your beliefs or knowledge about the parameters before observing any data. This distribution encapsulates the uncertainty about the parameters.</li>
<li><strong>Likelihood Function (Data Likelihood)</strong>: <span class="math inline">\(p(y \mid \theta)\)</span> describes the likelihood of observing the given data given the current values of the parameters. When we have independent and identically distributed <span class="math inline">\(y = (y_1, \ldots, y_n)\)</span>, the likelihood function is given by <span class="math display">\[
p(y \mid \theta) = \prod_{i=1}^n p(y_i \mid \theta).
\]</span></li>
</ol>
<p>The estimation problem is also called Bayesian parameter learning; the goal is then to update the probability distribution over the parameters of the model as new data becomes available. Suppose that you are interested in the values of <span class="math inline">\(k\)</span> unknown quantities <span class="math display">\[
\theta = (\theta_1, \ldots, \theta_k).
\]</span> Then learning is done by updating the prior distribution over the parameters of the model as new data becomes available and calculating the posterior distribution over the parameters. The posterior distribution represents the updated beliefs about the parameters after incorporating the observed data. It combines the prior distribution and the likelihood function using Bayes’ theorem: <span class="math display">\[
p( \theta \mid y )  = \frac{p(y \mid  \theta)p( \theta)}{p(y)} = \frac{\text{Likelihood} \times \text{Prior}}{\text{Marginal}}.
\]</span> The left hand side <span class="math inline">\(p( \theta | y )\)</span> is the posterior distribution, and <span class="math inline">\(p(y)\)</span> is the probability of the observed data (also known as the total probability) given by <span class="math display">\[
p(y)  = \int p(y \mid  \theta)p( \theta)d \theta
\]</span></p>
<p>Nice feature of the Bayes approach is that you can use the posterior distribution obtained from one round of observation as the prior distribution for the next round when more data becomes available. This process can be iteratively repeated as new evidence is acquired. It makes sequential learning possible.</p>
<p>The downstream tasks then use the posterior distribution. For example, if we want to predict the value of a future observation <span class="math inline">\(y_{n+1}\)</span> based on the data already observed, <span class="math inline">\(y_1, \ldots, y_n\)</span> via a model <span class="math inline">\(p(y_{n+1} \mid y_1, \ldots, y_n, \theta)\)</span>, we can use the posterior distribution to calculate the expected value of <span class="math inline">\(y_{n+1}\)</span> as <span class="math display">\[
p(y_{n+1} \mid y_1, \ldots, y_n) = \int p(y_{n+1} \mid y_1, \ldots, y_n, \theta)p(\theta \mid y_1, \ldots, y_n)d \theta.
\]</span> You can think of prediction as a mixture of the conditional distributions <span class="math inline">\(p(y_{n+1} \mid y_1, \ldots, y_n, \theta)\)</span> weighted by the posterior distribution <span class="math inline">\(p(\theta \mid y_1, \ldots, y_n)\)</span>.</p>
<p>A simple hypothesis test then involves calculating the probability of the observed data under the null hypothesis <span class="math inline">\(H_0\)</span> as <span class="math display">\[
p(y \mid H_0) = \int p(y \mid \theta)p(\theta \mid H_0)d \theta.
\]</span></p>
<p>bThe downside of the Bayes approach is the requirement to calculate the marginal likelihood <span class="math inline">\(p(y)\)</span>, which often requires calculating high-dimensional integrals that are intractable (do not have closed-form solutions). However, often, Bayesian analysis can be performed without calculating the marginal likelihood, in this case we omit the total probability in the denominator on the right hand side and write Bayes rule as <span class="math display">\[
\text{Posterior} \propto \text{Likelihood} \times \text{Prior}.
\]</span></p>
<p>The choice of prior distribution can significantly impact the ease of computation and the interpretation of the posterior distribution. Conjugate priors are a special type of prior distribution that, when combined with a specific likelihood function, result in a posterior distribution that belongs to the same family as the prior. This property simplifies the computation of the posterior distribution, and allows for analytical solutions.</p>
<p>Common examples of conjugate priors include:</p>
<ul>
<li><p><em>Normal distribution with known variance:</em> If the likelihood is a normal distribution with known variance, then a normal distribution is a conjugate prior for the mean.</p></li>
<li><p><em>Binomial distribution:</em> If the likelihood is a binomial distribution, then a beta distribution is a conjugate prior for the probability of success.</p></li>
<li><p><em>Poisson distribution:</em> If the likelihood is a Poisson distribution, then a Gamma distribution is a conjugate prior for the rate parameter.</p></li>
</ul>
<p>Using conjugate priors simplifies the Bayesian analysis, especially in cases where analytical solutions are desirable. However, the choice of a conjugate prior is often a modeling assumption, and in some cases, non-conjugate priors may be more appropriate for capturing the true underlying uncertainty in the problem. The blind use of conjugate priors can lead to misleading results. We should never ignore the absence of evidence for use of a specific model.</p>
<section id="exchangeability-and-the-bayesian-view-of-probability-models" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="exchangeability-and-the-bayesian-view-of-probability-models"><span class="header-section-number">3.1</span> Exchangeability and the Bayesian view of probability models</h2>
<p>At the basis of all statistical problems is a potential sample of data, <span class="math inline">\(y=\left( y_{1},\ldots,y_{T}\right)\)</span>, and assumptions over the data generating process such as independence, a model or models, and parameters. How should one view the relationship between models, parameters, and samples of data? How should one define a model and parameters? These questions have fundamental implications for statistical inference and can be answered from different perspectives. We will discuss de Finetti’s representation theorem which provides a formal connection between data, models, and parameters.</p>
<p>To understand the issues, consider the simple example of an experiment consisting of tosses of a simple thumb tack in ideal “laboratory” conditions. The outcome of the experiment can be defined as a random variable <span class="math inline">\(y_{i},\)</span> where <span class="math inline">\(y_{i}=1\)</span> if the <span class="math inline">\(i^{th}\)</span> toss was a heads (the tack lands on the spike portion) and <span class="math inline">\(y_{i}=0\)</span> if the tack lands tails (on its flat portion). How do we model these random variables? The frequentist or objective approach assumes tosses are independent and identically distributed. In this setting, independence implies that <span class="math display">\[
P\left(  y_{2}=1,y_{1}=1\right)  =P\left(  y_{2}=1\right)
P\left(  y_{1}=1\right).
\]</span></p>
<p>Given this, are thumbtack tosses independent? Surprisingly, the answer is no. Or at least absolutely not under the current assumptions. Independence implies that <span class="math display">\[
P\left(  y_{2}=1 \mid y_{1}=1\right)  =P\left(  y_{2}=1\right),
\]</span> which means that observing <span class="math inline">\(y_{1}=1\)</span> does not affect the probability that <span class="math inline">\(y_{2}=1\)</span>. To see the implications of this simple fact, suppose that the results of 500 tosses were available. If the tosses were independent, then <span class="math display">\[
P\left(  y_{501}=1\right)  =P\left(  y_{501}=1\mid {\textstyle\sum\nolimits_{t=1}^{500}}y_{t}=1\right)  =P\left(  y_{501}=1\mid {\textstyle\sum\nolimits_{t=1}^{500}}y_{t}=499\right).
\]</span> It is hard to imagine that anyone would believe this–nearly every observer would state that the second probability is near zero and the third probability is near 1 as the first 500 tosses contain a lot of information. Thus, the tosses are not independent.</p>
<p>To see the resolution of this apparent paradox, introduce a parameter, <span class="math inline">\(\theta\)</span>, which is the probability that a thumb tack toss is heads. If <span class="math inline">\(\theta\)</span> were known, then it is true that, conditional on the value of this parameter, the tosses are independent and <span class="math display">\[
P\left(  y_{2}=1\mid y_{1}=1,\theta\right)  =P\left(y_{2}=1\mid \theta\right)  =\theta.
\]</span> Thus, the traditional usage of independence, and independent sampling, requires that “true” parameter values are known. With unknown probabilities, statements about future tosses are heavily influenced by previous observations, clearly violating the independence assumption. Ironically, if the data was really independent, we would not need samples in the first place to estimate parameters because the probabilities would already be known! Given this, if you were now presented with a thumb tack from a box that was to be repeatedly tossed, do you think that the tosses are independent?</p>
<p>This example highlights the tenuous foundations, an odd circularity, and the internal inconsistency of the frequentist approach that proceeds under the assumption of a fixed “true” parameter. All frequentist procedures are founded on the assumption of known parameter values: sampling distributions of estimators are computed conditional on <span class="math inline">\(\theta\)</span>; confidence intervals consist of calculations of the form: <span class="math inline">\(P\left( f\left( y_{1}, \ldots ,y_{T}\right) \in\left( a,b\right) |\theta\right)\)</span>; and asymptotics also all rely on the assumption of known parameter values. None of these calculations are possible without assuming the known parameters.</p>
<p>In the frequentist approach, even though the parameter is completely unknown to the researcher, <span class="math inline">\(\theta\)</span> is not a random variable, does not have a distribution, and therefore inference is not governed by the rules of probability. Given this “fixed, but unknown” definition, it is impossible to discuss concepts like “parameter uncertainty.” This strongly violates our intuition, since things that are not known are typically thought of as random.</p>
<p>The Bayesian approach avoids this internal inconsistency by shedding the strong assumption of independence and assumption of a fixed but unknown parameter. Instead it assumes that <span class="math inline">\(\theta\)</span> is a random variable and describes the uncertainty about <span class="math inline">\(\theta\)</span> using a probability distribution, <span class="math inline">\(p\left( \theta\right)\)</span> (the prior). The joint distribution of the data is then <span class="math display">\[
p(y_{1}, \ldots ,y_{T})  = \int p(y_{1}, \ldots ,y_{T} \mid \theta)  p(\theta)d\theta = \int\prod_{t=1}^Tp(y_t\mid \theta)  p( \theta)d\theta.
\]</span> Notice, that the right-hand-side does not depend on the order of the data, and the joint distribution of the data is the same for all potential orderings. This is a natural assumption about the symmetry of the data, and is called <em>exchangeability</em>. The Bayesian approach makes no assumptions about the order in which the data may arrive, and each observation has the same marginal distribution, <span class="math inline">\(P\left( y_{i}=1\right) =P\left(y_{j}=1\right)\)</span> for any <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>.</p>
<p>Thus, we replace the independence assumption with a weaker and more natural assumption of exchangeability: a collection of random variables, <span class="math inline">\(y_{1}, \ldots ,y_{T}\)</span>, is exchangeable if the distribution of <span class="math inline">\(y_{1}, \ldots ,y_{T}\)</span> is the same as the distribution of any permutation <span class="math inline">\(y_{\pi_{1}}, \ldots ,y_{\pi_{T}}\)</span>, where <span class="math inline">\(\pi=\left( \pi_{1}, \ldots ,\pi_{T}\right)\)</span> is a permutation of the integers <span class="math inline">\(1\)</span> to <span class="math inline">\(T\)</span>. Independent events are always exchangeable, but the converse is not true. Notice the differences between the assumptions in the Bayesian and frequentist approach: the Bayesian makes assumptions over potentially realized data, and there is no need to invent the construct of a fixed but unknown parameter, since exchangeability makes no reference to parameters.</p>
<p>In the case of the tack throwing experiment, exchangeability states that the ordering of heads and tails does not matter. Thus, if the experiment of 8 tosses generated 4 heads, it does not matter if the ordering was <span class="math inline">\(\left(1,0,1,0,1,0,1,0\right)\)</span> or <span class="math inline">\(\left( 0,1,1,0,1,0,0,1\right)\)</span>. This is a natural assumption about the symmetry of the tack tosses, capturing the idea that the information in any toss or sequence of tosses is the same as any other–the idea of a truly random sample. It is important to note that exchangeability is a property that applies prior to viewing the data. After observation, data is no longer a random variable, but a realization of a random variable.</p>
<p>Bruno de Finetti introduced the notion of exchangeability, and then asked a simple question: “What do exchangeable sequences of random variables look like?” The answer to this question is given in the famous de Finetti’s theorem, which also <em>defines</em> models, parameters, and provides important linkages between frequentist and classical statistics.</p>
<section id="de-finettis-representation-theorem" class="level3">
<h3 class="anchored" data-anchor-id="de-finettis-representation-theorem">de Finetti’s representation theorem</h3>
<p>de Finetti’s representation theorem provides the theoretical connection between data, models, and parameters. It is stated first in the simplest setting, where the observed data takes two values, either zero or one, and then extended below.</p>
<div id="thm-Representation" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.1 (de Finetti’s representation theorem)</strong></span> Let <span class="math inline">\(\left( Y_{1},Y_{2},\ldots\right)\)</span> be an infinite sequence of 0-1 exchangeable random variables with joint density <span class="math inline">\(p\left(Y_{1}, \ldots ,Y_{n}\right)\)</span>. Then there exists a distribution <span class="math inline">\(P\)</span> such that <span id="eq-deFinetti"><span class="math display">\[
P(Y_{1}=y_1,\ldots,Y_{n}=y_n)=\int\prod_{i=1}^{n}\theta^{y_{i}}(1-\theta)^{1-y_{i}}dP(\theta)=\int\prod_{i=1}^{n}p\left(  y_{i} \mid \theta\right)  dP(\theta)
\tag{3.1}\]</span></span> where <span class="math display">\[
P(\theta)=\lim_{n\rightarrow\infty}\text{Prob}\left[  \frac{1}{n}\sum_{t=1}^{n}Y_{t}\leq\theta\right]  \text{ and }\theta=\lim_{n\rightarrow\infty}\frac{1}{n}\sum_{t=1}^{n}Y_{t}.
\]</span> If the distribution function or measure admits a density with respect to Lebesgue measure, then <span class="math inline">\(dP(\theta)=p\left( \theta\right) d\theta\)</span>.</p>
<p><span class="citation" data-cites="heath1976finettis">Heath and Sudderth (<a href="references.html#ref-heath1976finettis" role="doc-biblioref">1976</a>)</span> provide a general version and simple proof. For general spaces <span class="math inline">\(\mathcal{Y}\)</span>, we have <span class="math display">\[
P(Y_1 \le y_1, \ldots, Y_n \le y_n) = \int_{\mathcal{F}} \prod_{i=1}^{n} F(y_i) \, \mu(dF)
\]</span> where <span class="math inline">\(\mu(\cdot)\)</span> is a measure over the space of distributions, <span class="math inline">\(\mathcal{F}\)</span>. In the parametric case, <span class="math inline">\(F_\theta\)</span>, then <span class="math inline">\(\mu(d\theta) = p(\theta) d\theta\)</span> and <span class="math inline">\(p(\theta)\)</span> is the typical prior density. The predictive <span class="math inline">\(p(Y_{n+1} \mid y_1, \ldots, y_n)\)</span> is then a marginal over <span class="math inline">\(F_\theta\)</span> and the posterior <span class="math inline">\(p(\theta \mid y_1, \ldots, y_n)\)</span> which is updated via Bayes theorem.</p>
</div>
<p>de Finetti’s representation theorem has profound implications for understanding models from a subjectivist perspective and in relating subjectivist to frequentist theories of inference. The theorem is interpreted as follows:</p>
<ul>
<li><p>Under exchangeability, parameters exist, and one can <em>act as if</em> the <span class="math inline">\(y_{i}\)</span>’s are drawn independently from a Bernoulli distribution with parameter <span class="math inline">\(\theta\)</span>. That is, they are draws from the model <span class="math inline">\(p\left(y_{i} \mid \theta\right) =\theta^{y_{i}}(1-\theta)^{1-y_{i}},\)</span> generating a likelihood function <span class="math inline">\(p\left( y \mid \theta\right) =\prod_{i=1}^{n}p\left(y_{i} \mid \theta\right)\)</span>. Formally, the likelihood function is defined via the density <span class="math inline">\(p\left( y \mid \theta\right)\)</span>, viewed as a function of <span class="math inline">\(\theta\)</span> for a fixed sample <span class="math inline">\(y=\left( y_{1}, \ldots ,y_{n}\right)\)</span>. More "likely" parameter values generate higher likelihood values, thus the name. The maximum likelihood estimate (MLE) is <span class="math display">\[
\widehat{\theta}_{\mathrm{MLE}}=\arg\underset{\theta\in\Theta}{\max}\text{ }p\left(y \mid \theta\right)  =\arg\underset{\theta\in\Theta}{\max}\ln p\left(y \mid \theta\right),   
\]</span> where <span class="math inline">\(\Theta\)</span> is the parameter space.</p></li>
<li><p>Parameters are random variables. The limit <span class="math inline">\(\theta=\underset {n\rightarrow\infty}{\lim}n^{-1}\sum_{i=1}^{n}y_{i}\)</span> exists but is a random variable. This can be contrasted with the strong law of large numbers that requires independence and implies that <span class="math inline">\(n^{-1}\sum_{i=1}^{n}y_{i}\)</span> converges almost surely to a fixed value, <span class="math inline">\(\theta_{0}\)</span>. From this, one can interpret a parameter <span class="math inline">\(\theta\)</span> as a limit of observables and justifies the frequentist interpretation of <span class="math inline">\(\theta\)</span> as a limiting frequency of 1’s.</p></li>
<li><p>The distribution <span class="math inline">\(P\left( \theta\right)\)</span> or density <span class="math inline">\(p\left(\theta\right)\)</span> can be interpreted as beliefs about the limiting frequency <span class="math inline">\(\theta\)</span> prior to viewing the data. After viewing the data, beliefs are updated via Bayes rule resulting in the posterior distribution, <span class="math inline">\(p(\theta \mid y_{1},\ldots,y_{n})\)</span>.</p></li>
</ul>
<p>Since the likelihood function is fixed in this case, any distribution of observed data can be generated by varying the prior distribution.</p>
<p>The main implication of de Finetti’s theorem is a complete justification for Bayesian practice of treating the parameters as random variables and specifying a likelihood and parameter distribution. Stated differently, a “model” consists of both a likelihood and a prior distribution over the parameters. Thus, parameters as random variables and priors are a necessity for statistical inference, and not some extraneous component motivated by philosophical concerns.</p>
<p>More general versions of de Finetti’s theorem are available. A general version is as follows. If <span class="math inline">\(\left\{ Y_{i}\right\} _{i\geq1}\)</span>, <span class="math inline">\(Y_{i}\in\mathbb{R}\)</span>, is a sequence of infinitely exchangeable random variables, then there exists a probability measure <span class="math inline">\(P\)</span> on the space of all distribution functions, such that <span class="math display">\[
p(Y_{1}\le y_{1},\ldots,Y_{n}\le y_{n})=\int\prod_{i=1}^{n}F\left(  y_{i}\right)
P(dF)
\]</span> with mixing measure <span class="math display">\[
P\left(  F\right)  =\underset{n\rightarrow\infty}{\lim}P(F_{n}),
\]</span> where <span class="math inline">\(F_{n}\)</span> is the empirical distribution of the data. At this level of generality, the distribution function is infinite-dimensional. In practice, additional subjective assumptions are needed that usually restrict the distribution function to finite dimensional spaces, which implies that the distribution function is indexed by a parameter vector <span class="math inline">\(\theta\)</span>: <span class="math display">\[
p(Y_{1}\le y_{1},\ldots,Y_{n}\le y_{n})=\int\prod_{i=1}^{n}p\left(  Y_{i} \mid \theta\right)
dP\left(  \theta\right).
\]</span> To operationalize this result, the researcher needs to choose the likelihood function and the prior distribution of the parameters.</p>
</section>
<section id="posterior-empirical-cdf" class="level3">
<h3 class="anchored" data-anchor-id="posterior-empirical-cdf">Posterior Empirical CDF</h3>
<p>Let <span class="math inline">\(m = \{ f_\theta ( y ) : y \in \mathcal{Y} \}\)</span> be a model. When necessary we index the parameters in model <span class="math inline">\(m\)</span>, as <span class="math inline">\(\theta_m\)</span>. Let <span class="math inline">\(y = ( y_1 , \ldots , y_n )\)</span> be a vector of signals. The conditional likelihood, under <span class="math inline">\(m\)</span>, is given by <span class="math inline">\(f_\theta(y) =  \prod_{i=1}^n f_\theta ( y_i )\)</span>. We also allow for the possibility that the data is generated from a model <span class="math inline">\(f\)</span> that does not belong to the family of models <span class="math inline">\(f_\theta\)</span>.</p>
<p>Given a prior measure, <span class="math inline">\(\Pi ( d F )\)</span>, over <span class="math inline">\(\mathcal{F}\)</span> the set of distributions, we can calculate the predictive density <span class="math display">\[
f_n  ( y_{n+1} | y_1 , \ldots , y_n ) = \int f (y) \Pi_n ( d F ) \; \text{where}\; \Pi_n ( d f ) = \frac{ \prod_{i=1}^n f( y_i ) \Pi( d f ) }{  \int  \prod_{i=1}^n f( y_i ) \Pi( d f ) }
\]</span> Under the family, <span class="math inline">\(f_\theta\)</span>, we can calculate the parameter posterior as <span class="math display">\[
p( \theta | y ) =  \frac{ \prod_{i=1}^n f_\theta ( y_i ) p(\theta)  d \theta }{  m(y) } \;  \text{where}\; m(y) = \int f_\theta (y) p( \theta ) d \theta
\]</span> Here <span class="math inline">\(p(\theta)\)</span> is a prior distribution over parameters and <span class="math inline">\(m(y)\)</span> is the marginal distribution of the data implied by the model. There are many applications in Bayesian non-parametric statistics.</p>
<p>At first glance, de Finetti’s theorem may seem to suggest that there is a single model or likelihood function. This is not the case however, as models can be viewed in the same manner as parameters. Denoting a model specification by <span class="math inline">\(\mathcal{M}\)</span>, then de Finetti’s theorem would imply that <span class="math display">\[\begin{align*}
p(y_{1},\ldots,y_{n})  &amp;  =\int\prod_{i=1}^{n}p\left(  y_{i} \mid \theta ,\mathcal{M}\right)  p\left(  \theta \mid \mathcal{M}\right)  p\left(\mathcal{M}\right)  d\theta d\mathcal{M}\\
&amp;  =\int p(y_{1},\ldots,y_{n} \mid \mathcal{M})p\left(  \mathcal{M}\right)
d\mathcal{M},
\end{align*}\]</span> in the case of a continuum of models. Thus, under the mild assumption of exchangeability, it is <em>as if</em> the <span class="math inline">\(y_{i}\)</span>’s are generated from <span class="math inline">\(p\left( y_{i} \mid \theta,\mathcal{M}\right)\)</span>, conditional on the random variables <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\mathcal{M}\)</span>, where <span class="math inline">\(p\left( \theta \mid \mathcal{M}\right)\)</span> are the beliefs over <span class="math inline">\(\theta\)</span> in model <span class="math inline">\(\mathcal{M}\)</span>, and <span class="math inline">\(p\left(\mathcal{M}\right)\)</span> are the beliefs over model specifications.</p>
<p>Subjective probability is a more general definition of probability than the frequentist definition, as it can be used for all types of events, both repeatable and unrepeatable events. A subjectivist has no issues discussing the probability of a lection result, even though the underlying conditions has not been observed before. As Ramsey (1926) puts it, “the probability is simply the willingness to bet on an event with a counterparty”.</p>
<p>The event does not even have to be uncertain in nature. For example, the probability of me having coins in my pocket will depend on who is asked to make the assessment. I, knowing the contents of my pocket, will say the probability is 0. However, if you are asked to make the assessment, you will say the probability is 1/2, as you do not know the contents of my pocket. This is a classic example of subjectivist probability.</p>
<p>Similarly, consider the number of people currently in Antarctica. This number is fixed and deterministic at any given moment, yet different individuals will assign different probability distributions to this quantity based on their knowledge. A researcher who recently reviewed Antarctic population statistics might have a tight distribution centered around the correct value, while someone with no such knowledge might have a much wider distribution. A logistics coordinator for a polar research station would have precise information about personnel at their specific facility but uncertainty about other stations. Each of these represents valid subjective probabilities over the same underlying fixed quantity, illustrating how probability in the Bayesian sense quantifies personal uncertainty rather than intrinsic randomness.</p>
<p>The main difficulty in operationalizing subjective probability is the process of actually quantifying subjective beliefs into numeric probabilities. One practical approach is to elicit probabilities through a sequence of carefully designed bets.</p>
<p>Consider eliciting someone’s probability distribution over the number of people in Antarctica. We could start by asking: “Would you accept a bet that pays $100 if the number is below 5,000, and you pay $50 if it’s above 5,000?” If they accept, this suggests they believe <span class="math inline">\(P(\text{population} &lt; 5000) &gt; 1/3\)</span>. We then adjust the threshold and payoffs systematically. For instance, we might ask about betting on the population being below 2,000, or below 1,000, gradually narrowing down probability mass at different intervals.</p>
<p>For continuous quantities, we can elicit a full distribution through a sequence of binary bets about quantiles. By asking someone to specify values <span class="math inline">\(q_{0.25}, q_{0.5}, q_{0.75}\)</span> such that they are indifferent between bets paying equal amounts if the true value falls below or above each threshold, we construct their 25th, 50th, and 75th percentiles. This process, known as probability elicitation, transforms abstract beliefs into concrete probability distributions by observing revealed preferences through betting behavior.</p>
<p>The betting framework provides two key advantages. First, it forces coherence: if someone states inconsistent probabilities (such as <span class="math inline">\(P(A) + P(\neg A) \neq 1\)</span>), an adversary could construct a Dutch book—a set of bets that guarantees a loss regardless of the outcome. The threat of sure loss incentivizes rational probability assignments. Second, betting naturally handles non-repeatable events. We can elicit probabilities about tomorrow’s Supreme Court decision or next quarter’s GDP growth, neither of which has a frequentist interpretation.</p>
<p>Instead of using repetitive experiments, subjective probabilities can be measured using betting odds, which have been used for centuries to gauge the uncertainty over an event. The probability attributed to winning a coin toss is revealed by the type of odds one would accept to bet. Notice the difference between the frequentist and Bayesian approach. Instead of defining the probabilities via an infinite repeated experiment, the Bayesian approach elicits probabilities from an individual’s observed behavior.</p>
</section>
</section>
<section id="sufficient-statistic" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="sufficient-statistic"><span class="header-section-number">3.2</span> Sufficient Statistic</h2>
<p>In Bayesian inference, we need to compute the posterior over unknown model parameters <span class="math inline">\(\theta\)</span>, given data <span class="math inline">\(y\)</span>. The posterior density is denoted by <span class="math inline">\(p(\theta \mid y)\)</span>. A map from data <span class="math inline">\(y = (y_1, \ldots, y_n)\)</span> to a statistic <span class="math inline">\(S(y)\)</span> is called a <em>sufficient statistic</em> for <span class="math inline">\(\theta\)</span> if the conditional distribution of <span class="math inline">\(y\)</span> given <span class="math inline">\(S(y)\)</span> is independent of <span class="math inline">\(\theta\)</span>: <span class="math display">\[
p(y\mid S(y),\theta) = p(y\mid S(y)).
\]</span> This implies that <span class="math inline">\(S(y)\)</span> captures all the information in the data relevant to <span class="math inline">\(\theta\)</span>. Because the statistic is a deterministic function of the data, the likelihood factorizes as: <span class="math display">\[
p(y\mid \theta) = p(S(y)\mid \theta)p(y\mid S(y)).
\]</span></p>
<p>There is a powerful connection between the posterior mean and sufficient statistics in the exponential family. Kolmogorov (1942) showed that if <span class="math inline">\(S^*(y)\)</span> is a minimal sufficient statistic, then the posterior expectation <span class="math inline">\(E[\theta \mid y]\)</span> is a function of <span class="math inline">\(S^*(y)\)</span>. This provides a theoretical foundation for using summary statistics in simplified models.</p>
<div id="exm-coinposteror" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.1 (Posterior Distribution for Coin Toss)</strong></span> What if we gamble against unfair coin flips or the person who performs the flips is trained to get the side he wants? In this case, we need to estimate the probability of heads <span class="math inline">\(\theta\)</span> from the data. Suppose we have observed 10 flips <span class="math display">\[
\{H, T, H, H, H, T, H, T, H, H\},
\]</span> and only three of them were tails. What is the probability that the next flip will be tail? The frequency-based answer would be <span class="math inline">\(3/10 = 0.3\)</span>. However, the Bayes approach gives us more flexibility. Suppose we have a prior belief that the coin is fair, but we are not sure. We model this belief by a prior distribution. Let’s discretize the variable <span class="math inline">\(\theta\)</span> and assign prior probabilities to each value of <span class="math inline">\(\theta\)</span>, the prior distribution is shown in <a href="#fig-coinposterior" class="quarto-xref">Figure&nbsp;<span>3.1</span></a> (left panel).</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.024</span>, <span class="fl">0.077</span>, <span class="fl">0.132</span>, <span class="fl">0.173</span>, <span class="fl">0.188</span>, <span class="fl">0.173</span>, <span class="fl">0.132</span>, <span class="fl">0.077</span>, <span class="fl">0.024</span>, <span class="dv">0</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>We put most of the mass to the fair assumption (<span class="math inline">\(\theta = 0.5\)</span>) and zero mass to the extreme values <span class="math inline">\(\theta = 0\)</span> and <span class="math inline">\(\theta = 1\)</span>. Our mass is exponentially decaying as we move away from 0.5. This is a reasonable assumption, since we are not sure about the fairness of the coin. Now, we can use Bayes rule to update our prior belief. The posterior distribution is then combines likelihood shown in <a href="#fig-coinposterior" class="quarto-xref">Figure&nbsp;<span>3.1</span></a> (middle panel) and prior distributions as shown in <a href="#fig-coinposterior" class="quarto-xref">Figure&nbsp;<span>3.1</span></a> (right panel). <span class="math display">\[
p(\theta \mid y) = \frac{p(y \mid \theta) p(\theta)}{p(y)}.
\]</span> The denominator is the marginal likelihood, which is given by <span class="math display">\[
p(y) = \sum_{\theta} p(y \mid \theta) p(\theta).
\]</span> The likelihood is given by the Binomial distribution <span class="math display">\[
p(y \mid \theta) \propto \theta^3 (1 - \theta)^7.
\]</span> Notice, that the posterior distribution depends only on the number of positive and negative cases. Those numbers are <em>sufficient</em> for the inference about <span class="math inline">\(\theta\)</span>. T</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(prior, <span class="at">names.arg =</span> theta, <span class="at">xlab =</span> <span class="st">"theta"</span>, <span class="at">ylab =</span> <span class="st">"prior"</span>, <span class="at">col =</span> <span class="st">"lightblue"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, n, Y) {</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  theta<span class="sc">^</span>Y <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> theta)<span class="sc">^</span>(n <span class="sc">-</span> Y)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="fu">likelihood</span>(theta, <span class="dv">10</span>, <span class="dv">3</span>) <span class="sc">*</span> prior</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> posterior <span class="sc">/</span> <span class="fu">sum</span>(posterior) <span class="co"># normalize</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(posterior, <span class="at">names.arg =</span> theta, <span class="at">xlab =</span> <span class="st">"theta"</span>, <span class="at">ylab =</span> <span class="st">"posterior"</span>, <span class="at">col =</span> <span class="st">"lightblue"</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="fu">likelihood</span>(theta, <span class="dv">100</span>, <span class="dv">30</span>) <span class="sc">*</span> prior</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> posterior <span class="sc">/</span> <span class="fu">sum</span>(posterior) <span class="co"># normalize</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(posterior, <span class="at">names.arg =</span> theta, <span class="at">xlab =</span> <span class="st">"theta"</span>, <span class="at">ylab =</span> <span class="st">"posterior"</span>, <span class="at">col =</span> <span class="st">"lightblue"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div id="fig-coinposterior" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-coinposterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-coinposterior" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-coinposterior-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-coinposterior-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-coinposterior-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-coinposterior" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-coinposterior-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Prior
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-coinposterior" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-coinposterior-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-coinposterior-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-coinposterior-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-coinposterior" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-coinposterior-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Posterior for 10 flips
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-coinposterior" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-coinposterior-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-coinposterior-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-coinposterior-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-coinposterior" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-coinposterior-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Posterior for 100 flips
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-coinposterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1: Prior and Posterior distribution
</figcaption>
</figure>
</div>
<p>If you are to keep collecting more observations and say observe a sequence of 100 flips and 30 of them were heads, then the posterior distribution will be more concentrated around the value of <span class="math inline">\(\theta = 0.3\)</span> as shown in fig-coinposterior (right panel).</p>
<p>This demonstrates that for large sample sizes, the frequentist approach and the Bayesian approach agree.</p>
</div>
</section>
<section id="sec-betabinomial" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="sec-betabinomial"><span class="header-section-number">3.3</span> Beta-Binomial Model</h2>
<p>The <em>Beta-Binomial Bayesian model</em> is a statistical model that is used when we are interested in learning about a proportion or probability of success, denoted by <span class="math inline">\(p\)</span>. This model is used, for example, when dealing with binary data in A/B testing.</p>
<p>In the Beta-Binomial model, we assume that the the observed data is generated from a Binomial distribution with parameter <span class="math inline">\(\theta\)</span> and <span class="math inline">\(m\)</span> trials. The probability of success <span class="math inline">\(\theta\)</span> in each of <span class="math inline">\(m\)</span> Bernoulli trials is not fixed but randomly drawn from a Beta distribution. Thus, the model is given by <span class="math display">\[
y_i \mid \theta \sim Binomial(m,\theta) ~\text{(likelihood)}, \quad \theta \sim Beta(\alpha,\beta) ~\text{(prior)}.
\]</span></p>
<p>The <em>Beta distribution</em> is a family of continuous probability distributions defined on the interval [0,1] and has two parameters alpha (<span class="math inline">\(\alpha\)</span>) and beta (<span class="math inline">\(\beta\)</span>), that appear as exponents of the variable and its complement to 1, respectively, and control the shape of the distribution. The Beta distribution is frequently used in Bayesian statistics, empirical Bayes methods, and classical statistics to model random variables with values falling inside a finite interval.</p>
<p>The probability density function (PDF) of the Beta distribution is given by: <span class="math display">\[
Beta(y; \alpha, \beta) = \frac{y^{\alpha - 1}(1 - y)^{\beta - 1}}{B(\alpha, \beta)}
\]</span> where <span class="math inline">\(y \in [0, 1]\)</span>, <span class="math inline">\(\alpha &gt; 0\)</span>, <span class="math inline">\(\beta &gt; 0\)</span>, and <span class="math inline">\(B(\alpha, \beta)\)</span> is the beta function. It is simply a normalizing constant <span class="math display">\[
B\left( \alpha,\beta\right)  =\int_{0}^{1}y^{\alpha-1}\left(  1-y\right)^{\beta-1}dy .
\]</span></p>
<p>The mean and variance of the Beta distribution are given by: <span class="math display">\[
\begin{aligned}
\mu &amp;= \frac{\alpha}{\alpha + \beta} \\
\sigma^2 &amp;= \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}
\end{aligned}
\]</span> where <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma^2\)</span> is the variance.</p>
<p><a href="#fig-betadistributions" class="quarto-xref">Figure&nbsp;<span>3.2</span></a> illustrates the Beta distribution for different values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="cell-output-display">
<div id="fig-betadistributions" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-betadistributions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-betadistributions-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-betadistributions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.2: Beta distributions
</figcaption>
</figure>
</div>
</div>
</div>
<p>The Beta-Binomial model is one of the simplest Bayesian models and is widely used in various fields including epidemiology, intelligence testing, and marketing. It provides the tools we need to study the proportion of interest, <span class="math inline">\(\theta\)</span>, in a variety of settings.</p>
<p>The nice property of the Beta-Binomial model is that the posterior <span class="math display">\[
p(\theta \mid y) = \dfrac{p(y \mid \theta)p(\theta)}{p(y)}
\]</span> <span class="math inline">\(p(\theta\mid y)\)</span> is yet another Beta distribution. Beta is called a <em>conjugate prior</em> for the Binomial likelihood and is a very useful property.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Conjugate prior
</div>
</div>
<div class="callout-body-container callout-body">
<p>A prior is called a <em>conjugate prior</em> for a likelihood function if the posterior distribution is of the same family as the prior distribution.</p>
</div>
</div>
<p>When <span class="math inline">\(m=1\)</span> (observations follow the Bernoulli distribution), the posterior is given by <span class="math display">\[
p(\theta\mid Y) = Beta(Y+\alpha, 1-Y+\beta)
\]</span> where <span class="math inline">\(Y\)</span> is the number of successful outcomes <span class="math display">\[
Y = \sum_{i=1}^n y_i,
\]</span> where <span class="math inline">\(y_i \mid \theta \sim Bernoulli(\theta)\)</span>.</p>
<p>Here the count of successful outcome <span class="math inline">\(Y\)</span> acts as a <em>sufficient statistic</em> for the parameter <span class="math inline">\(\theta\)</span>. This means that the posterior distribution depends on the data only through the sufficient statistic <span class="math inline">\(Y\)</span>. This is a very useful property and is a consequence of the conjugacy of the Beta prior and Binomial likelihood.</p>
<p>In the case of <span class="math inline">\(n&gt;1\)</span> (observations follow the Binomial distribution), the posterior is given by <span class="math display">\[
\theta\mid Y \sim Beta(Y+\alpha, n-Y+\beta)
\]</span> where <span class="math inline">\(n\)</span> is the number of observations and <span class="math inline">\(Y\)</span> is the number of successful outcomes as before. <span class="math display">\[
Y = \sum_{i=1}^n y_i,
\]</span> where <span class="math inline">\(y_i \mid \theta \sim Binomial(n,\theta)\)</span>.</p>
<p>The posterior mean and variance are <span class="math display">\[
\mathbb{E}\left[ \theta\mid Y\right]  =\frac{\alpha_{n}}{\alpha_{n}+\beta_{n}} \;\text{ and }\; \Var{
\theta\mid Y}  =\frac{\alpha_{n}\beta_{n}}{\left(  \alpha_{n}+\beta_{n}\right)  ^{2}\left(   \alpha_{n}+\beta_{n}+1\right)  }\text{,}
\]</span> where <span class="math inline">\(\alpha_{n} = \alpha + Y\)</span> and <span class="math inline">\(\beta_{n} = \beta + n - Y\)</span>.</p>
<div id="exm-swan" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.2 (Black Swans)</strong></span> A related problem is the Black Swan inference problem. Suppose that after <span class="math inline">\(n\)</span> trials where <span class="math inline">\(n\)</span> is large you have only seen successes and that you assess the probability of the next trial being a success as <span class="math inline">\((T+1)/(T+2)\)</span> that is, almost certain. This is a model of observing White Swans and having never seen a Black Swan. <span class="citation" data-cites="taleb2007black">Taleb (<a href="references.html#ref-taleb2007black" role="doc-biblioref">2007</a>)</span> makes it sound as if the rules of probability are not rich enough to be able to handle Black Swan events. There is a related class of problems in finance known as <em>Peso problems</em> where countries decide to devalue their currencies and there is little prior evidence from recent history that such an event is going to happen.</p>
<p>To obtain such a probability assessment we use a Binomial/Beta conjugate Bayes updating model. The key point is that it can also explain that there is still a large probability of a Black Swan event to happen <em>sometime</em> in the future. An independence model has difficulty doing this.</p>
<p>The Bayes Learning Beta-Binomial model will have no problem. We model with <span class="math inline">\(y_{t}=0\)</span> or <span class="math inline">\(1\)</span>, with probability <span class="math inline">\(P\left( y_{t}=1\mid \theta\right) =\theta\)</span>. This is the classic Bernoulli “coin-flipping” model and is a component of more general specifications such as regime switching or outlier-type models.</p>
<p>Let <span class="math inline">\(Y = \sum_{t=1}^{T}y_{t}\)</span> be the number of observed successful outcomes. The likelihood for a sequence of Bernoulli observations is then <span class="math display">\[
p\left(  y\mid \theta\right)  =\prod_{t=1}^{T}p\left(  y_{t}\mid \theta\right)
=\theta^{Y}\left(  1-\theta\right)^{T-Y}.
\]</span> The maximum likelihood estimator is the sample mean, <span class="math inline">\(\widehat{\theta} = T^{-1}Y\)</span>. This makes little sense when you just observe white swans. It predicts <span class="math inline">\(\hat{\theta} = 1\)</span> and gets shocked when it sees a black swan (zero probability event). Bayes, on the other hand, allows for “learning”.</p>
<p>Bayes rule then tells us how to combine the likelihood and prior to obtain a posterior distribution, namely <span class="math inline">\(\theta \mid Y=y\)</span>. What do we believe about <span class="math inline">\(\theta\)</span> given a sequence of observations? It is straightforward to show that the posterior distribution is again a Beta distribution with <span class="math display">\[
p\left( \theta\mid y\right)  \sim Beta\left(  \alpha_{n},\beta_{n}\right)  \; \mathrm{ and} \;  \alpha_{n}=\alpha+k , \beta_{n}=\beta+T-k.
\]</span></p>
<p>Suppose we have observed <span class="math inline">\(T=100\)</span> white swans and no black swans (<span class="math inline">\(Y=100\)</span>). Using a uniform prior <span class="math inline">\(Beta(1,1)\)</span>, the posterior is <span class="math inline">\(Beta(101,1)\)</span>. The predictive probability that the next swan is white is the posterior mean: <span class="math display">\[
P(y_{T+1} = 1 \mid Y=100) = \mathbb{E}(\theta \mid Y) = \frac{\alpha_n}{\alpha_n + \beta_n} = \frac{101}{102} \approx 0.99.
\]</span> What about the probability of seeing at least one black swan in the next 100 observations? We compute this by integrating over the posterior: <span class="math display">\[
P(\text{at least one black swan in next } 100 \mid Y) = \int_0^1 \left[1 - \theta^{100}\right] p(\theta \mid Y) d\theta.
\]</span></p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<pre><code>## P(next swan is white) = 0.99
## P(at least one black swan in next 100) = 0.5</code></pre>
<div class="cell-output-display">
<div id="fig-blackswan" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-blackswan-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-blackswan-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-blackswan-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.3: Posterior distribution after observing 100 white swans
</figcaption>
</figure>
</div>
</div>
</div>
<p>Despite never having observed a black swan, the Bayesian approach assigns approximately 49.9% probability to seeing at least one black swan in the next 100 trials. This illustrates how Bayesian learning naturally handles rare events by maintaining uncertainty about <span class="math inline">\(\theta\)</span> through the posterior distribution.</p>
</div>
<div id="exm-normaltrials" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.3 (Clinical Trials)</strong></span> Consider a problem of designing clinical trials in which <span class="math inline">\(K\)</span> possible drugs <span class="math inline">\(a\in 1,\dots,K\)</span> need to be tested. The outcome of the treatment with drug <span class="math inline">\(a\)</span> is binary <span class="math inline">\(y(a) \in \{0,1\}\)</span>. We use Bernoulli distribution with mean <span class="math inline">\(f(a)\)</span> to model the outcome. Thus, the full probabilistic model is described by <span class="math inline">\(w = f(1),\dots,f(K)\)</span>. Say we have observed a sample <span class="math inline">\(D = \{y_1,\dots,y_n\}\)</span>. We would like to compute posterior distribution over <span class="math inline">\(w\)</span>. We start with a Beta prior <span class="math display">\[
p(w\mid \alpha,\beta) = \prod_{a=1}^K Beta(w_a\mid \alpha,\beta)    
\]</span> Then the posterior distribution is given by <span class="math display">\[
p(w\mid D) = \prod_{a=1}^K Beta(w_a\mid \alpha + n_{a,1},\beta + n_{a,0})   
\]</span></p>
<p>This setup allows us to perform sequential design of experiments. The simplest version of it is called Thompson sampling. After observing <span class="math inline">\(n\)</span> patients, we draw a single sample <span class="math inline">\(\tilde w\)</span> from the posterior and then maximize the resulting surrogate <span class="math display">\[
a_{n+1} = \arg\max_{a} f_{\tilde w}(a), ~~~ \tilde{w} \sim p(w\mid D)
\]</span></p>
</div>
<div id="exm-baseball" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.4 (Shrinkage and Baseball Batting Averages)</strong></span> The batter-pitcher match-up is a fundamental element of a baseball game. There are detailed baseball records that are examined regularly by fans and professionals. This data provides a good illustration of Bayesian hierarchical methods. There is a great deal of prior information concerning the overall ability of a player. However, we only see a small amount of data about a particular batter-pitcher match-up. Given the relatively small sample size, to determine our optimal estimator we build a hierarchical model taking into account the within pitcher variation.</p>
<p>Let’s analyze the variability in Jeter’s <span class="math inline">\(2006\)</span> season. Let <span class="math inline">\(p_{i}\)</span> denote Jeter’s ability against pitcher <span class="math inline">\(i\)</span> and assume that <span class="math inline">\(p_{i}\)</span> varies across the population of pitchers according to a particular probability distribution <span class="math inline">\((p_{i} \mid \alpha,\beta)\sim Be(\alpha,\beta)\)</span>. To account for extra-binomial variation we use a hierarchical model for the observed number of hits <span class="math inline">\(y_{i}\)</span> of the form <span class="math display">\[
(y_{i} \mid p_{i})\sim Bin(T_{i},p_{i})\;\;\mathrm{with}\;\;p_{i}\sim
Be(\alpha,\beta)
\]</span> where <span class="math inline">\(T_{i}\)</span> is the number of at-bats against pitcher <span class="math inline">\(i\)</span>. A priori we have a prior mean given by <span class="math inline">\(E(p_{i})=\alpha/(\alpha+\beta)=\bar{p}\)</span>. The extra heterogeneity leads to a prior variance <span class="math inline">\(Var(p_{i})=\bar{p}(1-\bar{p})\phi\)</span> where <span class="math inline">\(\phi=(\alpha+\beta+1)^{-1}\)</span>. Hence <span class="math inline">\(\phi\)</span> measures how concentrated the beta distribution is around its mean, <span class="math inline">\(\phi=0\)</span> means highly concentrated and <span class="math inline">\(\phi=1\)</span> means widely dispersed. <!-- where $T_{i}$ is the number of at-bats against pitcher $i$. A priori we have a prior mean given by $E(p_{i})=\alpha/(\alpha+\beta)=\bar{p}_{i}$. The extra heterogeneity leads to a prior variance $Var(p_{i})=\bar{p}_{i}(1-\bar{p}_{i})\phi$ where $\phi=(\alpha+\beta+1)^{-1}$. Hence $\phi$ measures how concentrated the beta distribution is around its mean, $\phi=0$ means highly concentrated and $\phi=1$ means widely dispersed. --></p>
<p>This model assumes that each player <span class="math inline">\(i\)</span> has a true ability <span class="math inline">\(p_{i}\)</span> that is drawn from a common distribution. The model is hierarchical in the sense that the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are estimated from the data. The model is also a shrinkage model in the sense that the estimates of <span class="math inline">\(p_{i}\)</span> are shrunk towards the overall mean <span class="math inline">\(\bar{p}_{i}\)</span>. In reality, we don’t know that each <span class="math inline">\(p_i\)</span> exists. We also don’t know if it follows a Binomial distribution with the Beta prior. We are making a model assumption. However, the model is a good approximation to the data and is a good way to estimate the parameters.</p>
<p><span class="citation" data-cites="stern2007inference">Stern et al. (<a href="references.html#ref-stern2007inference" role="doc-biblioref">2007</a>)</span> estimates the parameter <span class="math inline">\(\hat{\phi} = 0.002\)</span> for Derek Jeter, showing that his ability varies a bit but not very much across the population of pitchers. The effect of the shrinkage is not surprising. The extremes are shrunk the most with the highest degree of shrinkage occurring for the match-ups that have the smallest sample sizes. The amount of shrinkage is related to the large amount of prior information concerning Jeter’s overall batting average. Overall Jeter’s performance is extremely consistent across pitchers as seen from his estimates. Jeter had a season <span class="math inline">\(.308\)</span> average. We see that his Bayes estimates vary from<span class="math inline">\(.311\)</span> to<span class="math inline">\(.327\)</span> and that he is very consistent. If all players had a similar record then the assumption of a constant batting average would make sense.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Pitcher</th>
<th>At-bats</th>
<th>Hits</th>
<th>ObsAvg</th>
<th>EstAvg</th>
<th>95% Int</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>R. Mendoza</td>
<td>6</td>
<td>5</td>
<td>.833</td>
<td>.322</td>
<td>(.282, .394)</td>
</tr>
<tr class="even">
<td>H. Nomo</td>
<td>20</td>
<td>12</td>
<td>.600</td>
<td>.326</td>
<td>(.289, .407)</td>
</tr>
<tr class="odd">
<td>A.J.Burnett</td>
<td>5</td>
<td>3</td>
<td>.600</td>
<td>.320</td>
<td>(.275, .381)</td>
</tr>
<tr class="even">
<td>E. Milton</td>
<td>28</td>
<td>14</td>
<td>.500</td>
<td>.324</td>
<td>(.291, .397)</td>
</tr>
<tr class="odd">
<td>D. Cone</td>
<td>8</td>
<td>4</td>
<td>.500</td>
<td>.320</td>
<td>(.218, .381)</td>
</tr>
<tr class="even">
<td>R. Lopez</td>
<td>45</td>
<td>21</td>
<td>.467</td>
<td>.326</td>
<td>(.291, .401)</td>
</tr>
<tr class="odd">
<td>K. Escobar</td>
<td>39</td>
<td>16</td>
<td>.410</td>
<td>.322</td>
<td>(.281, .386)</td>
</tr>
<tr class="even">
<td>J. Wettland</td>
<td>5</td>
<td>2</td>
<td>.400</td>
<td>.318</td>
<td>(.275, .375)</td>
</tr>
<tr class="odd">
<td>T. Wakefield</td>
<td>81</td>
<td>26</td>
<td>.321</td>
<td>.318</td>
<td>(.279, .364)</td>
</tr>
<tr class="even">
<td>P. Martinez</td>
<td>83</td>
<td>21</td>
<td>.253</td>
<td>.312</td>
<td>(.254, .347)</td>
</tr>
<tr class="odd">
<td>K. Benson</td>
<td>8</td>
<td>2</td>
<td>.250</td>
<td>.317</td>
<td>(.264, .368)</td>
</tr>
<tr class="even">
<td>T. Hudson</td>
<td>24</td>
<td>6</td>
<td>.250</td>
<td>.315</td>
<td>(.260, .362)</td>
</tr>
<tr class="odd">
<td>J. Smoltz</td>
<td>5</td>
<td>1</td>
<td>.200</td>
<td>.314</td>
<td>(.253, .355)</td>
</tr>
<tr class="even">
<td>F. Garcia</td>
<td>25</td>
<td>5</td>
<td>.200</td>
<td>.314</td>
<td>(.253, .355)</td>
</tr>
<tr class="odd">
<td>B. Radke</td>
<td>41</td>
<td>8</td>
<td>.195</td>
<td>.311</td>
<td>(.247, .347)</td>
</tr>
<tr class="even">
<td>D. Kolb</td>
<td>5</td>
<td>0</td>
<td>.000</td>
<td>.316</td>
<td>(.258, .363)</td>
</tr>
<tr class="odd">
<td>J. Julio</td>
<td>13</td>
<td>0</td>
<td>.000</td>
<td>.312</td>
<td>(.243, .350 )</td>
</tr>
<tr class="even">
<td>Total</td>
<td>6530</td>
<td>2061</td>
<td>.316</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Some major league managers believe strongly in the importance of such data (Tony La Russa, <em>Three days in August</em>). One interesting example is the following. On Aug 29, 2006, Kenny Lofton (career <span class="math inline">\(.299\)</span> average, and current <span class="math inline">\(.308\)</span> average for <span class="math inline">\(2006\)</span> season) was facing the pitcher Milton (current record <span class="math inline">\(1\)</span> for <span class="math inline">\(19\)</span>). He was <em>rested</em> and replaced by a <span class="math inline">\(.273\)</span> hitter. Is putting in a weaker player really a better bet? Was this just an over-reaction to bad luck in the Lofton-Milton match-up? Statistically, from Lofton’s record against Milton we have <span class="math inline">\(P\left( \leq 1\;\mathrm{hit\;in}\ 19\;\mathrm{attempts} \mid p=0.3\right) =0.01\)</span> an unlikely <span class="math inline">\(1\)</span>-in-<span class="math inline">\(100\)</span> event. However, we have not taken into account the multiplicity of different batter-pitcher match-ups. We know that Lofton’s batting percentage will vary across different pitchers, it’s just a question of how much? A hierarchical analysis of Lofton’s variability gave a <span class="math inline">\(\phi=0.008\)</span> – four times larger than Jeter’s <span class="math inline">\(\phi=0.002\)</span>. Lofton has batting estimates that vary from <span class="math inline">\(.265\)</span> to <span class="math inline">\(.340\)</span> with the lowest being against Milton. Hence, the optimal estimate for a pitch against Milton is <span class="math inline">\(.265&lt;.275\)</span> and resting Lofton against Milton is justified by this analysis.</p>
</div>
</section>
<section id="poisson-model-for-count-data" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="poisson-model-for-count-data"><span class="header-section-number">3.4</span> Poisson Model for Count Data</h2>
<p>The Poisson distribution is obtained as a result of the Binomial when <span class="math inline">\(p\)</span> is small and <span class="math inline">\(n\)</span> is large. In applications, the Poisson models count data. Suppose we want to model the arrival rate of users to one of our stores. Let <span class="math inline">\(\lambda = np\)</span>, which is fixed and take the limit as <span class="math inline">\(n \rightarrow \infty\)</span>. There is a relationship between <span class="math inline">\(p(x)\)</span> and <span class="math inline">\(p(x+1)\)</span> given by <span class="math display">\[
\dfrac{p(x+1)}{p(x)}= \dfrac{\left(\dfrac{n}{x+1}\right)p^{x+1}(1-p)^{n-x-1}}{\left(\dfrac{n}{x}\right)p^{x}(1-p)^{n-x}} \approx \dfrac{np}{x+1}
\]</span> If we approximate <span class="math inline">\(p(x+1)\approx \lambda p(x)/(x+1)\)</span> with <span class="math inline">\(\lambda=np\)</span>, then we obtain the Poisson pdf given by <span class="math inline">\(p(x) = p(0)\lambda^x/x!\)</span>. To ensure that <span class="math inline">\(\sum_{x=0}^\infty p(x) = 1\)</span>, we set <span class="math display">\[
f(0) = \dfrac{1}{\sum_{x=0}^{\infty}\lambda^x/x!} = e^{-\lambda}.
\]</span> The above equality follows from the power series property of the exponent function <span class="math display">\[
e^{\lambda} = \sum_{x=0}^{\infty}\dfrac{\lambda^x}{x!}
\]</span> The <em>Poisson distribution</em> counts the occurrence of events. Given a rate parameter, denoted by <span class="math inline">\(\lambda\)</span>, we calculate probabilities as follows <span class="math display">\[
p( X = x ) = \frac{ e^{-\lambda} \lambda^x }{x!} \; \mathrm{ where} \; x=0,1,2,3, \ldots
\]</span> For <span class="math inline">\(n\)</span> independent Poisson observations <span class="math inline">\(x_1,\ldots,x_n\)</span>, the sufficient statistic for <span class="math inline">\(\lambda\)</span> is the sum <span class="math inline">\(\sum_{i=1}^n x_i\)</span>. The mean and variance of the Poisson are given by:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Poisson Distribution</th>
<th style="text-align: center;">Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Expected value</td>
<td style="text-align: center;"><span class="math inline">\(\mu = \E{X} = \lambda\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">Variance</td>
<td style="text-align: center;"><span class="math inline">\(\sigma^2 = \Var{X} = \lambda\)</span></td>
</tr>
</tbody>
</table>
<p>Here <span class="math inline">\(\lambda\)</span> denotes the rate of occurrence of an event.</p>
<p>Consider the problem of modeling soccer scores in the English Premier League (EPL) games. We use data from Betfair, a website, which posts odds on many football games. The goal is to calculate odds for the possible scores in a match. <span class="math display">\[
0-0, \; 1-0, \; 0-1, \; 1-1, \; 2-0, \ldots
\]</span></p>
<p>Another question we might ask, is what’s the odds of a team winning? This is given by <span class="math inline">\(P\left ( X&gt; Y \right )\)</span>. The odds of a draw are given by <span class="math inline">\(P \left ( X = Y \right )\)</span>. Here <span class="math inline">\(X\)</span> is the number of goals scored by the home team and <span class="math inline">\(Y\)</span> is the number of goals scored by the away team.</p>
<p>Professional sports bettors rely on sophisticated statistical models to predict the outcomes. Instead, we present a simple, but useful model for predicting outcomes of EPL games. We follow the methodology given in <span class="citation" data-cites="spiegelhalter2009one">Spiegelhalter and Ng (<a href="references.html#ref-spiegelhalter2009one" role="doc-biblioref">2009</a>)</span>.</p>
<p>To make the discussion more concrete, we will use data from the English Premier League (EPL) 2014/2015 season and model the game between Manchester United and Hull City.</p>
<p>First, load the data and then model the number of goals scored using Poisson distribution for each team.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">home_team_name</th>
<th style="text-align: left;">away_team_name</th>
<th style="text-align: right;">home_score</th>
<th style="text-align: right;">guest_score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Arsenal</td>
<td style="text-align: left;">Liverpool</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
</tr>
<tr class="even">
<td style="text-align: left;">Bournemouth</td>
<td style="text-align: left;">Manchester United</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Burnley</td>
<td style="text-align: left;">Swansea</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Chelsea</td>
<td style="text-align: left;">West Ham</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Crystal Palace</td>
<td style="text-align: left;">West Bromwich Albion</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Everton</td>
<td style="text-align: left;">Tottenham</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Let’s compare the empirical distribution across the number of goals scored by Manchester United to the Poisson distribution.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="03-bl_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="448"></p>
<figcaption>Histogram vs Poisson Model Prediction of Goals Scored by MU</figcaption>
</figure>
</div>
</div>
</div>
<p>Hence the historical data fits closely to a Poisson distribution, the parameter <span class="math inline">\(\lambda\)</span> describes the average number of goals scored and we calculate it by calculating the sample mean, the maximum likelihood estimate. A Bayesian method where we assume that <span class="math inline">\(\lambda\)</span> has a Gamma prior is also available. This lets you incorporate outside information into the predictive model.</p>
<p>Now we will use Poisson model and Monte Carlo simulations to predict possible outcomes of the MU vs Hull games. First we estimate the rate parameter for goals by MU <code>lmb_mu</code> and goals by Hull <code>lmb_h</code>. Each team played a home and away game with every other team, thus 38 total games was played by all teams. We calculate the average by dividing total number of goals scored by the number of games</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">Team</th>
<th style="text-align: right;">GF_H</th>
<th style="text-align: right;">GF_A</th>
<th style="text-align: right;">GA_H</th>
<th style="text-align: right;">GA_A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Hull</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">35</td>
<td style="text-align: right;">45</td>
</tr>
<tr class="even">
<td style="text-align: left;">Manchester United</td>
<td style="text-align: right;">26</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">17</td>
</tr>
</tbody>
</table>
<p>Summarizing the data</p>
</div>
</div>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>lmb_mu <span class="ot">&lt;-</span> (<span class="dv">26</span> <span class="sc">+</span> <span class="dv">28</span>) <span class="sc">/</span> <span class="dv">38</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>lmb_h <span class="ot">&lt;-</span> (<span class="dv">28</span> <span class="sc">+</span> <span class="dv">9</span>) <span class="sc">/</span> <span class="dv">38</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now we simulate 100 games between the teams</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="dv">100</span>, lmb_mu)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="dv">100</span>, lmb_h)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="fu">table</span>(x, y))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">0</th>
<th style="text-align: right;">1</th>
<th style="text-align: right;">2</th>
<th style="text-align: right;">3</th>
<th style="text-align: right;">4</th>
<th style="text-align: right;">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">3</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">4</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">5</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>From our simulation that <code>sum(x&gt;y)</code>: 48 number of times MU wins and <code>sum(x==y)</code>: 32 there is a draw. The actual outcome was 0-0 (Hull at MU) and 0-1 (Mu at Hull). Thus our model gives a reasonable prediction.</p>
<p>The model can be improved by calculating different averages for home and away games. For example, Hull does much better at home games compared to away games. Further, we can include the characteristics of the opponent team to account for interactions between attack strength (number of scored) and defense weakness of the opponent. Now we modify our value of expected goals for each of the teams by calculating <span class="math display">\[
\hat \lambda = \lambda \times  \text{Defense weakness}
\]</span></p>
<p>Let’s model the MU at Hull game. The average away goals for MU <span class="math inline">\(28/19 = 1.4736842\)</span> and the defense weakness of Hull is <span class="math inline">\(35/19 = 1.8421053\)</span>, thus the adjusted expected number of goals to be scored by MU is 2.7146814. Similarly, the adjusted number of goals Hull is expected to score is <span class="math inline">\(28/19 \times 17/19 = 1.3185596\)</span></p>
<p>As a result of the simulation, we obtain the following count matrix of possible outcomes, shown in <a href="#fig-sim-mu-hull" class="quarto-xref">Figure&nbsp;<span>3.4</span></a>.</p>
<div class="cell" data-layout-align="center" data-out-heigth="7in" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="dv">100</span>, <span class="dv">28</span> <span class="sc">/</span> <span class="dv">19</span> <span class="sc">*</span> <span class="dv">35</span> <span class="sc">/</span> <span class="dv">19</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="dv">100</span>, <span class="dv">28</span> <span class="sc">/</span> <span class="dv">19</span> <span class="sc">*</span> <span class="dv">17</span> <span class="sc">/</span> <span class="dv">19</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="at">z =</span> <span class="fu">table</span>(x, y), <span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">7</span>, <span class="at">y =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">5</span>, <span class="at">xlab =</span> <span class="st">"MU Score"</span>, <span class="at">ylab =</span> <span class="st">"Hull Score"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div id="fig-sim-mu-hull" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sim-mu-hull-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-sim-mu-hull-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sim-mu-hull-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.4: Simulation of MU vs Hull game
</figcaption>
</figure>
</div>
</div>
</div>
<p>Now we can calculate the number of times MU wins:</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(x <span class="sc">&gt;</span> y)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="do">## 67</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<!--     Team      Expected Goals   0    1    2    3    4    5 -->
<!-- ----------- ---------------- ---- ---- ---- ---- ---- ---- -->
<!--     Man U          2.95        7    22   26   12   11   13 -->
<!--   Hull City        0.65        49   41   10   0    0    0 -->
<p>A model is only as good as its predictions. Let’s see how well our model predicted the outcome of the MU vs Hull game. The actual outcome was 0-1 (MU at Hull). The model predicted that most likely MU would score 1-2 (16 games out of 100). In our simulation 0-1 was the third most probable outcome (8 games out of 100). Man U wins 67 games out of 100, we should bet when odds ratio is below 67 to 100.</p>
</section>
<section id="poisson-gamma-learning-about-an-intensity" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="poisson-gamma-learning-about-an-intensity"><span class="header-section-number">3.5</span> Poisson-Gamma: Learning about an Intensity</h2>
<p>Consider a continuous-time stochastic process, <span class="math inline">\(\left\{ N_{t}\right\} _{t\geq0}\)</span>, with <span class="math inline">\(N_{0}=0\)</span>, counting the number of events that have occurred up to time <span class="math inline">\(t\)</span>. The process is constant between event times, and jumps by one at event times: <span class="math inline">\(\Delta N_{t}=N_{t}-N_{t-}=1,\)</span> where <span class="math inline">\(N_{t-}\)</span> is the limit from the left. The probability of an event over the next short time interval, <span class="math inline">\(\Delta t\)</span> is <span class="math inline">\(\lambda\Delta t\)</span>, and <span class="math inline">\(N_{t}\)</span> is called a Poisson process because <span class="math display">\[
P\left[  N_{t}=k\right]  =\frac{e^{-\lambda t}\left(  \lambda
t\right)  ^{k}}{k!}\text{ for }k=1,\ldots
\]</span> which is the Poisson distribution, thus <span class="math inline">\(N_{t}\sim Poi\left(\lambda t\right)\)</span>. A more general version of the Poisson process is a Cox process, or doubly stochastic point process.</p>
<p>Here, there is additional conditioning information in the form of state variables, <span class="math inline">\(\left\{X_{t}\right\}_{t&gt;0}\)</span>. The process now has two sources of randomness, one associated with the discontinuous jumps and another in the form of random state variables, <span class="math inline">\(\left\{X_{t}\right\}_{t&gt;0}\)</span>, that drive the intensity of the process. The intensity of the Cox process is <span class="math inline">\(\lambda_{t}=\int_{0}^{t}\lambda\left( X_{s}\right) ds\)</span>, which is formally defined as <span class="math display">\[
P\left[  N_{t}-N_{s}=k \mid \left\{  X_{u}\right\}  _{s\leq u\leq
t}\right]  =\frac{\left(  \int_{s}^{t}\lambda\left(  X_{s}\right)  ds\right)
^{k}\exp\left(  -\int_{s}^{t}\lambda\left(  X_{s}\right)  ds\right)}{k!}, ~ \forall k
\]</span> Cox processes are very useful extensions to Poisson processes and are the basic building blocks of reduced form models of defaultable bonds.</p>
<p>The inference problem is to learn about <span class="math inline">\(\lambda\)</span> from a continuous-record of observation up to time <span class="math inline">\(t\)</span>. The likelihood function is given by <span class="math display">\[
p\left(  N_{t}=k \mid \lambda\right)  =\frac{\left(  \lambda t\right)  ^{k}%
\exp\left(  -\lambda t\right)  }{k!},
\]</span> and the MLE is <span class="math inline">\(\widehat{\lambda}=N_{t}/t\)</span>. Notice that the total count <span class="math inline">\(N_t\)</span> and elapsed time <span class="math inline">\(t\)</span> together form the sufficient statistic for <span class="math inline">\(\lambda\)</span>, since the likelihood depends on the data only through these two quantities. The MLE has the unattractive property that prior to the first event <span class="math inline">\(\left\{ t:N_{t}=0\right\}\)</span>, the MLE is 0, despite the fact that the model explicitly assumes that events are possible. This problem often arises in credit risk contexts, where it would seem odd to assume that the probability of default is zero just because a default has not yet occurred.</p>
<p>A natural prior for this model is the Gamma distribution, which has the following pdf <span id="eq-gamma-pdf"><span class="math display">\[
p\left(  \lambda \mid a,A\right)  =\frac{A^{a}}{\Gamma(a)  }\lambda^{a-1}\exp\left(  -A\lambda\right)  \text{.}
\tag{3.2}\]</span></span> Like the beta distribution, a Gamma prior distribution allows for a variety of prior shapes and is parameterized by two hyperparameters. Combining the prior and likelihood, the posterior is also Gamma: <span class="math display">\[
p\left(  \lambda \mid N_{t}\right)  \propto\frac{\left(  \lambda\right)
^{N_{t}+a-1}\exp\left(  -\lambda\left(  t+A\right)  \right)  }{N_{t}!}%
\sim\mathcal{G}\left(  a_{t},A_{t}\right)  ,
\]</span> where <span class="math inline">\(a_{t}=N_{t}+a\)</span> and <span class="math inline">\(A_{t}=t+A\)</span>. The expected intensity, based on information up to time <span class="math inline">\(t\)</span>, is <span class="math display">\[
\mathbb{E}\left[  \lambda \mid N_{t}\right]  =\frac{a_{t}}{A_{t}}=\frac{N_{t}%
+a}{t+A}=w_{t}\frac{N_{t}}{t}+\left(  1-w_{t}\right)  \frac{a}{A},
\]</span> where the second line expresses the posterior mean in shrinkage form as a weighted average of the MLE and the prior mean where <span class="math inline">\(w_{t}=t/(t+A)\)</span>. In large samples, <span class="math inline">\(w_{t}\rightarrow1\)</span> and <span class="math inline">\(E\left( \lambda \mid N_{t}\right) \approx N_{t}/t=\widehat{\lambda}\)</span>.</p>
<p>To understand the updating mechanics, <a href="#fig-poiss" class="quarto-xref">Figure&nbsp;<span>3.5</span></a> (right column) displays a simulated sample path, posterior means, and (5%,95%) posterior quantiles for various prior configurations. In this case, time is measured in years and the intensity used to simulate the data is <span class="math inline">\(\lambda=1\)</span>, implying on average one event per year. The four prior configurations embody different beliefs. In the first case, in the middle left panel, <span class="math inline">\(a=4\)</span> and <span class="math inline">\(A=1\)</span>, captures a high-activity prior, that posits that jumps occur, on average, four times per year, and there is substantial prior uncertainty over the arrival rate as the (5%,95%) prior quantiles are (1.75,6.7). In the second case, captures a prior that is centered over the true value with modest prior uncertainty. The third case captures a low-activity prior, with a prior mean of 0.2 jumps/year. The fourth case captures a dogmatic prior, that posits that jumps occur three times per year, with high confidence in these beliefs.</p>
<p>The priors were chosen to highlight different potential paths for Bayesian learning. The first thing to note from the priors is the discontinuity upward at event times, and the exponential decrease during periods of no events, both of which are generic properties of Bayesian learning in this model. If one thinks of the events as rare, this implies rapid revisions in beliefs at event times and a constant drop in estimates of the intensity in periods of no events. For the high-activity prior and the sample path observed, the posterior begins well above <span class="math inline">\(\lambda=1\)</span>, and slowly decreases, getting close to <span class="math inline">\(\lambda=1\)</span> at the end of the sample. This can be somewhat contrasted with the low-activity prior, which has drastic revisions upward at jump times. In the dogmatic case, there is little updating at event times. The prior parameters control how rapidly beliefs change, with noticeable differences across the priors.</p>
<p>In all cases, the orange line shows the cumulative event count <span class="math inline">\(N_t\)</span>, the blue dashed line represents the posterior mean of <span class="math inline">\(\lambda\)</span>, and the grey dashed lines indicate the 5% and 95% posterior quantiles. The discontinuous upward jumps at event times and exponential decay during quiet periods are characteristic features of Bayesian learning in Poisson processes.</p>
<div id="fig-poiss" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-poiss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-poiss" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-poiss-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-poiss-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-poiss-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-poiss" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-poiss-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) High-activity: a = 4, A = 1; 4 events/year, Substantial prior uncertainty
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-poiss" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-poiss-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-poiss-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-poiss-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-poiss" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-poiss-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Posterior: Starts high, gradually decreases toward true value
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-poiss" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-poiss-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-poiss-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-poiss-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-poiss" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-poiss-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Diffuse: a = 1, A = 1; 1 event/year, Minimal prior information
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-poiss" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-poiss-4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-poiss-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-poiss-4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-poiss" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-poiss-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d) Posterior: Data dominates inference relatively quickly
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-poiss" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-poiss-5" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-poiss-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-poiss-5.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-poiss" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-poiss-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(e) Low-activity: a = 1, A = 5; 0.2 events/year, Rare events expected
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-poiss" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-poiss-6" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-poiss-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-poiss-6.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-poiss" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-poiss-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(f) Posterior: The low prior count dominates the posterior
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-poiss" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-poiss-7" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-poiss-7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-poiss-7.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-poiss" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-poiss-7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(g) Dogmatic: a = 30, A = 10; 3 events/year, Strong prior beliefs
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-poiss" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-poiss-8" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-poiss-8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-poiss-8.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-poiss" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-poiss-8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(h) Posterior: Updates slowly, resistant to contradictory evidence
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-poiss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.5: Sensitivity of Gamma Prior for Poisson Process
</figcaption>
</figure>
</div>
<p>Poisson event models are often embedded as portion of more complicated model to capture rare events such as stock market crashes, volatility surges, currency revaluations, or defaults. In these cases, prior distributions are often important–even essential–since it is common to build models with events that could, but have not yet occurred. These events are often called ‘Peso’ events. For example, in the case of modeling corporate defaults a researcher wants to allow for a jump to default. This requires positing a prior distribution that places non-zero probability on an event occurring. Classical statistical methods have difficulties dealing with these situations since the MLE of the jump probability is zero, until the first event occurs.</p>
</section>
<section id="exponential-gamma-model" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="exponential-gamma-model"><span class="header-section-number">3.6</span> Exponential-Gamma Model</h2>
<p>The Exponential distribution is often used to model waiting times between events, such as the time between independent arrivals in a Poisson process. The probability density function (PDF) is defined as: <span class="math display">\[
p(x \mid \lambda) = \lambda e^{-\lambda x}, \quad x \geq 0
\]</span> where <span class="math inline">\(\lambda &gt; 0\)</span> is the rate parameter (inverse of the mean).</p>
<p>The <em>Exponential-Gamma</em> model assumes that the data follows an exponential distribution, and the rate parameter <span class="math inline">\(\lambda\)</span> follows a Gamma prior distribution. <span class="math display">\[\begin{align*}
    \lambda &amp;\sim \text{Gamma}(\alpha, \beta) \\
    y_i \mid \lambda &amp;\sim \text{Exponential}(\lambda)
\end{align*}\]</span></p>
<p>The probability density function of the Gamma prior is: <span class="math display">\[
p(\lambda \mid \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta\lambda}
\]</span></p>
<p>Given <span class="math inline">\(n\)</span> observations <span class="math inline">\(y = (y_1, \ldots, y_n)\)</span>, the likelihood depends on the data only through the count <span class="math inline">\(n\)</span> and the sum <span class="math inline">\(\sum_{i=1}^n y_i\)</span>, which form the sufficient statistics for <span class="math inline">\(\lambda\)</span>. The posterior distribution of <span class="math inline">\(\lambda\)</span> is: <span class="math display">\[
p(\lambda\mid y) \propto p(y \mid \lambda) p(\lambda) \propto \left( \prod_{i=1}^n \lambda e^{-\lambda y_i} \right) \lambda^{\alpha - 1} e^{-\beta\lambda} = \lambda^{\alpha + n - 1} e^{-(\beta + \sum y_i)\lambda}
\]</span> This is a Gamma distribution with updated parameters: <span class="math display">\[
\lambda \mid y \sim \text{Gamma}\left(\alpha + n, \beta + \sum_{i=1}^n y_i\right).
\]</span> The posterior mean is: <span class="math display">\[
\mathbb{E}[\lambda \mid y] = \frac{\alpha + n}{\beta + \sum y_i}.
\]</span></p>
<p>This model is widely used in reliability engineering (failure rates) and survival analysis, where the rate of events is uncertain and varies across populations.</p>
<p>The Normal or Gaussian distribution is central to probability and statistical inference. Suppose that we are trying to predict tomorrow’s return on the S&amp;P500. There’s a number of questions that come to mind</p>
<ol type="1">
<li><p>What is the random variable of interest?</p></li>
<li><p>How can we describe our uncertainty about tomorrow’s outcome?</p></li>
<li><p>Instead of listing all possible values we’ll work with intervals instead. The probability of an interval is defined by the area under the probability density function.</p></li>
</ol>
<p>Returns are continuous (as opposed to discrete) random variables. Hence a normal distribution would be appropriate - but on what scale? We will see that on the log-scale a Normal distribution provides a good approximation.</p>
<p>The most widely used model for a continuous random variable is the normal distribution. Standard normal random variable <span class="math inline">\(Z\)</span> has the following properties</p>
<p>The standard Normal has mean <span class="math inline">\(0\)</span> and has a variance <span class="math inline">\(1\)</span>, and is written as <span class="math display">\[
Z \sim N(0,1)
\]</span> Then, we have the probability statements of interest <span class="math display">\[\begin{align*}  
P(-1 &lt;Z&lt; 1) &amp;=0.68\\
P(-1.96 &lt;Z&lt; 1.96) &amp;=0.95\\
\end{align*}\]</span> In <code>R</code>, we can find probabilities <code>pnorm(1.96)</code>: 0.9750021 and quantiles <code>qnorm(0.9750)</code>: 1.959964. The quantile function <code>qnorm</code> is the inverse of <code>pnorm</code>.</p>
<p>A random variable that follows normal distribution with general mean and variance <span class="math inline">\(X \sim \mbox{N}(\mu, \sigma^2)\)</span>, has the following properties <span class="math display">\[\begin{align*}
  p(\mu - 2.58 \sigma &lt; X &lt; \mu + 2.58 \sigma) &amp;=0.99 \\
  p(\mu - 1.96 \sigma &lt; X &lt; \mu + 1.96 \sigma) &amp;=0.95 \, .
\end{align*}\]</span> The chance that <span class="math inline">\(X\)</span> will be within <span class="math inline">\(2.58 \sigma\)</span> of its mean is <span class="math inline">\(99\%\)</span>, and the chance that it will be within <span class="math inline">\(2\sigma\)</span> of its mean is about <span class="math inline">\(95\%\)</span>.</p>
<p>The probability model is written <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>, where <span class="math inline">\(\mu\)</span> is the mean, <span class="math inline">\(\sigma^2\)</span> is the variance. This can be transformed to a standardized normal via <span class="math display">\[
Z =\frac{X-\mu}{\sigma} \sim N(0,1).
\]</span> For a Normal distribution, we know that <span class="math inline">\(X \in [\mu-1.96\sigma,\mu+1.96\sigma]\)</span> with probability 95%. This is a specific property of the Normal curve (the “Empirical Rule”). For <em>any</em> distribution, regardless of shape, we can use <strong>Chebyshev’s Inequality</strong> to bound the probability mass. It states that at least <span class="math inline">\(100(1-1/k^2)\)</span>% of values lie within <span class="math inline">\(k\)</span> standard deviations of the mean:</p>
<ol type="1">
<li><p>At least 75% probability lies within <span class="math inline">\(2\sigma\)</span> (<span class="math inline">\(k=2\)</span>).</p></li>
<li><p>At least 89% probability lies within <span class="math inline">\(3\sigma\)</span> (<span class="math inline">\(k=3\)</span>).</p></li>
<li><p>At least <span class="math inline">\(100(1-1/m^2)\)</span>% lies within <span class="math inline">\(m\times \sigma\)</span> of the mean <span class="math inline">\(\mu\)</span>.</p></li>
</ol>
<p>While the Normal distribution guarantees 95% within <span class="math inline">\(2\sigma\)</span>, Chebyshev guarantees only 75%, reflecting the uncertainty given a lack of distributional assumptions.</p>
<div id="exm-googlestock" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.5 (Google Stock 2019)</strong></span> Consider observations of daily log-returns of a Google stock for 2019 Daily log-return on day <span class="math inline">\(t\)</span> is calculated by taking a logarithm of the ratio of price at close of day <span class="math inline">\(t\)</span> and at close of day <span class="math inline">\(t-1\)</span> <span class="math display">\[
  y_t = \log\left(\dfrac{P_t}{P_{t-1}}\right)
\]</span> For example on January 3 of 2017, the open price is 778.81 and close price was 786.140, then the log-return is <span class="math inline">\(\log(786.140/778.81) =  -0.0094\)</span>. It was empirically observed that log-returns follow a Normal distribution. This observation is a basis for Black-Scholes model with is used to evaluate future returns of a stock.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"../data/GOOG2019.csv"</span>)<span class="sc">$</span>Adj.Close</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(p)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">log</span>(p[<span class="dv">2</span><span class="sc">:</span>n] <span class="sc">/</span> p[<span class="dv">1</span><span class="sc">:</span>(n <span class="sc">-</span> <span class="dv">1</span>)])</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(r, <span class="at">breaks =</span> <span class="dv">30</span>, <span class="at">col =</span> <span class="st">"lightblue"</span>, <span class="at">main =</span> <span class="st">""</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="03-bl_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="448"></p>
</figure>
</div>
</div>
</div>
<p>Observations on the far right correspond to the days when positive news was released and on the far left correspond to bad news. Typically, those are days when the quarterly earnings reports are released.</p>
<p>To estimate the expected value <span class="math inline">\(\mu\)</span> (return) and standard deviation <span class="math inline">\(\sigma\)</span> (a measure of risk), we simply calculate their sample counterparts <span class="math display">\[
\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i, ~\mathrm{ and }~    s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x} )^2
\]</span> The empirical (or sample) values <span class="math inline">\(\bar x\)</span> and <span class="math inline">\(s^2\)</span> are called sample mean and sample variance. Here simply vie them as our best guess about the mean and variance of the normal distribution model then our probabilistic model for next day’s return is then given by <span class="math display">\[
R \sim N(\bar x, s^2).
\]</span></p>
<p>Say we are interested in investing into Google and would like to calculated the expected return of our investment as well as risk associated with this investment We assume that behavior of the returns in the future will be the same as in 2019.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(r)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>rbar <span class="ot">&lt;-</span> <span class="fu">sum</span>(r) <span class="sc">/</span> n</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rbar)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 0.00098</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>s2 <span class="ot">&lt;-</span> <span class="fu">sum</span>((r <span class="sc">-</span> rbar)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (n <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(s2)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 0.00023</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="fl">0.08</span>, <span class="fl">0.08</span>, <span class="at">length.out =</span> <span class="dv">200</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(r, <span class="at">breaks =</span> <span class="dv">30</span>, <span class="at">col =</span> <span class="st">"lightblue"</span>, <span class="at">freq =</span> F, <span class="at">main =</span> <span class="st">""</span>, <span class="at">xlab =</span> <span class="st">""</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">dnorm</span>(x, rbar, <span class="fu">sqrt</span>(s2)), <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="03-bl_files/figure-html/normal-fit-1.png" class="img-fluid figure-img" width="448"></p>
<figcaption>Histogram (blue) and fitted normal curve (red) of for the Google stock daily return data.</figcaption>
</figure>
</div>
</div>
</div>
<p>Now, assume, I invest all my portfolio into Google. I can predict my annual return to be <span class="math inline">\(251 \times 0.0009798\)</span> = 0.2459348 and risk (volatility) of my investment is <span class="math inline">\(\sqrt{s^2}\)</span> = 1.5198424% a year.</p>
<p>I can predict the risk of losing 3% or more in one day using my model is 1.93%.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fu">log</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fl">0.03</span>), rbar, <span class="fu">sqrt</span>(s2)) <span class="sc">*</span> <span class="dv">100</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="do">## 1.9</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(spret)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="do">## 0.012</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(spret)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 0.043</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="normal-with-unknown-mean" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="normal-with-unknown-mean"><span class="header-section-number">3.7</span> Normal With Unknown Mean</h2>
<p>Let <span class="math inline">\(Y\)</span> be a random variable with a normal distribution, <span class="math inline">\(Y \sim N(\mu, \sigma^2)\)</span>. The mean <span class="math inline">\(\mu\)</span> is unknown, but the variance <span class="math inline">\(\sigma^2\)</span> is known. The likelihood function is given by <span class="math display">\[
p(y \mid \mu) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(y-\mu)^2\right)
\]</span> The MLE of <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\hat{\mu} = \bar{y}\)</span>, the sample mean. Normal prior for the mean parameter <span class="math inline">\(\mu\)</span> is conjugate to the normal likelihood. <span class="math display">\[
\mu \sim N(\mu_0, \sigma_0^2)
\]</span> The posterior distribution is also normal. <span class="math display">\[
p(\mu \mid y) \sim N(\mu_n, \sigma_n^2)
\]</span></p>
<p>where <span class="math display">\[
\mu_n = \frac{\sigma^2}{n\sigma_0^2 + \sigma^2}\mu_0 + \frac{n\sigma_0^2}{n\sigma_0^2 + \sigma^2}\bar{y}
\]</span> and <span class="math display">\[
\sigma_n^2 = \frac{\sigma^2\sigma_0^2}{n\sigma_0^2 + \sigma^2}
\]</span> The posterior mean is a weighted average of the prior mean and the sample mean, with the weights being proportional to the precision of the prior and the likelihood. The posterior variance is smaller than the prior variance, and the sample size <span class="math inline">\(n\)</span> appears in the denominator. The posterior mean is a shrinkage estimator of the sample mean, and the amount of shrinkage is controlled by the prior variance <span class="math inline">\(\sigma_0^2\)</span>. A couple of observations <span class="math display">\[
\frac{\sigma^2}{n\sigma_0^2 + \sigma^2} \rightarrow 0 \text{ and } \frac{n\sigma_0^2}{n\sigma_0^2 + \sigma^2}\rightarrow 1, \text{ as } n \rightarrow \infty.
\]</span> Further, <span class="math display">\[
\frac{\sigma^2\sigma_0^2}{n\sigma_0^2 + \sigma^2} \rightarrow 0 \text{ as } n \rightarrow \infty.
\]</span></p>
<div id="exm-normal" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.6 (Stylized Example)</strong></span> Assuming the prior distribution <span class="math inline">\(\mu \sim N(-1,1)\)</span>, say we observed <span class="math inline">\(y=2\)</span> and we want to update our beliefs about <span class="math inline">\(\mu\)</span>. The likelihood function is <span class="math inline">\(p(y \mid \mu) = N(\mu,2)\)</span>, and the posterior distribution is <span class="math display">\[
p(\mu \mid y) \propto p(y \mid \mu) p(\mu) = N(y\mid \mu,2) N(\mu\mid -1,1) = N(-0.4,0.9).
\]</span></p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<pre><code>## "Posterior mean: -0.400000, Posterior variance: 0.894427"</code></pre>
</div>
<p>Graphically we can represent this as follows</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="cell-output-display">
<div id="fig-kalman" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-kalman-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-kalman-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-kalman-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.6: Norm-Norm Updating
</figcaption>
</figure>
</div>
</div>
</div>
<p>Note, the posterior mean is in between those of prior and likelihood and posterior variance is lower than variance of both prior and likelihood, this is effect of combining information from data and prior!</p>
</div>
<p>More generally, when we observe <span class="math inline">\(n\)</span> independent and identically distributed (i.i.d.) data points <span class="math inline">\(y_1,\ldots,y_n\)</span> from a normal distribution with known variance <span class="math inline">\(\sigma^2\)</span>, the likelihood function is given by <span class="math display">\[
p(y \mid \mu) = N(\bar y\mid \mu,\sigma^2/n),~ \text{where}~ \bar y = \frac{1}{n}\sum_{i=1}^n y_i.
\]</span> Note, that average over the observed data <span class="math inline">\(\bar y = \mathrm{Ave}(y_1,\ldots,y_n)\)</span> is the sufficient statistics for the mean <span class="math inline">\(\mu\)</span>. The prior distribution is given by <span class="math display">\[
p(\mu) = N(\mu\mid \mu_0,\sigma_0^2)
\]</span> The posterior distribution is given by <span class="math display">\[
\begin{split}
p(\mu\mid y)
&amp; \propto  \exp\Bigg[{\frac{-\mu^2+2\mu\mu_0-\mu_0^2}{2\sigma_0^2}}\Bigg]\exp\Bigg[{\frac{-\mu^2+2\mu\bar{y}-\bar{y}^2}{2\sigma^2/n}}\Bigg] \\
&amp; \propto  \exp\Bigg[{\frac{-\mu^2+2\mu\mu_0}{2\sigma_0^2}}\Bigg]\exp\Bigg[{\frac{-\mu^2+2\mu\bar{y}}{2\sigma^2/n}}\Bigg]. \\
\end{split}
\]</span> Now we combine the terms <span class="math display">\[
\begin{split}
p(\mu\mid y)
&amp; \propto  \exp\Bigg[{\frac{(-\mu^2+2\mu\mu_0)\sigma^2 +(-\mu^2+2\mu\bar{y})n\sigma_0^2}{2\sigma_0^2\sigma^2}}\Bigg]. \\
\end{split}
\]</span> Now re-arrange and combine <span class="math inline">\(\mu^2\)</span> and <span class="math inline">\(\mu\)</span> terms <span class="math display">\[
\begin{split}
p(\mu\mid y)
&amp; \propto  \exp\Bigg[{\frac{-\mu^2(n\sigma_0^2+\sigma^2)+2\mu(\mu_0\sigma^2+ \bar{y}n\sigma_0^2) }{2\sigma_0^2\sigma^2}}\Bigg] \\
&amp; \propto  \exp\Bigg[{\frac{-\mu^2+2\mu\left(\frac{\mu_0\sigma^2 + \bar{y}n\sigma_0^2}{n\sigma_0^2+\sigma^2}\right) }{2(\sigma_0^2\sigma^2) /(n\sigma_0^2+\sigma^2)}}\Bigg]. \\
\end{split}
\]</span> Now we add constants which do not depend upon <span class="math inline">\(\mu\)</span> to complete the square in the numerator: <span class="math display">\[
\begin{split}
p(\mu\mid y)
&amp; \propto  \exp\Bigg[{\frac{-\bigg(\mu - \frac{\mu_0\sigma^2 + \bar{y}n\sigma_0^2}{n\sigma_0^2+\sigma^2}\bigg)^2 }{2(\sigma_0^2\sigma^2) /(n\sigma_0^2+\sigma^2)}}\Bigg]. \\
\end{split}
\]</span> Finally we get the posterior mean <span class="math display">\[
\mu_n = \frac{\mu_0\sigma^2+ \bar{y}n\sigma_0^2}{n\sigma_0^2+\sigma^2} = \mu_0\frac{\sigma^2}{n\sigma_0^2+\sigma^2} + \bar{y}\frac{n\sigma_0^2}{n\sigma_0^2+\sigma^2}
\]</span> and the posterior variance <span class="math display">\[
\sigma_n^2 = \frac{\sigma_0^2\sigma^2}{n\sigma_0^2+\sigma^2}.
\]</span></p>
<div id="exm-bears" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.7 (Chicago Bears 2014-2015 Season)</strong></span> The Chicago Bears are a professional American football team based in Chicago, Illinois. The Bears were a young team in 2014-2015, an were last in the their division. This season the Chicago Bears suffered back-to-back <span class="math inline">\(50\)</span>-points defeats and lost to Patriots and Packers.</p>
<ul>
<li>Patriots-Bears <span class="math inline">\(51-23\)</span></li>
<li>Packers-Bears <span class="math inline">\(55-14\)</span></li>
</ul>
<p>Their next game was at home against the Minnesota Vikings. Current line against the Vikings was <span class="math inline">\(-3.5\)</span> points. Slightly over a field goal. What’s the Bayes approach to learning the line? We use hierarchical data and Bayes learning to update our beliefs in light of new information. The current average win/lose this year can be modeled as a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. We assume that <span class="math inline">\(\mu\)</span> is normally distributed with mean <span class="math inline">\(\mu_0\)</span> and standard deviation <span class="math inline">\(\tau\)</span>. <span class="math display">\[\begin{align*}
\bar{y} \mid \mu &amp; \sim N \left ( \mu , \frac{\sigma^2}{n} \right ) \sim N \left ( \mu , \frac{18.34^2}{9} \right )\\
\mu &amp; \sim N( 0 , \tau^2 )
\end{align*}\]</span> Here <span class="math inline">\(n =9\)</span> games so far. With <span class="math inline">\(s = 18.34\)</span> points. We assume the pre-season prior mean <span class="math inline">\(\mu_0 = 0\)</span>, standard deviation <span class="math inline">\(\tau = 4\)</span>. Base on the observed data so-far: <span class="math inline">\(\bar{y} = -9.22\)</span>.</p>
<p>The Bayes Shrinkage estimator is then <span class="math display">\[
\mathbb{E} \left( \mu \mid \tau, \bar y  \right) = \frac{ \tau^2 }{ \tau^2 + \frac{\sigma^2}{n} }\bar{y} .
\]</span></p>
<p>The shrinkage factor is <span class="math inline">\(0.3\)</span>! That’s quite a bit of shrinkage. Why? Our updated estimator is <span class="math display">\[
\mathbb{E} \left ( \mu | \bar{y} , \tau \right ) = - 2.75 &gt; -.3.5
\]</span> where current line is <span class="math inline">\(-3.5\)</span>.</p>
<ul>
<li>Based on our hierarchical model this is an over-reaction. One point change on the line is about <span class="math inline">\(3\)</span>% on a probability scale.</li>
<li>Alternatively, calculate a market-based <span class="math inline">\(\tau\)</span> given line <span class="math inline">\(=-3.5\)</span>. <span class="math display">\[
\tau^2 = \frac{\sigma^2}{n} \frac{1}{0.3^2} = 18.34^2 \frac{1}{0.3^2} = 180.
\]</span></li>
<li>The market-based <span class="math inline">\(\tau\)</span> is <span class="math inline">\(13.4\)</span> points.</li>
</ul>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>bears <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="sc">-</span><span class="dv">21</span>, <span class="sc">-</span><span class="dv">7</span>, <span class="dv">14</span>, <span class="sc">-</span><span class="dv">13</span>, <span class="sc">-</span><span class="dv">28</span>, <span class="sc">-</span><span class="dv">41</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">mean</span>(bears))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="do">## -9.2</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">sd</span>(bears))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 18</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>tau <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>sig2 <span class="ot">&lt;-</span> <span class="fu">sd</span>(bears) <span class="sc">*</span> <span class="fu">sd</span>(bears) <span class="sc">/</span> <span class="dv">9</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(tau<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (sig2 <span class="sc">+</span> tau<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="do">## 0.3</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fl">0.29997</span> <span class="sc">*</span> <span class="sc">-</span><span class="fl">9.22</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="do">## -2.8</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">2.76</span> <span class="sc">/</span> <span class="dv">18</span>))</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 0.44</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Home advantage is worth <span class="math inline">\(3\)</span> points. The actual result of the game is Bears 21, Vikings 13.</p>
</div>
<section id="posterior-predictive" class="level3">
<h3 class="anchored" data-anchor-id="posterior-predictive">Posterior Predictive</h3>
<p>After estimating the parameters, using the posterior distribution, we often want to predict future observations. This is done using the posterior predictive distribution. The posterior predictive distribution is the distribution of a new observation <span class="math inline">\(y_{n+1}\)</span> given the observed data <span class="math inline">\(y_1,\ldots,y_n\)</span>. The posterior predictive distribution is given by</p>
<p><span class="math display">\[\begin{align*}
p(y_{n+1} \mid &amp; y_1,\ldots,y_n) = \int p(y_{n+1} \mid \mu) p(\mu \mid y_1,\ldots,y_n) d\mu \\
&amp;  = \int N(y_{n+1} \mid \mu, \sigma^2) N(\mu \mid \mu_n, \sigma_n^2) d\mu = N(y_{n+1} \mid \mu_n, \sigma_n^2 + \sigma^2).
\end{align*}\]</span> This follows from the general properties of the Gaussian distribution</p>
</section>
</section>
<section id="normal-with-unknown-variance" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="normal-with-unknown-variance"><span class="header-section-number">3.8</span> Normal With Unknown Variance</h2>
<p>Consider, another example, when mean <span class="math inline">\(\mu\)</span> is fixed and variance is a random variable which follows some distribution <span class="math inline">\(\sigma^2 \sim p(\sigma^2)\)</span>. Given an observed sample <span class="math inline">\(y\)</span>, we can update the distribution over variance using the Bayes rule <span class="math display">\[
p(\sigma^2 \mid  y) = \dfrac{p(y\mid \sigma^2 )p(\sigma^2)}{p(y)}.
\]</span> Now, the total probability in the denominator can be calculated as <span class="math display">\[
p(y) = \int p(y\mid \sigma^2 )p(\sigma^2) d\sigma^2.
\]</span></p>
<p>A conjugate prior that leads to analytically calculable integral for variance under the normal likelihood is the inverse Gamma. When the mean <span class="math inline">\(\mu\)</span> is known, the sufficient statistic for <span class="math inline">\(\sigma^2\)</span> is the sum of squared deviations <span class="math inline">\(\sum_{i=1}^n(y_i - \mu)^2\)</span>. Thus, if <span class="math display">\[
\sigma^2 \mid  \alpha,\beta \sim IG(\alpha,\beta) = \dfrac{\beta^{\alpha}}{\Gamma(\alpha)}\sigma^{2(-\alpha-1)}\exp\left(-\dfrac{\beta}{\sigma^2}\right)
\]</span> and <span class="math display">\[
y \mid \mu,\sigma^2 \sim N(\mu,\sigma^2)
\]</span> Then the posterior distribution is another inverse Gamma <span class="math inline">\(IG(\alpha_{\mathrm{posterior}},\beta_{\mathrm{posterior}})\)</span>, with <span class="math display">\[
\alpha_{\mathrm{posterior}} = \alpha + \dfrac{1}{2}, ~~\beta_{\mathrm{posterior}} = \beta + \dfrac{y-\mu}{2}.
\]</span></p>
<p>Now, the predictive distribution over <span class="math inline">\(y\)</span> can be calculated by <span class="math display">\[
p(y_{new}\mid y) = \int p(y_{new},\sigma^2\mid y)p(\sigma^2\mid y)d\sigma^2.
\]</span> Which happens to be a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(2\alpha_{\mathrm{posterior}}\)</span> degrees of freedom, mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\alpha_{\mathrm{posterior}}/\beta_{\mathrm{posterior}}\)</span>.</p>
<section id="the-normal-gamma-model" class="level3">
<h3 class="anchored" data-anchor-id="the-normal-gamma-model">The Normal-Gamma Model</h3>
<p>Now, consider the case when both mean and variance are unknown. To simplify the formulas, we work with precision <span class="math inline">\(\tau = 1/\sigma^2\)</span>. The Normal-Gamma distribution is a conjugate prior for a Normal likelihood with unknown mean and precision. Given data <span class="math inline">\(y = \{y_1,\ldots,y_n\}\)</span>, we assume: <span class="math display">\[
y_i \mid \theta, \tau \sim N(\theta, 1/\tau)
\]</span></p>
<p>For this model, the sufficient statistics are the sample mean <span class="math inline">\(\bar{y} = n^{-1}\sum_{i=1}^n y_i\)</span>, the sample size <span class="math inline">\(n\)</span>, and the sum of squared deviations <span class="math inline">\(\sum_{i=1}^n(y_i - \bar{y})^2\)</span>. The Normal-Gamma prior distribution is defined as: <span class="math display">\[
\theta\mid \mu,\tau,\nu \sim N(\mu, 1/(\tau \nu)), \quad \tau \mid \alpha, \beta \sim \text{Gamma}(\alpha, \beta).
\]</span> Conditional on precision <span class="math inline">\(\tau\)</span>, the mean <span class="math inline">\(\theta\)</span> is Normal with precision <span class="math inline">\(\nu\tau\)</span>. The marginal distribution of <span class="math inline">\(\tau\)</span> is Gamma. Note that <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\tau\)</span> are not independent in the joint prior.</p>
<p>Given the likelihood: <span class="math display">\[
p(y\mid \theta, \tau) \propto \tau^{n/2}\exp\left(-\frac{\tau}{2}\sum_{i=1}^n(y_i-\theta)^2\right)
\]</span> and the prior, the posterior distribution is also Normal-Gamma with parameters: <span class="math display">\[
\begin{aligned}
\mu_n &amp;= \dfrac{\nu\mu + n\bar{y}}{\nu+n},\\
\nu_n &amp;= \nu+n,\\
\alpha_n &amp;= \alpha + \dfrac{n}{2},\\
\beta_n &amp;= \beta + \dfrac{1}{2}\sum_{i=1}^n(y_i-\bar{y})^2 + \dfrac{n\nu}{2(\nu+n)}(\bar{y}-\mu)^2.
\end{aligned}
\]</span> where <span class="math inline">\(\bar{y} = n^{-1}\sum_{i=1}^n y_i\)</span> is the sample mean and <span class="math inline">\(n\)</span> is the sample size. The posterior distribution is a normal-Gamma distribution with parameters <span class="math inline">\(\mu_n, \nu_n, \alpha_n, \beta_n\)</span>.</p>
</section>
<section id="credible-intervals-for-normal-gamma-model-posterior-parameters" class="level3">
<h3 class="anchored" data-anchor-id="credible-intervals-for-normal-gamma-model-posterior-parameters">Credible Intervals for Normal-Gamma Model Posterior Parameters</h3>
<p>The precision posterior follows a Gamma distribution with parameters <span class="math inline">\(\alpha_n, \beta_n\)</span>, thus we can use quantiles of the Gamma distribution to calculate credible intervals. A symmetric <span class="math inline">\(100(1-c)%\)</span> credible interval <span class="math inline">\([g_{c/2},g_{1-c/2}]\)</span> is given by <span class="math inline">\(c/2\)</span> and <span class="math inline">\(1-c/2\)</span> quantiles of the gamma distribution. To find credible interval for the variance <span class="math inline">\(v = 1/\tau\)</span>, we simply use <span class="math display">\[
[1/g_{1-c/2},1/g_{c/2}].
\]</span> and for standard deviation <span class="math inline">\(s = \sqrt{v}\)</span> we use <span class="math display">\[
[\sqrt{1/g_{1-c/2}},\sqrt{1/g_{c/2}}].
\]</span> To find credible interval over the mean <span class="math inline">\(\theta\)</span>, we need to integrate out the precision <span class="math inline">\(\tau^{-2}\)</span> from the posterior distribution. The marginal distribution of <span class="math inline">\(\theta\)</span> is a Student’s t-distribution with parameters center at <span class="math inline">\(\mu_n\)</span>, variance <span class="math inline">\(\beta_n/(\nu_n\alpha_n)\)</span> and degrees of freedom <span class="math inline">\(2\alpha_n\)</span>.</p>
</section>
</section>
<section id="multivariate-normal" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="multivariate-normal"><span class="header-section-number">3.9</span> Multivariate Normal</h2>
<p>We write <span class="math inline">\(X \sim N(\mu,\Sigma)\)</span> for a <span class="math inline">\(d\)</span>-dimensional multivariate normal random vector with mean vector <span class="math inline">\(\mu \in \mathbb{R}^d\)</span> and covariance matrix <span class="math inline">\(\Sigma \in \mathbb{R}^{d\times d}\)</span>, where <span class="math inline">\(\Sigma\)</span> is symmetric and positive definite. If the linear algebra below is unfamiliar (transpose, inverse, determinant, positive definiteness), see Appendix <a href="appendix-linalg.html" class="quarto-xref"><span>Chapter 26</span></a>. Its density is <span class="math display">\[
p(x\mid \mu,\Sigma) = \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}\exp\left(-\frac{1}{2}(x-\mu)^\top \Sigma^{-1}(x-\mu)\right), \qquad x\in\mathbb{R}^d.
\]</span> The multivariate normal is the workhorse distribution for joint modeling, conditioning, and linear transformations.</p>
<p>In the multivariate case, the normal-normal model is <span class="math display">\[
\theta \sim N(\mu_0,\Sigma_0), \quad y \mid \theta \sim N(\theta,\Sigma).
\]</span> For a single multivariate observation, <span class="math inline">\(y\)</span> itself serves as the sufficient statistic for <span class="math inline">\(\theta\)</span>. More generally, for <span class="math inline">\(n\)</span> independent observations <span class="math inline">\(y_1,\ldots,y_n\)</span>, the sample mean <span class="math inline">\(\bar{y} = n^{-1}\sum_{i=1}^n y_i\)</span> is the sufficient statistic. The posterior distribution is <span class="math display">\[
\theta \mid y \sim N(\mu_1,\Sigma_1),
\]</span> where <span class="math display">\[
\Sigma_1 = (\Sigma_0^{-1} + \Sigma^{-1})^{-1}, \quad \mu_1 = \Sigma_1(\Sigma_0^{-1}\mu_0 + \Sigma^{-1}y).
\]</span> The predictive distribution is <span class="math display">\[
y_{new} \mid y \sim N(\mu_1,\Sigma_1 + \Sigma).
\]</span></p>
<div id="exm-portfolio" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.8 (Satya Nadella: CEO of Microsoft)</strong></span> In 2014, Satya Nadella became the CEO of Microsoft. The stock price of Microsoft has been on a steady rise since then. Suppose that you are a portfolio manager and you are interested in analyzing the returns of Microsoft stock compared to the market.</p>
<p>Suppose you are managing a portfolio with two positions stock of Microsoft (MSFT) and an index fund that follows S&amp;P500 index and tracks overall market performance. We are interested in estimating the mean returns of the positions in our portfolio. You believe that the returns are normally distributed and are related to each other. You have prior beliefs about these returns, which are also normally distributed. We will use what is called the empirical prior for the mean returns. This is a prior that is based on historical data. The empirical prior is a good choice when you have a lot of historical data and you believe that the future mean returns will be similar to the historical mean returns. We assume the prior for the mean returns is a bivariate normal distribution, let <span class="math inline">\(\mu_0 = (\mu_{M}, \mu_{S})\)</span> represent the prior mean returns for the stocks. The covariance matrix <span class="math inline">\(\Sigma_0\)</span> captures your beliefs about the variability and the relationship between these stocks’ returns in the prior. We will use the sample mean and covariance matrix of the historical returns as the prior mean and covariance matrix. The prior covariance matrix is given by <span class="math display">\[
\Sigma_0 = \begin{bmatrix} \sigma_{M}^2 &amp; \sigma_{MS} \\ \sigma_{MS} &amp; \sigma_{S}^2 \end{bmatrix},
\]</span> where <span class="math inline">\(\sigma_{M}^2\)</span> and <span class="math inline">\(\sigma_{S}^2\)</span> are the sample variances of the historical returns of MSFT and SPY, respectively, and <span class="math inline">\(\sigma_{MS}\)</span> is the sample covariance of the historical returns of MSFT and SPY. The prior mean is given by <span class="math display">\[
\mu_0 = \begin{bmatrix} \mu_{M} \\ \mu_{S} \end{bmatrix},
\]</span> where <span class="math inline">\(\mu_{M}\)</span> and <span class="math inline">\(\mu_{S}\)</span> are the sample means of the historical returns of MSFT and SPY, respectively. The likelihood of observing the data, given the mean returns, is also a bivariate normal distribution. The mean of this distribution is the true (but unknown) mean returns <span class="math inline">\(\mu = [\mu_A, \mu_B]\)</span>. The covariance matrix <span class="math inline">\(\Sigma\)</span> of the likelihood represents the uncertainty in your data. We will use the sample mean and covariance matrix of the observed returns as the likelihood mean and covariance matrix. The likelihood covariance matrix is given by <span class="math display">\[
\Sigma = \begin{bmatrix} \sigma_{M}^2 &amp; \sigma_{MS} \\ \sigma_{MS} &amp; \sigma_{S}^2 \end{bmatrix},
\]</span> where <span class="math inline">\(\sigma_{M}^2\)</span> and <span class="math inline">\(\sigma_{S}^2\)</span> are the sample variances of the observed returns of MSFT and SPY, respectively, and <span class="math inline">\(\sigma_{MS}\)</span> is the sample covariance of the observed returns of MSFT and SPY. The likelihood mean is given by <span class="math display">\[
\mu = \begin{bmatrix} \mu_{M} \\ \mu_{S} \end{bmatrix},
\]</span> where <span class="math inline">\(\mu_{M}\)</span> and <span class="math inline">\(\mu_{S}\)</span> are the sample means of the observed returns of MSFT and SPY, respectively. In a Bayesian framework, you update your beliefs (prior) about the mean returns using the observed data (likelihood). The posterior distribution, which combines your prior beliefs and the new information from the data, is also a bivariate normal distribution. The mean <span class="math inline">\(\mu_{\text{post}}\)</span> and covariance <span class="math inline">\(\Sigma_{\text{post}}\)</span> of the posterior are calculated using Bayesian updating formulas, which involve <span class="math inline">\(\mu_0\)</span>, <span class="math inline">\(\Sigma_0\)</span>, <span class="math inline">\(\mu\)</span>, and <span class="math inline">\(\Sigma\)</span>.</p>
<p>We use observed returns prior to Nadella’s becoming CEO as our prior and analyze the returns post 2014. Thus, our observed data includes July 2015 - Dec 2023 period. We assume the likelihood of observing this data, given the mean returns, is also a bivariate normal distribution. The mean of this distribution is the true (but unknown) mean returns. The covariance matrix <span class="math inline">\(Sigma\)</span> of the likelihood represents the uncertainty in your data and is calculated from the overall observed returns data 2001-2023.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getSymbols</span>(<span class="fu">c</span>(<span class="st">"MSFT"</span>, <span class="st">"SPY"</span>), <span class="at">from =</span> <span class="st">"2001-01-01"</span>, <span class="at">to =</span> <span class="st">"2023-12-31"</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="do">## "MSFT" "SPY"</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="dv">3666</span> <span class="co"># 2015-07-30</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>s</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>obs <span class="ot">&lt;-</span> s<span class="sc">:</span><span class="fu">nrow</span>(MSFT) <span class="co"># post covid</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># obs = 5476:nrow(MSFT) # 2022-10-06 bull run if 22-23</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">dailyReturn</span>(MSFT))</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>c <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">dailyReturn</span>(SPY))</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>mu0 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">mean</span>(a[prior]), <span class="fu">mean</span>(c[prior]))</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>Sigma0 <span class="ot">&lt;-</span> <span class="fu">cov</span>(<span class="fu">data.frame</span>(<span class="at">a =</span> a[prior], <span class="at">c =</span> c[prior]))</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Data</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">mean</span>(a[obs]), <span class="fu">mean</span>(c[obs]))</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>Sigma <span class="ot">&lt;-</span> <span class="fu">cov</span>(<span class="fu">data.frame</span>(<span class="at">a =</span> a, <span class="at">c =</span> c))</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>SigmaPost <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">solve</span>(Sigma0) <span class="sc">+</span> <span class="fu">solve</span>(Sigma))</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>muPost <span class="ot">&lt;-</span> SigmaPost <span class="sc">%*%</span> (<span class="fu">solve</span>(Sigma0) <span class="sc">%*%</span> mu0 <span class="sc">+</span> <span class="fu">solve</span>(Sigma) <span class="sc">%*%</span> mu)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="cell-output-display">
<div id="fig-portfolio-plot" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-portfolio-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-bl_files/figure-html/fig-portfolio-plot-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="448">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-portfolio-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.7: Plotting Portfolio Updating with MSFT and SPY
</figcaption>
</figure>
</div>
</div>
</div>
<p>We can see the posterior mean for SPY is close to the prior mean, while the posterior mean for MSFT is further away. The performance of MSFT was significantly better past 2015 compared to SPY. The posterior mean (green) represents mean reversion value. We can think of it a expected mean return if the performance of MSFT starts reverting to its historical averages.</p>
<p>This model is particularly powerful because it can be extended to more dimensions (more stocks) and can include more complex relationships between the variables. It’s often used in finance, econometrics, and other fields where understanding the joint behavior of multiple normally-distributed variables is important.</p>
</div>
</section>
<section id="mixtures-of-conjugate-priors" class="level2" data-number="3.10">
<h2 data-number="3.10" class="anchored" data-anchor-id="mixtures-of-conjugate-priors"><span class="header-section-number">3.10</span> Mixtures of Conjugate Priors</h2>
<p>The mixture of conjugate priors is a powerful tool for modeling complex data. It allows us to combine multiple conjugate priors to create a more flexible model that can capture a wider range of data patterns. The mixture of conjugate priors is particularly useful when the data is generated from a mixture of distributions, where each component of the mixture is generated from a different distribution. <!-- http://www.mas.ncl.ac.uk/~nmf16/teaching/mas3301/week11.pdf --></p>
<p>If <span class="math inline">\(p_1(x),\ldots,p_k(x)\)</span> are proper density functions and <span class="math inline">\(\pi_1,\ldots,\pi_k\)</span> are non-negative weights that sum to 1, then the mixture distribution is given by <span class="math display">\[
p(x) = \sum_{i=1}^k \pi_i p_i(x).
\]</span> It is easy to show that <span class="math inline">\(p(x)\)</span> is a proper density. Indeed, given domain <span class="math inline">\(x\in A\subset \mathbb{R}\)</span> we have <span class="math display">\[
\int_A p(x)dx = \sum_{i=1}^k \pi_i \int_A p_i(x)dx  = \sum_{i=1}^k \pi_i = 1.
\]</span></p>
<p>Assume our prior is a mixture of distributions, that is <span class="math display">\[
\theta \sim p(\theta) = \sum_{k=1}^K \pi_k p_k(\theta).
\]</span> Then the posterior is also a mixture of normal distributions, that is <span class="math display">\[
p(\theta\mid y) = p(y\mid \theta)\sum_{k=1}^K \pi_k p_k(\theta)/Z.
\]</span> We introduce a normalizing constant for each component <span class="math display">\[
Z_k = \int p(y\mid \theta)p_k(\theta)d\theta.
\]</span> then <span class="math display">\[
p_k(\theta\mid y)  = p_k(\theta)p(y\mid \theta)/Z_k
\]</span> is a proper distribution and our posterior is a mixture of these distributions <span class="math display">\[
p(\theta\mid y) = \sum_{k=1}^K \pi_k Z_k p_k(\theta\mid y)/Z.
\]</span> Meaning that we need to require <span class="math display">\[
\dfrac{\sum_{k=1}^K \pi_k Z_k}{Z} = 1, \quad \text{or} \quad Z = \sum_{k=1}^K \pi_k Z_k.
\]</span> Then the posterior density is a mixture <span class="math display">\[
p(\theta\mid y) = \sum_{k=1}^K \hat \pi_k p_k(\theta \mid y).
\]</span></p>
<p>Consider an example of a mixture of two normal distributions. The prior distribution is a mixture of two normal distributions, that is <span class="math display">\[
\mu \sim 0.5 N(0,1) + 0.5 N(5,1).
\]</span> The likelihood is a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance 1, that is <span class="math display">\[
y \mid \mu \sim N(\mu,1).
\]</span> The posterior distribution is a mixture of two normal distributions, that is <span class="math display">\[
p(\mu \mid y) \propto \phi(y\mid \mu,1) \left(0.5 \phi(\mu\mid 0,1) + 0.5 \phi(\mu\mid 5,1)\right),
\]</span> where <span class="math inline">\(\phi(x\mid \mu,\sigma^2)\)</span> is the normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. We can calculate it using property of a normal distribution <span class="math display">\[
\phi(x\mid \mu_1,\sigma_1^2)\phi(x\mid \mu_2,\sigma_2^2) = \phi(x\mid \mu_3,\sigma_3^2)\phi(\mu_1-\mu_2\mid 0,\sigma_1^2+\sigma_2^2)
\]</span> where <span class="math display">\[
\mu_3 = \dfrac{\mu_1/\sigma_2^2 + \mu_2/\sigma_1^2}{1/\sigma_1^2 + 1/\sigma_2^2}, \quad \sigma_3^2 = \dfrac{1}{1/\sigma_1^2 + 1/\sigma_2^2}.
\]</span></p>
<p>Given, we observed <span class="math inline">\(y = 2\)</span>, we can calculate the posterior distribution for <span class="math inline">\(\mu\)</span></p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>mu0 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>sigma02 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>pi <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>mu3 <span class="ot">&lt;-</span> (mu0 <span class="sc">/</span> sigma02 <span class="sc">+</span> y) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">/</span> sigma02 <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>sigma3 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">/</span> sigma02 <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>Z <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(y <span class="sc">-</span> mu0, <span class="dv">0</span>, <span class="dv">1</span> <span class="sc">+</span> sigma02) <span class="sc">*</span> pi</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> Z <span class="sc">/</span> <span class="fu">sum</span>(Z)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># To add a new line in sprintf, use "\n" inside the format string.</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Component parameters:"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="do">## "Component parameters:"</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="fu">sprintf</span>(</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Mean = (%1.1f,%2.1f)  Var = (%1.1f,%1.1f)  weights = (%1.2f,%1.2f)"</span>,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>  mu3[<span class="dv">1</span>], mu3[<span class="dv">2</span>], sigma3[<span class="dv">1</span>], sigma3[<span class="dv">2</span>], w[<span class="dv">1</span>], w[<span class="dv">2</span>]</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="do">## "Mean = (1.0,3.5)  Var = (0.5,0.5)  weights = (0.65,0.35)"</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Summary table of random variables</p>
<div style="font-size: 0.85em;">
<div id="tbl-rv" class="quarto-float quarto-figure quarto-figure-center anchored" data-tbl-colwidths="[15,10,30,8,15,22]">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-rv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.1: Summary table of commonly used random variables
</figcaption>
<div aria-describedby="tbl-rv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 10%">
<col style="width: 30%">
<col style="width: 8%">
<col style="width: 15%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th><span class="math inline">\(\theta\)</span></th>
<th>PDF</th>
<th>Mean</th>
<th>Variance</th>
<th>Support</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Normal</td>
<td><span class="math inline">\(\mu, \sigma^2\)</span></td>
<td><span class="math inline">\(\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)\)</span></td>
<td><span class="math inline">\(\mu\)</span></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
<td><span class="math inline">\(x \in \mathbb{R}\)</span></td>
</tr>
<tr class="even">
<td>Exponential</td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(\lambda e^{-\lambda x}\)</span></td>
<td><span class="math inline">\(\frac{1}{\lambda}\)</span></td>
<td><span class="math inline">\(\frac{1}{\lambda^2}\)</span></td>
<td><span class="math inline">\(x \geq 0\)</span></td>
</tr>
<tr class="odd">
<td>Gamma</td>
<td><span class="math inline">\(\alpha, \beta\)</span></td>
<td><span class="math inline">\(\frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}\)</span></td>
<td><span class="math inline">\(\frac{\alpha}{\beta}\)</span></td>
<td><span class="math inline">\(\frac{\alpha}{\beta^2}\)</span></td>
<td><span class="math inline">\(x \geq 0\)</span></td>
</tr>
<tr class="even">
<td>Poisson</td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(\frac{e^{-\lambda}\lambda^x}{x!}\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(x \in \mathbb{N}\)</span></td>
</tr>
<tr class="odd">
<td>Binomial</td>
<td><span class="math inline">\(n, p\)</span></td>
<td><span class="math inline">\(\binom{n}{x}p^x(1-p)^{n-x}\)</span></td>
<td><span class="math inline">\(np\)</span></td>
<td><span class="math inline">\(np(1-p)\)</span></td>
<td><span class="math inline">\(x \in \{0, 1, \ldots, n\}\)</span></td>
</tr>
<tr class="even">
<td>Bernoulli</td>
<td><span class="math inline">\(p\)</span></td>
<td><span class="math inline">\(p^x(1-p)^{1-x}\)</span></td>
<td><span class="math inline">\(p\)</span></td>
<td><span class="math inline">\(p(1-p)\)</span></td>
<td><span class="math inline">\(x \in \{0, 1\}\)</span></td>
</tr>
<tr class="odd">
<td>Multinomial</td>
<td><span class="math inline">\(n, \boldsymbol{p}\)</span></td>
<td><span class="math inline">\(\frac{n!}{x_1!x_2!\cdots x_k!}p_1^{x_1}p_2^{x_2}\cdots p_k^{x_k}\)</span></td>
<td><span class="math inline">\(np_i\)</span></td>
<td><span class="math inline">\(np_i(1-p_i)\)</span></td>
<td><span class="math inline">\(\sum x_i = n, x_i \in \mathbb{R}^+\)</span></td>
</tr>
<tr class="even">
<td>Beta</td>
<td><span class="math inline">\(\alpha, \beta\)</span></td>
<td><span class="math inline">\(\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}\)</span></td>
<td><span class="math inline">\(\frac{\alpha}{\alpha + \beta}\)</span></td>
<td><span class="math inline">\(\frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}\)</span></td>
<td><span class="math inline">\(x \in [0, 1]\)</span></td>
</tr>
<tr class="odd">
<td>Inverse Gamma</td>
<td><span class="math inline">\(\alpha, \beta\)</span></td>
<td><span class="math inline">\(\frac{\beta^\alpha}{\Gamma(\alpha)}x^{-\alpha-1}e^{-\frac{\beta}{x}}\)</span></td>
<td><span class="math inline">\(\frac{\beta}{\alpha-1}\)</span></td>
<td><span class="math inline">\(\frac{\beta^2}{(\alpha-1)^2(\alpha-2)}\)</span></td>
<td><span class="math inline">\(x &gt; 0\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
<p><a href="#tbl-conjugate" class="quarto-xref">Table&nbsp;<span>3.2</span></a> summarizes the conjugate prior distributions for common likelihoods. Thus far, we’ve considered the Normal-Normal model with both known and unknown variance as well as Poisson-Gamma and Beta Binomial. The other pairs are left as an exercise. Given observed data <span class="math inline">\(x = (x_1,\ldots,x_n)\)</span> and <span class="math inline">\(s = \sum_{i=1}^nx_i\)</span>, <span class="math inline">\(\bar x = s/n\)</span>. For each conjugate pair, the table lists the sufficient statistics that summarize all information in the data relevant to the parameter. The posterior depends on the data only through these sufficient statistics, which is a key property of conjugate families.</p>
<div id="tbl-conjugate" class="quarto-float quarto-figure quarto-figure-center anchored" data-tbl-colwidths="[24,10,15,10,16,35]">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-conjugate-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.2: Conjugate prior table for common likelihoods
</figcaption>
<div aria-describedby="tbl-conjugate-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 9%">
<col style="width: 14%">
<col style="width: 9%">
<col style="width: 14%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Likelihood</th>
<th>Prior</th>
<th>Prior Parameters</th>
<th>Model Parameters</th>
<th>Sufficient Statistics</th>
<th>Posterior Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Normal (known <span class="math inline">\(\sigma^2\)</span>)</td>
<td>Normal</td>
<td><span class="math inline">\(\mu_0, \sigma^2_0\)</span></td>
<td><span class="math inline">\(\mu\)</span></td>
<td><span class="math inline">\(\bar x, n\)</span></td>
<td><span class="math inline">\(\frac{n\sigma^2_0 \bar x + \sigma^2 \mu_0}{\sigma^2 + n\sigma^2_0},~\frac{\sigma^2\sigma_0^2}{n\sigma_0^2+\sigma^2}\)</span></td>
</tr>
<tr class="even">
<td>Normal (known <span class="math inline">\(\mu\)</span>)</td>
<td>Inverse Gamma</td>
<td><span class="math inline">\(\alpha,\beta\)</span></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
<td><span class="math inline">\(\sum(x_i-\mu)^2, n\)</span></td>
<td><span class="math inline">\(\alpha+n/2, \beta + \frac{1}{2}\sum(x_i-\mu)^2\)</span></td>
</tr>
<tr class="odd">
<td>Binomial (<span class="math inline">\(m\)</span> trials)</td>
<td>Beta</td>
<td><span class="math inline">\(\alpha, \beta\)</span></td>
<td><span class="math inline">\(p\)</span></td>
<td><span class="math inline">\(s, n\)</span></td>
<td><span class="math inline">\(\alpha + s, \beta + nm - s\)</span></td>
</tr>
<tr class="even">
<td>Poisson</td>
<td>Gamma</td>
<td><span class="math inline">\(\alpha, \beta\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(s, n\)</span></td>
<td><span class="math inline">\(\alpha + s, \beta + n\)</span></td>
</tr>
<tr class="odd">
<td>Exponential</td>
<td>Gamma</td>
<td><span class="math inline">\(\alpha, \beta\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(s, n\)</span></td>
<td><span class="math inline">\(\alpha + n, \beta + s\)</span></td>
</tr>
<tr class="even">
<td>Multinomial</td>
<td>Dirichlet</td>
<td><span class="math inline">\(\alpha \in \mathbb{R}^k\)</span></td>
<td><span class="math inline">\(p \in \mathbb{R}^k\)</span></td>
<td><span class="math inline">\(s_j\)</span> for each category <span class="math inline">\(j\)</span></td>
<td><span class="math inline">\(\alpha+s\)</span></td>
</tr>
<tr class="odd">
<td>Normal</td>
<td>Normal-inverse gamma</td>
<td><span class="math inline">\(\mu_0, \nu, \alpha, \beta\)</span></td>
<td><span class="math inline">\(\mu, \sigma\)</span></td>
<td><span class="math inline">\(\bar x, \sum(x_i-\bar x)^2, n\)</span></td>
<td><span class="math inline">\(\frac{\nu\mu_0+n\bar{x}}{\nu+n} ,\, \nu+n,\, \alpha+\frac{n}{2} ,\,\)</span> <br> <span class="math inline">\(\beta + \tfrac{1}{2} \sum_{i=1}^n (x_i - \bar{x})^2 + \frac{n\nu}{\nu+n}\frac{(\bar{x}-\mu_0)^2}{2}\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>These conjugate relationships simplify Bayesian calculations by ensuring that the posterior distributions are in the same family as the priors.</p>
</section>
<section id="sec-computational-bridge" class="level2" data-number="3.11">
<h2 data-number="3.11" class="anchored" data-anchor-id="sec-computational-bridge"><span class="header-section-number">3.11</span> Bayesian Computation: when conjugacy breaks</h2>
<p>Conjugate priors are powerful because they keep the posterior in a familiar family and allow analytic updating. But most realistic Bayesian models are not conjugate: likelihoods can be non-Gaussian, priors can encode structure (sparsity, hierarchy), and predictors can enter through nonlinear functions. In those settings, the posterior still exists, but we cannot usually write it down in closed form.</p>
<p>The default remedy is approximation by simulation. The unifying idea is simple: if we can draw samples <span class="math inline">\(\theta^{(1)},\ldots,\theta^{(N)} \sim p(\theta\mid y)\)</span>, then posterior summaries become Monte Carlo averages. For example, for any function <span class="math inline">\(g(\theta)\)</span>, <span class="math display">\[
\E{g(\theta)\mid y} \approx \frac{1}{N}\sum_{n=1}^N g(\theta^{(n)}).
\]</span> This is the same law-of-large-numbers logic discussed in <a href="01-prob.html" class="quarto-xref"><span>Chapter 1</span></a>, but applied to posterior distributions rather than to a known data-generating distribution.</p>
<section id="posterior-consistency-and-the-law-of-large-numbers" class="level3">
<h3 class="anchored" data-anchor-id="posterior-consistency-and-the-law-of-large-numbers">Posterior Consistency and the Law of Large Numbers</h3>
<p>The law of large numbers provides theoretical justification for Bayesian learning. As we collect more data, the posterior distribution concentrates around the true parameter value, regardless of the prior. This phenomenon, known as <em>posterior consistency</em>, follows from the fact that the likelihood function—being a product of many terms—is dominated by the data for large samples.</p>
<p>Consider estimating the mean <span class="math inline">\(\mu\)</span> of a normal distribution from i.i.d. observations <span class="math inline">\(x_1, \ldots, x_n \sim N(\mu, \sigma^2)\)</span> with a prior <span class="math inline">\(\mu \sim N(\mu_0, \tau_0^2)\)</span>. The posterior mean is:</p>
<p><span class="math display">\[
\E{\mu \mid x_1, \ldots, x_n} = \frac{\tau_0^{-2}\mu_0 + n\sigma^{-2}\bar{x}_n}{\tau_0^{-2} + n\sigma^{-2}}
\]</span></p>
<p>As <span class="math inline">\(n \to \infty\)</span>, the data term <span class="math inline">\(n\sigma^{-2}\bar{x}_n\)</span> dominates, and by the law of large numbers, <span class="math inline">\(\bar{x}_n \to \mu\)</span> almost surely. Thus:</p>
<p><span class="math display">\[
\E{\mu \mid x_1, \ldots, x_n} \to \mu \quad \text{almost surely}.
\]</span></p>
<p>The posterior concentrates at <span class="math inline">\(\mu\)</span>, regardless of the prior <span class="math inline">\(\mu_0\)</span>. The prior matters for small samples but becomes negligible for large samples—a reassuring property that ensures different researchers with different priors eventually reach consensus as evidence accumulates.</p>
</section>
<section id="monte-carlo-methods" class="level3">
<h3 class="anchored" data-anchor-id="monte-carlo-methods">Monte Carlo Methods</h3>
<p>Monte Carlo simulation is also justified by the law of large numbers. To approximate an expectation <span class="math inline">\(\E{f(x)}\)</span> where <span class="math inline">\(x \sim p(x)\)</span>, we draw i.i.d. samples <span class="math inline">\(x_1, \ldots, x_n \sim p(x)\)</span> and compute: <span class="math display">\[
\hat{\mu}_n = \frac{1}{n}\sum_{i=1}^n f(x_i) \approx \E{f(x)}
\]</span></p>
<p>By the strong law of large numbers, <span class="math inline">\(\hat{\mu}_n \to \E{f(X)}\)</span> almost surely as <span class="math inline">\(n \to \infty\)</span>, provided <span class="math inline">\(\E{|f(X)|} &lt; \infty\)</span>. The approximation error decreases at rate <span class="math inline">\(O_p(n^{-1/2})\)</span> by the central limit theorem, giving us both convergence guarantees and quantifiable uncertainty.</p>
<p>The formal development of Monte Carlo methods emerged from the Manhattan Project during World War II, when Stanislaw Ulam, recovering from illness in 1946, realized that complex probability problems could be solved by simulating random processes rather than through analytical calculations. Ulam shared this insight with John von Neumann, who recognized its potential for solving neutron diffusion problems critical to nuclear weapons design and implemented the algorithms on early electronic computers like ENIAC. Nicholas Metropolis coined the term “Monte Carlo” as a reference to the Monaco casino, and the first unclassified paper appeared in 1949 <span class="citation" data-cites="metropolis1949monte">(<a href="references.html#ref-metropolis1949monte" role="doc-biblioref">Metropolis and Ulam 1949</a>)</span>. The 1953 Metropolis algorithm <span class="citation" data-cites="metropolis1953equation">(<a href="references.html#ref-metropolis1953equation" role="doc-biblioref">Metropolis et al. 1953</a>)</span> extended the method beyond simple averaging to sampling from complex distributions—precisely the situation in Bayesian inference—laying the groundwork for modern MCMC. The law of large numbers had existed for centuries, but only the combination of electronic computing and wartime urgency transformed this theoretical principle into the practical computational tool that underpins contemporary Bayesian statistics <span class="citation" data-cites="metropolis1987beginning">(<a href="references.html#ref-metropolis1987beginning" role="doc-biblioref">Metropolis 1987</a>)</span>.</p>
</section>
<section id="markov-chain-monte-carlo" class="level3">
<h3 class="anchored" data-anchor-id="markov-chain-monte-carlo">Markov Chain Monte Carlo</h3>
<p>Markov chain Monte Carlo (MCMC) methods extend Monte Carlo simulation to settings where samples are dependent but ergodic. For an ergodic Markov chain with stationary distribution <span class="math inline">\(\pi(x)\)</span>, the ergodic theorem guarantees:</p>
<p><span class="math display">\[
\frac{1}{n}\sum_{i=1}^n f(x_i) \to \E[\pi]{f(x)} \quad \text{almost surely}
\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> are states visited by the chain. This justifies using MCMC to approximate posterior expectations in Bayesian inference, even though consecutive samples are correlated, see <span class="citation" data-cites="polson1996convergence">Polson (<a href="references.html#ref-polson1996convergence" role="doc-biblioref">1996</a>)</span> for a formal analysis.</p>
<p>MCMC methods provide a powerful framework for sampling from complex distributions that cannot be sampled directly. The key insight is to construct a Markov chain <span class="math inline">\(P(x, y)\)</span> describing the transition probability from state <span class="math inline">\(x\)</span> to state <span class="math inline">\(y\)</span>, such that the desired posterior distribution <span class="math inline">\(\pi\)</span> is the equilibrium (stationary) distribution of the chain.</p>
<p>Formally, a distribution <span class="math inline">\(\pi\)</span> is stationary for a Markov chain with transition kernel <span class="math inline">\(P(x, y)\)</span> if: <span class="math display">\[
\pi(y) = \int \pi(x) P(x, y) dx
\]</span></p>
<p>Once we establish that <span class="math inline">\(\pi\)</span> is stationary, we can generate samples <span class="math inline">\(x^{(1)}, x^{(2)}, \ldots\)</span> by simulating the Markov chain for sufficiently many iterations. By the ergodic theorem, time averages along the chain converge to expectations under <span class="math inline">\(\pi\)</span>: <span class="math display">\[
\frac{1}{n}\sum_{i=1}^n f(x^{(i)}) \to \E[\pi]{f(x)} \quad \text{almost surely}
\]</span></p>
<p>The remarkable feature of MCMC is that we only need to know the <em>ratio</em> of densities <span class="math inline">\(\pi(y)/\pi(x)\)</span>, making it perfect for Bayesian inference where normalizing constants are often intractable. Two fundamental MCMC algorithms illustrate this principle:</p>
<section id="metropolis-hastings-algorithm" class="level4">
<h4 class="anchored" data-anchor-id="metropolis-hastings-algorithm">Metropolis-Hastings Algorithm</h4>
<p>The <em>Metropolis-Hastings</em> algorithm constructs a reversible Markov chain by proposing a candidate point <span class="math inline">\(y\)</span> and accepting it with probability: <span class="math display">\[
P(x, y) = \min\left(\frac{\pi(y)}{\pi(x)}, 1\right)
\]</span></p>
<p>It is straightforward to verify that this chain is time-reversible (satisfies detailed balance): <span class="math display">\[
\pi(x)P(x, y) = \min(\pi(y), \pi(x)) = \pi(y)P(y, x)
\]</span></p>
<p>This implies that <span class="math inline">\(\pi\)</span> satisfies the stationarity condition: <span class="math display">\[
\sum_x \pi(x)P(x, y) = \pi(y)
\]</span></p>
<p>and is therefore the equilibrium distribution of the chain.</p>
</section>
<section id="gibbs-sampler" class="level4">
<h4 class="anchored" data-anchor-id="gibbs-sampler">Gibbs Sampler</h4>
<p>The <em>Gibbs sampler</em> is a special case of the Metropolis-Hastings algorithm where the acceptance probability is always one. It is particularly useful for multivariate distributions where we can easily sample from conditional distributions. The Gibbs sampler cycles through coordinates, sampling each variable conditional on the current values of all others.</p>
<p>For a state vector <span class="math inline">\(x = (x_1, \ldots, x_p)\)</span>, one iteration of the Gibbs sampler updates: <span class="math display">\[
x_j^{(t+1)} \sim \pi(x_j \mid x_1^{(t+1)}, \ldots, x_{j-1}^{(t+1)}, x_{j+1}^{(t)}, \ldots, x_p^{(t)})
\]</span></p>
<p>The Gibbs sampler is time-reversible due to the Clifford-Hammersley theorem, which guarantees that the joint distribution is the unique stationary distribution. This makes the Gibbs sampler a special case of the multivariate coordinate-by-coordinate sampler where the acceptance probability is always one.</p>
<p>Both algorithms transform the problem of computing complex integrals into a problem of simulating a carefully constructed stochastic process. The variance-mean mixture representations discussed in <a href="17-theoryai.html" class="quarto-xref"><span>Chapter 17</span></a> leverage exactly this principle: by introducing auxiliary variables, they convert intractable posterior distributions into forms amenable to Gibbs sampling with conjugate conditional distributions.</p>
<p>Posterior predictive simulation is the recurring workflow that connects computation back to modeling. To forecast or to check fit, we first draw parameters from the posterior and then simulate replicated or future data: <span class="math display">\[
\theta^{(n)} \sim p(\theta\mid y),\qquad \tilde y^{(n)} \sim p(\tilde y\mid \theta^{(n)}).
\]</span> Repeating this produces an empirical approximation to the posterior predictive distribution <span class="math inline">\(p(\tilde y\mid y)\)</span> and makes uncertainty propagation concrete: parameter uncertainty becomes predictive uncertainty.</p>
<p>Later chapters return to this pattern in different guises: sampling-based Bayesian inference (e.g., for logistic regression), approximate inference for scalable models, and simulation-based decision making. The key takeaway here is that conjugacy is a convenience, not a requirement; when the algebra ends, simulation provides the continuation.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-heath1976finettis" class="csl-entry" role="listitem">
Heath, David, and William Sudderth. 1976. <span>“De Finetti’s Theorem on Exchangeable Variables.”</span> <em>The American Statistician</em> 30 (4): 188–89.
</div>
<div id="ref-metropolis1987beginning" class="csl-entry" role="listitem">
Metropolis, Nicholas. 1987. <span>“The <span>Beginning</span> of the <span>Monte Carlo Method</span>.”</span> <em>Los Alamos Science</em> 15: 125–30.
</div>
<div id="ref-metropolis1953equation" class="csl-entry" role="listitem">
Metropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Edward Teller. 1953. <span>“Equation of <span>State Calculations</span> by <span>Fast Computing Machines</span>.”</span> <em>The Journal of Chemical Physics</em> 21 (6): 1087–92.
</div>
<div id="ref-metropolis1949monte" class="csl-entry" role="listitem">
Metropolis, Nicholas, and Stanislaw Ulam. 1949. <span>“The <span>Monte Carlo Method</span>.”</span> <em>Journal of the American Statistical Association</em> 44 (247): 335–41.
</div>
<div id="ref-polson1996convergence" class="csl-entry" role="listitem">
Polson, Nicholas. 1996. <span>“Convergence of <span>Markov</span> Chain <span>Monte Carlo</span> Algorithms (with Discussion).”</span> <em>Bayesian Statistics</em> 5: 297–321.
</div>
<div id="ref-spiegelhalter2009one" class="csl-entry" role="listitem">
Spiegelhalter, David, and Yin-Lam Ng. 2009. <span>“One Match to Go!”</span> <em>Significance</em> 6 (4): 151–53.
</div>
<div id="ref-stern2007inference" class="csl-entry" role="listitem">
Stern, H, Adam Sugano, J Albert, and R Koning. 2007. <span>“Inference about Batter-Pitcher Matchups in Baseball from Small Samples.”</span> <em>Statistical Thinking in Sports</em>, 153–65.
</div>
<div id="ref-taleb2007black" class="csl-entry" role="listitem">
Taleb, Nassim Nicholas. 2007. <em>The <span>Black Swan</span>: <span>The Impact</span> of the <span>Highly Improbable</span></em>. Annotated edition. New York. N.Y: Random House.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-bayes.html" class="pagination-link" aria-label="Bayes Rule">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./04-dec.html" class="pagination-link" aria-label="Utility, Risk and Decisions">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>