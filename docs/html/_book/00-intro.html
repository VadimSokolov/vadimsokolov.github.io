<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Principles of Data Science – Bayes, AI and Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./01-prob.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-680e7c22d93ef26f016bec9199f8e6d8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
  // Load MathJax with custom macros
  window.MathJax = {
    tex: {
      macros: {
        Cov: ["\\mathrm{Cov}\\left(#1\\right)", 1],
        Cor: ["\\mathrm{Cor}\\left(#1\\right)", 1],
        Var: ["\\mathrm{Var}\\left(#1\\right)", 1],
        sd: ["\\mathrm{sd}\\left(#1\\right)", 1],
        E: ["\\mathrm{E}_{#1}\\left(#2\\right)", 2, ""],
        prob: ["\\mathrm{P}\\left(#1\\right)", 1],
        defeq: "\\stackrel{\\mathrm{def}}{=}",
        mini: "\\operatorname*{minimize}"
      }
    }
  };
</script>

<style>
  /* Custom styling for math content */
  .MathJax {
    font-size: 1em !important;
  }
  
  /* Ensure consistent math rendering */
  mjx-container[jax="CHTML"] {
    line-height: 1.2;
  }
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Principles of Data Science – Bayes, AI and Deep Learning">
<meta property="og:description" content="">
<meta property="og:image" content="fig/datadeluge.svg">
<meta property="og:site_name" content="Bayes, AI and Deep Learning">
<meta name="twitter:title" content="Principles of Data Science – Bayes, AI and Deep Learning">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="fig/datadeluge.svg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./00-intro.html">Principles of Data Science</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayes, AI and Deep Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Principles of Data Science</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-bl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-dec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-ab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">AB Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-hyp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-sp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-rl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Unreasonable Effectiveness of Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-pattern.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Pattern Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Tree Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-forecasting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Forecasting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Randomized Controlled Trials</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-select.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-theoryai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Theory of AI: From MLE to Bayesian Regularization</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-theorydl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Theory of Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-sgd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-qnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Quantile Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-nlp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Natural Language Processing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Large Language Models: A Revolution in AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26-robots.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">AI Agents</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Exercises</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#anything-as-a-vector" id="toc-anything-as-a-vector" class="nav-link active" data-scroll-target="#anything-as-a-vector">Anything as a Vector</a></li>
  <li><a href="#generative-ai" id="toc-generative-ai" class="nav-link" data-scroll-target="#generative-ai">Generative AI</a></li>
  <li><a href="#agi-and-aiq" id="toc-agi-and-aiq" class="nav-link" data-scroll-target="#agi-and-aiq">AGI and AIQ</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Principles of Data Science</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p><em>If you tell me precisely what it is a machine cannot do, then I can always make a machine which will do just that.</em> —John von Neumann (1956)</p>
</blockquote>
<p>When you open an Amazon page, there are many personal suggestions of goods to purchase. By analyzing previous product pages visited and purchases made by you and others who have bought similar products, Amazon uses AI and machine learning to predict what might interest you the next time you shop.</p>
<p>When you apply for a loan online, you typically get an immediate answer after filling out an application. The information you provide, combined with your credit history pulled from a credit bureau, is used by a predictive model to determine with high confidence whether you are likely to default on the loan.</p>
<p>What do Amazon, the finance industry, and a championship-winning baseball franchise have in common? They all use AI-driven predictive analytics to improve operations. By combining historical observations with rigorous statistical analysis and efficient algorithms, organizations can forecast future outcomes and make informed decisions. The ability to collect and analyze complex data sets has been the prerogative of a few for many years. It is vital to have experience in data engineering, statistics, machine learning, and probability. A data scientist possesses all these skills. Current tools developed by industry and academia make the data science profession accessible to a wider audience without requiring specific technical training.</p>
<p>Over the past decade, there has been an explosion of work, mostly applied, on deep learning. Applications of deep learning are ubiquitous. The main reason for this is that large Internet companies such as Google, Facebook, Amazon, and Netflix increasingly replace traditional statistical and machine learning methods with deep learning techniques. Though these companies are at the frontier of applying deep learning, virtually any industry can be impacted by its application.</p>
<p><em>Data Science</em> is a relatively new field that refers to sets of mathematical and statistical models, algorithms, and software that extract patterns from data sets. The algorithms are adaptations of applied mathematics techniques to specific computer architectures, and the software implements those algorithms.</p>
<p><em>Predictive analytics</em> applies AI models to design predictive rules used by engineers and businesses for forecasting or what-if analysis. For example, a company interested in predicting sales as a result of an advertisement campaign would use a predictive model to identify the best way to allocate its marketing budget. Similarly, a logistics company would use a predictive model to forecast demand for shipments to estimate the number of drivers needed in the coming months.</p>
<p><em>Artificial Intelligence</em> has been around for decades. The term AI was coined by the famous computer scientist John McCarthy in 1955. While initially connected to robotics, AI concepts are widely applicable in other fields, including predictive analytics. Currently, AI is understood as a set of mathematical tools used to develop algorithms that perform tasks typically done by humans, such as driving a car or scheduling a doctor’s appointment. This set of mathematical tools includes probabilistic models, machine learning algorithms, and deep learning. Previous successful applications included IBM’s DeepBlue victory over world champion Garry Kasparov in 1997.</p>
<p>Tree search algorithms were developed by DeepBlue engineers to implement the chess robot. A modification was the addition of heuristics to cut branches of the tree that would not lead to a win. These heuristics were designed by chess grandmasters based on their intuition and experience. Vehicles in the grand challenge also relied on traditional techniques such as Kalman filters and PID (proportional-integral-derivative) controllers that have been in use for many years.</p>
<p>Two distinguishing features of AI algorithms:</p>
<ol type="1">
<li>Algorithms typically deal with probabilities rather than certainties.</li>
<li>There’s the question of how these algorithms “know” what instructions to follow.</li>
</ol>
<p>A major difference between modern and historical AI algorithms is that most recent AI approaches rely on learning patterns from data. For example, the DeepBlue algorithm was “hardcoded,” and the human inputs were implemented as if-then statements by IBM engineers. On the other hand, the modern AlphaGo Zero algorithm did not use any human inputs and learned optimal strategies from large data sets generated from self-plays. Although handcrafted systems performed well in some tasks, such as chess playing, they are hard to design for many complex applications, such as self-driving cars. Large data sets allow us to replace sets of rules designed by engineers with sets of rules learned automatically from data. Thus, learning algorithms, such as deep learning, are at the core of most modern AI systems.</p>
<p>The main driving factor behind the growth of modern AI applications is the availability of massive and often unstructured data sets. We now have the computing power to develop computationally intensive AI algorithms. The three main modern AI enablers are Moore’s law (decades-long exponential growth in computer speed from Intel and Nvidia), the New Moore’s law (explosive growth in data as all of humanity’s information is digitized), and cloud computing (Nvidia, Google, AWS, Facebook, Azure).</p>
<p>Fitting complicated models to describe complex patterns without overfitting requires millions or billions of data points. Two key ideas behind pattern-recognition systems are that in AI, a “pattern” is a prediction rule that maps an input to an expected output, and “learning a pattern” means fitting a good prediction rule to a data set.</p>
<p>In AI, prediction rules are often referred to as “models.” The process of using data to find a good prediction rule is often called “training the model.” With millions (or billions) of data points and fast pattern-matching skills, machines can find needles in a haystack, providing insights for human health, transportation, and many other domains.</p>
<p><em>Machine learning (ML)</em> arises from this question: could a computer go beyond “what we know how to order it to perform” and learn on its own how to perform a specified task? Could a computer surprise us? Rather than programmers crafting data-processing rules by hand, could a computer automatically learn these rules by looking at data? This question opens the door to a new programming paradigm. In classical programming, the paradigm of symbolic AI, humans input rules (a program) and data to be processed according to these rules, and out come answers. With machine learning, humans input data as well as the answers expected from the data, and out come the rules. These rules can then be applied to new data to produce original answers.</p>
<p>A machine-learning system is trained rather than explicitly programmed. It’s presented with many examples relevant to a task, and it finds statistical structure in these examples that eventually allows the system to come up with rules for automating the task. For instance, if you wished to automate the task of tagging your vacation pictures, you could present a machine-learning system with many examples of pictures already tagged by humans, and the system would learn statistical rules for associating specific pictures to specific tags.</p>
<p>Although machine learning only started to flourish in the 1990s, it has quickly become the most popular and successful subfield of AI, a trend driven by the availability of faster hardware and larger datasets. Machine learning is tightly related to mathematical statistics, but it differs from statistics in several important ways. Unlike statistics, machine learning tends to deal with large, complex datasets (such as a dataset of millions of images, each consisting of tens of thousands of pixels) for which classical statistical analysis such as Bayesian analysis would be impractical. As a result, machine learning, and especially deep learning, exhibits comparatively little mathematical theory—maybe too little—and is engineering-oriented. It’s a hands-on discipline in which ideas are proven empirically more often than theoretically.</p>
<p><em>Deep learning</em> is a type of machine learning that performs a sequence of transformations (filters) on data. The output of each of those filters is called a factor in traditional statistical language and a hidden feature in machine learning. The word “deep” means that there is a large number of filters that process the data. The power of this approach comes from the hierarchical nature of the model.</p>
<p>The three main factors driving AI are massive data, trial and error (a billion times per second, as in Chess and Go), and deep learning pattern recognition.</p>
<p>The widespread adoption of mobile phones leads to generation of vast amounts of data. Besides images, users generate space and time trajectories, which are currently used to estimate and predict traffic, text messages, website clicking patterns, etc.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/datadeluge.svg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Amounts of data generated is growing with rapid adoption of mobile technologies and Internet</figcaption>
</figure>
</div>
<p>Deep learning, with many successful applications, has been frequently discussed in popular media. The popularity of the topic has led to hype where people tend to think that deep learning techniques are capable of replacing many human tasks, such as medical diagnostics and accounting. On the pessimistic side, people think that after a short hype, the DL techniques will disappoint and companies will stop funding R&amp;D work on its development. However, the research on pushing this field further is slow, and it will take time before deep learning penetrates a wide range of industries. At any rate, the demand for data scientists in general and AI specialists has been increasing over the last few years, with the biggest markets being in Silicon Valley, NYC, and Washington, DC<span class="citation" data-cites="indeed2018jobs">(<a href="references.html#ref-indeed2018jobs" role="doc-biblioref">indeed 2018</a>)</span>.</p>
<div id="fig-indeed" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-indeed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/indeed.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-indeed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: AI jobs are in high demand but salaries vary vastly with job titles. Indeed analyzed top paying AI jobs. Source: Indeed
</figcaption>
</figure>
</div>
<p>The field of predictive analytics was popularized by many famous competitions in which people compete to build the model with lowest prediction error. One of the first of these types of competitions was the Netflix prize. In 2009 Netflix paid $1 million to a team that developed the most accurate model for predicting movies a user would like to watch. At that time Netflix’s recommendation system generated 30 billion predictions per day. The initial goal of improving the recommendation algorithm by 10 percent was overachieved by the winning team. The winning team used what is called an ensemble technique, which takes a weighted average from different prediction algorithms. Thus, the first lesson from this competition is that we typically need to build several predictive models to achieve good results. On the other hand, the model developed by the winning team was never used by Netflix due to the complexity of those models and the fact that by the end of the competition Netflix mostly shifted to streaming movies versus sending DVDs over mail. The second lesson is that simplicity and interpretability of models matters when they are deployed on a large scale. The third lesson is that models need to adapt accordingly to meet fast changing business requirements.</p>
<p>Deep Learning’s (DL) growing popularity is summarized by the growth of products that Google is developing using DL. <a href="#fig-dlingoogle" class="quarto-xref">Figure&nbsp;<span>2</span></a> shows this immense growth. One key differentiating effect is that DL algorithms are scalable and can be implemented across the internet in apps such as YouTube and Gmail.</p>
<div id="fig-dlingoogle" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dlingoogle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/DL_growth.svg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dlingoogle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Deep Learning Projects at Google, including YouTube, Gmail and Maps
</figcaption>
</figure>
</div>
<p>Applications of Machine Learning/Deep Learning are endless, you just have to look at the right opportunity! There is a similar dynamics in popularity of deep learning search queries on Google. The growth is again exponential, although it is not yet close to the popularity of traditional statistical techniques, such as linear regression analysis.</p>
<p>Meanwhile, some ethical concerns are being raised as a result of the growing popularity of AI. The most discussed thus far is the impact on the job market and many jobs being replaced by deep learning models. Although some economic analysis <span class="citation" data-cites="acemoglu2018artificial">(<a href="references.html#ref-acemoglu2018artificial" role="doc-biblioref">Acemoglu and Restrepo 2018</a>)</span> shows that while job displacement leads to reduced demand for labor and wages, it is counteracted by a productivity effect and increases in demand for labor in non-automated tasks.</p>
<p>The algorithmic aspects of deep learning have existed for decades. In 1956, Kolmogorov showed that any function can be represented as a superposition of univariate functions (this is exactly what deep learning does). In 1951, Robbins and Monro proposed stochastic approximation algorithms. This is the main technique for finding weights of a deep learning model today.</p>
<p>The backpropagation algorithm for finding derivatives was first published and implemented by Werbos in 1974. In the mid-1980s, Schmidhuber studied many practical aspects of applying neural networks to real-life problems. Since the key ingredients of DL have been around for several decades, one could wonder why we observe a recent peak in popularity of those methods.</p>
<p>One of the strong driving forces is the adoption of DL by internet companies that need to analyze large-scale high-dimensional datasets, such as human-written text, speech, and images. Smartphone photography led to people uploading vast amounts of images to services like Instagram and Facebook. In 2012, more mobile devices were sold than PCs. The number of images shared on the Internet has skyrocketed as well. This can be seen in products that Google is developing using DL.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/numberofphotos-bi.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Number of phones and photos taken on the phones are rapidly growing over the last five years. Source: InfoTrends via Bitkom.</figcaption>
</figure>
</div>
<p>The proliferation of smartphones globally has been one of the most dramatic technological adoptions in human history. From just 173 million smartphone users worldwide in 2010, the number exploded to over 6.8 billion users by 2023, representing nearly 86% of the global population. This exponential growth has been particularly pronounced in developing markets, where smartphones often serve as the primary gateway to the internet. Countries like India and China have seen smartphone penetration rates exceed 80%, while regions in Africa and Southeast Asia continue to show rapid adoption curves. The ubiquity of smartphones has fundamentally transformed how data is generated and consumed - these devices produce continuous streams of location data, user interactions, images, messages, and behavioral patterns that form the foundation for modern AI applications. The convergence of increasingly powerful mobile processors, high-resolution cameras, and always-on internet connectivity has created an unprecedented data generation ecosystem that feeds directly into the machine learning models powering everything from recommendation systems to autonomous vehicles.</p>
<p>Therefore, data generated by Internet users creates a demand for techniques to analyze large-scale data sets. Mathematical methodologies were in place for many years. One missing ingredient in the explosive nature of DL popularity is the availability of computing power. DL models are computationally hungry; a trial and error process is required to build a useful model. Sometimes hundreds or thousands of different models are required to be evaluated before choosing one to be used in an application. Training models can be computationally expensive, as we are usually talking about large amounts of training data that need to be analyzed to build a model.</p>
<p>The adoption rate of AI technologies, particularly generative AI like ChatGPT, has shattered all previous records for technology adoption. While it took the internet 7 years to reach 100 million users, the telephone 75 years, and television 13 years, ChatGPT achieved this milestone in just 2 months after its launch in November 2022. This unprecedented speed of adoption reflects not just the accessibility of AI tools, but also their immediate utility across diverse user needs. Unlike previous innovations that required significant infrastructure changes or learning curves, AI chatbots could be accessed through simple web interfaces and provided immediate value for tasks ranging from writing assistance to problem-solving. The viral nature of AI adoption has been further accelerated by social media demonstrations and word-of-mouth sharing of impressive AI capabilities, creating a network effect that compounds the growth rate. This rapid adoption suggests that AI represents a fundamentally different type of technological shift - one that augments human capabilities rather than replacing existing systems entirely. The chart below illustrates the explosive growth potential of AI technologies.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/chatgpt-growth.png" class="img-fluid figure-img"></p>
<figcaption>Source: <a href="https://johnnosta.medium.com/the-most-important-chart-in-100-years-1095915e1605" class="uri">https://johnnosta.medium.com/the-most-important-chart-in-100-years-1095915e1605</a></figcaption>
</figure>
</div>
<p>The first generation of AI models was fundamentally enabled by the availability of powerful GPU chips, which provided the parallel processing capabilities necessary to train deep neural networks on large datasets. The breakthrough in deep learning around 2012, including innovations like AlexNet for image recognition, would not have been possible without GPUs that could perform thousands of matrix operations simultaneously. Current AI models, including ChatGPT, Claude, and other large language models, continue to rely primarily on GPUs for both training and inference. Modern AI training clusters consist of thousands of interconnected GPUs working together for weeks or months to process the enormous datasets required for today’s sophisticated models. While some companies have developed specialized AI chips like Google’s TPUs, GPUs remain the dominant platform for AI development due to their versatility, widespread availability, and established software ecosystems.</p>
<p>The gaming industry was one of the earliest drivers of GPU development, as game developers demanded increasingly sophisticated graphics rendering capabilities to create immersive virtual worlds with realistic lighting, textures, and physics simulations. Companies like NVIDIA and AMD invested heavily in parallel processing architectures optimized for the matrix operations required to render complex 3D scenes in real-time. The rise of cryptocurrency mining, particularly Bitcoin and Ethereum, created an unexpected second wave of GPU demand as miners discovered that graphics cards were far more efficient than traditional CPUs for the repetitive hash calculations required by proof-of-work algorithms. This mining boom drove massive investments in GPU manufacturing capacity and spurred innovations in memory bandwidth and energy efficiency. More recently, the explosion of AI-generated video content has created a third major demand driver, as video generation models require enormous computational power to process and synthesize high-resolution video frames. The convergence of these three use cases - gaming graphics, cryptocurrency mining, and AI video generation - has accelerated GPU development far beyond what any single application could have achieved alone, creating the powerful hardware infrastructure that now enables training of large language models and other AI applications.</p>
<p><a href="#tbl-nvda-chips" class="quarto-xref">Table&nbsp;<span>1</span></a> illustrates the dramatic evolution of GPU performance over two decades, from early graphics cards to specialized AI accelerators. The data shows exponential growth in computational power: from the modest 0.23 TeraFLOPS of the 2006 GeForce 7900 GTX to the projected 100 PetaFLOPS (FP4) of the 2027 Rubin Ultra - representing a performance increase of over 400,000x. Here FP4 is a lower precision (4-bit) floating-point arithmetic that is used for AI workloads. It is an alternative to FP32 (32-bit) floating-point arithmetic that is used for general purpose computing.</p>
<p>Memory capacity has similarly exploded from 0.5GB to a projected 1TB. Modern GPUs have evolved from simple graphics processors to sophisticated AI-optimized architectures featuring specialized tensor cores, mixed-precision arithmetic (FP8/FP4), and massive high-bandwidth memory systems. The transition from traditional FP32 floating-point operations to lower-precision AI workloads (FP8/FP4) has enabled unprecedented computational throughput measured in PetaFLOPS and ExaFLOPS scales, making current and future GPUs the primary engines driving the deep learning revolution and large language model training.</p>
<div id="tbl-nvda-chips" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-nvda-chips-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Evolution of Nvidia’s GPU performance
</figcaption>
<div aria-describedby="tbl-nvda-chips-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Year</th>
<th style="text-align: left;">GPU Model/Architecture</th>
<th style="text-align: left;">FP32 Peak (TeraFLOPS)</th>
<th style="text-align: left;">FP8/FP4 Peak (Peta/ExaFLOPS)</th>
<th style="text-align: left;">Memory (per GPU)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">2006</td>
<td style="text-align: left;">GeForce 7900 GTX</td>
<td style="text-align: left;">0.23</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0.5GB GDDR3</td>
</tr>
<tr class="even">
<td style="text-align: left;">2016</td>
<td style="text-align: left;">GeForce GTX 1080</td>
<td style="text-align: left;">8.9</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">8GB GDDR5X</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2024</td>
<td style="text-align: left;">RTX 4070 SUPER</td>
<td style="text-align: left;">~32</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">12GB GDDR6X</td>
</tr>
<tr class="even">
<td style="text-align: left;">2024</td>
<td style="text-align: left;">Blackwell B200</td>
<td style="text-align: left;">~45 (FP64)</td>
<td style="text-align: left;">20 PFLOPS (FP4) / 1.4 ExaFLOPS (AI cluster)</td>
<td style="text-align: left;">288GB HBM3e</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2026</td>
<td style="text-align: left;">Rubin VR300</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">50 PFLOPS (FP4) / 1.2 ExaFLOPS (FP8, rack)</td>
<td style="text-align: left;">288GB HBM4</td>
</tr>
<tr class="even">
<td style="text-align: left;">2027</td>
<td style="text-align: left;">Rubin Ultra</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">100 PFLOPS (FP4) / 5 ExaFLOPS (FP8, rack)</td>
<td style="text-align: left;">1TB HBM4e (per 4 dies)</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Now AI models are the main consumers of those processors. The most popular of those are ChatGPT-4, Anthropic’s Claude and Perplexity. <em>ChatGPT-4</em> is based on the transformer architecture. It is able to handle long conversations and maintain better context over multiple turns. It is stronger in creative writing, technical writing, reasoning tasks, and code generation. It has better performance on logic-heavy tasks and answering technical queries. It is mainly used for chatbots, automated content creation, code writing, customer support, and more advanced AI tasks.</p>
<p>OpenAI, the company behind ChatGPT, has experienced remarkable growth in both valuation and revenue. As of late 2024, OpenAI reached a valuation of $157 billion following its latest funding round, making it one of the most valuable private companies in the world. The company’s annual recurring revenue (ARR) has grown exponentially, reaching approximately $3.7 billion in 2024, driven primarily by ChatGPT subscriptions and API usage. OpenAI has raised over $13 billion in total funding, with major investors including Microsoft, which has invested $13 billion and maintains a strategic partnership that includes exclusive cloud computing arrangements. This rapid financial growth reflects the massive demand for generative AI capabilities across industries and the transformative potential of large language models.</p>
<p>Claude is the main competitor of OpenAI. It is supported by Amazon and excels at complex reasoning tasks, problem-solving, and in-depth analysis across a wide range of domains. Claude can write, debug, and explain code in many programming languages. It can analyze images and documents in addition to text and can engage in various conversation styles, from formal analysis to creative writing to casual discussion.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/claude.png" class="img-fluid figure-img"></p>
<figcaption>Claude</figcaption>
</figure>
</div>
<p>Amazon has made a significant strategic investment in Anthropic, Claude’s creator, committing up to $4 billion to advance AI safety research and development. This partnership positions Amazon Web Services (AWS) as Anthropic’s primary cloud provider while giving Amazon a minority ownership stake in the company. Unlike ChatGPT, which excels in creative writing and general-purpose conversations, Claude is specifically designed with a focus on safety, harmlessness, and nuanced reasoning. Claude demonstrates superior performance in tasks requiring careful analysis, ethical reasoning, and handling sensitive topics. It employs Constitutional AI training methods that make it more reliable in avoiding harmful outputs and better at acknowledging uncertainty when it doesn’t know something. Recent advances in Claude 3.7 and Claude 4.0 have introduced groundbreaking multimodal capabilities, allowing these models to process and analyze images, documents, and code with unprecedented accuracy. Claude 4.0 represents a significant leap forward in mathematical reasoning, coding assistance, and complex problem-solving tasks, with performance improvements of 40-60% over previous versions in benchmark evaluations. These newer models feature enhanced “thinking” processes that are more transparent, often explaining their reasoning step-by-step with greater depth and clarity, which makes them particularly valuable for educational applications, research assistance, and professional analysis where understanding the AI’s decision-making process is crucial. Claude 4.0 also introduces improved long-context understanding, capable of processing documents up to 200,000 tokens, and demonstrates remarkable advances in scientific reasoning and technical writing. This approach has made Claude increasingly popular among researchers, academics, and professionals who require more thoughtful and contextually aware AI assistance.</p>
<p>Perplexity synthesizes information from multiple sources and presents it with proper citations. Each response includes references for easy verification. It functions as a conversational search engine. Perplexity has emerged as a formidable competitor to Google Search by offering a fundamentally different approach to information discovery. Unlike traditional search engines that provide links to websites, Perplexity acts as an AI-powered research assistant that directly answers questions while citing sources. The company has attracted significant investment, including backing from Amazon founder Jeff Bezos, who participated in Perplexity’s $74 million Series B funding round in 2024. This strategic investment reflects growing confidence in AI-first search alternatives that could disrupt Google’s longstanding dominance in the search market.</p>
<p>The company has also developed innovative partnerships with major brands like Marriott and Nike, demonstrating how AI search can be integrated into enterprise applications. Marriott has explored using Perplexity’s technology to enhance customer service by providing instant, cited answers about hotel amenities, local attractions, and booking policies. Similarly, Nike has experimented with Perplexity’s capabilities to help customers find specific product information, sizing guides, and availability across different locations. These enterprise partnerships showcase Perplexity’s potential to move beyond general web search into specialized, domain-specific applications.</p>
<p>Perplexity’s advertising model differs significantly from Google’s traditional approach. Rather than displaying ads alongside search results, Perplexity is exploring sponsored answers and branded content integration that maintains the conversational flow while clearly identifying commercial partnerships. This approach could prove less intrusive than traditional search advertising while providing new revenue streams. The company’s growth trajectory and enterprise adoption suggest it could pose a meaningful challenge to Google’s search monopoly, particularly among users who prefer direct answers over browsing multiple websites.</p>
<p>The explosive growth of Large Language Models (LLMs) like ChatGPT, Claude, and Perplexity has been fundamentally enabled by the vast repositories of digital text that have accumulated over the past three decades. The “fuel” powering these sophisticated AI systems comes from an unprecedented collection of human knowledge digitized and made accessible through the internet. Wikipedia alone contains over 60 million articles across hundreds of languages, representing one of humanity’s largest collaborative knowledge projects. Web crawling technologies have systematically captured billions of web pages, blog posts, news articles, and forum discussions, creating massive text corpora that encode diverse writing styles, domains of expertise, and forms of human expression. The digitization of literature through projects like Google Books and Internet Archive has made millions of books searchable and processable, from classical literature to technical manuals. Social media platforms have contributed streams of conversational text, while academic databases provide formal scientific and scholarly writing. This digital text explosion created training datasets containing trillions of words - orders of magnitude larger than what any human could read in multiple lifetimes. By processing these enormous text collections through transformer architectures, LLMs learned statistical patterns of language use, absorbing grammar, syntax, semantics, and even reasoning patterns embedded in human writing. The models discovered how words relate to each other, how concepts connect across different contexts, and how to generate coherent, contextually appropriate responses by predicting the most likely next word given preceding text. This approach allowed AI systems to develop surprisingly sophisticated language understanding and generation capabilities without explicit programming of linguistic rules, instead learning the deep structure of human communication from the collective digital footprint of our species.</p>
<p>The mathematical operations used for manipulating and rendering images are the same as those used in deep learning models. Researchers started to use graphical processing units (GPUs) (a.k.a graphics cards) to train deep learning models in the 2010s. The wide availability of GPUs made deep learning modeling accessible for a large number of researchers and engineers and eventually led to the popularity of DL. Recently, several competitive hardware architectures were developed by large companies like Google, which uses its own TPU (Tensor Processing Units) as well as smaller start-ups.</p>
<p>This course will focus on practical and theoretical aspects of predicting using deep learning models. Currently, deep learning techniques are almost exclusively used for image analysis and natural language processing and are practiced by a handful of scientists and engineers, most of whom are trained in computer science. However, modern methodologies, software, and the availability of cloud computing make deep learning accessible to a wide range of data scientists who would typically use more traditional predictive models such as generalized linear regression or tree-based methods.</p>
<p>A unified approach to analyze and apply deep learning models to a wide range of problems that arise in business and engineering is required. To make this happen, we will bring together ideas from probability and statistics, optimization, scalable linear algebra, and high-performance computing. Although deep learning models are very interesting to study from a methodological point of view, the most important aspect of those is the predictive power unseen before with more traditional models. The ability to learn very complex patterns in data and generate accurate predictions makes deep learning a useful and exciting methodology to use. We hope to convey that excitement. This set of notes is self-contained and has a set of references for a reader interested in learning further.</p>
<p>Although basics of probability, statistics, and linear algebra will be revisited, this book is targeted towards students who have completed a course in introductory statistics and high school calculus. We will make extensive use of computational tools, such as <code>R</code> language, as well as <code>PyTorch</code> and <code>TensorFlow</code> libraries for predictive modeling, both for illustration and in homework problems.</p>
<p>There are many aspects of data analysis that do not deal with building predictive models, for example, data processing and labeling can require significant human resources<span class="citation" data-cites="hermann2017meet baylor2017tfx">(<a href="references.html#ref-hermann2017meet" role="doc-biblioref">Hermann and Balso 2017</a>; <a href="references.html#ref-baylor2017tfx" role="doc-biblioref">Baylor et al. 2017</a>)</span>.</p>
<div id="exm-maps" class="theorem example">
<p><span class="theorem-title"><strong>Example 1 (Updating Google Maps with Deep Learning and Street View.)</strong></span> Every day, Google Maps provides useful directions, real-time traffic information, and information on businesses to millions of people. To provide the best experience for users, this information must constantly mirror an ever-changing world. While Street View cars collect millions of images daily, it is impossible to manually analyze more than 80 billion high-resolution images collected to date to find new or updated information for Google Maps. One of the goals of Google’s Ground Truth team is to enable the automatic extraction of information from geo-located imagery to improve Google Maps.</p>
<p><span class="citation" data-cites="wojna2017attentionbased">(<a href="references.html#ref-wojna2017attentionbased" role="doc-biblioref">Wojna et al. 2017</a>)</span> describes an approach to accurately read street names out of very challenging Street View images in many countries, automatically, using a deep neural network. The algorithm achieves 84.2% accuracy on the challenging French Street Name Signs (FSNS) dataset, significantly outperforming previous state-of-the-art systems. Further, the model was extended to extract business names from street fronts.</p>
<div id="fig-streetview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-streetview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/fsns.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-streetview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Some examples of FSNS images.
</figcaption>
</figure>
</div>
<p>Another piece of information that researchers were able to extract from street view is political leanings of a neighborhood based on the vehicles parked on its streets. Using computer algorithms that can see and learn, they have analyzed millions of publicly available images on Google Street View. The researchers say they can use that knowledge to determine the political leanings of a given neighborhood just by looking at the cars on the streets.</p>
<div id="fig-streetviewvote" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-streetviewvote-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/streetview-vote.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-streetviewvote-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Types of cars detected in StreetView Images can be used to predict voting patterns
</figcaption>
</figure>
</div>
</div>
<div id="exm-cnn" class="theorem example">
<p><span class="theorem-title"><strong>Example 2 (CNN for Self Driving Car)</strong></span> In 2004 a self-driving vehicle that participated in Darpa’s grand challenge drove 150 miles through the Mojave Desert without human intervention.</p>
<div id="fig-darpa" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-darpa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/darpa.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-darpa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Darpa Grand Challenge Flyer from 2004
</figcaption>
</figure>
</div>
<p>Current self-driving systems rely on convolutional neural networks (CNN). This is a particular neural network architecture that can be trained to map raw pixels from a single front-facing camera directly to steering commands<span class="citation" data-cites="bojarski2016end">(<a href="references.html#ref-bojarski2016end" role="doc-biblioref">Bojarski et al. 2016</a>)</span>. This end-to-end approach proved surprisingly powerful. With minimum training data from humans the system learns to drive in traffic on local roads with or without lane markings and on highways. It also operates in areas with unclear visual guidance such as in parking lots and on unpaved roads. The system automatically learns internal representations of the necessary processing steps such as detecting useful road features with only the human steering angle as the training signal. We never explicitly trained it to detect, for example, the outline of roads.</p>
<p>Compared to explicit decomposition of the problem, such as lane marking detection, path planning, and control, our end-to-end system optimizes all processing steps simultaneously. We argue that this will eventually lead to better performance and smaller systems. Better performance will result because the internal components self-optimize to maximize overall system performance, instead of optimizing human-selected intermediate criteria, e.g., lane detection. Such criteria understandably are selected for ease of human interpretation which doesn’t automatically guarantee maximum system performance. Smaller networks are possible because the system learns to solve the problem with the minimal number of processing steps.</p>
<p>An NVIDIA DevBox and Torch 7 were used for training and an NVIDIA Drive PX self-driving car computer also running Torch 7 for determining where to drive. The system operates at 30 FPS.</p>
<div id="fig-cnnselfdriving" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cnnselfdriving-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/endtoendcar.svg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cnnselfdriving-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: The architecture for self driving car
</figcaption>
</figure>
</div>
</div>
<div id="exm-eye" class="theorem example">
<p><span class="theorem-title"><strong>Example 3 (Predicting Heart disease from eye images)</strong></span> Scientists from Google’s health-tech subsidiary Verily have discovered a new way to assess a person’s risk of heart disease using machine learning<span class="citation" data-cites="poplin2018prediction">(<a href="references.html#ref-poplin2018prediction" role="doc-biblioref">Poplin et al. 2018</a>)</span>. By analyzing scans of the back of a patient’s eye, the company’s software is able to accurately deduce data, including an individual’s age, blood pressure, and whether or not they smoke. This can then be used to predict their risk of suffering a major cardiac event — such as a heart attack — with roughly the same accuracy as current leading methods.</p>
<p>To train the algorithm, Verily’s scientists used machine learning to analyze a medical dataset of nearly 300,000 patients. This information included eye scans as well as general medical data. As with all deep learning analysis, neural networks were then used to mine this information for patterns, learning to associate telltale signs in the eye scans with the metrics needed to predict cardiovascular risk (e.g., age and blood pressure).</p>
<div id="fig-fundus" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fundus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/fundus.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fundus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Two images of the fundus, or interior rear of your eye. The one on the left is a regular image; the one on the right shows how Google’s algorithm picks out blood vessels (in green) to predict blood pressure. Photo by Google - Verily Life Sciences
</figcaption>
</figure>
</div>
<p>When presented with retinal images of two patients, one of whom suffered a cardiovascular event in the following five years, and one of whom did not, Google’s algorithm was able to tell which was which 70 percent of the time. This is only slightly worse than the commonly used SCORE method of predicting cardiovascular risk, which requires a blood test and makes correct predictions in the same test 72 percent of the time.</p>
<section id="painting-a-new-rembrandt" class="level2">
<h2 class="anchored" data-anchor-id="painting-a-new-rembrandt">Painting a New Rembrandt</h2>
<p>A new Rembrandt painting unveiled in Amsterdam Tuesday has the tech world buzzing more than the art world. “The Next Rembrandt,” as it’s been dubbed, was the brainchild of Bas Korsten, creative director at the advertising firm J. Walter Thompson in Amsterdam.</p>
<p>The new portrait is the product of 18 months of analysis of 346 paintings and 150 gigabytes of digitally rendered graphics. Everything about the painting — from the subject matter (a Caucasian man between the age of 30 and 40) to his clothes (black, wide-brimmed hat, black shirt and white collar), facial hair (small mustache and goatee) and even the way his face is positioned (facing right) — was distilled from Rembrandt’s body of work.</p>
<p>“A computer learned, with artificial intelligence, how to re-create a new Rembrandt right eye,” Korsten explains. “And we did that for all facial features, and after that, we assembled those facial features using the geometrical dimensions that Rembrandt used to use in his own work.” Can you guess which image was generated by the algorithm?</p>
<div id="fig-rembrant" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rembrant-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/rembrant.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rembrant-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Can you guess which image was generated by the algorithm?
</figcaption>
</figure>
</div>
</section>
</div>
<div id="exm-traj" class="theorem example">
<p><span class="theorem-title"><strong>Example 4 (Learning Person Trajectory Representations for Team Activity Analysis)</strong></span> Activity analysis in which multiple people interact across a large space is challenging due to the interplay of individual actions and collective group dynamics. A recently proposed end-to-end approach <span class="citation" data-cites="mehrasa2017learning">(<a href="references.html#ref-mehrasa2017learning" role="doc-biblioref">Mehrasa et al. 2017</a>)</span> allows for learning person trajectory representations for group activity analysis. The learned representations encode rich spatio-temporal dependencies and capture useful motion patterns for recognizing individual events, as well as characteristic group dynamics that can be used to identify groups from their trajectories alone. Deep learning was applied in the context of team sports, using the sets of events (e.g.&nbsp;pass, shot) and groups of people (teams). Analysis of events and team formations using NHL hockey and NBA basketball datasets demonstrate the generality of applicability of DL to sports analytics.</p>
<p>When activities involve multiple people distributed in space, the relative trajectory patterns of different people can provide valuable cues for activity analysis. We learn rich trajectory representations that encode useful information for recognizing individual events as well as overall group dynamics in the context of team sports.</p>
<div id="fig-traj" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-traj-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/hockey.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-traj-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Hockey trajectory analysis visualization
</figcaption>
</figure>
</div>
</div>
<div id="exm-epl-liverppol" class="theorem example">
<p><span class="theorem-title"><strong>Example 5 (EPL Liverpool Prediction)</strong></span> Liverpool FC has become a benchmark in football for integrating advanced data analytics into both their recruitment and on-field strategies. The Expected Possession Value (EPV) pitch map shown below displays the likelihood that possession from a given location will result in a goal, with red areas indicating high-value zones where Liverpool’s chances of scoring increase significantly when they gain or retain the ball. Liverpool’s analysts use these EPV maps to inform tactical decisions and player positioning, allowing the coaching staff to instruct players to press, pass, or move into these high-value zones.</p>
<div id="fig-liverpool-pitch" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-liverpool-pitch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/liverpool-pitch.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-liverpool-pitch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Expected Possession Value (EPV) pitch map
</figcaption>
</figure>
</div>
<p>On April 26, 2019, Liverpool scored their fastest-ever Premier League goal—Naby Keita found the net just 15 seconds into the match against Huddersfield Town, setting the tone for a dominant 5-0 victory. This remarkable goal exemplified Liverpool’s data-driven approach to football. Keita’s immediate pressure on Huddersfield’s Jon Gorenc Stankovic was not random—it was a calculated move informed by analytics revealing Huddersfield’s vulnerability when building from the back under pressure. This demonstrates the effective application of Expected Possession Value (EPV) principles. Liverpool’s analysts systematically study opponent build-up patterns, using video and tracking data to predict where and how opponents are likely to play the ball from kick-off or in early possession phases. This intelligence allows Liverpool players to position themselves strategically for maximum disruption. When Huddersfield’s goalkeeper played out from the back, Keita was already moving to intercept, anticipating the pass route—a behavior that had been drilled through analytics-driven preparation and scenario planning.</p>
</div>
<div id="exm-SailGP" class="theorem example">
<p><span class="theorem-title"><strong>Example 6 (SailGP)</strong></span> SailGP is a global sailing championship that represents the pinnacle of competitive sailing, featuring identical F50 foiling catamarans raced by national teams. Unlike traditional sailing competitions, the series combines high-performance sailing with advanced analytics, real-time data processing, and 5G connectivity to create a modern, technology-driven sport where success depends as much on data analysis and optimization as traditional sailing skills. SailGP races take place in iconic venues around the world, with teams representing countries competing in a season-long championship format that emphasizes both athletic excellence and technological innovation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/Emirates_GBR_SailGP_Team_F50_Race_Boat.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Emirates GBR SailGP Team F50 Race. Source:<a href="https://commons.wikimedia.org/wiki/File:Emirates_GBR_SailGP_Team_F50_Race_Boat.jpg">Wikimedia</a>.</figcaption>
</figure>
</div>
<p>Oracle’s co-founder Larry Ellison is a pioneer and a significant investor in sailing analytics and technology, particularly through his involvement with Oracle Team USA and the America’s Cup. His team’s success in the 2010 and 2013 America’s Cup campaigns demonstrated how data analysis done in real-time could provide competitive advantages. His approach has influenced the development of modern sailing competitions like SailGP.</p>
<p>Jimmy Spithill is a veteran of eight consecutive America’s Cup campaigns. His most legendary achievement came in 2013 with ORACLE TEAM USA, where he led what is widely acclaimed as one of the greatest comebacks in sporting history. After falling behind 8-1 in the best-of-17 series against Emirates Team New Zealand, Spithill and his team faced seemingly insurmountable odds. No team had ever come back from such a deficit in America’s Cup history.</p>
<p>The turning point came after the 8-1 loss when the team made a critical technological decision. They installed additional sensors throughout the boat to collect more comprehensive data about performance, wind conditions, and boat dynamics. These sensors provided real-time feedback that allowed the team to make precise adjustments to their sailing strategy and boat configuration.</p>
<p>With the enhanced data collection system in place, ORACLE TEAM USA began their historic comeback, winning eight consecutive races to claim the America’s Cup with a final score of 9-8. The victory demonstrated how the integration of advanced sensor technology and data analytics could provide the competitive edge needed to overcome even the most daunting deficits.</p>
<p>This 2013 comeback remains a defining moment in sailing history, showcasing how the marriage of traditional sailing skill with cutting-edge technology can produce extraordinary results. Spithill’s leadership during this period highlighted the importance of adaptability and the willingness to embrace technological solutions when facing adversity.</p>
<p>One of the main features is velocity made good (VMG), which calculates the optimal course to maximize speed toward the mark while accounting for wind direction and current. Tack and gybe optimization uses statistical modeling to determine the optimal timing for direction changes based on wind shifts, boat speed, and course geometry. Layline calculations employ predictive analytics to determine the optimal approach angles to marks, minimizing distance sailed.</p>
<p>Further, boundary layer modeling provides statistical analysis of wind gradients across the racecourse to identify optimal sailing lanes. Weather routing uses optimization algorithms that consider multiple weather models to find the fastest route between marks.</p>
<p>Pressure sensors combined with models of flow dynamics of hydrofoils allow for calculating optimal foil position. Sail trim analysis examines statistical correlation between sail settings, wind conditions, and boat speed. Weight distribution modeling optimizes crew positioning and ballast distribution based on real-time conditions.</p>
<p>Real-time dashboards display statistical process control charts showing performance metrics against historical benchmarks. Predictive modeling employs machine learning algorithms that forecast optimal strategies based on current conditions and historical performance.</p>
<p>The statistical foundation relies heavily on time series analysis, regression modeling, and Monte Carlo simulations to account for the inherent variability in wind and sea conditions. Teams use Bayesian inference to update their models in real-time as new data becomes available during races, creating a dynamic optimization system that continuously refines strategy based on actual performance data.</p>
<p>The <a href="https://www.linkedin.com/pulse/transforming-sailgp-5g-52-billion-data-points-per-race-van-loon-5l92e/">LinkedIn article</a> by Van Loon describes how SailGP provides a good summary of modern evolution of traditional sailing competitions, leveraging cutting-edge technology to enhance both performance and spectator experience.</p>
<p>There are over 1,000 sensors on a SailGP boat that generate an astonishing 52 billion data points per race, providing unprecedented insights into boat performance, wind conditions, and crew actions.</p>
<p>SailGP’s approach demonstrates how modern sports are increasingly becoming technology competitions as much as athletic competitions, with success depending heavily on the ability to collect, process, and act on real-time data effectively. This represents a significant shift from traditional sailing, where success was primarily determined by experience, intuition, and traditional sailing skills.</p>
</div>
<div id="exm-googlenergy" class="theorem example">
<p><span class="theorem-title"><strong>Example 7 (Google Energy)</strong></span> In 2016, Google’s DeepMind published a white paper outlining their approach to save energy in data centers. Reducing energy usage has been a major focus for data center operators over the past 10 years. Major breakthroughs, however, are few and far between, but Google managed to reduce the amount of energy used for cooling by up to 40 percent. In any large-scale energy-consuming environment, this would be a huge improvement. Given how sophisticated Google’s data centers are, even a small reduction in energy will lead to large savings. DeepMind used a system of neural networks trained on different operating scenarios and parameters within their data centers, creating a more efficient and adaptive framework to understand data center dynamics and optimize efficiency.</p>
<p>To accomplish this, the historical data that had already been collected by thousands of sensors within the data center – data such as temperatures, power, pump speeds, setpoints, etc. – was used to train an ensemble of deep neural networks. Since the objective was to improve data center energy efficiency, the model was trained on the average future PUE (Power Usage Effectiveness), which is defined as the ratio of the total building energy usage to the IT energy usage. Two ensembles of deep neural networks were developed to predict the future temperature and pressure of the data center over the next hour. The purpose of these predictions is to simulate the recommended actions from the PUE model, to ensure that we do not go beyond any operating constraints.</p>
<p>The DL system was able to consistently achieve a 40 percent reduction in the amount of energy used for cooling, which equates to a 15 percent reduction in overall PUE overhead after accounting for electrical losses and other non-cooling inefficiencies. It also produced the lowest PUE the site had ever seen.</p>
<div id="fig-googlenergy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-googlenergy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/googlenergy.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-googlenergy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: DL system was able to consistently achieve a 40 percent reduction in the amount of energy used for cooling, which equates to a 15 percent reduction in overall PUE overhead after accounting for electrical losses and other non-cooling inefficiencies. It also produced the lowest PUE the site had ever seen.
</figcaption>
</figure>
</div>
</div>
<div id="exm-chess" class="theorem example">
<p><span class="theorem-title"><strong>Example 8 (Chess and Backgammon)</strong></span> The game of Chess is the most studied domain in AI. Many bright minds attempted to build an algorithm that can beat a human master. Both Alan Turing and John von Neumann, who are considered pioneers of AI, developed Chess algorithms. Historically, highly specialized systems, such as IBM’s Deep Blue have been successful in chess.</p>
<div id="fig-deepblue" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-deepblue-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/deepblue.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-deepblue-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: Kasparov vs IBM’s DeepBlue in 1997
</figcaption>
</figure>
</div>
<p>Most of those systems are based on alpha-beta search, handcrafted by human grand masters. Human inputs are used to design game-specific heuristics that allow truncating moves which are unlikely to lead to a win.</p>
<p>Recent implementations of chess robots rely on deep learning models. <span class="citation" data-cites="silver2017mastering">(<a href="references.html#ref-silver2017mastering" role="doc-biblioref">Silver et al. 2017</a>)</span> shows a simplified example of a binary-linear value function <span class="math inline">\(v\)</span>, which assigns a numeric score to each board position <span class="math inline">\(s\)</span>. The value function parameters <span class="math inline">\(w\)</span> are estimated from outcomes of a series of self-play and is represented as dot product of a binary feature vector <span class="math inline">\(x(s)\)</span> and the learned weight vector <span class="math inline">\(w\)</span>: e.g.&nbsp;value of each piece. Then, each future position is evaluated by summing weights of active features.</p>
<div id="fig-chessboard" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-chessboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/chess_board.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-chessboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: Chess Algorithm, <span class="math inline">\(v(s,w)\)</span> denotes value of strategy, <span class="math inline">\(s\)</span>, given the learned weights, <span class="math inline">\(w\)</span>.
</figcaption>
</figure>
</div>
<p>Before deep learning models were used for Go and Chess, IBM used them to develop a backgammon robot, which they called TD-Gammon<span class="citation" data-cites="tesauro1995temporal">(<a href="references.html#ref-tesauro1995temporal" role="doc-biblioref">Tesauro 1995</a>)</span>. TD-Gammon uses a deep learning model as a value function which predicts the value, or reward, of a particular state of the game for the current player.</p>
<div id="fig-backgammon" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-backgammon-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/TD_gammon.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-backgammon-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: Backgammon Algorithm: Tree-Search for Backgammon policies
</figcaption>
</figure>
</div>
</div>
<div id="exm-alphago" class="theorem example">
<p><span class="theorem-title"><strong>Example 9 (Alpha Go and Move 37)</strong></span> One of the great challenges of computational games was to conquer the ancient Chinese game of Go. The number of possible board positions is <span class="math inline">\(10^{960}\)</span> which prevents us from using tree search algorithms as it was done with chess. There are only <span class="math inline">\(10^{170}\)</span> possible chess positions. Alpha Go uses 2 deep learning neural networks to assist a move and to evaluate a position: a policy network for move recommendation and a value network for current evaluation (who will win?).</p>
<p>The policy network was initially trained with supervised learning with data fed from human master games. Then, it was trained in unsupervised mode by playing against itself. The value network was trained based on the outcome of games. A key trick is to reduce breadth of search space by only considering moves recommended by the policy network. The next advance is to reduce depth of search space by replacing search space sub trees with a single value created by the value network.</p>
<p>The game is played by performing a Monte Carlo tree search which we illustrate in <a href="#fig-mctree" class="quarto-xref">Figure&nbsp;<span>15</span></a>. The algorithm involves traversing the tree using highest recommended moves that haven’t been picked yet, expanding leaf nodes and evaluating with both policy and value networks, and backing up through the tree and storing mean evaluation at each node of its leaf nodes.</p>
<div id="fig-mctree" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mctree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/mc-tree-search.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mctree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15: Steps of Monte Carlo tree search
</figcaption>
</figure>
</div>
<p>AlphaGo won 4-1 vs.&nbsp;Lee Sedol, but the loss was informative.</p>
<p>AlphaGo Zero is the next iteration of the algorithm that removes all human knowledge from the training process. It uses no human data - only self play, no human features - only takes raw board as input, a single neural network - combining policy and value networks into a single network, and simpler search - no randomized monte-carlo rollout - only uses NN evaluation.</p>
<div id="fig-alphagozero" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alphagozero-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/move37.jpeg" class="img-fluid figure-img" style="width:30.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alphagozero-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16: Alpha GO vs Lee Sedol: Move 37 by AlphaGo in Game Two
</figcaption>
</figure>
</div>
</div>
<div id="exm-gameofthrones" class="theorem example">
<p><span class="theorem-title"><strong>Example 10 (Game of Thrones)</strong></span> A fan of HBO’s Game of Thrones saga who could not wait until the next chapter of the <em>A Song of Ice and Fire</em> book it is based on comes out, used a deep learning model to generate one. He used recurrent neural networks which were trained on the previous chapters. First, each of the 32,000 unique words in the text were enumerated and then the machine learned some plot points and was able to generate new patterns of text.</p>
<p>In August 2023, George R.R. Martin, author of the “A Song of Ice and Fire” series that inspired Game of Thrones, joined a lawsuit against OpenAI, the creator of ChatGPT. The lawsuit alleges that OpenAI used copyrighted material from the New York Times, including articles about Game of Thrones, to train its AI models without permission. While not directly about the show itself, Martin’s involvement draws a connection due to his authorship of the source material. Here is the reply ChatGPT 4.0 gives for the <code>Can you tell about lawsuit related to Game of Thrones?</code> query.</p>
<blockquote class="blockquote">
<p>“In September 2023, a class-action lawsuit was filed against OpenAI by George R.R. Martin, the author of”Game of Thrones”, along with other best-selling authors like John Grisham and Jodi Picoult. The lawsuit, organized by the Authors Guild, accuses OpenAI of using their copyrighted works without permission to train its AI chatbot, ChatGPT. The authors argue that this constitutes “systematic theft on a mass scale,” and they are concerned that such use of their works by AI could endanger their ability to make a living from their writings.</p>
</blockquote>
<blockquote class="blockquote">
<p>The lawsuit was filed in the U.S. District Court for the Southern District of New York, alleging “flagrant and harmful infringements” of the plaintiffs’ registered copyrights. The authors are seeking a ban on the use of copyrighted books to develop language models without express authorization, as well as damages.</p>
</blockquote>
<blockquote class="blockquote">
<p>OpenAI, in response to similar lawsuits, has claimed that their use of training data scraped from the internet qualifies as fair use under US copyright law. They have stated that they respect the rights of writers and are having productive conversations with creators, including the Authors Guild, about how they can benefit from AI technology.</p>
</blockquote>
<blockquote class="blockquote">
<p>This legal action is part of a broader trend where artists, writers, and coders are raising concerns and taking legal action against AI companies for using their work without permission. These cases are bringing attention to the complex issues surrounding AI and copyright, especially as AI technologies become more advanced and widespread in their applications.”</p>
</blockquote>
</div>
<section id="anything-as-a-vector" class="level2">
<h2 class="anchored" data-anchor-id="anything-as-a-vector">Anything as a Vector</h2>
<p>We saw in the chess example that a board position can be represented as a vector. This is a key idea in modern AI. We can represent any object as a vector. Modern AI uses deep learning to learn a representation of an object that is useful for a particular task. In this book, we will study convolutional neural networks (CNNs) which are used to learn a representation of images and embeddings neural networks which are used to learn a representation of text.</p>
<p>The power of vector representations lies in their ability to capture complex relationships through simple mathematical operations. Similarity between objects can be measured using cosine similarity or Euclidean distance. Linear combinations of vectors can represent mixtures of concepts. This mathematical framework enables the development of powerful algorithms for classification, clustering, and generation tasks.</p>
<p>The second key idea is to use negative log-likelihood (loss function) to combine information from multiple sources represented as vectors into a single number that measures how well model performs the task at hand, e.g.&nbsp;text generation or image classification. This is a key idea in modern AI.</p>
<p>While vector representations provide the language, loss functions provide the learning signal that guides AI systems toward better performance. The negative log-likelihood (NLL) loss function is particularly important because it connects probabilistic reasoning with optimization, creating a bridge between statistical theory and practical implementation. The combination of learned vector representations and loss functions has enabled remarkable advances across AI domains:</p>
<p><em>Natural Language Processing</em>: Modern language models like GPT and BERT learn contextual vector representations of words and sentences. The NLL loss guides the learning process, ensuring that the representations capture semantic relationships that are useful for tasks like translation, summarization, and question answering.</p>
<p><em>Computer Vision</em>: Convolutional neural networks learn hierarchical feature representations, from low-level edges and textures to high-level object parts and categories. The loss ensures these representations are optimized for the specific task, whether it’s object detection, segmentation, or image generation.</p>
<p><em>Recommendation Systems</em>: User and item representations are learned simultaneously, with the NLL loss measuring how well the model predicts user preferences. This approach has revolutionized recommendation engines at companies like Netflix, Amazon, and Spotify.</p>
<p>The success of this approach has led to the development of sophisticated frameworks and tools that abstract away the complexity of implementing these components. Libraries like PyTorch and TensorFlow provide efficient implementations of both vector operations and loss functions, making it possible for practitioners to focus on the high-level design of their AI systems rather than the low-level implementation details.</p>
<p>As AI continues to evolve, these two pillars remain central to the field’s progress. New architectures and training methods build upon these foundations, but the fundamental principles of learning meaningful vector representations and optimizing them through appropriate loss functions continue to drive innovation in artificial intelligence.</p>
</section>
<section id="generative-ai" class="level2">
<h2 class="anchored" data-anchor-id="generative-ai">Generative AI</h2>
<p>The landscape of Artificial Intelligence is rapidly being reshaped by the rise of Generative AI (Gen AI). As of 2025, Gen AI has moved beyond hype and into practical application across a multitude of personal and professional domains. A recent article in the Harvard Business Review, “How People Are Really Using Gen AI in 2025” by Marc Zao-Sanders, highlights this shift, noting that user interest has significantly increased and investment in AI is skyrocketing.</p>
<p>The article reveals a fascinating trend: a move from purely technical applications towards more emotive and personal uses. The top use cases in 2025 reflect this, with “Therapy/companionship” leading the list. Other prominent uses include “Organizing my life,” “Finding purpose,” “Enhanced learning,” and “Generating code (for pros).” This indicates that individuals are leveraging Gen AI not just for productivity, but also for personal development and well-being.</p>
<p>Some concrete examples of how people are using Gen AI, as cited in the article, include providing accessible mental health support and a sense of connection (therapy/companionship), especially in regions with limited access to human therapists where users find AI to be available 24/7 and non-judgmental. People are also creating timelines for tasks, planning daily habits, and managing personal projects (organizing my life), using AI as a study guide to explain complex topics and reinforce learning (enhanced learning), generating meal plans based on specific dietary needs and macro calculations (healthier living), planning detailed vacations, including finding rustic accommodations and hidden gems while optimizing travel time (creating travel itineraries), and drafting appeal letters for things like parking tickets (disputing fines).</p>
<p>The article also points to the increasing sophistication of Gen AI users, who are developing a deeper understanding of the technology’s capabilities and limitations, including concerns around data privacy and the potential for over-reliance.</p>
<p>Below is an image from the HBR article summarizing the top 10 use cases:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hbr.org/resources/images/article_assets/2025/04/W250310_SANDERS_AI_USES_TOP_10_USES_360-1200x2763.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Top 10 Gen AI Use Cases in 2025. Source: Harvard Business Review, “How People Are Really Using Gen AI in 2025”, April 9, 2025.</figcaption>
</figure>
</div>
<p><em>Source: Marc Zao-Sanders, “How People Are Really Using Gen AI in 2025,” Harvard Business Review, April 9, 2025, <a href="https://hbr.org/2025/04/how-people-are-really-using-gen-ai-in-2025">https://hbr.org/2025/04/how-people-are-really-using-gen-ai-in-2025</a>.</em></p>
<p>The continued evolution of Gen AI promises even more sophisticated applications in the future, moving from providing information to taking action (agentic behavior).</p>
<p>The computer therapist is not something new. In 1966, Joseph Weizenbaum created ELIZA, a computer program that could simulate a conversation with a psychotherapist. ELIZA used simple pattern matching to respond to user inputs, creating the illusion of understanding. While it was a groundbreaking achievement at the time, it lacked true comprehension and relied on scripted responses.</p>
</section>
<section id="agi-and-aiq" class="level2">
<h2 class="anchored" data-anchor-id="agi-and-aiq">AGI and AIQ</h2>
<blockquote class="blockquote">
<p>“<em>I visualize a time when we will be to robots what dogs are to humans. And I am rooting for the machines.</em>” - Claude Shannon</p>
</blockquote>
<blockquote class="blockquote">
<p>“<em>Let us suppose we have set up a machine with certain initial instruction tables, so constructed that these tables might on occasion, if good reason arose, modify those tables. One can imagine that after the machine had been operating for some time, the instructions would have altered out of all recognition, but nevertheless still be such that one would have to admit that the machine was still doing very worthwhile calculations. Possibly it might still be getting results of the type desired when the machine was first set up, but in a much more efficient manner. In such a case one would have to admit that the progress of the machine had not been foreseen when its original instructions were put in. It would be like a pupil who had learnt much from his master, but had added much more by his own work. When this happens I feel that one is obliged to regard the machine as showing intelligence.</em>” – Alan Turing</p>
</blockquote>
<p>People, organizations, and markets interact in complex ways. AI facilitates organization and hence connects people to markets faster and more simply. Hence it creates economic value. Most of the recessions in the 19th century were a result of not being able to get goods to markets quickly enough, which led to banking crises. AI accelerates speed to market. It creates growth. The age of abundance is here.</p>
<p>Andrej Karpathy’s talk, <a href="https://youtu.be/LCEmiRjPEtQ?si=Ktn4NF1Z6gwQgvfI">“Software Is Changing (Again),”</a> explores how large language models (LLMs) are fundamentally transforming the way software is developed and used. He describes this new era as “Software 3.0,” where natural language becomes the primary programming interface and LLMs act as a new kind of computer. He compares it to the previous generations of software development approaches summarized in the table below.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 25%">
<col style="width: 33%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Paradigm</th>
<th>“Program” is…</th>
<th>Developer’s main job</th>
<th>Canonical depot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Software 1.0</em></td>
<td>Hand-written code</td>
<td>Write logic</td>
<td>GitHub</td>
</tr>
<tr class="even">
<td><em>Software 2.0</em></td>
<td>Neural-net <em>weights</em></td>
<td>Curate data &amp; train</td>
<td>Hugging Face / Model Atlas</td>
</tr>
<tr class="odd">
<td><em>Software 3.0</em></td>
<td>Natural-language <em>prompts</em></td>
<td>Compose/police English instructions</td>
<td>Prompt libraries</td>
</tr>
</tbody>
</table>
<p>Currently, LLMs are collaborative partners that can augment human abilities, democratizing software creation and allowing people without traditional programming backgrounds to build complex applications simply by describing what they want in plain English.</p>
<p><span class="citation" data-cites="polson2018aiq">Polson and Scott (<a href="references.html#ref-polson2018aiq" role="doc-biblioref">2018</a>)</span> have predicted that human-machine interaction will be the next frontier of AI.</p>
<p>Hal Varian’s 2010 paper “Computer Mediated Transactions” <span class="citation" data-cites="varian2010computer">Varian (<a href="references.html#ref-varian2010computer" role="doc-biblioref">2010</a>)</span> provides a foundational framework for understanding how computers can automate routine tasks and decision-making processes, reducing transaction costs and increasing efficiency. This includes automated pricing, inventory management, and customer service systems. He discusses systems that can coordinate between multiple parties by providing real-time information sharing and communication platforms. This enables more complex multi-party transactions and supply chain management.</p>
<p>This framework remains highly relevant for understanding modern AI and machine learning applications in business, as these technologies represent the next evolution of computer-mediated transactions, enabling even more sophisticated automation, coordination, and communication capabilities.</p>
<p>In his talk on “Why are LLMs not Better at Finding Proofs?”, Timothy Gowers discusses that while large language models (LLMs) can display some sensible reasoning—such as narrowing down the search space in a problem—they tend to falter when they get stuck, relying too heavily on intelligent guesswork rather than systematic problem-solving. Unlike humans, who typically respond to a failed attempt with a targeted adjustment based on what went wrong, LLMs often just make another guess that isn’t clearly informed by previous failures. He also highlights a key difference in approach: humans usually build up to a solution incrementally, constructing examples that satisfy parts of the problem and then refining their approach based on the requirements. For example, when trying to prove an existential statement, a human might first find examples satisfying one condition, then look for ways to satisfy additional conditions, adjusting parameters as needed. LLMs, by contrast, are more likely to skip these intermediate steps and try to jump directly to the final answer, missing the structured, iterative reasoning that characterizes human problem-solving.</p>
<p>While there are indeed limitations to what current large language models can solve, particularly in areas requiring systematic mathematical reasoning, they continue to demonstrate remarkable capabilities in solving complex problems through alternative approaches. A notable example is the application of deep learning to the classical three-body problem in physics, a problem that has challenged mathematicians and physicists for centuries. Traditional analytical methods have struggled to find closed-form solutions for the three-body problem, but deep neural networks have shown surprising success in approximating solutions through pattern recognition and optimization techniques. These neural networks can learn the underlying dynamics from training data and generate accurate predictions for orbital trajectories, even when analytical solutions remain elusive. This success demonstrates that the trial-and-error approach, when combined with sophisticated pattern recognition capabilities, can lead to practical solutions for problems that have resisted traditional mathematical approaches. The key insight is that while these methods may not provide the elegant closed-form solutions that mathematicians prefer, they offer valuable computational tools that can advance scientific understanding and enable practical applications in fields ranging from astrophysics to spacecraft navigation.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-acemoglu2018artificial" class="csl-entry" role="listitem">
Acemoglu, Daron, and Pascual Restrepo. 2018. <span>“Artificial Intelligence, Automation and Work.”</span> National Bureau of Economic Research.
</div>
<div id="ref-baylor2017tfx" class="csl-entry" role="listitem">
Baylor, Denis, Eric Breck, Heng-Tze Cheng, Noah Fiedel, Chuan Yu Foo, Zakaria Haque, Salem Haykal, et al. 2017. <span>“Tfx: <span>A</span> Tensorflow-Based Production-Scale Machine Learning Platform.”</span> In <em>Proceedings of the 23rd <span>ACM SIGKDD</span> International Conference on Knowledge Discovery and Data Mining</em>, 1387–95. ACM.
</div>
<div id="ref-bojarski2016end" class="csl-entry" role="listitem">
Bojarski, Mariusz, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D Jackel, et al. 2016. <span>“End to End Learning for Self-Driving Cars.”</span> <em>arXiv Preprint arXiv:1604.07316</em>. <a href="https://arxiv.org/abs/1604.07316">https://arxiv.org/abs/1604.07316</a>.
</div>
<div id="ref-hermann2017meet" class="csl-entry" role="listitem">
Hermann, Jeremy, and Mike Del Balso. 2017. <span>“Meet Michelangelo: <span>Uber</span>’s Machine Learning Platform.”</span>
</div>
<div id="ref-indeed2018jobs" class="csl-entry" role="listitem">
indeed. 2018. <span>“Jobs of the Future: <span>Emerging</span> Trends in Artificial Intelligence.”</span>
</div>
<div id="ref-mehrasa2017learning" class="csl-entry" role="listitem">
Mehrasa, Nazanin, Yatao Zhong, Frederick Tung, Luke Bornn, and Greg Mori. 2017. <span>“Learning Person Trajectory Representations for Team Activity Analysis.”</span> <em>arXiv Preprint arXiv:1706.00893</em>. <a href="https://arxiv.org/abs/1706.00893">https://arxiv.org/abs/1706.00893</a>.
</div>
<div id="ref-polson2018aiq" class="csl-entry" role="listitem">
Polson, Nicholas G, and James Scott. 2018. <em><span>AIQ</span>: How People and Machines Are Smarter Together</em>. St. Martin’s Press.
</div>
<div id="ref-poplin2018prediction" class="csl-entry" role="listitem">
Poplin, Ryan, Avinash V Varadarajan, Katy Blumer, Yun Liu, Michael V McConnell, Greg S Corrado, Lily Peng, and Dale R Webster. 2018. <span>“Prediction of Cardiovascular Risk Factors from Retinal Fundus Photographs via Deep Learning.”</span> <em>Nature Biomedical Engineering</em> 2 (3): 158.
</div>
<div id="ref-silver2017mastering" class="csl-entry" role="listitem">
Silver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, et al. 2017. <span>“Mastering <span>Chess</span> and <span>Shogi</span> by <span>Self-Play</span> with a <span>General Reinforcement Learning Algorithm</span>.”</span> arXiv. <a href="https://arxiv.org/abs/1712.01815">https://arxiv.org/abs/1712.01815</a>.
</div>
<div id="ref-tesauro1995temporal" class="csl-entry" role="listitem">
Tesauro, Gerald. 1995. <span>“Temporal Difference Learning and <span>TD-Gammon</span>.”</span> <em>Communications of the ACM</em> 38 (3): 58–68.
</div>
<div id="ref-varian2010computer" class="csl-entry" role="listitem">
Varian, Hal R. 2010. <span>“Computer <span>Mediated Transactions</span>.”</span> <em>American Economic Review</em> 100 (2): 1–10.
</div>
<div id="ref-wojna2017attentionbased" class="csl-entry" role="listitem">
Wojna, Zbigniew, Alex Gorban, Dar-Shyang Lee, Kevin Murphy, Qian Yu, Yeqing Li, and Julian Ibarz. 2017. <span>“Attention-Based Extraction of Structured Information from Street View Imagery.”</span> <em>arXiv Preprint arXiv:1704.03549</em>. <a href="https://arxiv.org/abs/1704.03549">https://arxiv.org/abs/1704.03549</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Preface">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./01-prob.html" class="pagination-link" aria-label="Probability and Uncertainty">
        <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>