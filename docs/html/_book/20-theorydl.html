<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>20&nbsp; Theory of Deep Learning – Bayes, AI and Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./21-sgd.html" rel="next">
<link href="./19-nn.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-680e7c22d93ef26f016bec9199f8e6d8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head><body class="nav-sidebar docked quarto-light"><div class="hidden">
<p><span class="math display">\[
\newcommand{\prob}[1]{\operatorname{P}\left(#1\right)}
\newcommand{\Var}[1]{\operatorname{Var}\left(#1\right)}
\newcommand{\sd}[1]{\operatorname{sd}\left(#1\right)}
\newcommand{\Cor}[1]{\operatorname{Corr}\left(#1\right)}
\newcommand{\Cov}[1]{\operatorname{Cov}\left(#1\right)}
\newcommand{\E}[2][]{\operatorname{E}_{#1}\left[#2\right]}
\newcommand{\defeq}{\overset{\text{\tiny def}}{=}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\mini}{minimize}
\DeclareMathOperator*{\minf}{minimize \quad}
\newcommand{\mininlineeq}[4]{\begin{equation}\label{#4}\mbox{minimize}_{#1}\quad#2\qquad\mbox{subject to }#3\end{equation}}
\]</span></p>
</div>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>





<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./19-nn.html">Deep Learning</a></li><li class="breadcrumb-item"><a href="./20-theorydl.html"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Theory of Deep Learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayes, AI and Deep Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principles of Data Science</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-bl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-dec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-ab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">AB Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-hyp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-sp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-rl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Unreasonable Effectiveness of Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-pattern.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Pattern Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Tree Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-forecasting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Forecasting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Randomized Controlled Trials</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-select.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-theoryai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Theory of AI: From MLE to Bayesian Regularization</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-theorydl.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Theory of Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-sgd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-qnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Quantile Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-nlp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Natural Language Processing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Large Language Models: A Revolution in AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26-robots.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Robots and AI Agents</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#ridge-and-projection-pursuit-regression" id="toc-ridge-and-projection-pursuit-regression" class="nav-link active" data-scroll-target="#ridge-and-projection-pursuit-regression"><span class="header-section-number">20.1</span> Ridge and Projection Pursuit Regression</a></li>
  <li><a href="#space-partitioning" id="toc-space-partitioning" class="nav-link" data-scroll-target="#space-partitioning"><span class="header-section-number">20.2</span> Space Partitioning</a></li>
  <li><a href="#kolmogorov-superposition-theorem-kst" id="toc-kolmogorov-superposition-theorem-kst" class="nav-link" data-scroll-target="#kolmogorov-superposition-theorem-kst"><span class="header-section-number">20.3</span> Kolmogorov Superposition Theorem (KST)</a>
  <ul class="collapse">
  <li><a href="#kolmogorov-arnold-networks" id="toc-kolmogorov-arnold-networks" class="nav-link" data-scroll-target="#kolmogorov-arnold-networks">Kolmogorov-Arnold Networks</a></li>
  </ul></li>
  <li><a href="#kolmogorov-generalized-additive-models-k-gam" id="toc-kolmogorov-generalized-additive-models-k-gam" class="nav-link" data-scroll-target="#kolmogorov-generalized-additive-models-k-gam"><span class="header-section-number">20.4</span> Kolmogorov Generalized Additive Models (K-GAM)</a>
  <ul class="collapse">
  <li><a href="#kernel-smoothing-interpolation" id="toc-kernel-smoothing-interpolation" class="nav-link" data-scroll-target="#kernel-smoothing-interpolation">Kernel Smoothing: Interpolation</a></li>
  </ul></li>
  <li><a href="#transformers-as-kernel-smoothing" id="toc-transformers-as-kernel-smoothing" class="nav-link" data-scroll-target="#transformers-as-kernel-smoothing"><span class="header-section-number">20.5</span> Transformers as Kernel Smoothing</a>
  <ul class="collapse">
  <li><a href="#transformer" id="toc-transformer" class="nav-link" data-scroll-target="#transformer">Transformer</a></li>
  </ul></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application"><span class="header-section-number">20.6</span> Application</a>
  <ul class="collapse">
  <li><a href="#simulated-data" id="toc-simulated-data" class="nav-link" data-scroll-target="#simulated-data">Simulated Data</a></li>
  <li><a href="#training-rates" id="toc-training-rates" class="nav-link" data-scroll-target="#training-rates">Training Rates</a></li>
  </ul></li>
  <li><a href="#general-latent-feature-model" id="toc-general-latent-feature-model" class="nav-link" data-scroll-target="#general-latent-feature-model"><span class="header-section-number">20.7</span> General latent feature model</a></li>
  <li><a href="#deep-learning-expansions" id="toc-deep-learning-expansions" class="nav-link" data-scroll-target="#deep-learning-expansions"><span class="header-section-number">20.8</span> Deep Learning Expansions</a></li>
  <li><a href="#sec:dim-exp" id="toc-sec:dim-exp" class="nav-link" data-scroll-target="#sec\:dim-exp"><span class="header-section-number">20.9</span> Dimensionality Expansion</a></li>
  <li><a href="#sec:pca-pcr" id="toc-sec:pca-pcr" class="nav-link" data-scroll-target="#sec\:pca-pcr"><span class="header-section-number">20.10</span> Dimensionality Reduction: PCA, PCR and PLS</a></li>
  <li><a href="#uncertainty-quantification" id="toc-uncertainty-quantification" class="nav-link" data-scroll-target="#uncertainty-quantification"><span class="header-section-number">20.11</span> Uncertainty Quantification</a></li>
  <li><a href="#double-descent" id="toc-double-descent" class="nav-link" data-scroll-target="#double-descent"><span class="header-section-number">20.12</span> Double Descent</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./19-nn.html">Deep Learning</a></li><li class="breadcrumb-item"><a href="./20-theorydl.html"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Theory of Deep Learning</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Theory of Deep Learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This chapter explores the theoretical foundations of deep learning through the lens of multivariate function approximation, beginning with ridge functions as fundamental building blocks. Ridge functions, which take the form <span class="math inline">\(f(x) = g(w^Tx)\)</span>, represent one of the simplest forms of nonlinear multivariate functions by combining a single linear projection with a univariate nonlinear transformation. Their key geometric property—remaining constant along directions orthogonal to the projection vector <span class="math inline">\(w\)</span>—makes them particularly useful for high-dimensional approximation. The chapter then introduces projection pursuit regression, which approximates complex input-output relationships using linear combinations of ridge functions, demonstrating how these mathematical constructs provide the groundwork for modern deep learning approaches.</p>
<p>The chapter culminates with the Kolmogorov Superposition Theorem (KST), a profound result that shows any real-valued continuous function can be represented as a sum of compositions of single-variable functions. This theorem provides a theoretical framework for understanding how complex multivariate functions can be decomposed into simpler, more manageable components—a principle that underlies the architecture of modern neural networks. The discussion raises important questions about the trade-off between computational power and mathematical efficiency in machine learning, challenging whether superior performance can be achieved through mathematically elegant representations rather than brute-force computational approaches.</p>
<section id="ridge-and-projection-pursuit-regression" class="level2" data-number="20.1">
<h2 data-number="20.1" class="anchored" data-anchor-id="ridge-and-projection-pursuit-regression"><span class="header-section-number">20.1</span> Ridge and Projection Pursuit Regression</h2>
<p>To understand the significance of this trade-off, we consider ridge functions, which represent a fundamental building block in multivariate analysis. Since our ultimate goal is to model arbitrary multivariate functions <span class="math inline">\(f\)</span>, we need a way to reduce dimensionality while preserving the ability to capture nonlinear relationships. Ridge functions accomplish this by representing one of the simplest forms of nonlinear multivariate functions, requiring only a single linear projection and a univariate nonlinear transformation. Formally, a ridge function <span class="math inline">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> takes the form <span class="math inline">\(f(x) = g(w^Tx)\)</span>, where <span class="math inline">\(g\)</span> is a univariate function and <span class="math inline">\(x,w \in \mathbb{R}^n\)</span>. The non-zero vector <span class="math inline">\(w\)</span> is called the direction. The term “ridge” reflects a key geometric property: the function remains constant along any direction orthogonal to <span class="math inline">\(w\)</span>. Specifically, for any direction <span class="math inline">\(u\)</span> such that <span class="math inline">\(w^Tu = 0\)</span>, we have</p>
<p><span class="math display">\[
f(x+u) = g(w^T(x+u)) = g(w^Tx) = f(x)
\]</span></p>
<p>This structural simplicity makes ridge functions particularly useful as building blocks for high-dimensional approximation.</p>
<p>Ridge functions play a central role in high-dimensional statistical analysis. For example, projection pursuit regression approximates input-output relations using a linear combination of ridge functions <span class="citation" data-cites="friedman1981projection">Friedman and Stuetzle (<a href="references.html#ref-friedman1981projection" role="doc-biblioref">1981</a>)</span>,huber1985proje:</p>
<p><span class="math display">\[
\phi(x) = \sum_{i=1}^{p}g_i(w_i^Tx),
\]</span></p>
<p>where both the directions <span class="math inline">\(w_i\)</span> and functions <span class="math inline">\(g_i\)</span> are variables and <span class="math inline">\(w_i^Tx\)</span> are one-dimensional projections of the input vector. The vector <span class="math inline">\(w_i^Tx\)</span> is a projection of the input vector <span class="math inline">\(x\)</span> onto a one-dimensional space and <span class="math inline">\(g_i(w_i^Tx)\)</span> can be though as a feature calculated from data. <span class="citation" data-cites="diaconis1984nonlinear">Diaconis and Shahshahani (<a href="references.html#ref-diaconis1984nonlinear" role="doc-biblioref">1984</a>)</span> use nonlinear functions of linear combinations, laying important groundwork for deep learning.</p>
<p>The landscape of modern machine learning has been shaped by the exponential growth in computational power, particularly through advances in GPU technology and frameworks like PyTorch. While Moore’s Law has continued to drive hardware improvements and CUDA algorithms have revolutionized our ability to process vast amounts of internet data, we pose the following question: can we achieve superior performance through mathematically efficient representations of multivariate functions rather than raw computational power?</p>
<p>A fundamental challenge in machine learning lies in effectively handling high-dimensional input-output relationships. This challenge manifests itself in two distinct but related tasks. First, one task is to construct a “look-up” table (dictionary) for fast search and retrieval of input-output examples. This is an encoding and can be thought of as a data compression problem. Second, and perhaps more importantly, we must develop prediction rules that can generalize beyond these examples to handle arbitrary inputs.</p>
<p>More formally, we seek to find a good predictor function <span class="math inline">\(f(x)\)</span> that maps an input <span class="math inline">\(x\)</span> to its output prediction <span class="math inline">\(y\)</span>. In practice, the input <span class="math inline">\(x\)</span> is typically a high-dimensional vector:</p>
<p><span class="math display">\[
y = f ( x )  \; \; {\rm where}  \; \; x =  ( x_1 , \ldots , x_d )
\]</span></p>
<p>Given a training dataset <span class="math inline">\((y_i,x_i)_{i=1}^N\)</span> of example input-output pairs, our goal is to train a model, i.e.&nbsp;to find the function <span class="math inline">\(f\)</span>. The key question is: <em>how do we represent a multivariate function so as to obtain a desirable <span class="math inline">\(f\)</span>?</em></p>
</section>
<section id="space-partitioning" class="level2" data-number="20.2">
<h2 data-number="20.2" class="anchored" data-anchor-id="space-partitioning"><span class="header-section-number">20.2</span> Space Partitioning</h2>
<p>The partitioning of the input space by a deep learner is similar to the one performed by decision trees and partition-based models such as CART, MARS, RandomForests, BART. However, trees are more local in the regions that they use to construct their estimators within a region. Each neuron in deep learning model corresponds to a manifold that divides the input space. In case of ReLU activation function <span class="math inline">\(f(x) = \max(0,x)\)</span> the manifold is simply a hyperplane and neuron gets activated when the new observation is on the “right” side of this hyperplane, the activation amount is equal to how far from the boundary the given point is. For example in two dimensions, three neurons with ReLU activation functions will divide the space into seven regions, as shown on Figure <a href="#fig-hyper-planes" class="quarto-xref">Figure&nbsp;<span>20.1</span></a>.</p>
<div id="fig-hyper-planes" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hyper-planes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="fig/hyperplane.svg" id="fig-hyper-planes" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-hyper-planes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.1
</figcaption>
</figure>
</div>
<p>The key difference then between tree-based architecture and neural network based models is the way hyper-planes are combined. Figure <a href="#fig-tree-dl-comp" class="quarto-xref">Figure&nbsp;<span>20.2</span></a> shows the comparison of space decomposition by hyperplanes as performed by a tree-based and neural network architectures. We compare a neural network with two layers (bottom row) with tree model trained with CART algorithm (top row). The network architecture used is:</p>
<p><span class="math display">\[
Y =  \mathrm{softmax}(w^0Z^2 + b^0)\\
Z^2 =  \tanh(w^2Z^1 + b^2)\\
Z^1 =  \tanh(w^1X + b^1)
\]</span></p>
<p>The weight matrices for simple data <span class="math inline">\(W^1, W^2 \in \mathbb{R}^{2 \times 2}\)</span>, for circle data <span class="math inline">\(W^1 \in \mathbb{R}^{2 \times 2}\)</span> and <span class="math inline">\(W^2 \in \mathbb{R}^{3 \times 2}\)</span>, for spiral data we have <span class="math inline">\(W^1 \in \mathbb{R}^{2 \times 2}\)</span> and <span class="math inline">\(W^2 \in \mathbb{R}^{4 \times 2}\)</span>. In our notations, we assume that the activation function is applied pointwise at each layer. An advantage of deep architectures is that the number of hyper-planes grow exponentially with the number of layers. The key property of an activation function (link) is <span class="math inline">\(f(0) = 0\)</span> and it has zero value in certain regions. For example, hinge or rectified learner <span class="math inline">\(\max(x,0)\)</span>, box car (differences in Heaviside) functions are very common. As compared to a logistic regression, rather than using <span class="math inline">\(\mathrm{softmax}(1/(1+e^{-x}))\)</span> in deep learning <span class="math inline">\(\tanh\)</span> is typically used for training.</p>
<div id="fig-tree-dl-comp" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tree-dl-comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="fig/simple_data_tree.svg" class="img-fluid figure-img"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="fig/spiral_data_tree.svg" class="img-fluid figure-img"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="fig/circle_data_tree.svg" class="img-fluid figure-img"></p>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="fig/simple_data_dl.png" class="img-fluid figure-img"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="fig/circle_data_dl.png" class="img-fluid figure-img"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="fig/spiral_data_dl.png" class="img-fluid figure-img"></p>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tree-dl-comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.2: Space partition by tree architectures (top row) and deep learning architectures (bottom row) for three different data sets.
</figcaption>
</figure>
</div>
<p>Formally, a Bayesian probabilistic approach (if computationally feasible) knows how to optimally weight predictors via a model averaging approach: <span class="math display">\[
\hat{Y}(X) = \sum_{r=1}^R w_k \hat{Y}_k(X)
\]</span></p>
<p>where <span class="math inline">\(\hat{Y}_k(x) = E(Y \mid X_k)\)</span>. Such rules can achieve great out-of-sample performance. <span class="citation" data-cites="amit2000multiple">Amit, Blanchard, and Wilder (<a href="references.html#ref-amit2000multiple" role="doc-biblioref">2000</a>)</span> discuss the striking success of multiple randomized classifiers. Using a simple set of binary local features, one classification tree can achieve 5% error on the NIST data base with 100,000 training data points. On the other hand 100 trees, trained under one hour, when aggregated yield an error rate under 7%. We believe that this stems from the fact that a sample from a very rich and diverse set of classifiers produces on average weakly dependent classifiers conditional on class. A Bayesian model of weak dependence is exchangeability.</p>
</section>
<section id="kolmogorov-superposition-theorem-kst" class="level2" data-number="20.3">
<h2 data-number="20.3" class="anchored" data-anchor-id="kolmogorov-superposition-theorem-kst"><span class="header-section-number">20.3</span> Kolmogorov Superposition Theorem (KST)</h2>
<p>Kolmogorov demonstrated that any real-valued continuous function <span class="math inline">\(f(\mathbf{x})\)</span> defined on <span class="math inline">\(E^n\)</span> can be represented as a convolution of two single variable functions:</p>
<p><span class="math display">\[
f(x_1,\ldots,x_n) = \sum_{q=1}^{2n+1} g_q\left(\phi_q(x_1,\ldots,x_n)\right)
\]</span></p>
<p>where <span class="math inline">\(g_q\)</span> are continuous single-variable functions defined on <span class="math inline">\(\phi_q(E^n)\)</span>. Kolmogorov further showed that the <span class="math inline">\(\phi_q\)</span> functions can be decomposed into sums of single-variable functions:</p>
<p><span class="math display">\[
\phi_q(x_1,\ldots,x_n) = \sum_{i=1}^n \psi_{q,i}(x_i)
\]</span></p>
<p>This result is known as Kolmogorov representation theorem <span class="citation" data-cites="kolmogorov1956representation">Kolmogorov (<a href="references.html#ref-kolmogorov1956representation" role="doc-biblioref">1956</a>)</span> and is often written in the following form:</p>
<p><span class="math display">\[
f(x_1,\ldots,x_n) = \sum_{q=1}^{2n+1} g_q\left(\sum_{i=1}^n \psi_{q,i}(x_i)\right)
\]</span></p>
<p>The theorem has seen several refinements over time, the inner functions could be Hölder continuous and Lipschitz continuous, though this required modifications to both the outer and inner functions.</p>
<p>The inner functions <span class="math inline">\(\Psi_q\)</span> partition the input space into distinct regions, and the outer function, <span class="math inline">\(g\)</span>, must be constructed to provide the correct output values across the regions that the inner function defines. The outer function, <span class="math inline">\(g\)</span>, can be determined via a computationally intensive process of averaging. For each input configuration, the inner functions <span class="math inline">\(\Psi_q\)</span> generate a unique encoding, and <span class="math inline">\(g\)</span> must map this encoding to the appropriate value of <span class="math inline">\(f(x)\)</span>. This creates a dictionary-like structure that associates each region with its corresponding output value. Köppen made significant contributions by correcting Sprecher’s original proof of this construction process, with improvements to the computational algorithm later suggested by <span class="citation" data-cites="actor2018computation">Actor (<a href="references.html#ref-actor2018computation" role="doc-biblioref">2018</a>)</span> and <span class="citation" data-cites="demb2021note">Demb and Sprecher (<a href="references.html#ref-demb2021note" role="doc-biblioref">2021</a>)</span>. Braun further enhanced the understanding by providing precise definitions of the shift parameters <span class="math inline">\(\delta_k\)</span> and characterizing the topological structure induced by <span class="math inline">\(\Psi_q\)</span>.</p>
<p>A fundamental trade-off in KST exists between function smoothness and dimensionality. The inner functions <span class="math inline">\(\psi_{p,q}\)</span> can be chosen from two different function spaces, each offering distinct advantages. The first option is to use functions from <span class="math inline">\(C^1([0,1])\)</span>, but this limits the network’s ability to handle higher dimensions effectively. The second option is to relax the smoothness requirement to Hölder continuous functions (<span class="math inline">\(\psi_{p,q} \in \text{Holder}_\alpha([0,1])\)</span>), which satisfy the inequality <span class="math inline">\(|\psi(x) - \psi(y)| &lt; |x-y|^\alpha\)</span>. These functions are less smooth, but this “roughness” enables better approximation in higher dimensions.</p>
<section id="kolmogorov-arnold-networks" class="level3">
<h3 class="anchored" data-anchor-id="kolmogorov-arnold-networks">Kolmogorov-Arnold Networks</h3>
<p>A significant development has been the emergence of Kolmogorov-Arnold Networks (KANs). The key innovation of KANs is their use of learnable functions rather than weights on the network edges. This replaces traditional linear weights with univariate functions, typically parametrized by splines, enhancing both representational capacity and interpretability.</p>
<p>There is a practical connection between KST and neural networks by showing that any KAN can be constructed as a 3-layer MLP. Consider a KST in the form of sums of functions, a two layer model:</p>
<p><span class="math display">\[
f( x_1 , \ldots , x_d ) = f( x) = ( g \circ \psi ) (x )
\]</span></p>
<p>Then KAN not only a superposition of functions but also a particular case of a tree of discrete Urysohn operators:</p>
<p><span class="math display">\[
U(x_1 , \ldots , x_d ) = \sum_{j=1}^d g_j (x_j )
\]</span></p>
<p>This insight leads to a fast scalable algorithm that avoids back-propagation, applicable to any GAM model, using a projection descent method with a Newton-Kacmarz scheme.</p>
</section>
</section>
<section id="kolmogorov-generalized-additive-models-k-gam" class="level2" data-number="20.4">
<h2 data-number="20.4" class="anchored" data-anchor-id="kolmogorov-generalized-additive-models-k-gam"><span class="header-section-number">20.4</span> Kolmogorov Generalized Additive Models (K-GAM)</h2>
<p>Rather than using learnable functions as network nodes activations, Polson Sokolov directly use KST representation. This is a 2-layer network with a non-differentiable inner function. The network’s architecture can be expressed as:</p>
<p><span class="math display">\[
f(x_1,\ldots,x_d) = \sum_{q=0}^{2d} g_q(z_q)
\]</span></p>
<p>where the inner layer performs an embedding from <span class="math inline">\([0,1]^d\)</span> to <span class="math inline">\(\mathbb{R}^{2d+1}\)</span> via:</p>
<p><span class="math display">\[
z_q = \eta_q ( x_1 , \ldots , x_d ) = \sum_{p=1}^ d \lambda_p \psi  ( x_p + q a )
\]</span></p>
<p>Here, <span class="math inline">\(\lambda_p = \sum_{r=1}^\infty \gamma^{-(p-1)\beta(r)}\)</span> is a <span class="math inline">\(p\)</span>-adic expansion with <span class="math inline">\(\beta(r) = (n^r-1)/(n-1)\)</span> and <span class="math inline">\(\gamma \geq d+2\)</span> with <span class="math inline">\(a = (\gamma(\gamma-1))^{-1}\)</span>.</p>
<p>The Köppen function <span class="math inline">\(\psi\)</span> is defined through a recursive limit:</p>
<p><span class="math display">\[
\psi(x) = \lim_{k \rightarrow \infty} \psi_k\left(\sum_{l=1}^{k}i_l\gamma^{-l}\right)
\]</span></p>
<p>where each <span class="math inline">\(x \in [0,1]\)</span> has the representation:</p>
<p><span class="math display">\[
x = \sum_{l=1}^{\infty}i_l\gamma^{-l} = \lim_{k \rightarrow \infty} \left(\sum_{l=1}^{k}i_l\gamma^{-l}\right)
\]</span></p>
<p>and <span class="math inline">\(\psi_k\)</span> is defined recursively as:</p>
<p><span class="math display">\[
\psi_k =
\begin{cases}
    d, &amp; d \in D_1\\
    \psi_{k-1}(d-i_k\gamma^{-k}) + i_k\gamma^{-\beta_n(k)}, &amp; d \in D_k,k&gt;1,i_k&lt;\gamma-1\\
    \frac{1}{2}\left(\psi_k(d-\gamma^{-k}) + \psi_{k-1}(d+\gamma^{-k})\right), &amp; d \in D_k, k&gt;1, i_k = \gamma - 1
\end{cases}
\]</span></p>
<p>The most striking aspect of KST is that it leads to a Generalized Additive Model (GAM) with fixed features that are independent of the target function <span class="math inline">\(f\)</span>. These features, determined by the Köppen function, provide universal topological information about the input space, effectively implementing a k-nearest neighbors structure that is inherent to the representation.</p>
<p>This leads to the following architecture. Any deep learner can be represented as a GAM with feature engineering (topological information) given by features <span class="math inline">\(z_k\)</span> in the hidden layer:</p>
<p><span class="math display">\[
\begin{align*}
y_i &amp;= \sum_{k=1}^{2n+1} g(z_k)\\
z_k &amp;= \sum_{j=1}^n \lambda^k\psi(x_j + \epsilon k) + k
\end{align*}
\]</span></p>
<p>where <span class="math inline">\(\psi\)</span> is a single activation function common to all nodes, and <span class="math inline">\(g\)</span> is a single outer function.</p>
<p>One approach is to replace each <span class="math inline">\(\phi_j\)</span> with a single ReLU network <span class="math inline">\(g\)</span>:</p>
<p><span class="math display">\[
g(x) = \sum_{k=1}^K \beta_k\text{ReLU}(w_kx + b_k)
\]</span></p>
<p>where <span class="math inline">\(K\)</span> is the number of neurons.</p>
<section id="kernel-smoothing-interpolation" class="level3">
<h3 class="anchored" data-anchor-id="kernel-smoothing-interpolation">Kernel Smoothing: Interpolation</h3>
<p>The theory of kernel methods was developed by Fredholm in the context of integral equations <span class="citation" data-cites="fredholm1903classe">Fredholm (<a href="references.html#ref-fredholm1903classe" role="doc-biblioref">1903</a>)</span>. The idea is to represent a function as a linear combination of basis functions, which are called kernels.</p>
<p><span class="math display">\[
f(x) = \int_{a}^{b} K(x,x')  d \mu (x') dx'  \; \; {\rm where} \; \; x = ( x_1 , \ldots , x_d )
\]</span></p>
<p>Here, the unknown function <span class="math inline">\(f(x)\)</span> is represented as a linear combination of kernels <span class="math inline">\(K(x,x')\)</span> with unknown coefficients <span class="math inline">\(\phi(x')\)</span>. The kernels are known, and the coefficients are unknown. The coefficients are found by solving the integral equation. The first work in this area was done by Abel who considered equations of the form above.</p>
<p>Nowadays, we call those equations Volterra integral equations of the first kind. Integral equations typically arise in inverse problems. Their significance extends beyond their historical origins, as kernel methods have become instrumental in addressing one of the fundamental challenges in modern mathematics: the curse of dimensionality.</p>
<p>Bartlett <span class="citation" data-cites="nadaraya1964estimating">Nadaraya (<a href="references.html#ref-nadaraya1964estimating" role="doc-biblioref">1964</a>)</span> and <span class="citation" data-cites="watson1964smooth">Watson (<a href="references.html#ref-watson1964smooth" role="doc-biblioref">1964</a>)</span> proposed the use of kernels to estimate the regression function. The idea is to estimate the regression function <span class="math inline">\(f(x)\)</span> at point <span class="math inline">\(x\)</span> by averaging the values of the response variable <span class="math inline">\(y_i\)</span> at points <span class="math inline">\(x_i\)</span> that are close to <span class="math inline">\(x\)</span>. The kernel is used to define the weights.</p>
<p>The regression function is estimated as follows:</p>
<p><span class="math display">\[
\hat{f}(x) = \sum_{i=1}^n  y_i K(x,x_i)/ \sum_{i=1}^n K(x,x_i) ,
\]</span></p>
<p>where the kernel weights are normalized.</p>
<p>Both Nadaraya and Watson considered the symmetric kernel <span class="math inline">\(K(x,x') = K(\|x'-x\|_2)\)</span>, where <span class="math inline">\(||\cdot||_2\)</span> is the Euclidean norm. The most popular kernel of that sort is the Gaussian kernel:</p>
<p><span class="math display">\[
K(x,x') = \exp\left( -\dfrac{\|x-x'\|_2^2}{2\sigma^2}\right).
\]</span></p>
<p>Alternatively, the 2-norm can be replaced by the inner-product: <span class="math inline">\(K(x,x')  =  \exp\left( x^Tx'/2\sigma^2\right)\)</span>.</p>
<p>Kernel methods are supported by numerous generalization bounds which often take the form of inequalities that describe the performance limits of kernel-based estimators. A particularly important example is the Bayes risk for <span class="math inline">\(k\)</span>-nearest neighbors (<span class="math inline">\(k\)</span>-NN), which can be expressed in a kernel framework as:</p>
<p><span class="math display">\[
\hat{f} ( x) =  \sum_{i=1}^N w_i y_i        \; {\rm where} \; w_i := K( x_i , x ) /  \sum_{i=1}^N K( x_i ,x )   
\]</span></p>
<p><span class="math inline">\(k\)</span>-NN classifiers have been proven to converge to an error rate that is bounded in relation to the Bayes error rate, with the exact relationship depending on the number of classes. For binary classification, the asymptotic error rate of <span class="math inline">\(k\)</span>-NN is at most <span class="math inline">\(2R^*(1-R^*)\)</span>, where <span class="math inline">\(R^*\)</span> is the Bayes error rate. This theoretical bound suggests potential for improvement in practice. Cover and Hart proved that interpolated k-NN schemes are consistent estimators, meaning that their performance improves with increasing sample size.</p>
</section>
</section>
<section id="transformers-as-kernel-smoothing" class="level2" data-number="20.5">
<h2 data-number="20.5" class="anchored" data-anchor-id="transformers-as-kernel-smoothing"><span class="header-section-number">20.5</span> Transformers as Kernel Smoothing</h2>
<p><span class="citation" data-cites="bahdanau2014neural">Bahdanau, Cho, and Bengio (<a href="references.html#ref-bahdanau2014neural" role="doc-biblioref">2014</a>)</span> proposed using kernel smoothing for sequence-to-sequence learning. This approach estimates the probability of the next word in the sequence using a so-called context vector, which is a weighted average of the vectors from the input sequence <span class="math inline">\(h_j\)</span>:</p>
<p><span class="math display">\[
c_i = \sum_{j=1}^n \alpha_{ij} h_j,
\]</span></p>
<p>where <span class="math inline">\(\alpha_{ij}\)</span> are the weights. The weights are defined by the kernel function:</p>
<p><span class="math display">\[
\alpha_{ij} = \dfrac{\exp\left( e_{ij}\right)}{\sum_{k=1}^n \exp\left( e_{ik}\right)}.
\]</span></p>
<p>Instead of using a traditional similarity measure like the 2-norm or inner product, the authors used a neural network to define the energy function <span class="math inline">\(e_{ij} = a(s_{i-1},h_j)\)</span>. This neural network measures the similarity between the last generated element of the output sequence <span class="math inline">\(s_{i-1}\)</span> and <span class="math inline">\(j\)</span>-th element of the input sequence <span class="math inline">\(h_j\)</span>. The resulting context vector is then used to predict the next word in the sequence.</p>
<section id="transformer" class="level3">
<h3 class="anchored" data-anchor-id="transformer">Transformer</h3>
<p>Transformers have since become a main building block for various natural language processing (NLP) tasks and has been extended to other domains as well due to their effectiveness. The transformer architecture is primarily designed to handle sequential data, making it well-suited for tasks such as machine translation, language modeling, text generation, and more. It achieves state-of-the-art performance by leveraging a novel attention mechanism.</p>
<p>The idea to use kernel smoothing for sequence to sequence was called “attention”, or cross-attention, by <span class="citation" data-cites="bahdanau2014neural">Bahdanau, Cho, and Bengio (<a href="references.html#ref-bahdanau2014neural" role="doc-biblioref">2014</a>)</span>. When used for self-supervised learning, it is called self-attention. When a sequence is mapped to a matrix <span class="math inline">\(M\)</span>, it is called multi-head attention. The concept of self-attention and attention for natural language processing was further developed by <span class="citation" data-cites="vaswani2023attention">Vaswani et al. (<a href="references.html#ref-vaswani2023attention" role="doc-biblioref">2023</a>)</span> who developed a smoothing method that they called the transformer.</p>
<p>The transformer architecture revolves around a series of mathematical concepts and operations:</p>
<ul>
<li><strong>Embeddings</strong>: The input text is converted into vectors using embeddings. Each word (or token) is represented by a unique vector in a high-dimensional space.</li>
<li><strong>Positional Encoding</strong>: Since transformers do not have a sense of sequence order (like RNNs do), positional encodings are added to the embeddings to provide information about the position of each word in the sequence.</li>
<li><strong>Multi-Head Attention</strong>: The core of the transformer model. It enables the model to focus on different parts of the input sequence simultaneously. The attention mechanism is defined as: <span class="math display">\[ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V \]</span> where <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(V\)</span> are query, key, and value matrices respectively.</li>
<li><strong>Query (Q), Key (K), and Value (V) Vectors</strong>: These are derived from the input embeddings. They represent different aspects of the input.</li>
<li><strong>Scaled Dot-Product Attention</strong>: The attention mechanism calculates the dot product of the Query with all Keys, scales these values, and then applies a softmax function to determine the weights of the Values.</li>
<li><strong>Multiple ‘Heads’</strong>: The model does this in parallel multiple times (multi-head), allowing it to capture different features from different representation subspaces.</li>
<li><strong>Layer Normalization and Residual Connections</strong>: After each sub-layer in the encoder and decoder (like multi-head attention or the feed-forward layers), the transformer applies layer normalization and adds the output of the sub-layer to its input (residual connection). This helps in stabilizing the training of deep networks.</li>
<li><strong>Feed-Forward Neural Networks</strong>: Each layer in the transformer contains a fully connected feed-forward network applied to each position separately and identically. It is defined as: <span class="math display">\[ \text{FFN}(x) = \max(0, xW_1 + b_1)W_2 + b_2 \]</span> where <span class="math inline">\(W_1\)</span>, <span class="math inline">\(W_2\)</span>, <span class="math inline">\(b_1\)</span>, and <span class="math inline">\(b_2\)</span> are learnable parameters.</li>
<li><strong>Output Linear Layer and Softmax</strong>: The decoder’s final output passes through a linear layer followed by a softmax layer. This layer converts the decoder output into predicted next-token probabilities.</li>
<li><strong>Training and Loss Function</strong>: Transformers are often trained using a variant of Cross-Entropy Loss to compare the predicted output with the actual output.</li>
<li><strong>Masking</strong>: In the decoder, to prevent future tokens from being used in the prediction, a technique called ‘masking’ is applied.</li>
<li><strong>Backpropagation and Optimization</strong>: The model’s parameters are adjusted through backpropagation and optimization algorithms like Adam.</li>
</ul>
<p>Later, <span class="citation" data-cites="lin2017structured">Lin et al. (<a href="references.html#ref-lin2017structured" role="doc-biblioref">2017</a>)</span> proposed using similar idea for self-supervised learning, where a sequence of words (sentence) is mapped to a single matrix:</p>
<p><span class="math display">\[
M = AH,
\]</span></p>
<p>where <span class="math inline">\(H\)</span> is the matrix representing an input sequence <span class="math inline">\(H = (h_1,\ldots,h_n)\)</span> and <span class="math inline">\(A\)</span> is the matrix of weights:</p>
<p><span class="math display">\[
A = \mathrm{softmax}\left(W_2\tanh\left(W_1H^T\right)\right).
\]</span></p>
<p>This allows to represent a sequence of words of any length <span class="math inline">\(n\)</span> using a “fixed size” <span class="math inline">\(r\times u\)</span> matrix <span class="math inline">\(M\)</span>, where <span class="math inline">\(u\)</span> is the dimension of a vector that represents an element of a sequence (word embedding) and <span class="math inline">\(r\)</span> is the hyper-parameter that defines the size of the matrix <span class="math inline">\(M\)</span>.</p>
<p>The main advantage of using smoothing techniques (transformers) is that they are parallelizable. Current language models such as BERT, GPT, and T5 rely on this approach. Further, they also has been applied to computer vision and other domains. Its ability to capture long-range dependencies and its scalability have made it a powerful tool for a wide range of applications. See <span class="citation" data-cites="tsai2019transformer">Tsai et al. (<a href="references.html#ref-tsai2019transformer" role="doc-biblioref">2019</a>)</span> et al for further details.</p>
</section>
</section>
<section id="application" class="level2" data-number="20.6">
<h2 data-number="20.6" class="anchored" data-anchor-id="application"><span class="header-section-number">20.6</span> Application</h2>
<section id="simulated-data" class="level3">
<h3 class="anchored" data-anchor-id="simulated-data">Simulated Data</h3>
<p>We also apply the K-GAM architecture to a simulated dataset to evaluate its performance on data with known structure and relationships. The dataset contains 100 observations generated from the following function:</p>
<p><span class="math display">\[
\begin{align*}
    &amp;y = \mu(x) + \epsilon, \quad \epsilon \sim \mathcal{N}(0,1)\\
         &amp;\mu(x) = 10\sin(\pi x_1 x_2) + 20(x_3-0.5)^2 + 10x_4 + 5x_5.
\end{align*}
\]</span></p>
<p>The goal is to predict the function <span class="math inline">\(y(x)\)</span> based on the input <span class="math inline">\(x\)</span>. The dataset is often used as a benchmark dataset for regression algorithms due to its diverse mix of relationships (linear, quadratic, nonlinear, Gaussian random noise) between the input features and the target function.</p>
<p>We use the Köppen function to transform the five-dimensional input into a set of 11 features (<span class="math inline">\(2d+1\)</span>). We then learn the outer function <span class="math inline">\(g\)</span> using a ReLU network. To thoroughly investigate the model’s capabilities, we implement two distinct approaches to learning the outer function. The first approach uses different <span class="math inline">\(g\)</span> functions for each feature, following the original KST formulation. This allows each function to specialize in capturing specific patterns, but might be more difficult to train and has more parameters. The second approach uses a single <span class="math inline">\(g\)</span> function for all features, as proposed by <span class="citation" data-cites="lorentz197613th">Lorentz (<a href="references.html#ref-lorentz197613th" role="doc-biblioref">1976</a>)</span>, providing a more unified and parameter-efficient representation.</p>
<p>For the first model with multiple <span class="math inline">\(g_i\)</span> functions, the dimensions of each <span class="math inline">\(g_i\)</span> are as follows: <span class="math inline">\(W^0_i \in \mathbb{R}^{16\times 1}\)</span> and for <span class="math inline">\(j=1,\ldots,18\)</span>, <span class="math inline">\(W^j_i \in \mathbb{R}^{16\times 16}\)</span>.</p>
<p>The next architecture, which used only one function <span class="math inline">\(g\)</span> for all features, maintains a similar structure to the multiple <span class="math inline">\(g\)</span> functions approach. The only difference is in the dimensionality of the inner layers: we increased the width from 16 to 200. This increased capacity allows the single function to learn more complex patterns and compensate for the constraint of using just one function instead of multiple specialized ones.</p>
</section>
<section id="training-rates" class="level3">
<h3 class="anchored" data-anchor-id="training-rates">Training Rates</h3>
<p>Consider the non-parametric condition regression, <span class="math inline">\(y_i= f (x_i) + \epsilon_i\)</span> where <span class="math inline">\(x_i = ( x_{1i} , \ldots , x_{di} )\)</span>. We wish to estimate <span class="math inline">\(f( x_1 , \ldots , x_d )\)</span> where <span class="math inline">\(x  = ( x_1 , \ldots , x_d ) \in [0,1]^d\)</span>. From a classical risk perspective, define</p>
<p><span class="math display">\[
R ( f , \hat{f}_N ) = E_{X,Y} \left ( \lVert  f - \hat{f}_N \rVert^2 \right )
\]</span></p>
<p>where <span class="math inline">\(\lVert . \rVert\)</span> denotes <span class="math inline">\(L^2 ( P_X)\)</span>-norm.</p>
<p>Under standard assumptions, we have an optimal minimax rate <span class="math inline">\(\inf_{\hat{f}} \sup_f R( f , \hat{f}_N )\)</span> of <span class="math inline">\(O_p \left ( N^{- 2 \beta /( 2 \beta + d )} \right )\)</span> for <span class="math inline">\(\beta\)</span>-Hölder smooth functions <span class="math inline">\(f\)</span>. This rate still depends on the dimension <span class="math inline">\(d\)</span>, which can be problematic in high-dimensional settings. By restricting the class of functions, better rates can be obtained, including ones that do not depend on <span class="math inline">\(d\)</span>. In this sense, we avoid the curse of dimensionality. Common approaches include considering the class of linear superpositions (a.k.a. ridge functions) and projection pursuit models.</p>
<p>Another asymptotic result comes from a posterior concentration property. Here, <span class="math inline">\(\hat{f}_N\)</span> is constructed as a regularized MAP (maximum a posteriori) estimator, which solves the optimization problem</p>
<p><span class="math display">\[
\hat{f}_N = \arg \min_{ \hat{f}_N } \frac{1}{N} \sum_{i=1}^N ( y_i - \hat{f}_N ( x_i )^2 + \phi ( \hat{f}_N )
\]</span></p>
<p>where <span class="math inline">\(\phi(\hat{f})\)</span> is a regularization term. Under appropriate conditions, the ensuing posterior distribution <span class="math inline">\(\Pi(f | x, y)\)</span> can be shown to concentrate around the true function at the minimax rate (up to a <span class="math inline">\(\log N\)</span> factor).</p>
<p>A key result in the deep learning literature provides convergence rates for deep neural networks. Given a training dataset of input-output pairs <span class="math inline">\(( x_i , y_i)_{i=1}^N\)</span> from the model <span class="math inline">\(y = f(x) + \epsilon\)</span> where <span class="math inline">\(f\)</span> is a deep learner (i.e.&nbsp;superposition of functions</p>
<p><span class="math display">\[
f = g_L \circ \ldots g_1 \circ g_0
\]</span></p>
<p>where each <span class="math inline">\(g_i\)</span> is a <span class="math inline">\(\beta_i\)</span>-smooth Hölder function with <span class="math inline">\(d_i\)</span> variables, that is <span class="math inline">\(| g_i (x) -g_i (y) &lt; | x-y |^\beta\)</span>.</p>
<p>Then, the estimator has optimal rate:</p>
<p><span class="math display">\[
O \left ( \max_{1\leq i \leq L } N^{- 2 \beta^* /( 2 \beta^* + d_i ) } \right )  \; {\rm where} \; \beta_i^* = \beta_i \prod_{l = i+1}^L \min ( \beta_l , 1 )
\]</span></p>
<p>This result can be applied to various function classes, including generalized additive models of the form</p>
<p><span class="math display">\[
f_0 ( x ) = h \left ( \sum_{p=1}^d f_{0,p} (x_p) \right )
\]</span></p>
<p>where <span class="math inline">\(g_0(z) = h(z)\)</span>, <span class="math inline">\(g_1 ( x_1 , \ldots , x_d ) = ( f_{01}(x_1) , \ldots , f_{0d} (x_d) )\)</span> and <span class="math inline">\(g_2 ( y_1 , \ldots , y_d ) = \sum_{i=1}^d y_i\)</span>. In this case, <span class="math inline">\(d_1 = d_2 = 1\)</span>, and assuming <span class="math inline">\(h\)</span> is Lipschitz, we get an optimal rate of <span class="math inline">\(O(N^{-1/3})\)</span>, which is independent of <span class="math inline">\(d\)</span>.</p>
<p><span class="citation" data-cites="schmidt-hieber2021kolmogorov">Schmidt-Hieber (<a href="references.html#ref-schmidt-hieber2021kolmogorov" role="doc-biblioref">2021</a>)</span> show that deep ReLU networks also have optimal rate of <span class="math inline">\(O( N^{-1/3} )\)</span> for certain function classes. For <span class="math inline">\(3\)</span>-times differentiable (e.g.&nbsp;cubic B-splines ), <span class="citation" data-cites="coppejans2004kolmogorovs">Coppejans (<a href="references.html#ref-coppejans2004kolmogorovs" role="doc-biblioref">2004</a>)</span> finds a rate of <span class="math inline">\(O( N^{-3/7} ) = O( N^{-3/(2 \times 3 + 1) } )\)</span>. <span class="citation" data-cites="igelnik2003kolmogorovs">Igelnik and Parikh (<a href="references.html#ref-igelnik2003kolmogorovs" role="doc-biblioref">2003</a>)</span> finds a rate <span class="math inline">\(O( N^{-1} )\)</span> for Kolmogorov Spline Networks.</p>
<p>Finally, it’s worth noting the relationship between expected risk and empirical risk. The expected risk, <span class="math inline">\(R\)</span>, is typically bounded by the empirical risk plus a term of order <span class="math inline">\(1/\sqrt{N}\)</span>:</p>
<p><span class="math display">\[
R(y, f^\star) \leq \frac{1}{N} \sum_{i=1}^N R(y_i, f^\star(x_i)) + O\left(\frac{\|f\|}{\sqrt{N}}\right)
\]</span></p>
<p>where <span class="math inline">\(f^\star\)</span> is the minimizer of the expected risk. However, in the case of interpolation, where the model perfectly fits the training data, the empirical risk term becomes zero, leaving only the <span class="math inline">\(O(1/\sqrt{N})\)</span> term.</p>
</section>
</section>
<section id="general-latent-feature-model" class="level2" data-number="20.7">
<h2 data-number="20.7" class="anchored" data-anchor-id="general-latent-feature-model"><span class="header-section-number">20.7</span> General latent feature model</h2>
<p>Given a training data-set of input-output pairs <span class="math inline">\((\mathbf{X}_i , \mathbf{Y}_i )_{i=1}^N\)</span>, the goal is to find a prediction rule for a new output <span class="math inline">\(\mathbf{Y}_*\)</span> given a new input <span class="math inline">\(\mathbf{X}_*\)</span>. Let <span class="math inline">\(\mathbf{Z}\)</span> denote latent hidden features that are to be hand-coded or learned from the data and our nonlinear latent feature predictive model takes the form:</p>
<p><span class="math display">\[
\begin{align}
\mathbf{Y}\mid \mathbf{Z} &amp; \sim p(\mathbf{Y} \mid \mathbf{Z} ) \label{eq:bry}\\
\mathbf{Z} &amp;=\phi(\mathbf{X}) \label{eq:brf}
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\phi(\cdot)\)</span> is a data transformation that allows for relations between latent features <span class="math inline">\(\mathbf{Z} = \phi(\mathbf{X})\)</span> and <span class="math inline">\(\mathbf{Y}\)</span> to be modeled by a well-understood probabilistic model <span class="math inline">\(p\)</span>. Typically, <span class="math inline">\(\phi(\cdot)\)</span> will perform dimension reduction or dimension expansion and can be learned from data. It is worthwhile to emphasize that the top level of such a model is necessarily stochastic.</p>
<p>As pointed out before, the basic problem of machine learning is to learn a predictive rule from observed pairs <span class="math inline">\((\mathbf{X},\mathbf{Y})\)</span>, <span class="math inline">\(\mathbf{Y}_{\star}  = F(\mathbf{X}_{\star} )\)</span> where <span class="math inline">\(F(\mathbf{X}_{\star} ) = \mathbb{E}\{\mathbf{Y} \mid  \phi(\mathbf{X}_{\star})\}\)</span>. Even though it is well known that deep learners are universal approximators, it is still an open area of research to understand why deep learners generalize well on out-of-sample predictions. One of the important factors for the success of deep learning approach is the ability to perform a non-linear dimensionality reduction.</p>
<p>The purely statistical approach requires full specification of the conditional distribution <span class="math inline">\(p(\mathbf{Y} \mid \mathbf{X})\)</span> and then uses conditional probability via Bayes’ rule to perform inference. However, a fully Bayesian approach is often computationally prohibitive in high-dimensional feature space, without resorting to approximations or foregoing UQ. The alternative approach is to perform a data transformation or reduction on the data input <span class="math inline">\(\mathbf{X}\)</span>, such as performing a PCA or PCR first and then use a statistical approach on the transformed feature space. Deep learning methods can fit into this spectrum by viewing it as a non-linear PCA or PLS <span class="citation" data-cites="polson2021deep">N. Polson, Sokolov, and Xu (<a href="references.html#ref-polson2021deep" role="doc-biblioref">2021</a>)</span>,<span class="citation" data-cites="malthouse1997nonlinear">Malthouse, Mah, and Tamhane (<a href="references.html#ref-malthouse1997nonlinear" role="doc-biblioref">1997</a>)</span>. However, it possesses some unique properties not available for shallow models.</p>
</section>
<section id="deep-learning-expansions" class="level2" data-number="20.8">
<h2 data-number="20.8" class="anchored" data-anchor-id="deep-learning-expansions"><span class="header-section-number">20.8</span> Deep Learning Expansions</h2>
<p>Similar to a tree model that finds features (<em>aka</em> tree leaves) via recursive space partitioning, the deep learning model finds the regions by using hyperplanes at the first layer and combinations of hyperplanes in the further layers. The prediction rule is embedded into a parameterized deep learner, a composite of univariate semi-affine functions, denoted by <span class="math inline">\(F_{\mathbf{W}}\)</span> where <span class="math inline">\(\mathbf{W} = [\mathbf{W}^{(1)}, \ldots , \mathbf{W}^{(L)}]\)</span> represents the weights of each layer of the network. A deep learner takes the form of a composition of link functions:</p>
<p><span class="math display">\[
F_{\mathbf{W}} = f_L \circ f_{L-1} \circ \cdots \circ f_1  \; {\rm where} \; f_L = \sigma_L ( \mathbf{W}_L \phi (\mathbf{X}) + \mathbf{b}_L),
\]</span></p>
<p>where <span class="math inline">\(\sigma_L(\cdot)\)</span> is a univariate link or activation function. Specifically, let $^{(l)} $ denote the <span class="math inline">\(l^{th}\)</span> layer, and so <span class="math inline">\(\mathbf{X} = \mathbf{Z}^{(0)}\)</span>. The final output is the response <span class="math inline">\(\mathbf{Y}\)</span>, which can be numeric or categorical. A deep prediction rule is then <span class="math inline">\(\hat{\mathbf{Y}}(\mathbf{X}) = \mathbf{W}^{(L)} \mathbf{Z}^{(L)} + \mathbf{b}^{(L)}\)</span> where</p>
<p><span class="math display">\[
\begin{align*}
\mathbf{Z}^{(L)} &amp; = f^{(L)} \left ( \mathbf{W}^{(L-1)} \mathbf{Z}^{(L-1)} + \mathbf{b}^{(L-1)} \right ),\\
&amp; \ldots\\
\mathbf{Z}^{(2)} &amp; = f^{(2)} \left ( \mathbf{W}^{(1)} \mathbf{Z}^{(1)} + \mathbf{b}^{(1)} \right ),\\
\mathbf{Z}^{(1)} &amp; = f^{(1)} \left (\mathbf{W}^{(0)} \phi(\mathbf{X}) + \mathbf{b}^{(0)} \right ).
\end{align*}
\]</span></p>
<p>It is often beneficial to replace the original input <span class="math inline">\(\mathbf{X}\)</span> with the features <span class="math inline">\(\mathbf{Z} = \phi(\mathbf{X})\)</span> of lower dimensionality when developing a predictive model for <span class="math inline">\(\mathbf{Y}\)</span>. For example, in the context of regressions, a lower variance prediction rule can be obtained in lower dimensional space. DL simply uses a composition or superposition of semi-affine filters (<em>aka</em> link functions), leading to a new framework for high-dimensional modeling in Section @ref(sec:merging).</p>
<p>Deep learning can then be viewed as a feature engineering solution and one of finding nonlinear factors via supervised dimension reduction. A composition of hand-coded characteristics i.e.&nbsp;dimension expanding, with supervised learning of data filters i.e.&nbsp;dimension reduction. Advances in computation allow for massive data and gradients of high-dimensional nonlinear filters. Neural networks can be viewed from two perspectives: either as a flexible link function, as in a generalized linear model, or as a method to achieve dimensionality reduction, similar to sliced inverse regression or sufficient dimensionality reduction.</p>
<p>One advantage of <em>depth</em> is that the hierarchical mixture allows the width of a given layer to be manageable. With a single layer (<em>e.g.</em>, kernel PCA/SVM) we need exponentially many more basis functions in that layer. Consider kernel PCA with say radial basis functions (RBF) kernels: technically there are infinitely many basis functions, but it cannot handle that many input dimensions. Presumably, a deep neural network allows a richer class of covariances that allows anisotropy and non-stationarity. In the end, this is reflected in the function realizations from a DNN. To see this, consider the deep GP models, which are infinite width limits of DNNs. There is a recursive formula connecting the covariance of layer <span class="math inline">\(k\)</span> to that of layer <span class="math inline">\(k+1\)</span>, but no closed form. The covariance function of the final hidden layer is probably very complicated and capable of expressing an arbitrary number of features, even if the covariances in each layer may be simple. The increase in dimensionality happens through the hierarchical mixture, rather than trying to do it all in one layer. From a statistical viewpoint, this is similar to the linear shallow wide projections introduced by <span class="citation" data-cites="wold1975soft">Wold (<a href="references.html#ref-wold1975soft" role="doc-biblioref">1975/ed</a>)</span> and the sufficient dimension reduction framework of <span class="citation" data-cites="cook2007fisher">Cook (<a href="references.html#ref-cook2007fisher" role="doc-biblioref">2007</a>)</span>.</p>
<p>In the context of unsupervised learning, information in the marginal distribution, <span class="math inline">\(p(\mathbf{X})\)</span>, of the input space is used as opposed to the conditional distribution, <span class="math inline">\(p(\mathbf{X}\mid \mathbf{Y})\)</span>. Methods such as PCA (PCA), PCR (PCR), Reduced Rank Regression (RRR), Projection-Pursuit Regression (PPR) all fall into this category and PLS (PLS), Sliced Inverse Regression (SIR) are examples of supervised learning of features, see <span class="citation" data-cites="polson2017deep">N. G. Polson, Sokolov, et al. (<a href="references.html#ref-polson2017deep" role="doc-biblioref">2017</a>)</span> for further discussion.</p>
<p>We first uncover the structure in the predictors relevant for modeling the output <span class="math inline">\(\mathbf{Y}\)</span>. The learned factors are denoted by <span class="math inline">\(F(\phi(\mathbf{X}))\)</span> and are constructed as a sequence of input filters. The predictive model is given by a probabilistic model of the form <span class="math inline">\(p(\mathbf{Y} \mid \mathbf{X}) \equiv p(\mathbf{Y} \mid F(\phi(\mathbf{X})))\)</span>. Here <span class="math inline">\(\phi: \mathbb{R}^p \mapsto \mathbb{R}^c,~c \gg p\)</span> initially expands the dimension of the input space by including terms such as interactions, dummy variables (<em>aka</em> one-hot encodings) and other nonlinear features of the input space deemed relevant. Then, <span class="math inline">\(F\)</span> reduces dimension of deep learning by projecting back with a univariate activation function into an affine space (<em>aka</em> regression). This framework also sheds light on how to build deep (skinny) architectures. Given <span class="math inline">\(n\)</span> data points, we split into <span class="math inline">\(L = 2^p\)</span> regions so that there is a <em>fixed</em> sample size within each bin. This process transforms <span class="math inline">\(\mathbf{X}\)</span> into many interpretable characteristics. This can lead to a huge number of predictors that can be easily dealt within the DL architecture, making the advantage of <em>depth</em> clear.</p>
</section>
<section id="sec:dim-exp" class="level2" data-number="20.9">
<h2 data-number="20.9" class="anchored" data-anchor-id="sec:dim-exp"><span class="header-section-number">20.9</span> Dimensionality Expansion</h2>
<p>First, we review ‘dimensionality expansions’: data transformation that transforms an input vector <span class="math inline">\(\mathbf{X}\)</span> into a higher dimensional vector <span class="math inline">\(\phi(\mathbf{X})\)</span>. One approach is to use hand-coded predictors. This expanded set can include terms such as interactions, dummy variables or nonlinear functional of the original predictors. The goal is to model the joint distribution of outputs and inputs, namely $p( , ()) $, where we allow our stochastic predictors.</p>
<p><strong>Kernel Expansion:</strong> The kernel expansion idea is to enlarge the feature space via basis expansion. The basis is expanded using nonlinear transformations of the original inputs: <span class="math display">\[\phi(\mathbf{X}) = (\phi_1(\mathbf{X}),\phi_2(\mathbf{X}),\ldots,\phi_M(\mathbf{X}))\]</span> so that linear regression <span class="math inline">\(\hat{\mathbf{Y}} = \phi(\mathbf{X})^T\beta + \beta_0\)</span> or generalized linear model can be used to model the input-output relations. Here, the ‘kernel trick’ increases dimensionality, and allows hyperplane separation while avoiding an exponential increase in the computational complexity. The transformation <span class="math inline">\(\phi(\mathbf{x})\)</span> is specified via a kernel function <span class="math inline">\(K(\cdot, \cdot)\)</span> which calculates the dot product of feature mappings: <span class="math inline">\(K(\mathbf{x},\mathbf{x}') = \phi(\mathbf{x})^T\phi(\mathbf{x}').\)</span> By choosing a feature map <span class="math inline">\(\phi\)</span>, we implicitly choose a kernel function and, conversely, every positive semi-definite kernel matrix corresponds to a feature mapping <span class="math inline">\(\phi\)</span>. For example, when <span class="math inline">\(\mathbf{X}\in \mathbb{R}^2\)</span>, choosing <span class="math inline">\(K(\mathbf{X},\mathbf{X}') = (1+\mathbf{X}^T\mathbf{X}')^2\)</span> is equivalent to expanding the basis to <span class="math inline">\(\phi(\mathbf{X}) = (1,\sqrt{2}\mathbf{X}_1, \sqrt{2}\mathbf{X}_1, \mathbf{X}_1^2,\mathbf{X}_2^2,\sqrt{2}\mathbf{X}_1 \mathbf{X}_2)\)</span>.</p>
<p><strong>Tree Expansion:</strong> Similar to kernels, we can think of trees as a technique for expanding a feature space. Each region in the input space defined by a terminating node of a tree corresponds to a new feature. Then, the predictive rule becomes very simple: identify in which region the new input is and use the average across observations or a majority voting rule from this region to calculate the prediction.</p>
</section>
<section id="sec:pca-pcr" class="level2" data-number="20.10">
<h2 data-number="20.10" class="anchored" data-anchor-id="sec:pca-pcr"><span class="header-section-number">20.10</span> Dimensionality Reduction: PCA, PCR and PLS</h2>
<p>Given input/predictors <span class="math inline">\(\mathbf{X}\)</span> and response <span class="math inline">\(\mathbf{Y}\)</span> and associated observed data <span class="math inline">\(\mathbf{X}\in {\mathbb{R}}^{n \times p}\)</span> and <span class="math inline">\(\mathbf{Y} \in {\mathbb{R}}^{n\times q}\)</span>, the goal is to find data transformations <span class="math inline">\((\mathbf{Y},\mathbf{X}) \mapsto \phi(\mathbf{Y},\mathbf{X})\)</span> so that modeling the transformed data becomes an easier task. In this paper, we consider several types of transformations and model non-linear relations.</p>
<p>We start by reviewing the widely used singular value decomposition (SVD) which allows finding linear transformations to identify a lower dimensional representation of either <span class="math inline">\(\mathbf{X}\)</span>, by what is known as principal component analysis (PCA), or, when using both <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span>, known as partial least squares (PLS). First, start with the SVD decomposition of the input matrix: <span class="math inline">\(\mathbf{X} = \mathbf{U} \mathbf{D} \mathbf{W}^T\)</span>, which is full-rank if <span class="math inline">\(n &gt; p\)</span>. Here, $ = (d_1 , , d_p ) $ are the nonzero ordered singular values (<span class="math inline">\(d_1 \ge \ldots \ge d_p)\)</span> . The matrices <span class="math inline">\(\mathbf{U}\)</span> and <span class="math inline">\(\mathbf{W}\)</span> are orthogonal matrices of dimensions <span class="math inline">\(n\times p\)</span> and <span class="math inline">\(p \times p\)</span> with columns of <span class="math inline">\(\mathbf{U}\)</span> as the right singular vectors and columns of <span class="math inline">\(\mathbf{W}\)</span> as the left singular vectors, <span class="math inline">\(\mathbf{W}\)</span> can be also thought of as the matrix consisting of eigenvectors for <span class="math inline">\(\mathbf{S} = \mathbf{X}^T \mathbf{X}\)</span>. We can then transform the original first layer to an orthogonal regression, namely defining <span class="math inline">\(\mathbf{Z} = \mathbf{U}\mathbf{D}\)</span> whose columns are the principal components. For PCR, using <span class="math inline">\(\boldsymbol{\alpha} = \mathbf{W}^T \boldsymbol{\beta}\)</span>, we arrive at the corresponding OLS estimator <span class="math inline">\(\hat{\boldsymbol{\alpha}} = (\mathbf{Z}^T \mathbf{Z} )^{-1} \mathbf{Z}^T \mathbf{Y} = \mathbf{D}^{-1} \mathbf{U}^T \mathbf{y}\)</span>, and obtain <span class="math inline">\(\hat{y}_{pcr} = \sum_{j=1}^{K}\hat{\alpha}_j \mathbf{z}_j\)</span>, where <span class="math inline">\(\hat{\alpha}_j = \mathbf{z}_j^T \mathbf{y}/\mathbf{z}_j^T \mathbf{z}_j\)</span>, since <span class="math inline">\(\mathbf{z}_j\)</span>’s are orthogonal, and <span class="math inline">\(K \ll p\)</span> denotes the reduced dimension that captures a certain percentage of the total variability.</p>
<p>PCR, as an unsupervised approach to dimension reduction, has a long history in statistics. Specifically, we first center and standardize <span class="math inline">\((\mathbf{Y}, \mathbf{X})\)</span>, followed by a singular value decomposition of <span class="math inline">\(\mathbf{V}: = \mathrm{ave} ( \mathbf{X} \mathbf{X}^T )  = \dfrac{1}{n}\sum_{i=1}^{n}\mathbf{X}_i\mathbf{X}_i^T\)</span> where <span class="math inline">\(\mathrm{ave}(\cdot)\)</span> denotes the empirical average. Then, we find the eigenvalues $e_j^2 $ and eigenvectors arranged in non-increasing order, so we can write:</p>
<p><span class="math display">\[
\mathbf{V} = \sum_{j=1}^p  e_j^2 {\mathbf{v}}_j {\mathbf{v}}_k^T .
\]</span></p>
<p>This leads to a sequence of regression models <span class="math inline">\((\hat Y_0, \ldots, \hat Y_K)\)</span> with $Y_0 $ being the overall mean:</p>
<p><span class="math display">\[
\hat{Y}_L = \sum_{l=0}^K (\mathrm{ave} ( \mathbf{W}_l^T \mathbf{X} ) / e_l^2 ) \mathbf{v}_l^T \mathbf{X}.
\]</span></p>
<p>Therefore, PCR finds features <span class="math inline">\(\{\mathbf{Z}_k\}_{k=0}^K = \{\mathbf{v}_k^T \mathbf{x}\}_{k=0}^K = \{\mathbf{f}_k \}_{k=0}^K\)</span>.</p>
<p><strong>PLS and SVD Algorithm:</strong> Partial least squares, or PLS, is a related dimension reduction technique similar to PCR that first identifies a lower-dimensional set of features and then fits a linear model on this feature set, but PLS does this in a supervised fashion unlike PCR. In successive steps, PLS finds a reduced dimensional representation of <span class="math inline">\(\mathbf{X}\)</span> that is relevant for the response <span class="math inline">\(\mathbf{Y}\)</span>.</p>
<p><strong>PCA and multivariate output:</strong> PCA requires us to compute a reduction of multivariate output <span class="math inline">\(\mathbf{Y}\)</span> using a singular value decomposition of <span class="math inline">\(\mathbf{Y}\)</span> by finding eigenvectors of <span class="math inline">\(\mathbf{Z} = \mathrm{ave}(\mathbf{Y}\mathbf{Y}^T)\)</span>. Then, the output is a linear combination of the singular vectors</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{W}_1 \mathbf{Z}_1 + \cdots + \mathbf{W}_k \mathbf{Z}_k,
\]</span></p>
<p>where the weights <span class="math inline">\(\mathbf{W}_i\)</span> follow a Gaussian Process, <span class="math inline">\(\mathbf{W}\sim \mathrm{GP}(m,K)\)</span>. Hence, the method can be highly non-linear. This method is typically used when input variables come from a designed experiment. If the interpretability of factors is not important, and from a purely predictive point of view, PLS will lead to improved performance.</p>
<p>In the light of the above, one can view deep learning models as non-stochastic hierarchical data transformations. The advantage is that we can learn deterministic data transformations before applying a stochastic model. This allows us to establish a connection between a result due to <span class="citation" data-cites="brillinger2012generalized">Brillinger (<a href="references.html#ref-brillinger2012generalized" role="doc-biblioref">2012</a>)</span> and the use of deep learning models to develop a unified framework for modeling complex high-dimensional data sets. The prediction rule can be viewed as interpolation. In high-dimensional spaces, one can mix-and-match the deterministic and stochastic data transformation rules.</p>
</section>
<section id="uncertainty-quantification" class="level2" data-number="20.11">
<h2 data-number="20.11" class="anchored" data-anchor-id="uncertainty-quantification"><span class="header-section-number">20.11</span> Uncertainty Quantification</h2>
<p>Our probabilistic model takes the form <span class="math inline">\(\mathbf{Y} \mid F \sim p(\mathbf{Y} \mid F )\)</span>, $F = g ( ) $, where <span class="math inline">\(\mathbf{Y}\)</span> is possibly a multivariate output matrix and <span class="math inline">\(\mathbf{X}\)</span> is a $n p $ matrix of input variables, and <span class="math inline">\(\mathbf{B} \mathbf{X}\)</span> performs dimension reduction. Here <span class="math inline">\(g = g_{\mathbf{W}, \mathbf{b}}\)</span> is a deep learner and the parameters <span class="math inline">\((\hat{\mathbf{W}} , \hat{\mathbf{b}} )\)</span> are estimated using traditional SGD methods. The key result, due to <span class="citation" data-cites="brillinger2012generalized">Brillinger (<a href="references.html#ref-brillinger2012generalized" role="doc-biblioref">2012</a>)</span> and <span class="citation" data-cites="naik2000partial">Naik and Tsai (<a href="references.html#ref-naik2000partial" role="doc-biblioref">2000</a>)</span> is that <span class="math inline">\(\hat{\mathbf{B}}\)</span> can be estimated consistently, up to a constant of proportionality, using PLS irrespective of the nonlinearity on <span class="math inline">\(g\)</span>. Even though <span class="citation" data-cites="brillinger2012generalized">Brillinger (<a href="references.html#ref-brillinger2012generalized" role="doc-biblioref">2012</a>)</span> assumes that input <span class="math inline">\(\mathbf{X}\)</span> is Gaussian in order to apply Stein’s lemma, this result generalizes to scale-mixtures of Gaussians. See also <span class="citation" data-cites="iwata2001recentered">Iwata (<a href="references.html#ref-iwata2001recentered" role="doc-biblioref">2001</a>)</span> who provides analytical derivation of the uncertainty intervals for ReLU and Probit nonlinear activation functions.</p>
<p>The key insight here is that the lion’s share of the UQ can be done at the top layer that outputs <span class="math inline">\(\mathbf{Y}\)</span> as the uncertainty in the dimension reduction of the <span class="math inline">\(\mathbf{X}\)</span> space is much harder to quantify compared to quantifying the uncertainty for the prediction rule. By merging the two cultures, the probabilistic model on the first stage and deep learning on the subsequent stage, for the transformation of input data, we can obtain the best of both worlds.</p>
<p>Given a specification of <span class="math inline">\(g\)</span>, the constant of proportionality can also be estimated consistently with <span class="math inline">\(\sqrt{n}\)</span>-asymptotics. Hence, to predict at a new level <span class="math inline">\(\mathbf{X}_{\star}\)</span>, we can use the predictive distribution to make a forecast and provide uncertainty bounds.</p>
<p><span id="eq-pls-uq"><span class="math display">\[
\begin{align*}
    \mathbf{Y}_{\star}  &amp; \sim  p \left ( \mathbf{Y} \; \mid \;   g_{ \hat{\mathbf{W}}, \hat{\mathbf{b}}} ( \hat{\mathbf{B}}_{\mathrm{PLS}} \mathbf{X} )  \right )   \\
    \hat{\mathbf{Y}}_* &amp;  =  \mathrm{E(\mathbf{Y}_* \mid \mathbf{F}_*)} = \mathrm{E}_{\mathbf{B} \mid \mathbf{X},\mathbf{Y}} \left(g(\hat{\mathbf{B}}_{\mathrm{PLS}}\mathbf{X}_*)\right),
\end{align*}
\tag{20.1}\]</span></span></p>
<p>where <span class="math inline">\(\hat{\mathbf{B}}_{\mathrm{PLS}}\)</span> is given by the left-hand side of <a href="#eq-pls-uq" class="quarto-xref">Equation&nbsp;<span>20.1</span></a>.</p>
<p>Notice that we can also incorporate uncertainty in the estimation of <span class="math inline">\(\mathbf{B}\)</span> via the posterior <span class="math inline">\(p(\mathbf{B} \mid \mathbf{X},\mathbf{Y})\)</span>. Furthermore, a result of <span class="citation" data-cites="iwata2001recentered">Iwata (<a href="references.html#ref-iwata2001recentered" role="doc-biblioref">2001</a>)</span> can be used to show that the posterior distribution is asymptotically normal. Hence, we can calculate the expectations analytically for activation functions, such as ReLU. As ReLU is convex, Jensen’s inequality <span class="math inline">\(g\left(\mathrm{E}(\mathbf{B} \mathbf{X})\right) \le \mathrm{E}\left(g(\mathbf{B} \mathbf{X})\right)\)</span> shows that ignoring parameter uncertainty leads to under-prediction.</p>
</section>
<section id="double-descent" class="level2" data-number="20.12">
<h2 data-number="20.12" class="anchored" data-anchor-id="double-descent"><span class="header-section-number">20.12</span> Double Descent</h2>
<p>Double descent is a phenomenon of over-parameterized statistical models. In this section, we present a view of double descent from a Bayesian perspective. Over-parameterized models such as deep neural networks have an interesting re-descending property in their risk characteristics. This is a recent phenomenon in machine learning and has been the subject of many studies. As the complexity of the model increases, there is a U-shaped region corresponding to the traditional bias-variance trade-off, but then as the number of parameters equals the number of observations and the model becomes one of interpolation, the risk can become infinite and then, in the over-parameterized region, it re-descends—the double descent effect. We show that this has a natural Bayesian interpretation. Moreover, we show that it is not in conflict with the traditional Occam’s razor that Bayesian models possess, in that they tend to prefer simpler models when possible.</p>
<p>Empirically, the double descent effect was initially observed for high-dimensional neural network regression models and the good performance of these models on such tasks as large language models, image processing, and generative AI methods<span class="citation" data-cites="nareklishvili2023generative">(<a href="references.html#ref-nareklishvili2023generative" role="doc-biblioref">Nareklishvili, Polson, and Sokolov 2023</a>)</span>. The double descent effect extends the classical bias-variance trade-off curve that shrinkage estimators possess. This phenomenon was first observed in the context of linear regression<span class="citation" data-cites="belkin2019reconciling">(<a href="references.html#ref-belkin2019reconciling" role="doc-biblioref">Belkin et al. 2019</a>)</span>. The authors showed that the test error of the estimator can decrease as the number of parameters increases. <span class="citation" data-cites="bach2024highdimensional">Bach (<a href="references.html#ref-bach2024highdimensional" role="doc-biblioref">2024</a>)</span> extends these results to stochastic regression models.</p>
<p>Interpolators—estimators that achieve zero training error—were then shown to have attractive properties due to the double descent effect<span class="citation" data-cites="hastie2022surprises">(<a href="references.html#ref-hastie2022surprises" role="doc-biblioref">Hastie et al. 2022</a>)</span>. Our goal is to show that Bayesian estimators can also possess a double descent phenomenon. Interpolators such as ReLU neural networks<span class="citation" data-cites="polson2017deep">(<a href="references.html#ref-polson2017deep" role="doc-biblioref">N. G. Polson, Sokolov, et al. 2017</a>)</span> have increased in popularity with many applications such as traffic flow modeling<span class="citation" data-cites="polson2017deep">(<a href="references.html#ref-polson2017deep" role="doc-biblioref">N. G. Polson, Sokolov, et al. 2017</a>)</span> and high-frequency trading<span class="citation" data-cites="dixon2019deep">(<a href="references.html#ref-dixon2019deep" role="doc-biblioref">Dixon, Polson, and Sokolov 2019</a>)</span>, among many others.</p>
<p>Occam’s razor—the favoring of simpler models over complex ones—is a natural feature of Bayesian methods that are based on the weight of evidence (a.k.a. the marginal likelihood of the data). To do this, they penalize models with higher complexity via a correction term as in the Bayesian Information Criterion (BIC). This seems inconsistent with the double descent phenomenon. We show that this is not the case, as even though Bayesian methods shift the posterior towards lower-complexity models, highly parameterized Bayesian models can also have good risk properties due to the conditional prior of parameters given the model. We illustrate this with an application to neural network models.</p>
<p>Double descent has been studied from a frequentist point of view in <span class="citation" data-cites="belkin2019reconciling">Belkin et al. (<a href="references.html#ref-belkin2019reconciling" role="doc-biblioref">2019</a>)</span>, <span class="citation" data-cites="bach2024highdimensional">Bach (<a href="references.html#ref-bach2024highdimensional" role="doc-biblioref">2024</a>)</span>. The phenomenon of double descent is illustrated in <span class="quarto-unresolved-ref">?fig-double-descent</span>. The first part of the curve represents the classical U-shaped bias-variance trade-off. The second part demonstrates the double descent phenomenon, where the test error of the estimator can decrease as the model becomes over-parameterized beyond the interpolation threshold. This phenomenon was later observed in the context of deep learning<span class="citation" data-cites="nakkiran2021deep">(<a href="references.html#ref-nakkiran2021deep" role="doc-biblioref">Nakkiran et al. 2021</a>)</span>. The authors showed that the test error of the estimator can decrease as the number of parameters increases.</p>
<div id="exm-double-descent" class="theorem example">
<p><span class="theorem-title"><strong>Example 20.1 (Double Descent Demonstration using Polynomial Regression)</strong></span> To illustrate the double descent phenomenon in a concrete setting, we present a detailed example using polynomial regression with Legendre basis functions. This example demonstrates how the test error can exhibit the characteristic U-shaped curve followed by a re-descent as model complexity increases far beyond the interpolation threshold.</p>
<p>Our demonstration uses a one-dimensional regression problem where we attempt to learn a sinusoidal function <span class="math inline">\(f(x) = \sin(5x)\)</span> from a small dataset of only <span class="math inline">\(n = 20\)</span> observations sampled from the interval <span class="math inline">\([-1, 1]\)</span>. We add Gaussian noise with standard deviation <span class="math inline">\(\sigma = 0.3\)</span> to simulate realistic measurement error. The choice of a small sample size is crucial for observing double descent, as it creates a regime where the number of model parameters can substantially exceed the number of observations.</p>
<p>We fit polynomial models of varying degrees <span class="math inline">\(d = 1, 2, \ldots, 50\)</span> using Legendre polynomial basis functions. Legendre polynomials provide a numerically stable orthogonal basis that helps avoid the numerical instabilities associated with standard monomial bases in high-degree polynomial fitting. For each degree <span class="math inline">\(d\)</span>, we estimate the coefficients using the Moore-Penrose pseudoinverse, which provides the minimum-norm solution when the system is overdetermined (i.e., when <span class="math inline">\(d &gt; n\)</span>).</p>
<p><a href="#fig-double-descent-grid" class="quarto-xref">Figure&nbsp;<span>20.3</span></a> illustrates how model behavior changes dramatically across different polynomial degrees. The four panels show representative cases that capture the key phases of the double descent phenomenon:</p>
<ul>
<li><p><strong>Degree 1 (Underparameterized)</strong>: The linear model is too simple to capture the oscillatory nature of the underlying sine function, resulting in high bias and poor fit to both training and test data.</p></li>
<li><p><strong>Degree 5 (Classical Optimum)</strong>: This represents the sweet spot of the classical bias-variance tradeoff, where the model has sufficient complexity to capture the main features of the sine function without overfitting severely.</p></li>
<li><p><strong>Degree 20 (Interpolation Threshold)</strong>: At this degree, the model has exactly as many parameters as training observations, enabling perfect interpolation of the training data. However, the resulting fit exhibits wild oscillations between data points, leading to poor generalization performance.</p></li>
<li><p><strong>Degree 50 (Over-parameterized)</strong>: Surprisingly, despite having far more parameters than observations, this highly over-parameterized model achieves better test performance than the interpolating model, demonstrating the double descent effect.</p></li>
</ul>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">20</span>  <span class="co"># number of samples</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="fl">0.3</span>  <span class="co"># stdev of noise</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="dv">1</span>  <span class="co"># range of x values</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Use Legendre polynomial basis by default</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> np.polynomial.legendre.legvander</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> poly(pts, beta, d):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> G(pts, d).dot(beta)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize data</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>ground_truth <span class="op">=</span> sin</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(a, b, n)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> ground_truth(x) <span class="op">+</span> sigma <span class="op">*</span> np.random.normal(size<span class="op">=</span>n)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>xdense <span class="op">=</span> np.linspace(a, b, <span class="dv">100</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>ygt <span class="op">=</span> ground_truth(xdense)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Core functions</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> solve_reg(A, y, lamb):</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> la.solve(A.T.dot(A) <span class="op">+</span> lamb <span class="op">*</span> np.identity(A.shape[<span class="dv">1</span>]), A.T.dot(y))</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit(d):</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    betaHat <span class="op">=</span> la.pinv(G(x, d)).dot(y)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    mseos <span class="op">=</span> np.sqrt(np.mean((G(xdense, d).dot(betaHat) <span class="op">-</span> ygt)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    mseis <span class="op">=</span> np.sqrt(np.mean((G(x, d).dot(betaHat) <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> betaHat, mseos, mseis</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run(d, ax):</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute the regressor for degree d, and plot the solution."""</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    betaHat, mseos, mseois <span class="op">=</span> fit(d)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    ax.plot(xdense, ygt, label<span class="op">=</span><span class="st">'ground-truth'</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    ax.scatter(x, y, c<span class="op">=</span><span class="st">'r'</span>, label<span class="op">=</span><span class="st">'samples'</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    ax.plot(xdense, poly(xdense, betaHat, d), label<span class="op">=</span><span class="st">'model'</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    ax.set_ylim(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'d=</span><span class="sc">%d</span><span class="st">, MSE: Test=</span><span class="sc">%.2f</span><span class="st">, Train=</span><span class="sc">%.2f</span><span class="st">'</span> <span class="op">%</span> (d, mseos, mseois))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create 2x2 subplot grid (all functions and variables are now persistent!)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">'Double Descent Phenomenon: Polynomial Regression'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot each degree in its respective subplot</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>run(<span class="dv">1</span>, axes[<span class="dv">0</span>, <span class="dv">0</span>])   <span class="co"># Top left</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>run(<span class="dv">5</span>, axes[<span class="dv">0</span>, <span class="dv">1</span>])   <span class="co"># Top right  </span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>run(<span class="dv">20</span>, axes[<span class="dv">1</span>, <span class="dv">0</span>])  <span class="co"># Bottom left</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>run(<span class="dv">50</span>, axes[<span class="dv">1</span>, <span class="dv">1</span>])  <span class="co"># Bottom right</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-double-descent-grid" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-double-descent-grid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="20-theorydl_files/figure-html/fig-double-descent-grid-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1152">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-double-descent-grid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.3: Double Descent Phenomenon: Polynomial Regression with Different Degrees
</figcaption>
</figure>
</div>
</div>
</div>
<p>Now, let’s plot the MSE curve. We will plot the test error (blue line) and the training error (red line) for different polynomial degrees from 1 to 50.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate MSE data for different polynomial degrees (using persistent functions!)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>nd <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>mse1 <span class="op">=</span> np.zeros(nd)  <span class="co"># Test MSE</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>mse2 <span class="op">=</span> np.zeros(nd)  <span class="co"># Train MSE</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, nd):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    betaHat, mseos, mseois <span class="op">=</span> fit(d)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    mse1[d] <span class="op">=</span> mseos</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    mse2[d] <span class="op">=</span> mseois</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>fig, ax1 <span class="op">=</span> plt.subplots()</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Number of Features'</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'MSE'</span>, color<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>ax1.plot(np.log10(mse1), color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'out-of-sample'</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> ax1.twinx()</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>ax2.plot(np.log10(mse2), color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'in-sample'</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(mse1, label='out-of-sample')</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(mse2, label='in-sample')</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>fig.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-mse-curve" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mse-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="20-theorydl_files/figure-html/fig-mse-curve-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mse-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.4: Bias-Variance Trade-off: Training and Test MSE vs Model Complexity
</figcaption>
</figure>
</div>
</div>
</div>
<p>The key insight from <a href="#fig-mse-curve" class="quarto-xref">Figure&nbsp;<span>20.4</span></a> is the characteristic double descent shape in the test error (blue line). The curve exhibits three distinct phases:</p>
<ol type="1">
<li><p><strong>Classical Regime</strong>: For low degrees (<span class="math inline">\(d &lt; 5\)</span>), increasing model complexity reduces both bias and test error, following the traditional understanding of the bias-variance tradeoff.</p></li>
<li><p><strong>Interpolation Crisis</strong>: Around the interpolation threshold (<span class="math inline">\(d \approx n = 20\)</span>), test error peaks dramatically as the model begins to perfectly fit the training data while generalizing poorly.</p></li>
<li><p><strong>Over-parameterized Regime</strong>: For very high degrees (<span class="math inline">\(d &gt; 30\)</span>), test error decreases again, demonstrating that extreme over-parameterization can lead to improved generalization despite the model’s ability to memorize the training data.</p></li>
</ol>
<p>This behavior challenges the conventional wisdom that more parameters necessarily lead to worse generalization. The double descent phenomenon arises from the implicit regularization effects of minimum-norm solutions in over-parameterized settings. When <span class="math inline">\(d &gt; n\)</span>, the pseudoinverse solution corresponds to the minimum <span class="math inline">\(\ell_2\)</span>-norm coefficients among all possible interpolating solutions. This implicit bias toward simpler functions can lead to surprisingly good generalization properties.</p>
<p>While this example uses polynomial regression for clarity, the double descent phenomenon has been observed across a wide range of modern machine learning models, including deep neural networks, random forests, and kernel methods. The implications for practice are significant. Given that model selection is time consuming and computationally expensive, this example shows, that instead of spending time to do model selection to find the “sweet spot” model with 5-degree polynomial, we just over-parametrise and get a good model for free!</p>
<p>This example serves as a concrete illustration of how classical statistical intuitions about model complexity may not apply in contemporary machine learning settings, particularly when dealing with over-parameterized models that have become increasingly common in practice.</p>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-actor2018computation" class="csl-entry" role="listitem">
Actor, Jonas. 2018. <span>“Computation for the <span>Kolmogorov Superposition Theorem</span>.”</span> {{MS Thesis}}, Rice.
</div>
<div id="ref-amit2000multiple" class="csl-entry" role="listitem">
Amit, Yali, Gilles Blanchard, and Kenneth Wilder. 2000. <span>“Multiple Randomized Classifiers: <span>MRCL</span>.”</span>
</div>
<div id="ref-bach2024highdimensional" class="csl-entry" role="listitem">
Bach, Francis. 2024. <span>“High-Dimensional Analysis of Double Descent for Linear Regression with Random Projections.”</span> <em>SIAM Journal on Mathematics of Data Science</em> 6 (1): 26–50.
</div>
<div id="ref-bahdanau2014neural" class="csl-entry" role="listitem">
Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. 2014. <span>“Neural <span>Machine Translation</span> by <span>Jointly Learning</span> to <span>Align</span> and <span>Translate</span>.”</span> arXiv. <a href="https://arxiv.org/abs/1409.0473">https://arxiv.org/abs/1409.0473</a>.
</div>
<div id="ref-belkin2019reconciling" class="csl-entry" role="listitem">
Belkin, Mikhail, Daniel Hsu, Siyuan Ma, and Soumik Mandal. 2019. <span>“Reconciling Modern Machine-Learning Practice and the Classical Bias–Variance Trade-Off.”</span> <em>Proceedings of the National Academy of Sciences</em> 116 (32): 15849–54.
</div>
<div id="ref-brillinger2012generalized" class="csl-entry" role="listitem">
Brillinger, David R. 2012. <span>“A <span>Generalized Linear Model With</span> <span>‘<span>Gaussian</span>’</span> <span>Regressor Variables</span>.”</span> In <em>Selected <span>Works</span> of <span>David Brillinger</span></em>, edited by Peter Guttorp and David Brillinger, 589–606. Selected <span>Works</span> in <span>Probability</span> and <span>Statistics</span>. New York, NY: Springer.
</div>
<div id="ref-cook2007fisher" class="csl-entry" role="listitem">
Cook, R. Dennis. 2007. <span>“Fisher Lecture: <span>Dimension</span> Reduction in Regression.”</span> <em>Statistical Science</em>, 1–26. <a href="https://www.jstor.org/stable/27645799">https://www.jstor.org/stable/27645799</a>.
</div>
<div id="ref-coppejans2004kolmogorovs" class="csl-entry" role="listitem">
Coppejans, Mark. 2004. <span>“On <span>Kolmogorov</span>’s Representation of Functions of Several Variables by Functions of One Variable.”</span> <em>Journal of Econometrics</em> 123 (1): 1–31.
</div>
<div id="ref-demb2021note" class="csl-entry" role="listitem">
Demb, Robert, and David Sprecher. 2021. <span>“A Note on Computing with <span>Kolmogorov Superpositions</span> Without Iterations.”</span> <em>Neural Networks</em> 144 (December): 438–42.
</div>
<div id="ref-diaconis1984nonlinear" class="csl-entry" role="listitem">
Diaconis, Persi, and Mehrdad Shahshahani. 1984. <span>“On Nonlinear Functions of Linear Combinations.”</span> <em>SIAM Journal on Scientific and Statistical Computing</em> 5 (1): 175–91.
</div>
<div id="ref-dixon2019deep" class="csl-entry" role="listitem">
Dixon, Matthew F, Nicholas G Polson, and Vadim O Sokolov. 2019. <span>“Deep Learning for Spatio-Temporal Modeling: Dynamic Traffic Flows and High Frequency Trading.”</span> <em>Applied Stochastic Models in Business and Industry</em> 35 (3): 788–807.
</div>
<div id="ref-fredholm1903classe" class="csl-entry" role="listitem">
Fredholm, Ivar. 1903. <span>“Sur Une Classe d’<span>é</span>quations Fonctionnelles.”</span> <em>Acta Mathematica</em> 27 (none): 365–90.
</div>
<div id="ref-friedman1981projection" class="csl-entry" role="listitem">
Friedman, Jerome H., and Werner Stuetzle. 1981. <span>“Projection <span>Pursuit Regression</span>.”</span> <em>Journal of the American Statistical Association</em> 76 (376): 817–23.
</div>
<div id="ref-hastie2022surprises" class="csl-entry" role="listitem">
Hastie, Trevor, Andrea Montanari, Saharon Rosset, and Ryan J. Tibshirani. 2022. <span>“Surprises in High-Dimensional Ridgeless Least Squares Interpolation.”</span> <em>The Annals of Statistics</em> 50 (2): 949–86.
</div>
<div id="ref-igelnik2003kolmogorovs" class="csl-entry" role="listitem">
Igelnik, B., and N. Parikh. 2003. <span>“Kolmogorov’s Spline Network.”</span> <em>IEEE Transactions on Neural Networks</em> 14 (4): 725–33.
</div>
<div id="ref-iwata2001recentered" class="csl-entry" role="listitem">
Iwata, Shigeru. 2001. <span>“Recentered and <span>Rescaled Instrumental Variable Estimation</span> of <span>Tobit</span> and <span>Probit Models</span> with <span>Errors</span> in <span>Variables</span>.”</span> <em>Econometric Reviews</em> 20 (3): 319–35.
</div>
<div id="ref-kolmogorov1956representation" class="csl-entry" role="listitem">
Kolmogorov, AN. 1956. <span>“On the Representation of Continuous Functions of Several Variables as Superpositions of Functions of Smaller Number of Variables.”</span> In <em>Soviet. <span>Math</span>. <span>Dokl</span></em>, 108:179–82.
</div>
<div id="ref-lin2017structured" class="csl-entry" role="listitem">
Lin, Zhouhan, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. 2017. <span>“A <span class="nocase">Structured Self-attentive Sentence Embedding</span>.”</span> arXiv. <a href="https://arxiv.org/abs/1703.03130">https://arxiv.org/abs/1703.03130</a>.
</div>
<div id="ref-lorentz197613th" class="csl-entry" role="listitem">
Lorentz, George G. 1976. <span>“The 13th Problem of <span>Hilbert</span>.”</span> In <em>Proceedings of <span>Symposia</span> in <span>Pure Mathematics</span></em>, 28:419–30. American Mathematical Society.
</div>
<div id="ref-malthouse1997nonlinear" class="csl-entry" role="listitem">
Malthouse, Edward, Richard Mah, and Ajit Tamhane. 1997. <span>“Nonlinear <span>Partial Least Squares</span>.”</span> <em>Computers &amp; Chemical Engineering</em> 12 (April): 875–90.
</div>
<div id="ref-nadaraya1964estimating" class="csl-entry" role="listitem">
Nadaraya, E. A. 1964. <span>“On <span>Estimating Regression</span>.”</span> <em>Theory of Probability &amp; Its Applications</em> 9 (1): 141–42.
</div>
<div id="ref-naik2000partial" class="csl-entry" role="listitem">
Naik, Prasad, and Chih-Ling Tsai. 2000. <span>“Partial <span>Least Squares Estimator</span> for <span>Single-Index Models</span>.”</span> <em>Journal of the Royal Statistical Society. Series B (Statistical Methodology)</em> 62 (4): 763–71. <a href="https://www.jstor.org/stable/2680619">https://www.jstor.org/stable/2680619</a>.
</div>
<div id="ref-nakkiran2021deep" class="csl-entry" role="listitem">
Nakkiran, Preetum, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, and Ilya Sutskever. 2021. <span>“Deep Double Descent: Where Bigger Models and More Data Hurt*.”</span> <em>Journal of Statistical Mechanics: Theory and Experiment</em> 2021 (12): 124003.
</div>
<div id="ref-nareklishvili2023generative" class="csl-entry" role="listitem">
Nareklishvili, Maria, Nicholas Polson, and Vadim Sokolov. 2023. <span>“Generative <span>Causal Inference</span>,”</span> June. <a href="https://arxiv.org/abs/2306.16096">https://arxiv.org/abs/2306.16096</a>.
</div>
<div id="ref-polson2017deep" class="csl-entry" role="listitem">
Polson, Nicholas G, Vadim Sokolov, et al. 2017. <span>“Deep <span>Learning</span>: <span>A Bayesian Perspective</span>.”</span> <em>Bayesian Analysis</em> 12 (4): 1275–1304.
</div>
<div id="ref-polson2021deep" class="csl-entry" role="listitem">
Polson, Nicholas, Vadim Sokolov, and Jianeng Xu. 2021. <span>“Deep <span>Learning Partial Least Squares</span>.”</span> <em>arXiv Preprint arXiv:2106.14085</em>. <a href="https://arxiv.org/abs/2106.14085">https://arxiv.org/abs/2106.14085</a>.
</div>
<div id="ref-schmidt-hieber2021kolmogorov" class="csl-entry" role="listitem">
Schmidt-Hieber, Johannes. 2021. <span>“The <span>Kolmogorov</span>–<span>Arnold</span> Representation Theorem Revisited.”</span> <em>Neural Networks</em> 137 (May): 119–26.
</div>
<div id="ref-tsai2019transformer" class="csl-entry" role="listitem">
Tsai, Yao-Hung Hubert, Shaojie Bai, Makoto Yamada, Louis-Philippe Morency, and Ruslan Salakhutdinov. 2019. <span>“Transformer <span>Dissection</span>: <span>A Unified Understanding</span> of <span>Transformer</span>’s <span>Attention</span> via the <span>Lens</span> of <span>Kernel</span>.”</span> arXiv. <a href="https://arxiv.org/abs/1908.11775">https://arxiv.org/abs/1908.11775</a>.
</div>
<div id="ref-vaswani2023attention" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023. <span>“Attention <span>Is All You Need</span>.”</span> arXiv. <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.
</div>
<div id="ref-watson1964smooth" class="csl-entry" role="listitem">
Watson, Geoffrey S. 1964. <span>“Smooth <span>Regression Analysis</span>.”</span> <em>Sankhy<span>ā</span>: The Indian Journal of Statistics, Series A (1961-2002)</em> 26 (4): 359–72. <a href="https://www.jstor.org/stable/25049340">https://www.jstor.org/stable/25049340</a>.
</div>
<div id="ref-wold1975soft" class="csl-entry" role="listitem">
Wold, Herman. 1975/ed. <span>“Soft <span>Modelling</span> by <span>Latent Variables</span>: <span>The Non-Linear Iterative Partial Least Squares</span> (<span>NIPALS</span>) <span>Approach</span>.”</span> <em>Journal of Applied Probability</em> 12 (S1): 117–42.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./19-nn.html" class="pagination-link" aria-label="Neural Networks">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Neural Networks</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./21-sgd.html" class="pagination-link" aria-label="Gradient Descent">
        <span class="nav-page-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>