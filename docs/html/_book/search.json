[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayes, AI and Deep Learning",
    "section": "",
    "text": "Preface\nWelcome to the fascinating world of Bayesian learning, artificial intelligence, and deep learning! This book is your guide to understanding these powerful tools and their applications in various fields. This book is a culmination of our experiences teaching these exciting fields to two distinct audiences: business school students at the University of Chicago and engineers at George Mason University.\nThis unique blend of perspectives allows us to present these complex concepts in a way that is accessible to both business professionals and technical experts. Whether you’re a manager seeking to leverage AI in your organization or an engineer building the next generation of intelligent systems, this book has something for you.\nTechniques discussed in this book emerged as a transformative force in modern society, and its impact on automation is undeniable. From self-driving cars to virtual assistants, these technologies are already a part of our daily lives. In the coming years, they will become even more ubiquitous, impacting every industry and aspect of our lives. Understanding these technologies is essential for anyone who wants to stay ahead of the curve.\nThrough its ability to learn, adapt, and make decisions, AI is accelerating the pace of automation across various industries and sectors. This impact is multifaceted, encompassing both positive and negative aspects that warrant careful consideration. AI algorithms can analyze vast amounts of data to identify patterns and trends, providing valuable insights for informed decision-making. This leads to better resource allocation, optimized processes, and improved outcomes across various domains. Chatbots and virtual assistants powered by AI can handle customer inquiries and provide support 24/7, offering a personalized and efficient experience. It even works on Jewish holidays! This improves customer satisfaction and loyalty, ultimately benefiting businesses.\nAs a result, AI enables the creation of entirely new business models and industries that were previously not possible. This disrupts traditional markets and creates opportunities for innovation and growth. AI is driving significant progress in fields like self-driving cars, personalized medicine, and space exploration. This has the potential to revolutionize these industries and improve lives in numerous ways.\nThe term AI has morphed over time. It was first coined in 1956 by John McCarthy, who defined it as “the science and engineering of making intelligent machines.” Since then, the field has evolved significantly, and the definition of AI has changed accordingly. Today, AI is a broad field that encompasses various subfields, including machine learning, deep learning, and natural language processing. These subfields are often used interchangeably, but they are not the same thing. Machine learning is a subfield of AI that focuses on algorithms that can learn from data. Deep learning is a subfield of machine learning that uses artificial neural networks to learn complex patterns and relationships in data. Natural language processing is a subfield of AI that focuses on algorithms that can understand and generate human language.\nSince 1956, the field of artificial intelligence (AI) has undergone significant transformations traditional AI was mostly focused on rule-based systems and boolean logic programming, with limited learning capabilities. It lead to them being brittle in changing environments. On the other hand, emerging AI is focused on modeling uncertainties, pattern matching, and deep learning. All of those are data-driven approaches. These approaches are more adaptable and can handle complex and unstructured data. They are also more data-dependent and lack interpretability.\n\n\n\n\n\n\n\n\n\n\n\n\nOld AI\n\n\n\nIf rain outside, then take umbrella\nThis rule cannot be learned from data. It does not allow inference. Cannot say anything about rain outside if I see an umbrella.\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nNew AI\n\n\n\nProbability of taking umbrella, given there is rain\nConditional probability rule can be learned from data. Allows for inference. We can calculate the probability of rain outside if we see an umbrella.\n\n\n\n\n\nThis book is based on the lecture notes from our courses, which have been refined and expanded over years of teaching. We have incorporated valuable feedback from students, both at the University of Chicago and George Mason University, to create a comprehensive and engaging learning experience. This book is organized into three parts:\n\nPart 1: Bayesian Learning: This part covers the basics of probability and Bayesian inference.\nPart 2: Artificial Intelligence: This part explores the core concepts of AI such and mostly focuses on pattern matching techniques such as decision trees and generalized linear models.\nPart 3: Deep Learning: This part delves into the world of deep learning, focusing on the architecture and training of deep neural networks. It covers convolutional neural networks, recurrent neural networks, and generative adversarial networks.\n\nBayesian learning is a powerful statistical framework based on the work of Thomas Bayes. It provides a probabilistic approach to reasoning and learning, allowing us to update our beliefs about the world as we gather new data. This makes it a natural fit for artificial intelligence, where we often need to deal with uncertainty and incomplete information. Artificial intelligence (AI) is a vast field that seeks to create intelligent agents capable of performing tasks that typically require human intelligence. These tasks can include perception, reasoning, learning, problem-solving, decision-making, and language processing. AI has made significant progress in recent years, driven by advances in computing power, data availability, and algorithms. Deep learning is a subfield of AI that uses artificial neural networks to learn from data. These networks are inspired by the structure and function of the human brain and have the ability to learn complex patterns and relationships in data. Deep learning has achieved remarkable results in various tasks such as image recognition, natural language processing, and machine translation.\nThe world of business and engineering are increasingly intertwined, as AI becomes an essential tool in both domains. This book bridges the gap between these disciplines by demonstrating how Bayesian learning, AI, and deep learning can be applied to address real-world challenges in:\n\nBusiness: Market analysis, customer segmentation, risk management, and strategic decision-making.\nEngineering: Robotics, image recognition, natural language processing, and data-driven automation.\n\nKey Features of This Book:\n\nAccessible explanations: We break down complex concepts into manageable chunks, using real-world examples and analogies to illustrate key principles.\nCase studies: We showcase practical applications of Bayesian learning, AI, and deep learning across diverse industries.\nHands-on exercises: We provide practical exercises and code examples to help you apply the concepts covered in the book to your own projects.\n\nJoining the AI Revolution:\nThe field of AI is rapidly evolving, and this book equips you with the knowledge and skills necessary to stay ahead of the curve. Whether you’re looking to enhance your business acumen or advance your engineering career, understanding the power of Bayesian learning, AI, and deep learning is crucial.\nWe invite you to join us on this exciting journey and discover the transformative potential of these powerful tools!",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "qmd/nn.html",
    "href": "qmd/nn.html",
    "title": "1  Neural Networks",
    "section": "",
    "text": "1.1 Introduction\nOur goal is to provide a review of deep learning methods which provide insight into structured high-dimensional data. Rather than using shallow additive architectures common to most statistical models, deep learning uses layers of semi-affine input transformations to provide a predictive rule. Applying these layers of transformations leads to a set of attributes (or, features) to which probabilistic statistical methods can be applied. Thus, the best of both worlds can be achieved: scalable prediction rules fortified with uncertainty quantification, where sparse regularization finds the features.\nDeep learning is one of the widely used machine learning method for analysis of large scale and high-dimensional data sets. Large-scale means that we have many samples (observations) and high dimensional means that each sample is a vector with many entries, usually hundreds and up.\nMachine learning is the engineer’s version of statistical data analysis. Major difference between ML and statistics is that ML focuses on practical aspects, such as computational efficiency and ease of use of techniques. While statistical analysis is more concerned with rigorousness of the analysis and interpretability of the results.\nDeep learning provides a powerful pattern matching tool suitable for many AI applications. Image recognition and text analysis are probably two of the deep learning’s most successful. From a computational perspective, you can think of an image or a text as a high dimensional matrices and vectors, respectively. The problem of recognizing objects in images or translating a text requires designing complex decision boundaries in the high dimensional space of inputs.\nAlthough, image analysis and natural language processing are the applications where deep learning is the dominating approach, more traditional engineering and science applications, such as spatio-temporal and financial analysis is where DL also showed superior performance compared to traditional statistical learning techniques (N. Polson, Sokolov, and Xu 2021; N. G. Polson and Sokolov 2017, 2023; Dixon, Polson, and Sokolov 2019; Heaton, Polson, and Witte 2017; Sokolov 2017; Bhadra et al. 2021, 2021; Behnia, Karbowski, and Sokolov 2021; Nareklishvili, Polson, and Sokolov 2022a, 2022b, 2023; Wang, Polson, and Sokolov 2022; N. Polson and Sokolov 2020)\nThere are several deep learning architectures exist - each has its own uses and purposes. Convolutional Neural Networks (CNN) deal with 2-dimensional input objects, i.e. images and were shown to outperform any other techniques. Recurrent Neural Networks (RNN) were shown the best performance on speech and text analysis tasks.\nIn general, a neural network can be described as follows. Let \\(f_1 , \\ldots , f_L\\) be given univariate activation functions for each of the \\(L\\) layers. Activation functions are nonlinear transformations of weighted data. A semi-affine activation rule is then defined by \\[\nf_l^{W,b} = f_l \\left ( \\sum_{j=1}^{N_l} W_{lj} X_j + b_l \\right ) = f_l ( W_l X_l + b_l )\\,,\n\\] which implicitly needs the specification of the number of hidden units \\(N_l\\). Our deep predictor, given the number of layers \\(L\\), then becomes the composite map\n\\[\n\\hat{Y}(X) = F(X) = \\left ( f_l^{W_1,b_1} \\circ \\ldots \\circ f_L^{W_L,b_L} \\right ) ( X)\\,.\n\\]\nThe fact that DL forms a universal “basis” which we recognize in this formulation dates to Poincare and Hilbert is central. From a practical perspective, given a large enough data set of “test cases”, we can empirically learn an optimal predictor. Similar to a classic basis decomposition, the deep approach uses univariate activation functions to decompose a high dimensional \\(X\\).\nLet \\(Z^{(l)}\\) denote the \\(l\\)th layer, and so \\(X = Z^{(0)}\\). The final output \\(Y\\) can be numeric or categorical. The explicit structure of a deep prediction rule is then \\[\n\\begin{aligned}\n\\hat{Y} (X) & = W^{(L)} Z^{(L)} + b^{(L)} \\\\\nZ^{(1)} & = f^{(1)} \\left ( W^{(0)} X + b^{(0)} \\right ) \\\\\nZ^{(2)} & = f^{(2)} \\left ( W^{(1)} Z^{(1)} + b^{(1)} \\right ) \\\\\n\\ldots  & \\\\\nZ^{(L)} & = f^{(L)} \\left ( W^{(L-1)} Z^{(L-1)} + b^{(L-1)} \\right )\\,.\n\\end{aligned}\n\\] Here \\(W^{(l)}\\) is a weight matrix and \\(b^{(l)}\\) are threshold or activation levels. Designing a good predictor depends crucially on the choice of univariate activation functions \\(f^{(l)}\\). The \\(Z^{(l)}\\) are hidden features which the algorithm will extract.\nPut differently, the deep approach employs hierarchical predictors comprising of a series of \\(L\\) nonlinear transformations applied to \\(X\\). Each of the \\(L\\) transformations is referred to as a layer, where the original input is \\(X\\), the output of the first transformation is the first layer, and so on, with the output \\(\\hat Y\\) as the first layer. The layers \\(1\\) to \\(L\\) are called hidden layers. The number of layers \\(L\\) represents the depth of our routine.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Neural Networks</span>"
    ]
  },
  {
    "objectID": "qmd/nn.html#motivating-example",
    "href": "qmd/nn.html#motivating-example",
    "title": "1  Neural Networks",
    "section": "1.2 Motivating Example",
    "text": "1.2 Motivating Example\nWe will start with applying a feed-forward neural network with one hidden layer to a problem of binary classification on a simulated data set. We start by generating a simple dataset shown in Figure below. The data is generated from a mixture of two distributions (Gaussian and truncated Gaussian). The red points are the positive class and the green points are the negative class. The goal is to find a model boundary that discriminates the two classes.\n\n\n\n\n\n\n\n\n\nLet’s try to use a simple logistic regression model to separate the two classes.\n\n# Fit a logistic regression model\nfit = glm(label~x1+x2, data=as.data.frame(d), family=binomial(link='logit'))\n# Plot the training dataset\nplot(d[,2],d[,3], col=d[,1]+2, pch=16, xlab=\"x1\", ylab=\"x2\")\nth = fit$coefficients\n# Plot the decision boundary\nabline(-th[1]/th[3], -th[2]/th[3], col=2)\n\n\n\n\n\n\n\n\nWe can see that a logistic regression could not do it. It uses a single line to separate observations of two classes. We can see that the data is not linearly separable. However, we can use multiple lines to separate the data.\n\nplot(x1~x2, data=d,col=d[,1]+2, pch=16)\n# Plot lines that separate once class (red) from another (green)\nlines(x1, -x1 - 6); text(-4,-3,1)\nlines(x1, -x1 + 6); text(4,3,2)\nlines(x1,  x1 - 6); text(4,-3,3)\nlines(x1,  x1 + 6); text(-3,4,4)\n\n\n\n\n\n\n\n\nNow, we do the same thing as in simple logistic regression and apply logistic function to each of those lines\n\n# Define sigmoid function\nsigmoid  = function(z) exp(z)/(1+exp(z))\n\n# Define hidden layer of our neural network\nfeatures = function(x1,x2) {\n  z1 =  6 + x1 + x2; a1 = sigmoid(z1)\n  z2 =  6 - x1 - x2; a2 = sigmoid(z2)\n  z3 =  6 - x1 + x2; a3 = sigmoid(z3)\n  z4 =  6 + x1 - x2; a4 = sigmoid(z4)\n  return(c(a1,a2,a3,a4))\n}\n\nUsing the matrix notaitons, we have \\[\nz = \\sigma(Wx + b), ~ W = \\begin{bmatrix} 1 & 1 \\\\ -1 & -1 \\\\ -1 & 1 \\\\ 1 & -1 \\end{bmatrix}, ~ b = \\begin{bmatrix} 6 \\\\ 6 \\\\ 6 \\\\ 6 \\end{bmatrix}, ~ \\sigma(z) = \\frac{1}{1+e^{-z}}\n\\]\nThe model shown above is the first layer of our neural network. It takes a two-dimensional input \\(x\\) and produces a four-dimensional output \\(z\\) which is a called a feature vector. The feature vector is then passed to the output layer, which applies simple logistic regression to the feature vector. \\[\n\\hat{y} = \\sigma(w^Tz + b), ~ w = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}, ~ b = -3.1, ~ \\sigma(z) = \\frac{1}{1+e^{-z}}\n\\]\nThe output of the output layer is the probability of the positive class.\n\n# Calculate prediction (classification) using our neural network\npredict_prob = function(x){\n  x1 = x[1]; x2 = x[2]\n  z = features(x1,x2)\n  # print(z)\n  mu = sum(z) - 3.1\n  # print(mu)\n  sigmoid(mu)\n}\n\nWe can use our model to do the predictions now\n\n# Predict the probability of the positive class for a given point\npredict_prob(c(0,0))\n\n 0.71\n\npredict_prob(c(0,10))\n\n 0.26\n\n\nThe model generates sensible predictions, let’s plot the decision boundary to see how well it separates the data.\n\nx1 = seq(-11,11,length.out = 100)\nx2 = seq(-11,11,length.out = 100)\ngr = as.matrix(expand.grid(x1,x2));\n\n 10000     2\n\nyhat = apply(gr,1,predict_prob)\n\n 10000\n\nimage(x1,x2,matrix(yhat,ncol = 100), col = heat.colors(20,0.7))\n\n\n\n\n\n\n\n\nHow about a regression model. We will use a one-layer neural network to fit a quadratic function. We simulate noisy data from the following model \\[\ny = 0.5 + 0.3x^2 + \\epsilon, ~ \\epsilon \\sim N(0,0.02^2)\n\\] And use 3 hidden units in the first hidden layer and two units in the second hidden layer. The output layer is a single unit. We will use the hyperbolic tangent (tanh) activation function for all layers. The model is defined as follows\n\nrelu = function(x) max(0,x)\nsigmoid  = function(z) exp(z)/(1+exp(z))\nnn = function(W,f=relu) {\n    b0 = W[1]; w0=W[2:4];b1 = W[5]; w1 = W[6:8]\n    z0 = apply(b0 + outer(x,w0,'*'),1:2,f)\n    yhat = b1 + z0 %*% w1\n    return(list(yhat = yhat[,1],z0=z0))\n}\n\nThe hidden layer has three outputs (neurons) and uses the ReLu activation function. The output linear layer has a single output. Thus, the prediction yhat is generated as a linear model of the feature vector z0. The model has 8 parameters Let’s generate training data and fit the model. We will use the BFGS optimization algorithm to minimize the loss function (negative log-likelihood) of the model.\n\nset.seed(99) #gretzky\nnl  = c(3,2)\nparams = c(0,rnorm(3),0,rnorm(3))\nx = seq(-1,1,0.02)\ny = 0.5 + 0.3*x^2 + rnorm(length(x),0,0.02)\nloss = function(W) sum((nn(W)$yhat - y)^2)\nres = optim(params, loss, method='BFGS')\nres$par\n\n -0.24  1.39 -0.82  0.46  0.50  0.17  0.46  0.39\n\n\nThe Figure 1.1 shows the quadratic function and the neural network model. The solid black line is the neural network model, and the dashed lines are the basis functions. The model fits the data well.\n\no = nn(res$par)\nplot(x,y); lines(x,o$yhat, lwd=2)\nlines(x,0.5+o$z0[,1],col=2, lwd=2, lty=2); lines(x,0.5+o$z0[,2],col=3, lwd=2, lty=2); lines(x,0.5+o$z0[,3],col=4, lwd=2, lty=2)\n\n\n\n\n\n\n\nFigure 1.1: Plot\n\n\n\n\n\nLet’s try the sigmoid function\n\nparams = c(0,rnorm(3),0,rnorm(3))\nloss = function(W) sum((nn(W,f=sigmoid)$yhat - y)^2)\nres = optim(params, loss, method='BFGS')\nres$par\n\n  1.84 -1.61  0.29  2.05 -0.22 -1.13  3.24 -1.28\n\no = nn(res$par, f=sigmoid)\nplot(x,y, ylim=c(0.4,0.95)); lines(x,o$yhat, lwd=2);\nlines(x,o$z0[,1], lwd=2, lty=2, col=2); lines(x,o$z0[,2], lwd=2, lty=2, col=2); lines(x,o$z0[,3], lwd=2, lty=2, col=2)\n\n\n\n\n\n\n\n\nNotice that we did not have to explicitly specify that our model need to have a quadratic term, the model learned it from the data. This is the power of deep learning. The model is able to learn the structure of the data from the data itself.\nWe can apply the same approach to the interactions, say the true model for the data as follows \\[\ny = 0.5 + 0.1x_1 + 0.2x_2  + 0.5x_1x_2+ \\epsilon, ~ \\epsilon \\sim N(0,0.02^2)\n\\] We can use the same model as above, but with two input variables. The model will learn the interaction term from the data.\n\nset.seed(99) #ovi\nx1 = seq(-1,1,0.01)\nx2 = x1\ny = 0.5 + 0.1*x1 + 0.2*x2 + 0.5*x1*x2 + rnorm(length(x1),0,0.02)\nlibrary(\"scatterplot3d\")\ns3d = scatterplot3d(x1,x2,y, pch=16)\nx = cbind(x1,x2)\nnn = function(W,f=relu) {\n    b0 = W[1]; w0 = W[2:5]; b1 = W[6]; w1 = W[7:8]\n    w0 = matrix(w0,nrow=2)\n    z0 = apply(b0 + x%*%w0,1:2,f)\n    yhat = b1 + z0 %*% w1\n    return(list(yhat = yhat[,1],z0=z0))\n}\nW = c(0,rnorm(4),0,rnorm(2))\nloss = function(W) sum((nn(W, f=sigmoid)$yhat - y)^2)\nres = optim(W, fn=loss, method='BFGS')\nres$par\n\n  1.585 -0.023 -1.919  0.450 -1.121 -4.929 -4.996 11.526\n\no = nn(res$par, f=sigmoid)\ns3d$points3d(x1,x2,o$yhat, col=2, type='l', lwd=5)\ns3d$points3d(x1,x2,o$z0[,1], col=3, type='l', lwd=5)\ns3d$points3d(x1,x2,o$z0[,2], col=4, type='l', lwd=5)\n\n\n\n\n\n\n\n\nEffectively, you can think of the neural network as a flexible function approximator, equivalent to a nonparametric regression approach which learns the basis functions from data. The model can learn the structure of the data from the data itself. This is the power of deep learning.\n\n\n\n\nBehnia, Farnaz, Dominik Karbowski, and Vadim Sokolov. 2021. “Deep Generative Models for Vehicle Speed Trajectories.” arXiv Preprint arXiv:2112.08361.\n\n\nBhadra, Anindya, Jyotishka Datta, Nick Polson, Vadim Sokolov, and Jianeng Xu. 2021. “Merging Two Cultures: Deep and Statistical Learning.” arXiv Preprint arXiv:2110.11561.\n\n\nDixon, Matthew F, Nicholas G Polson, and Vadim O Sokolov. 2019. “Deep Learning for Spatio-Temporal Modeling: Dynamic Traffic Flows and High Frequency Trading.” Applied Stochastic Models in Business and Industry 35 (3): 788–807.\n\n\nHeaton, JB, NG Polson, and Jan Hendrik Witte. 2017. “Deep Learning for Finance: Deep Portfolios.” Applied Stochastic Models in Business and Industry 33 (1): 3–12.\n\n\nNareklishvili, Maria, Nicholas Polson, and Vadim Sokolov. 2022a. “Deep Partial Least Squares for Iv Regression.” arXiv Preprint arXiv:2207.02612.\n\n\n———. 2022b. “Feature Selection for Personalized Policy Analysis.” arXiv Preprint arXiv:2301.00251.\n\n\n———. 2023. “Generative Causal Inference.” arXiv Preprint arXiv:2306.16096.\n\n\nPolson, Nicholas G, and Vadim Sokolov. 2017. “Deep Learning: A Bayesian Perspective.”\n\n\n———. 2023. “Generative AI for Bayesian Computation.” arXiv Preprint arXiv:2305.14972.\n\n\nPolson, Nicholas, and Vadim Sokolov. 2020. “Deep Learning: Computational Aspects.” Wiley Interdisciplinary Reviews: Computational Statistics 12 (5): e1500.\n\n\nPolson, Nicholas, Vadim Sokolov, and Jianeng Xu. 2021. “Deep Learning Partial Least Squares.” arXiv Preprint arXiv:2106.14085.\n\n\nSokolov, Vadim. 2017. “Discussion of ’Deep Learning for Finance: Deep Portfolios’.” Applied Stochastic Models in Business and Industry 33 (1): 16–18.\n\n\nWang, Yuexi, Nicholas Polson, and Vadim O Sokolov. 2022. “Data Augmentation for Bayesian Deep Learning.” Bayesian Analysis 1 (1): 1–29.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Neural Networks</span>"
    ]
  },
  {
    "objectID": "qmd/dlopt.html",
    "href": "qmd/dlopt.html",
    "title": "2  Gradient Descent",
    "section": "",
    "text": "2.1 Deep Learning and Least Squares\nThe deep learning model approximates the relation between inputs \\(x\\) and outputs \\(y\\) using a non-linear function \\(f(x,\\theta)\\), where \\(\\theta\\) is a vector of parameters. The goal is to find the optimal value of \\(\\theta\\) that minimizes the expected loss function, given a training data set \\(D = \\{x_i,y_i\\}_{i=1}^n\\). The loss function is a measure of discrepancy between the true value of \\(y\\) and the predicted value \\(f(x,\\theta)\\). The loss function is usually defined as the negative log-likelihood function of the model. \\[\n    l(\\theta) = - \\sum_{i=1}^n \\log p(y_i | x_i, \\theta),\n\\] where \\(p(y_i | x_i, \\theta)\\) is the conditional distribution of \\(y_i\\) given \\(x_i\\) and \\(\\theta\\). Thus, in the case of regression, we have \\[\n  y_i = f(x_i,\\theta) + \\epsilon, ~ \\epsilon \\sim N(0,\\sigma^2),\n\\] Thus, the loss function is \\[\n    l(\\theta) = - \\sum_{i=1}^n \\log p(y_i | x_i, \\theta) = \\sum_{i=1}^n (y_i - f(x_i, \\theta))^2,\n\\]",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Gradient Descent</span>"
    ]
  },
  {
    "objectID": "qmd/dlopt.html#regression",
    "href": "qmd/dlopt.html#regression",
    "title": "2  Gradient Descent",
    "section": "2.2 Regression",
    "text": "2.2 Regression\nRegression is simply a neural network which is wide and shallow. The insight of DL is that you use a deep and shallow neural network. Let’s look at a simple example and fit a linear regression model to iris dataset.\n\ndata(iris)\ny = iris$Petal.Length\nloss = function(theta) sum((y - x %*% theta)^2)\ngrad = function(theta) -2 * t(x) %*% (y - x %*% theta)\nres = optim(c(0,0), loss, grad, method=\"BFGS\")\ntheta = res$par\n\nOur loss minimization algorithm finds the following coefficients\n\n\n\n\n\nIntercept (\\(\\theta_1\\))\nPetal.Width (\\(\\theta_2\\))\n\n\n\n\n1.083558\n2.22994\n\n\n\n\n\nLet’s plot the data and model estimated using gradient descent\n\nplot(x[,2],y,pch=16, xlab=\"Petal.Width\")\nabline(theta[2],theta[1], lwd=3,col=\"red\")\n\n\n\n\n\n\n\n\nLet’s compare it to the standard estimation algorithm\n\nm = lm(Petal.Length~Petal.Width, data=iris)\n\n\n\n\n(Intercept)\nPetal.Width\n\n\n\n\n1.083558\n2.22994\n\n\n\n\n\nThe values found by gradient descent are very close to the ones found by the standard OLS algorithm.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Gradient Descent</span>"
    ]
  },
  {
    "objectID": "qmd/dlopt.html#logistic-regression",
    "href": "qmd/dlopt.html#logistic-regression",
    "title": "2  Gradient Descent",
    "section": "2.3 Logistic Regression",
    "text": "2.3 Logistic Regression\nLogistic regression is a generalized linear model (GLM) with a logit link function, defined as: \\[\n    \\log \\left(\\frac{p}{1-p}\\right) = \\theta_0 + \\theta_1 x_1 + \\ldots + \\theta_p x_p,\n\\] where \\(p\\) is the probability of the positive class. The negative log-likelihood function for logistic regression is a cross-entropy loss \\[\n    l(\\theta) = - \\sum_{i=1}^n \\left[ y_i \\log p_i + (1-y_i) \\log (1-p_i) \\right],\n\\] where \\(p_i = 1/\\left(1 + \\exp(-\\theta_0 - \\theta_1 x_{i1} - \\ldots - \\theta_p x_{ip})\\right)\\). The derivative of the negative log-likelihood function is \\[\n    \\nabla l(\\theta) = - \\sum_{i=1}^n \\left[ y_i - p_i \\right] \\begin{pmatrix} 1 \\\\ x_{i1} \\\\ \\vdots \\\\ x_{ip} \\end{pmatrix}.\n\\] In matrix notations, we have \\[\n    \\nabla l(\\theta) = - X^T (y - p).\n\\] Let’s implement gradient descent algorithm now.\n\ny = ifelse(iris$Species==\"setosa\",1,0)\nx = cbind(rep(1,150),iris$Sepal.Length)\nlrgd  = function(x,y, alpha, n_iter) {\n  theta &lt;- matrix(c(0, 0), nrow = 2, ncol = 1)\n  for (i in 1:n_iter) {\n    # compute gradient\n    p = 1/(1+exp(-x %*% theta))\n    grad &lt;- -t(x) %*% (y - p)\n    # update theta\n    theta &lt;- theta - alpha * grad\n  }\n  return(theta)\n}\ntheta = lrgd(x,y,0.005,20000)\n\nThe gradient descent parameters are\n\n\n\n\n\nIntercept (\\(\\theta_1\\))\nSepal.Length (\\(\\theta_2\\))\n\n\n\n\n27.74433\n-5.160146\n\n\n\n\n\nAnd the plot is\n\npar(mar=c(4,4,0,0), bty='n')\nplot(x[,2],y,pch=16, xlab=\"Sepal.Length\")\nlines(x[,2],p,type='p', pch=16,col=\"red\")\n\n\n\n\n\n\n\n\nLet’s compare it to the standard estimation algorithm\n\nglm(y~x-1, family=binomial(link=\"logit\"))\n\n## \n## Call:  glm(formula = y ~ x - 1, family = binomial(link = \"logit\"))\n## \n## Coefficients:\n##     x1      x2  \n## 27.829  -5.176  \n## \n## Degrees of Freedom: 150 Total (i.e. Null);  148 Residual\n## Null Deviance:       207.9 \n## Residual Deviance: 71.84     AIC: 75.84\n\n\nNow, we demonstrate the gradient descent for estimating a generalized linear model (GLM), namely logistic regression. We will use the iris data set again and try to predict the species of the flower using the petal width as a predictor. We will use the following model \\[\n    \\log \\left(\\frac{p_i}{1-p_i}\\right) = \\theta_0 + \\theta_1 x_i,\n\\] where \\(p_i = P(y_i = 1)\\) is the probability of the flower being of the species \\(y_i = 1\\) (setosa).\nThe negative log-likelihood function for logistic regression model is \\[\n    l(\\theta) = - \\sum_{i=1}^n \\left[ y_i \\log p_i + (1-y_i) \\log (1-p_i) \\right],\n\\] where \\(p_i = 1/\\left(1 + \\exp(-\\theta_0 - \\theta_1 x_i)\\right)\\). The derivative of the negative log-likelihood function is \\[\n    \\nabla l(\\theta) = - \\sum_{i=1}^n \\left[ y_i - p_i \\right] \\begin{pmatrix} 1 \\\\ x_i \\end{pmatrix}.\n\\] In matrix notations, we have \\[\n    \\nabla l(\\theta) = - X^T (y - p).\n\\]",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Gradient Descent</span>"
    ]
  },
  {
    "objectID": "qmd/dlopt.html#stochastic-gradient-descent",
    "href": "qmd/dlopt.html#stochastic-gradient-descent",
    "title": "2  Gradient Descent",
    "section": "2.4 Stochastic Gradient Descent",
    "text": "2.4 Stochastic Gradient Descent\nStochastic gradient descent (SGD) is a variant of the gradient descent algorithm. The main difference is that instead of computing the gradient over the whole data set, SGD computes the gradient over a randomly selected subset of the data. This allows SGD to be applied to estimate models when data set is too large to fit into memory, which is often the case with the deep learning models. The SGD algorithm replaces the gradient of the negative log-likelihood function with the gradient of the negative log-likelihood function computed over a randomly selected subset of the data \\[\n    \\nabla l(\\theta) \\approx \\dfrac{1}{|B|} \\sum_{i \\in B} \\nabla l(y_i, f(x_i, \\theta)),\n\\] where \\(B \\in \\{1,2,\\ldots,n\\}\\) is the batch samples from the data set. This method can be interpreted as gradient descent using noisy gradients, which are typically called mini-batch gradients with batch size \\(|B|\\).\nThe SGD is based on the idea of stochastic approximation introduced by Robbins and Monro (1951). Stochastic simply replaces \\(F(l)\\) with its Monte Carlo approximation.\nIn a small mini-batch regime, when \\(|B| \\ll n\\) and typically \\(|B| \\in \\{32,64,\\ldots,1024\\}\\) it was shown that SGD converges faster than the standard gradient descent algorithm, it does converge to minimizers of strongly convex functions (negative log-likelihood function from exponential family is strongly convex) (Bottou, Curtis, and Nocedal 2018) and it is more robust to noise in the data (Hardt, Recht, and Singer 2016). Further, it was shown that it can avoid saddle-points, which is often an issue with deep learning log-likelihood functions. In the case of multiple-minima, SGD can find a good solution LeCun et al. (2002), meaning that the out-of-sample performance is often worse when trained with large- batch methods as compared to small-batch methods.\nNow, we implement SGD for logistic regression and compare performance for different batch sizes \n\nlrgd_minibatch  = function(x,y, alpha, n_iter, bs) {\n  theta &lt;- matrix(c(0, 0), nrow = 2, ncol = n_iter+1)\n  n = length(y)\n  for (i in 1:n_iter) {\n    s = ((i-1)*bs+1)%%n\n    e = min(s+bs-1,n)\n    xl = x[s:e,]; yl = y[s:e]\n    p = 1/(1+exp(-xl %*% theta[,i]))\n    grad &lt;- -t(xl) %*% (yl - p)\n    # update theta\n    theta[,i+1] &lt;- theta[,i] - alpha * grad\n  }\n  return(theta)\n}\n\nNow run our SGD algorithm with different batch sizes.\n\nset.seed(92) # kuzy\nind = sample(150)\ny = ifelse(iris$Species==\"setosa\",1,0)[ind] # shuffle data\nx = cbind(rep(1,150),iris$Sepal.Length)[ind,] # shuffle data\nnit=200000\nlr = 0.01\nth1 = lrgd_minibatch(x,y,lr,nit,5)\nth2 = lrgd_minibatch(x,y,lr,nit,15)\nth3 = lrgd_minibatch(x,y,lr,nit,30)\n\n\n\n\n\n\n\n\nWe run it with 2^{5} iterations and the learning rate of 0.01 and plot the values of \\(\\theta_1\\) every 1000 iteration. There are a couple of important points we need to highlight when using SGD. First, we shuffle the data before using it. The reason is that if the data is sorted in any way (e.g. by date or by value of one of the inputs), then data within batches can be highly correlated, which reduces the convergence speed. Shuffling helps avoiding this issue. Second, the larger the batch size, the smaller number of iterations are required for convergence, which is something we would expect. However, in this specific example, from the number of computation point of view, the batch size does not change the number calculations required overall. Let’s look at the same plot, but scale the x-axis according to the amount of computations\n\nplot(ind/1000,th1[1,ind], type='l', ylim=c(0,33), col=1, ylab=expression(theta[1]), xlab=\"Iteration\")\nabline(h=27.83, lty=2)\nlines(ind/1000*3,th2[1,ind], type='l', col=2)\nlines(ind/1000*6,th3[1,ind], type='l', col=3)\nlegend(\"bottomright\", legend=c(5,15,30),col=1:3, lty=1, bty='n',title = \"Batch Size\")\n\n\n\n\n\n\n\n\nThere are several important considerations about choosing the batch size for SGD.\n\nThe larger the batch size, the more memory is required to store the data.\nParallelization is more efficient with larger batch sizes. Modern harware supports parallelization of matrix operations, which is the main operation in SGD. The larger the batch size, the more efficient the parallelization is. Usually there is a sweet spot \\(|B|\\) for the batch size, which is the largest batch size that can fit into the memory or parallelized. Meaning it takes the same amount of time to compute SGD step for batch size \\(1\\) and \\(B\\).\nThird, the larger the batch size, the less noise in the gradient. This means that the larger the batch size, the more accurate the gradient is. However, it was empirically shown that in many applications we should prefer noisier gradients (small batches) to obtain high quality solutions when the objective function (negative log-likelihood) is non-convex (Keskar et al. 2016).\n\nDeep learning estimation problem as well as a large number of statistical problems, can be expressed in the form \\[\n\\min l(x) + \\phi(x).\n\\] In learning \\(l(x)\\) is the negative log-likelihood and \\(\\phi(x)\\) is a penalty function that regularizes the estimate. From the Bayesian perspective, the solution to this problem may be interpreted as a maximum a posteriori \\[p(y\\mid x) \\propto \\exp\\{-l(x)\\}, ~ p(x) \\propto \\exp\\{-\\phi(x)\\}.\\]\nSecond order optimisation algorithms, such as BFGS used for traditional statistical models do not work well for deep learning models. The reason is that the number of parameters a DL model has is large and estimating second order derivatives (Hessian or Fisher information matrix) becomes prohibitive from both computational and memory use standpoints. Instead, first order gradient descent methods are used for estimating parameters of a deep learning models.\nThe problem of parameter estimation (when likelihood belongs to the exponential family) is an optimisation problem\n\\[\n    \\min_{\\theta} l(\\theta) := \\dfrac{1}{n} \\sum_{i=1}^n \\log p(y_i, f(x_i, \\theta))\n\\] where \\(l\\) is the negative log-likelihood of a sample, and \\(\\theta\\) is the vector of parameters. The gradient descent method is an iterative algorithm that starts with an initial guess \\(\\theta^{0}\\) and then updates the parameter vector \\(\\theta\\) at each iteration \\(t\\) as follows: \\[\n    \\theta^{t+1} = \\theta^t - \\alpha_t \\nabla l(\\theta^t).\n\\]\nLet’s demonstrate these algorithms on a simple example of linear regression. We will use the mtcars data set and try to predict the fuel consumption (mpg) \\(y\\) using the number of cylinders (cyl) as a predictor \\(x\\). We will use the following model: \\[\n    y_i = \\theta_0 + \\theta_1 x_i + \\epsilon_i,\n\\] or in matrix form \\[\n    y = X \\theta + \\epsilon,\n\\] where \\(\\epsilon_i \\sim N(0, \\sigma^2)\\), \\(X = [1 ~ x]\\) is the design matrix with first column beign all ones.\nThe negative log-likelihood function for the linear regression model is \\[\n    l(\\theta) = \\sum_{i=1}^n (y_i - \\theta_0 - \\theta_1 x_i)^2.\n\\]\nThe gradient then is \\[\n    \\nabla l(\\theta) = -2 \\sum_{i=1}^n (y_i - \\theta_0 - \\theta_1 x_i) \\begin{pmatrix} 1 \\\\ x_i \\end{pmatrix}.\n\\] In matrix form, we have \\[\n    \\nabla l(\\theta) = -2 X^T (y - X \\theta).   \n\\]",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Gradient Descent</span>"
    ]
  },
  {
    "objectID": "qmd/dlopt.html#automatic-differentiation-backpropagation",
    "href": "qmd/dlopt.html#automatic-differentiation-backpropagation",
    "title": "2  Gradient Descent",
    "section": "2.5 Automatic Differentiation (Backpropagation)",
    "text": "2.5 Automatic Differentiation (Backpropagation)\nTo calculate the value of the gradient vector, at each step of the optimization process, deep learning libraries require calculations of derivatives. In general, there are three different ways to calculate those derivatives. First, is numerical differentiation, when a gradient is approximated by a finite difference \\(f'(x) = (f(x+h)-f(x))/h\\) and requires two function evaluations. However, the numerical differentiation is not backward stable (Griewank, Kulshreshtha, and Walther 2012), meaning that for a small perturbation in input value \\(x\\), the calculated derivative is not the correct one. Second, is a symbolic differentiation which has been used in symbolic computational frameworks such as Mathematica or Maple for decades. Symbolic differentiation uses a tree form representation of a function and applies chain rule to the tree to calculate the symbolic derivative of a given function. Figure @ref(fig:comp-graph) shows a tree representation of of composition of affine and sigmoid functions (the first layer of our neural network).\n\n\n\nComputational graph of the first layer of our neural network\n\n\nThe advantage of symbolic calculations is that the analytical representation of derivative is available for further analysis. For example, when derivative calculation is in an intermediate step of the analysis. Third way to calculate a derivative is to use automatic differentiation (AD). Similar to symbolic differentiation, AD recursively applies the chain rule and calculates the exact value of derivative and thus avoids the problem of numerical instability. The difference between AD and symbolic differentiation is that AD provides the value of derivative evaluated at a specific point, rather than an analytical representation of the derivative.\nAD does not require analytical specification and can be applied to a function defined by a sequence of algebraic manipulations, logical and transient functions applied to input variables and specified in a computer code. AD can differentiate complex functions which involve IF statements and loops, and AD can be implemented using either forward or backward mode. Consider an example of calculating a derivative of the following function with respect to x.\n\nsigmoid = function(x,b,w){\n  v1 = w*x;\n  v2 = v1 + b\n  v3 = 1/(1+exp(-v2))\n}\n\nIn the forward mode an auxiliary variable, called a dual number, will be added to each line of the code to track the value of the derivative associated with this line. In our example, if we set x=2, w=3, b=52, we get the calculations given in Table below.\n\n\n\n\n\n\n\nFunction calculations\nDerivative calculations\n\n\n\n\n1. v1 = w*x = 6\n1. dv1 = w = 3 (derivative of v1 with respect to x)\n\n\n2. v2 = v1 + b = 11\n2. dv2 = dv1 = 3 (derivative of v2 with respect to x)\n\n\n3. v3 = 1/(1+exp(-v2)) = 0.99\n3. dv3 = eps2*exp(-v2)/(1+exp(-v2))**2  = 5e-05\n\n\n\nVariables dv1,dv2,dv3 correspond to partial (local) derivatives of each intermediate variables v1,v2,v3 with respect to \\(x\\), and are called dual variables. Tracking for dual variables can either be implemented using source code modification tools that add new code for calculating the dual numbers or via operator overloading.\nThe reverse AD also applies chain rule recursively but starts from the outer function, as shown in Table below.\n\n\n\n\n\n\n\nFunction calculations\nDerivative calculations\n\n\n\n\n1. v1 = w*x = 6\n4. dv1dx =w; dv1 = dv2*dv1dx = 3*1.3e-05=5e-05\n\n\n2. v2 = v1 + b = 11\n3. dv2dv1 =1; dv2 = dv3*dv2dv1 = 1.3e-05\n\n\n3. v3 = 1/(1+exp(-v2)) = 0.99\n2. dv3dv2 = exp(-v2)/(1+exp(-v2))**2;\n\n\n4. v4 = v3\n1. dv4=1\n\n\n\nFor DL, derivatives are calculated by applying reverse AD algorithm to a model which is defined as a superposition of functions. A model is defined either using a general purpose language as it is done in PyTorch or through a sequence of function calls defined by framework libraries (e.g. in TensorFlow). Forward AD algorithms calculate the derivative with respect to a single input variable, but reverse AD produces derivatives with respect to all intermediate variables. For models with many parameters, it is much more computationally feasible to perform the reverse AD.\nIn the context of neural networks, the reverse AD algorithms is called back-propagation and was popularized in AI by Rumelhart, Hinton, and Williams (1986). According to Schmidhuber (2015) the first version of what we call today back-propagation was published in 1970 in a master’s thesis Linnainmaa (1970) and was closely related to the work of Ostrovskii, Volin, and Borisov (1971). However, similar techniques rooted in Pontryagin’s maximization principle Boltyanskii, Gamkrelidze, and Pontryagin (1960) were discussed in the context of multi-stage control problems Bryson (1961),bryson1969applied}. Dreyfus (1962) applies back-propagation to calculate the first order derivative of a return function to numerically solve a variational problem. Later Dreyfus (1973) used back-propagation to derive an efficient algorithm to solve a minimization problem. The first neural network specific version of back-propagation was proposed in P. Werbos (1974) and an efficient back-propagation algorithm was discussed in P. J. Werbos (1982).\nModern deep learning frameworks fully automate the process of finding derivatives using AD algorithms. For example, PyTorch relies on autograd library which automatically finds gradient using back-propagation algorithm. Here is a small code example using autograd library in jax.\n\nimport jax.numpy as jnp\nfrom jax import grad,jit\nimport pandas as pd\nfrom jax import random\nimport matplotlib.pyplot as plt\n\ndef abline(slope, intercept):\n    \"\"\"Plot a line from slope and intercept\"\"\"\n    axes = plt.gca()\n    x_vals = jnp.array(axes.get_xlim())\n    ylim = axes.get_xlim()\n    y_vals = intercept + slope * x_vals\n    plt.plot(x_vals, y_vals, '-'); plt.ylim(ylim)\n\nd = pd.read_csv('../../data/circle.csv').values\nx = d[:, 1:3]; y = d[:, 0]\ndef sigmoid(x):\n    return 1 / (1 + jnp.exp(-x))\ndef predict(x, w1,b1,w2,b2):\n    z = sigmoid(jnp.dot(x, w1)+b1)\n    return sigmoid(jnp.dot(z, w2)+b2)[:,0]\ndef nll(x, y, w1,b1,w2,b2):\n    yhat = predict(x, w1,b1,w2,b2)\n    return -jnp.sum(y * jnp.log(yhat) + (1 - y) * jnp.log(1 - yhat))\n@jit\ndef sgd_step(x, y, w1,b1,w2,b2, lr):\n    grads = grad(nll,argnums=[2,3,4,5])(x, y, w1,b1,w2,b2)\n    return w1 - lr * grads[0],b1 - lr * grads[1],w2 - lr * grads[2],b2 - lr * grads[3]\ndef accuracy(x, y, w1,b1,w2,b2):\n    y_pred = predict(x, w1,b1,w2,b2)\n    return jnp.mean((y_pred &gt; 0.5) == y)\nk = random.PRNGKey(0)\nw1 = 0.1*random.normal(k,(2,4))\nb1 = 0.01*random.normal(k,(4,))\nw2 = 0.1*random.normal(k,(4,1))\nb2 = 0.01*random.normal(k,(1,))\n\nfor i in range(1000):\n    w1,b1,w2,b2 = sgd_step(x,y,w1,b1,w2,b2,0.003)\nprint(accuracy(x,y,w1,b1,w2,b2))\n\n## 1.0\n\nfig, ax = plt.subplots()\nax.scatter(x[:,0], x[:,1], c=['r' if x==1 else 'g' for x in y],s=7); plt.xlabel(\"x1\"); plt.ylabel(\"x2\"); plt.xlim(-10,10)\n\n## &lt;matplotlib.collections.PathCollection object at 0x3032cef40&gt;\n## Text(0.5, 0, 'x1')\n## Text(0, 0.5, 'x2')\n## (-10.0, 10.0)\n\nax.spines['top'].set_visible(False)\n# plt.scatter((x[:,1]*w1[1,0] - b1[0])/w1[0,0], x[:,1])\nabline(w1[1,0]/w1[0,0],b1[0]/w1[0,0])\nabline(w1[1,1]/w1[0,1],b1[1]/w1[0,1])\nabline(w1[1,2]/w1[0,2],b1[2]/w1[0,2])\nabline(w1[1,3]/w1[0,3],b1[3]/w1[0,3])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nBoltyanskii, V. G., R. V. Gamkrelidze, and Pontryagin. 1960. “Theory of Optimal Processes i: Maximum Principle.” News of Akad. Nauk SSSR. Mathematics Series 24: 3–42.\n\n\nBottou, Léon, Frank E Curtis, and Jorge Nocedal. 2018. “Optimization Methods for Large-Scale Machine Learning.” SIAM Review 60 (2): 223–311.\n\n\nBryson, Arthur E. 1961. “A Gradient Method for Optimizing Multi-Stage Allocation Processes.” In Proc. Harvard Univ. Symposium on Digital Computers and Their Applications. Vol. 72.\n\n\nDreyfus, Stuart. 1962. “The Numerical Solution of Variational Problems.” Journal of Mathematical Analysis and Applications 5 (1): 30–45.\n\n\n———. 1973. “The Computational Solution of Optimal Control Problems with Time Lag.” IEEE Transactions on Automatic Control 18 (4): 383–85.\n\n\nGriewank, Andreas, Kshitij Kulshreshtha, and Andrea Walther. 2012. “On the Numerical Stability of Algorithmic Differentiation.” Computing 94 (2-4): 125–49.\n\n\nHardt, Moritz, Ben Recht, and Yoram Singer. 2016. “Train Faster, Generalize Better: Stability of Stochastic Gradient Descent.” In International Conference on Machine Learning, 1225–34. PMLR.\n\n\nKeskar, Nitish Shirish, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. 2016. “On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima.” arXiv Preprint arXiv:1609.04836.\n\n\nLeCun, Yann, Léon Bottou, Genevieve B Orr, and Klaus-Robert Müller. 2002. “Efficient Backprop.” In Neural Networks: Tricks of the Trade, 9–50. Springer.\n\n\nLinnainmaa, Seppo. 1970. “The Representation of the Cumulative Rounding Error of an Algorithm as a Taylor Expansion of the Local Rounding Errors.” Master’s Thesis (in Finnish), Univ. Helsinki, 6–7.\n\n\nOstrovskii, GM, Yu M Volin, and WW Borisov. 1971. “Uber Die Berechnung von Ableitungen.” Wissenschaftliche Zeitschrift Der Technischen Hochschule f Ur Chemie, Leuna-Merseburg 13 (4): 382–84.\n\n\nRobbins, Herbert, and Sutton Monro. 1951. “A Stochastic Approximation Method.” The Annals of Mathematical Statistics 22 (3): 400–407. https://doi.org/10.1214/aoms/1177729586.\n\n\nRumelhart, David E, Geoffrey E Hinton, and Ronald J Williams. 1986. “Learning Representations by Back-Propagating Errors.” Nature 323 (6088): 533.\n\n\nSchmidhuber, Jürgen. 2015. “Deep Learning in Neural Networks: An Overview.” Neural Networks 61: 85–117.\n\n\nWerbos, Paul. 1974. “Beyond Regression:\" New Tools for Prediction and Analysis in the Behavioral Sciences.” Ph. D. Dissertation, Harvard University.\n\n\nWerbos, Paul J. 1982. “Applications of Advances in Nonlinear Sensitivity Analysis.” In System Modeling and Optimization, 762–70. Springer.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Gradient Descent</span>"
    ]
  },
  {
    "objectID": "qmd/arch.html",
    "href": "qmd/arch.html",
    "title": "3  Image Processing",
    "section": "",
    "text": "3.1 Convolutions\nUsing a fully connected neural network to classify images has some limitations. The main limitation is that it does not take into account the spatial structure of the image and treats each pixel independently. As a result, it does not perform well on real-life images and have a large number of parameters. Images have a spatial structure, and the spatial structure contains important information that can be used to improve classification accuracy. For example, it is not unusual to find that the same element can appear in different parts of the image. For example background with a solid color or a specific texture, such as a grass or a sky.\nApplying a filter to an image is a way to extract features from the image. A filter is a small matrix that is used to extract features from the image. The filter is applied to the image by sliding it over the image and computing the dot product at each position. The result is a new image that contains the features extracted by the filter. The filter is also called a kernel. The size of the filter is called the kernel size. The kernel size is usually an odd number, such as 3x3 or 5x5. The kernel size determines the receptive field of the filter. The receptive field is the region of the input image that is used to compute the output. The stride is the number of pixels by which the filter is shifted at each step. The stride determines the size of the output image. The process of convolving a filter with an image is called a convolution operation and it is similar to the approach used by kernel smoothing in statistics.\nLet’s look at a one-dimensional example. Suppose we have a one-dimensional input signal \\(x\\) and a one-dimensional filter \\(w\\). The convolution of \\(x\\) and \\(w\\) is defined as follows: \\[\n(x*w)(t) = \\sum_{i=0}^{h}x(t+i)w(i),\n\\] where \\(h\\) is the size of the filter. The convolution operation is used to filter the input signal.\nimport matplotlib.pyplot as plt\n\nfrom jax import random\nimport jax.numpy as jnp\nimport numpy as np\n\nkey = random.PRNGKey(1701)\n\nx = jnp.linspace(0, 10, 500)\ny = jnp.sin(x) + 0.2 * random.normal(key, shape=(500,))\n\nwindow = jnp.ones(10) / 10\ny_smooth = jnp.convolve(y, window, mode='same')\n\nplt.plot(x, y, 'lightgray')\n\n[&lt;matplotlib.lines.Line2D object at 0x32aff45e0&gt;]\n\nplt.plot(x, y_smooth, 'black');\nWe will demonstrate the concept using a simple example, where we have a 5x5 image and a 3x3 filter. We need to classify each image into one of the tree classes: cross, diagonal, right-diagonal\nThe filter is applied to the image by sliding it over the image and computing the dot product at each position. The result is a new image that contains the features extracted by the filter. The filter is also called a kernel. The size of the filter is called the kernel size. The kernel size is usually an odd number, such as 3x3 or 5x5. The kernel size determines the receptive field of the filter. The receptive field is the region of the input image that is used to compute the output. The stride is the number of pixels by which the filter is shifted at each step. The stride determines the size of the output image. The process of convolving a filter with an image is called a convolution operation.\nWe will use two filters.\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n\n\n[[0. 0. 1.]\n [0. 1. 0.]\n [1. 0. 0.]]\nThe first filter designed to detect a diagonal line from the top left to the bottom right. The second filter is designed to detect a diagonal line from the top right to the bottom left. We will apply the filters to the cross image and the diagonal image.\n[[3. 0. 1.]\n [0. 3. 0.]\n [1. 0. 3.]]\n[[1. 0. 3.]\n [0. 3. 0.]\n [3. 0. 1.]]\nWe see that on both outputs, we have pixels with high values. However, when we apply the same two filters to the diagonal image, we get different results.\nThe result of applying the second filter to the diagonal image is a close to zero matrix. This is because the filter is designed to detect a diagonal line from the top right to the bottom left, and the diagonal image does not contain such a line. We use this observation design the next layer of our networks, which is a pooing layer. The simplest one is the max-pool that simply calculates returns the pixel with the highest value in the receptive field. Finally, we concatinate the outputs of the pooling layer and apply a fully connected layer to classify the image. Let’s compare the predictions for three images.\nzrd, outrd1, outrd2 = cnn(imgrd,f1,f2)\nprint(f'Cross: {zx}')\n\nCross: [0.26163495 0.26163495 0.47673005]\n\nprint(f'Diagonal: {zd}')\n\nDiagonal: [0.5937724  0.08035836 0.32586923]\n\nprint(f'Right-Diagonal: {zrd}')\n\nRight-Diagonal: [0.08035836 0.5937724  0.32586923]\nThe model correclty predicted all three classes.\nNow, we return to the MNIST example and use highel level functions toi implement the convolutional neural network.\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nx = parse_images(\"../../data/t10k-images-idx3-ubyte.gz\")\ny = parse_labels(\"../../data/t10k-labels-idx1-ubyte.gz\")\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\ndef data_stream():\n    perm = rng.permutation(num_train)\n    while True:\n        for i in range(num_batches):\n            batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n            yield torch.from_numpy(x[batch_idx,:,:]/ np.float32(255.))[:, None, :, :], torch.from_numpy(y[batch_idx])\n\ndef train(model, optimizer):\n    model.train()\n    batches = data_stream()\n    for epoch in range(num_epochs):\n        for _ in range(num_batches):\n            optimizer.zero_grad()\n            data, target = next(batches)\n            output = model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch}: Loss {loss.item()}\")\n\nmodel = Net()\noptimizer = torch.optim.Adadelta(model.parameters(), lr=0.1)\ntrain(model, optimizer)\n\nEpoch 0: Loss 0.691113293170929\nEpoch 1: Loss 0.44188016653060913\nEpoch 2: Loss 0.33435770869255066\nEpoch 3: Loss 0.2622855305671692\nEpoch 4: Loss 0.20537415146827698\nEpoch 5: Loss 0.16154637932777405\nEpoch 6: Loss 0.13039305806159973\nEpoch 7: Loss 0.10674168169498444\nEpoch 8: Loss 0.08762205392122269\nEpoch 9: Loss 0.07366820424795151",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Image Processing</span>"
    ]
  },
  {
    "objectID": "qmd/arch.html#convolutions",
    "href": "qmd/arch.html#convolutions",
    "title": "3  Image Processing",
    "section": "",
    "text": "img = np.genfromtxt(\"../../data/img-x.tsv\", delimiter=\"\\t\")\nimgx = img[0:5,:]\nimgd = img[5:10,:]\nimgrd = img[10:15,:]\nplt.imshow(imgx, cmap='binary'); plt.title(f'Cross'); plt.show();\nplt.imshow(imgd, cmap='binary');  plt.title(f'Diagonal'); plt.show();\nplt.imshow(imgrd, cmap='binary'); plt.title(f'Right-Diagonal'); plt.show();\n\n\nf = np.genfromtxt(\"../../data/img-filter.tsv\", delimiter=\"\\t\")\nf1 = f[0:3,:]\nf2 = f[3:6,:]\nplt.imshow(f1, cmap='binary'); plt.title(f'Filter 1'); plt.show();\nplt.imshow(f2, cmap='binary'); plt.title(f'Filter 2'); plt.show();\nprint(f1)\nprint(f2)\n\n\ndef conv(img, f):\n    out = np.zeros((3,3))\n    for i in range(3):\n        for j in range(3):\n            out[i,j] = np.sum(img[i:i+3,j:j+3]*f)\n    return out\ndef maxpool(img):\n    return np.max(img)\ndef fc(x, w, b):\n    return jnp.dot(w,x) + b\ndef softmax(x):\n    return jnp.exp(x) / jnp.sum(jnp.exp(x))\n\ndef cnn(img, f1, f2):\n    out1 = conv(img,f1)\n    out2 = conv(img,f2)\n    x = np.array([maxpool(out1), maxpool(out2)])\n    w = np.array([[1,0],[0,1],[0.6,0.6]])\n    b = 0\n    z = fc(x,w,b)\n    return softmax(z),out1,out2\n\nzx, outx1, outx2 = cnn(imgx,f1,f2)\nplt.imshow(outx1, cmap='binary'); plt.title(f'Output 1'); plt.show();\nplt.imshow(outx2, cmap='binary'); plt.title(f'Output 2'); plt.show();\nprint(outx1); print(outx2)\n\n\nzd, outd1, outd2 = cnn(imgd,f1,f2)\nplt.imshow(outd1, vmin=0,vmax=3,cmap='binary'); plt.title(f'Output 1');  plt.show();\nplt.imshow(outd2, vmin=0,vmax=3, cmap='binary'); plt.title(f'Output 2'); plt.show();",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Image Processing</span>"
    ]
  },
  {
    "objectID": "qmd/references.html",
    "href": "qmd/references.html",
    "title": "References",
    "section": "",
    "text": "Behnia, Farnaz, Dominik Karbowski, and Vadim Sokolov. 2021. “Deep\nGenerative Models for Vehicle Speed Trajectories.” arXiv\nPreprint arXiv:2112.08361.\n\n\nBhadra, Anindya, Jyotishka Datta, Nick Polson, Vadim Sokolov, and\nJianeng Xu. 2021. “Merging Two Cultures: Deep and Statistical\nLearning.” arXiv Preprint arXiv:2110.11561.\n\n\nBoltyanskii, V. G., R. V. Gamkrelidze, and Pontryagin. 1960.\n“Theory of Optimal Processes i: Maximum Principle.”\nNews of Akad. Nauk SSSR. Mathematics Series 24: 3–42.\n\n\nBottou, Léon, Frank E Curtis, and Jorge Nocedal. 2018.\n“Optimization Methods for Large-Scale Machine Learning.”\nSIAM Review 60 (2): 223–311.\n\n\nBryson, Arthur E. 1961. “A Gradient Method for Optimizing\nMulti-Stage Allocation Processes.” In Proc. Harvard Univ.\nSymposium on Digital Computers and Their Applications. Vol. 72.\n\n\nDixon, Matthew F, Nicholas G Polson, and Vadim O Sokolov. 2019.\n“Deep Learning for Spatio-Temporal Modeling: Dynamic Traffic Flows\nand High Frequency Trading.” Applied Stochastic Models in\nBusiness and Industry 35 (3): 788–807.\n\n\nDreyfus, Stuart. 1962. “The Numerical Solution of Variational\nProblems.” Journal of Mathematical Analysis and\nApplications 5 (1): 30–45.\n\n\n———. 1973. “The Computational Solution of Optimal Control Problems\nwith Time Lag.” IEEE Transactions on Automatic Control\n18 (4): 383–85.\n\n\nGriewank, Andreas, Kshitij Kulshreshtha, and Andrea Walther. 2012.\n“On the Numerical Stability of Algorithmic\nDifferentiation.” Computing 94 (2-4): 125–49.\n\n\nHardt, Moritz, Ben Recht, and Yoram Singer. 2016. “Train Faster,\nGeneralize Better: Stability of Stochastic Gradient Descent.” In\nInternational Conference on Machine Learning, 1225–34. PMLR.\n\n\nHeaton, JB, NG Polson, and Jan Hendrik Witte. 2017. “Deep Learning\nfor Finance: Deep Portfolios.” Applied Stochastic Models in\nBusiness and Industry 33 (1): 3–12.\n\n\nKeskar, Nitish Shirish, Dheevatsa Mudigere, Jorge Nocedal, Mikhail\nSmelyanskiy, and Ping Tak Peter Tang. 2016. “On Large-Batch\nTraining for Deep Learning: Generalization Gap and Sharp Minima.”\narXiv Preprint arXiv:1609.04836.\n\n\nLinnainmaa, Seppo. 1970. “The Representation of the Cumulative\nRounding Error of an Algorithm as a Taylor Expansion of the Local\nRounding Errors.” Master’s Thesis (in Finnish), Univ.\nHelsinki, 6–7.\n\n\nNareklishvili, Maria, Nicholas Polson, and Vadim Sokolov. 2022a.\n“Deep Partial Least Squares for Iv Regression.” arXiv\nPreprint arXiv:2207.02612.\n\n\n———. 2022b. “Feature Selection for Personalized Policy\nAnalysis.” arXiv Preprint arXiv:2301.00251.\n\n\n———. 2023. “Generative Causal Inference.” arXiv\nPreprint arXiv:2306.16096.\n\n\nOstrovskii, GM, Yu M Volin, and WW Borisov. 1971. “Uber Die\nBerechnung von Ableitungen.” Wissenschaftliche Zeitschrift\nDer Technischen Hochschule f Ur Chemie, Leuna-Merseburg 13 (4):\n382–84.\n\n\nPolson, Nicholas G, and Vadim Sokolov. 2017. “Deep Learning: A\nBayesian Perspective.”\n\n\n———. 2023. “Generative AI for Bayesian Computation.”\narXiv Preprint arXiv:2305.14972.\n\n\nPolson, Nicholas, and Vadim Sokolov. 2020. “Deep Learning:\nComputational Aspects.” Wiley Interdisciplinary Reviews:\nComputational Statistics 12 (5): e1500.\n\n\nPolson, Nicholas, Vadim Sokolov, and Jianeng Xu. 2021. “Deep\nLearning Partial Least Squares.” arXiv Preprint\narXiv:2106.14085.\n\n\nRobbins, Herbert, and Sutton Monro. 1951. “A Stochastic\nApproximation Method.” The Annals of Mathematical\nStatistics 22 (3): 400–407. https://doi.org/10.1214/aoms/1177729586.\n\n\nRumelhart, David E, Geoffrey E Hinton, and Ronald J Williams. 1986.\n“Learning Representations by Back-Propagating Errors.”\nNature 323 (6088): 533.\n\n\nSchmidhuber, Jürgen. 2015. “Deep Learning in Neural Networks: An\nOverview.” Neural Networks 61: 85–117.\n\n\nSokolov, Vadim. 2017. “Discussion of ’Deep Learning for Finance:\nDeep Portfolios’.” Applied Stochastic Models in Business and\nIndustry 33 (1): 16–18.\n\n\nWang, Yuexi, Nicholas Polson, and Vadim O Sokolov. 2022. “Data\nAugmentation for Bayesian Deep Learning.” Bayesian\nAnalysis 1 (1): 1–29.\n\n\nWerbos, Paul. 1974. “Beyond Regression:\" New Tools for Prediction\nand Analysis in the Behavioral Sciences.” Ph. D.\nDissertation, Harvard University.\n\n\nWerbos, Paul J. 1982. “Applications of Advances in Nonlinear\nSensitivity Analysis.” In System Modeling and\nOptimization, 762–70. Springer.",
    "crumbs": [
      "References"
    ]
  }
]