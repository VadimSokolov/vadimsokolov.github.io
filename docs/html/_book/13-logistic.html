<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>14&nbsp; Logistic Regression – Bayes, AI and Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./14-tree.html" rel="next">
<link href="./12-regression.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-680e7c22d93ef26f016bec9199f8e6d8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
  // Load MathJax with custom macros
  window.MathJax = {
    tex: {
      macros: {
        Cov: ["\\mathrm{Cov}\\left(#1\\right)", 1],
        Cor: ["\\mathrm{Cor}\\left(#1\\right)", 1],
        Var: ["\\mathrm{Var}\\left(#1\\right)", 1],
        sd: ["\\mathrm{sd}\\left(#1\\right)", 1],
        E: ["\\mathrm{E}_{#1}\\left[#2\\right]", 2, ""],
        prob: ["\\mathrm{P}\\left(#1\\right)", 1],
        defeq: "\\stackrel{\\mathrm{def}}{=}",
        mini: "\\operatorname*{minimize}"
      }
    }
  };
</script>

<style>
  /* Custom styling for math content */
  .MathJax {
    font-size: 1em !important;
  }
  
  /* Ensure consistent math rendering */
  mjx-container[jax="CHTML"] {
    line-height: 1.2;
  }
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="14&nbsp; Logistic Regression – Bayes, AI and Deep Learning">
<meta property="og:description" content="">
<meta property="og:image" content="13-logistic_files/figure-html/unnamed-chunk-1-1.png">
<meta property="og:site_name" content="Bayes, AI and Deep Learning">
<meta name="twitter:title" content="14&nbsp; Logistic Regression – Bayes, AI and Deep Learning">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="13-logistic_files/figure-html/unnamed-chunk-1-1.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./10-data.html">AI</a></li><li class="breadcrumb-item"><a href="./13-logistic.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Logistic Regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayes, AI and Deep Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Bayes, AI and Deep Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principles of Data Science</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-bl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayesian Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-dec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-ab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">AB Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-hyp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-sp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-rl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Unreasonable Effectiveness of Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-pattern.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Pattern Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-logistic.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Tree Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-forecasting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Forecasting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Randomized Controlled Trials</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-select.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-theoryai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Theory of AI: From MLE to Bayesian Regularization</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-theorydl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Theory of Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-sgd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-qnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Quantile Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-nlp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Natural Language Processing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Large Language Models: A Revolution in AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26-robots.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">AI Agents</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#model-fitting" id="toc-model-fitting" class="nav-link active" data-scroll-target="#model-fitting"><span class="header-section-number">14.1</span> Model Fitting</a></li>
  <li><a href="#confusion-matrix" id="toc-confusion-matrix" class="nav-link" data-scroll-target="#confusion-matrix"><span class="header-section-number">14.2</span> Confusion Matrix</a></li>
  <li><a href="#roc-curve-and-confounding-variables" id="toc-roc-curve-and-confounding-variables" class="nav-link" data-scroll-target="#roc-curve-and-confounding-variables"><span class="header-section-number">14.3</span> ROC Curve and Confounding Variables</a></li>
  <li><a href="#imbalanced-data" id="toc-imbalanced-data" class="nav-link" data-scroll-target="#imbalanced-data"><span class="header-section-number">14.4</span> Imbalanced Data</a></li>
  <li><a href="#kernel-trick" id="toc-kernel-trick" class="nav-link" data-scroll-target="#kernel-trick"><span class="header-section-number">14.5</span> Kernel Trick</a></li>
  <li><a href="#polya-gamma" id="toc-polya-gamma" class="nav-link" data-scroll-target="#polya-gamma"><span class="header-section-number">14.6</span> Polya-Gamma</a></li>
  <li><a href="#the-polya-gamma-distribution" id="toc-the-polya-gamma-distribution" class="nav-link" data-scroll-target="#the-polya-gamma-distribution"><span class="header-section-number">14.7</span> The P{'o}lya-Gamma Distribution</a>
  <ul class="collapse">
  <li><a href="#the-data-augmentation-strategy" id="toc-the-data-augmentation-strategy" class="nav-link" data-scroll-target="#the-data-augmentation-strategy">The Data-Augmentation Strategy</a></li>
  <li><a href="#gibbs-sampling-algorithm" id="toc-gibbs-sampling-algorithm" class="nav-link" data-scroll-target="#gibbs-sampling-algorithm">Gibbs Sampling Algorithm</a></li>
  <li><a href="#the-pg1z-sampler" id="toc-the-pg1z-sampler" class="nav-link" data-scroll-target="#the-pg1z-sampler">The PG(1,z) Sampler</a></li>
  <li><a href="#general-pgbz-sampling" id="toc-general-pgbz-sampling" class="nav-link" data-scroll-target="#general-pgbz-sampling">General PG(b,z) Sampling</a></li>
  </ul></li>
  <li><a href="#implementation-with-bayeslogit-package" id="toc-implementation-with-bayeslogit-package" class="nav-link" data-scroll-target="#implementation-with-bayeslogit-package"><span class="header-section-number">14.8</span> Implementation with BayesLogit Package</a>
  <ul class="collapse">
  <li><a href="#package-overview" id="toc-package-overview" class="nav-link" data-scroll-target="#package-overview">Package Overview</a></li>
  <li><a href="#core-functions" id="toc-core-functions" class="nav-link" data-scroll-target="#core-functions">Core Functions</a></li>
  <li><a href="#installation-and-basic-usage" id="toc-installation-and-basic-usage" class="nav-link" data-scroll-target="#installation-and-basic-usage">Installation and Basic Usage</a></li>
  <li><a href="#implementing-bayesian-logistic-regression" id="toc-implementing-bayesian-logistic-regression" class="nav-link" data-scroll-target="#implementing-bayesian-logistic-regression">Implementing Bayesian Logistic Regression</a></li>
  <li><a href="#modern-applications" id="toc-modern-applications" class="nav-link" data-scroll-target="#modern-applications">Modern Applications</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./10-data.html">AI</a></li><li class="breadcrumb-item"><a href="./13-logistic.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Logistic Regression</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-logistic" class="quarto-section-identifier"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Classification is a type of predictive modeling where the goal is to predict a categorical variable based on a set of input variables. A categorical variable is a variable that can take on only a limited number of values, such as 0 or 1, or it can be a multi-class variable, meaning it can take on more than two values. For example, in medical diagnosis, we might want to predict whether a patient has a disease (1) or not (0) based on symptoms and test results. A particularly important application is in self-driving cars, where computer vision systems must classify objects in real-time from camera feeds - distinguishing between pedestrians, other vehicles, traffic signs, and road obstacles to make safe driving decisions.</p>
<p>Given observed data <span class="math inline">\(\{(x_i,y_i)\}_{i=1}^n\)</span>, where each <span class="math inline">\(y_i\)</span> is either 0 or 1, we start by assuming a binomial likelihood function for the response variable, defined as follows: <span class="math display">\[
P(y_i = 1\mid p_i) = p_i^{y_i} (1-p_i)^{1-y_i},
\]</span> where <span class="math inline">\(p_i\)</span> is the funciton of the inputs <span class="math inline">\(x_i\)</span> and coefficients <span class="math inline">\(\beta\)</span> that gives us the probability of the response variable taking on a value of 1, given the input variables. A typical approach to calculate <span class="math inline">\(p_i\)</span> is to use logistic function <span class="math display">\[\begin{align*}
f_{\beta}(x_i) = &amp; \beta^Tx_i\\
p_i  = &amp; \sigma(f_{\beta}(x_i)) =  \frac{e^{f_{\beta}(x_i)}}{1+e^{f_{\beta}(x_i)}},
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\beta\)</span> is a vector of parameters. The logistic function <span class="math inline">\(\sigma(\cdot)\)</span> is a function that maps any real number to a number between zero and one.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">10</span>,<span class="dv">10</span>,<span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, <span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span>x)), <span class="at">type=</span><span class="st">'l'</span>, <span class="at">col=</span><span class="st">"red"</span>, <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab=</span><span class="st">"p"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<section id="model-fitting" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="model-fitting"><span class="header-section-number">14.1</span> Model Fitting</h2>
<p>The we fit the model using Binomial log-likelihood minimisation. It leads us to the maximum likelihood estimator for parameters <span class="math inline">\(\beta\)</span> (a.k.a <strong>cross-entropy estimator</strong>), defined as <span class="math display">\[
\hat \beta = \arg\min_{\beta}\mathcal{L}(\beta),
\]</span> where <span class="math display">\[
\mathcal{L}(\beta) =  -\sum_{i=1}^n \left[ y_i \log p_i  + (1-y_i) \log \left ( 1-p_i \right ) \right].
\]</span> Similar to the least squares estimator, the cross-entropy estimator optimisaiton problem is convex, it has a unique solution.</p>
<p>In the unconditional case, when we do not observe any inputs <span class="math inline">\(x\)</span>, the cross-entropy estimator is again, the sample mean. If we take the derivative of the above expression with respect to <span class="math inline">\(\beta_0\)</span> and set it to zero, we get <span class="math display">\[
- \frac{d}{d\beta_0}\sum_{i=1}^n \left[ y_i \log \left ( \beta_0 \right ) + (1-y_i) \log \left ( 1-\beta_0 \right ) \right] = -\sum_{i=1}^n \left[ \frac{y_i}{\beta_0} - \frac{1-y_i}{1-\beta_0} \right] = 0
\]</span> which gives us the solution <span class="math display">\[
\hat{\beta}_0 = \frac{1}{n}\sum_{i=1}^n y_i.
\]</span> which is the sample mean.</p>
<p>Unlike the least squares estimator or in unconditional case, the system of equations <span class="math display">\[
\nabla \mathcal{L}(\beta) = 0
\]</span> is not linear and cannot be solved by inverting a matrix. However, there are efficient iterative numerical optimization algorithms that can be used to find the optimal solution. The most common one is the <strong>BFGS</strong> (Broyden-Fletcher-Goldfarb-Shanno) algorithm. It is a quasi-Newton method that’s particularly well-suited for optimizing the cross-entropy loss function in logistic regression.</p>
<p>In the case when we have more than two classes <span class="math inline">\(y \in \{1,\ldots,K\}\)</span>, we simply build <span class="math inline">\(K\)</span> models <span class="math inline">\(f_{\beta_1}(x),\ldots, f_{\beta_K}(x)\)</span>, one for each class and then use the softmax function to convert the output of each model into a number between zero and one. The softmax function is defined as follows <span class="math display">\[
\mathrm{softmax}\left(f_{\beta_j}(x)\right) = \frac{\exp(f_{\beta_j}(x))}{\sum_{i=1}^K \exp(f_{\beta_i}(x))}.
\]</span> The softmax function is a generalization of the logistic function to the case of more than two classes. It is often used as the activation function in the output layer of neural networks for multi-class classification problems. It converts the output of each model into a probability distribution over the classes, making it suitable for multi-class classification with probabilistic outputs.</p>
<p>The vecotr of non-scaled outputs <span class="math inline">\((f_{\beta_1}(x),\ldots, f_{\beta_K}(x))\)</span> is called the <strong>logits</strong>.</p>
<p>The logistic function has a nice statistical interpretation. It is the CDF of the logistic distribution, which is a symmetric distribution with mean 0 and variance <span class="math inline">\(\pi^2/3\)</span>, thus <span class="math inline">\(p_i\)</span> is simply a value of this CDF, evaluated at <span class="math inline">\(\beta^Tx_i\)</span>.</p>
<p>Further, Logistic regression models the log-odds (logit) of the probability as a linear function of the predictors, which aligns with the maximum likelihood estimation framework and provides desirable statistical properties. Specifically, if we invert the logistic function, <span class="math display">\[
p_i  = \sigma(\beta^Tx_i) =  \frac{e^{\beta^Tx_i}}{1+e^{\beta^Tx_i}},
\]</span> we get the log-odds <span class="math display">\[
\log\left(\frac{p_i}{1-p_i}\right) = \beta^Tx_i.
\]</span> Meaning that <span class="math inline">\(\beta^Tx_i\)</span> measures how probability of <span class="math inline">\(y_i = 1\)</span> changes with respect to the change in <span class="math inline">\(x_i\)</span> on the log-odds scale. It allows us to interpret the model coefficients as the log-odds ratios of the response variable.</p>
<p>In some disciplines, such as econometrics, physcology and natural sciences, a normal CDF is used instead of the logistic CDF. It is done for historical reasons and because Normal CDF has slightly differnt assumptions about the data, that might be more natural in some cases.</p>
<p>In the case of the normal CDF, the model is called <strong>probit</strong>, it stands for probability unit, and the link function is called <strong>probit link</strong>. The probit model is defined as <span class="math display">\[
\Phi^{-1}(p_i) =  \beta^Tx_i.
\]</span> where <span class="math inline">\(\Phi(\cdot)\)</span> is the normal CDF.</p>
<p>The term probit was coined in the 1930’s by biologists studying the dosage-cure rate link. We can fit a probit model using <code>glm</code> function in <code>R</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">92</span>) <span class="co"># Kuzy</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>,<span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">pnorm</span>(x<span class="sc">+</span><span class="fu">rnorm</span>(<span class="dv">100</span>))<span class="sc">&gt;</span><span class="fl">0.5</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>probitModel <span class="ot">=</span> <span class="fu">glm</span>(y<span class="sc">~</span>x, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span><span class="st">"probit"</span>))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>mc <span class="ot">=</span> <span class="fu">as.double</span>(<span class="fu">coef</span>(probitModel))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># we want to predict outcome for x = -1</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>xnew <span class="ot">=</span> <span class="sc">-</span><span class="dv">1</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>(<span class="at">yt =</span> mc[<span class="dv">1</span>] <span class="sc">+</span> mc[<span class="dv">2</span>]<span class="sc">*</span>xnew)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] -0.86</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">pnorm</span>(yt))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.19</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">pred =</span> <span class="fu">predict</span>(probitModel, <span class="fu">list</span>(<span class="at">x =</span> <span class="fu">c</span>(xnew)), <span class="at">type=</span><span class="st">"response"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##    1 
## 0.19</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>nd <span class="ot">=</span> <span class="fu">dnorm</span>(mc[<span class="dv">1</span>] <span class="sc">+</span> mc[<span class="dv">2</span>]<span class="sc">*</span>x)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,nd, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">col=</span><span class="st">"red"</span>, <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab =</span> <span class="st">"P(y=1)"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>,x[x<span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">1</span>],<span class="sc">-</span><span class="dv">1</span>),<span class="fu">c</span>(<span class="dv">0</span>,nd[x<span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">1</span>],<span class="dv">0</span>), <span class="at">col=</span><span class="st">"blue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Our prediction is the blue area which is equal to 0.195.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">type=</span><span class="st">'p'</span>, <span class="at">col=</span><span class="st">"red"</span>, <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab =</span> <span class="st">"P(y=1)"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>pred_probit <span class="ot">=</span> <span class="fu">predict</span>(probitModel, <span class="fu">list</span>(<span class="at">x=</span>x), <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,pred_probit, <span class="at">type=</span><span class="st">'l'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Outside of specific field, i.e.&nbsp;behavioral economics, the logistic function is much more popular of a choice compared to probit model. Besides that fact that is more intuitive to work with logit transform, it also has several nice properties when we deal with multiple classes (more then 2). Also, it is computationally easier then working with normal distributions. The density function of the logit is very similar to the probit one.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>logitModel  <span class="ot">=</span> <span class="fu">glm</span>(y<span class="sc">~</span>x, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span><span class="st">"logit"</span>))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>pred_logit <span class="ot">=</span> <span class="fu">predict</span>(logitModel, <span class="fu">list</span>(<span class="at">x =</span> x), <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,pred_probit, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">col=</span><span class="st">"red"</span>, <span class="at">cex=</span><span class="fl">0.9</span>, <span class="at">ylab=</span><span class="st">"y"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,pred_logit, <span class="at">type=</span><span class="st">'p'</span>, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">cex=</span><span class="fl">0.5</span>, <span class="at">col=</span><span class="st">"blue"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,y, <span class="at">type=</span><span class="st">'p'</span>, <span class="at">pch=</span><span class="dv">21</span>, <span class="at">cex=</span><span class="fl">0.5</span>, <span class="at">bg=</span><span class="st">"lightblue"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomright"</span>,<span class="at">pch=</span><span class="dv">20</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">"Logit"</span>, <span class="st">"Probit"</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="st">"blue"</span>,<span class="st">"red"</span>),<span class="at">y.intersp =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div id="exm-nba" class="theorem example">
<p><span class="theorem-title"><strong>Example 14.1 (Example: NBA point spread)</strong></span> We will use the NBA point spread data to illustrate the logistic regression. The data is available in the <code>NBAspread.csv</code> file. The data contains the point spread for each game in the NBA from 2013 to 2014 season. The data also contains the outcome of the game, whether the favorite won or not. The point spread is the number of points by which the favorite is expected to win the game and is predicted by the bookmakers. We simply want to see how well the point spread predicts the outcome of the game.</p>
<p>We start by loading the data and visualizing it.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>NBA <span class="ot">=</span> <span class="fu">read.csv</span>(<span class="st">"../data/NBAspread.csv"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">nrow</span>(NBA)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(NBA)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="kable-table">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">favwin</th>
<th style="text-align: right;">favscr</th>
<th style="text-align: right;">undscr</th>
<th style="text-align: right;">spread</th>
<th style="text-align: right;">favhome</th>
<th style="text-align: right;">fregion</th>
<th style="text-align: right;">uregion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">72</td>
<td style="text-align: right;">61</td>
<td style="text-align: right;">7.0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">82</td>
<td style="text-align: right;">74</td>
<td style="text-align: right;">7.0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">87</td>
<td style="text-align: right;">57</td>
<td style="text-align: right;">17.0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">69</td>
<td style="text-align: right;">70</td>
<td style="text-align: right;">9.0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">77</td>
<td style="text-align: right;">79</td>
<td style="text-align: right;">2.5</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">91</td>
<td style="text-align: right;">65</td>
<td style="text-align: right;">9.0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(NBA<span class="sc">$</span>spread[NBA<span class="sc">$</span>favwin<span class="sc">==</span><span class="dv">1</span>], <span class="at">col=</span><span class="dv">5</span>, <span class="at">main=</span><span class="st">""</span>, <span class="at">xlab=</span><span class="st">"spread"</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(NBA<span class="sc">$</span>spread[NBA<span class="sc">$</span>favwin<span class="sc">==</span><span class="dv">0</span>], <span class="at">add=</span><span class="cn">TRUE</span>, <span class="at">col=</span><span class="dv">6</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">"favwin=1"</span>, <span class="st">"favwin=0"</span>), <span class="at">fill=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">6</span>), <span class="at">bty=</span><span class="st">"n"</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(NBA<span class="sc">$</span>spread <span class="sc">~</span> NBA<span class="sc">$</span>favwin, <span class="at">col=</span><span class="fu">c</span>(<span class="dv">6</span>,<span class="dv">5</span>), <span class="at">horizontal=</span><span class="cn">TRUE</span>, <span class="at">ylab=</span><span class="st">"favwin"</span>, <span class="at">xlab=</span><span class="st">"spread"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell quarto-layout-panel" data-layout-align="center" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-7-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
</div>
<p>Does the Vegas point spread predict whether the favorite wins or not? The histogram shows the distribution of point spreads for games where the favorite won (turquoise) versus games where the favorite lost (purple). The boxplot provides another view of this relationship. Let’s fit a logistic regression model to quantify this relationship:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>nbareg <span class="ot">=</span> <span class="fu">glm</span>(favwin<span class="sc">~</span>spread<span class="dv">-1</span>, <span class="at">family=</span>binomial, <span class="at">data=</span>NBA)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>nbareg <span class="sc">%&gt;%</span> <span class="fu">tidy</span>() <span class="sc">%&gt;%</span> <span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">spread</td>
<td style="text-align: right;">0.16</td>
<td style="text-align: right;">0.01</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>s <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">30</span>,<span class="at">length=</span><span class="dv">100</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">exp</span>(s<span class="sc">*</span>nbareg<span class="sc">$</span>coef[<span class="dv">1</span>])<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(s<span class="sc">*</span>nbareg<span class="sc">$</span>coef[<span class="dv">1</span>]))</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(s, fit, <span class="at">typ=</span><span class="st">"l"</span>, <span class="at">col=</span><span class="dv">4</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">0.5</span>,<span class="dv">1</span>), <span class="at">xlab=</span><span class="st">"spread"</span>, <span class="at">ylab=</span><span class="st">"P(favwin)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>The <span class="math inline">\(\beta\)</span> measures how our log-odds change, For this model, we have <span class="math inline">\(\beta = 0.156\)</span>, meaning that for every one point increase in the point spread, the log-odds of the favorite winning increases by 0.156.</p>
<p>Not, we can use the model to predict the probability of the favorite winning for a new game with a point spread of 8 or 4.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(nbareg, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">spread =</span> <span class="fu">c</span>(<span class="dv">8</span>,<span class="dv">4</span>)), <span class="at">type =</span> <span class="st">"response"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##    1    2 
## 0.78 0.65</code></pre>
</div>
</div>
<p>The code above simply “Plugs-in” the values for the new game into our logistic regression <span class="math display">\[
{ P \left ( \mathrm{ favwin}  \mid  \mathrm{ spread} \right ) = \frac{ e^{ \beta x } }{ 1 + e^{\beta x} } }
\]</span> We can calculate it manually as well.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fl">0.156</span><span class="sc">*</span><span class="dv">8</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="fl">0.156</span><span class="sc">*</span><span class="dv">8</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.78</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fl">0.156</span><span class="sc">*</span><span class="dv">4</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="fl">0.156</span><span class="sc">*</span><span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.65</code></pre>
</div>
</div>
<p>Check that when <span class="math inline">\(\beta =0\)</span> we have <span class="math inline">\(p= \frac{1}{2}\)</span>.</p>
<p>Given our new values spread<span class="math inline">\(=8\)</span> or spread<span class="math inline">\(=4\)</span>, the win probabilities are <span class="math inline">\(78\)</span>% and <span class="math inline">\(65\)</span>%, respectively. Clearly, the bigger spread means a higher chance of winning.</p>
</div>
<p>Notice, that the predict function returns a numeric value between 0 and 1. However, if we want to make a decision (to bet or not to bet), we need to have a binary outcome. A simple methods to move between the predicted probability and binary value is to use thresholding. <span class="math display">\[
\hat y_i = \begin{cases}
1 &amp; \text{if } \hat p_i &gt; \alpha \\
0 &amp; \text{if } \hat p_i \leq \alpha
\end{cases}
\]</span> where <span class="math inline">\(\alpha\)</span> is a threshold value. A typical choice is <span class="math inline">\(\alpha = 0.5\)</span>.</p>
<p>Now let’s calculate the number of correct predictions using threshold <span class="math inline">\(\alpha = 0.5\)</span>. <code>R</code> has a convinient <code>table</code> function that can summarise the counts of the predicted and actual values in a table.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(NBA<span class="sc">$</span>favwin, <span class="fu">as.integer</span>(<span class="fu">predict</span>(nbareg, <span class="at">type=</span><span class="st">"response"</span>)<span class="sc">&gt;</span><span class="fl">0.5</span>), <span class="at">dnn=</span><span class="fu">c</span>(<span class="st">"Actual"</span>, <span class="st">"Predicted"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##       Predicted
## Actual   1
##      0 131
##      1 422</code></pre>
</div>
</div>
<p>Our model gets 0.7631103 of the predictions correctly. This number is called <strong>accuracy</strong> of the model.</p>
</section>
<section id="confusion-matrix" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="confusion-matrix"><span class="header-section-number">14.2</span> Confusion Matrix</h2>
<p>We will analyse the tennis data set to show what is the decision boundary for the logistic regression model. The decision boundary is the line that separates the two classes. It is defined as the line where the probability of the favorite winning is 0.5. Then we will use the confusion matrix to evaluate the performance of the model.</p>
<div id="exm-tennis" class="theorem example">
<p><span class="theorem-title"><strong>Example 14.2 (Logistic Regression for Tennis Classification)</strong></span> Data science plays a major role in tennis, you can learn about recent AI tools developed by IBM from this <a href="https://finance.yahoo.com/video/ibm-serving-ai-technology-tennis-150742376.html">This Yahoo Article</a>.</p>
<p>We will analyze the <a href="https://archive.ics.uci.edu/ml/datasets/Tennis+Major+Tournament+Match+Statistics">Tennis Major Tournament Match Statistics Data Set</a> from the UCI ML repository. The data set has one per each game from four major Tennis tournaments in 2013 (Australia Open, French Open, US Open, and Wimbledon).</p>
<p>Let’s load the data and familiarize ourselves with it</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="fu">read.csv</span>(<span class="st">"./../data/tennis.csv"</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 943  44</code></pre>
</div>
</div>
<p>Let’s look at the few coluns of the randomly selected five rows of the data</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>d[<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">943</span>,<span class="at">size =</span> <span class="dv">5</span>),<span class="fu">c</span>(<span class="st">"Player1"</span>,<span class="st">"Player2"</span>,<span class="st">"Round"</span>,<span class="st">"Result"</span>,<span class="st">"gender"</span>,<span class="st">"surf"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="kable-table">
<table class="caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 5%">
<col style="width: 26%">
<col style="width: 33%">
<col style="width: 8%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Player1</th>
<th style="text-align: left;">Player2</th>
<th style="text-align: right;">Round</th>
<th style="text-align: right;">Result</th>
<th style="text-align: left;">gender</th>
<th style="text-align: left;">surf</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">532</td>
<td style="text-align: left;">Florian Mayer</td>
<td style="text-align: left;">Juan Monaco</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: left;">M</td>
<td style="text-align: left;">Hard</td>
</tr>
<tr class="even">
<td style="text-align: left;">816</td>
<td style="text-align: left;">L.Kubot</td>
<td style="text-align: left;">J.Janowicz</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">0</td>
<td style="text-align: left;">M</td>
<td style="text-align: left;">Grass</td>
</tr>
<tr class="odd">
<td style="text-align: left;">431</td>
<td style="text-align: left;">Svetlana Kuznetsova</td>
<td style="text-align: left;">Ekaterina Makarova</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">Clay</td>
</tr>
<tr class="even">
<td style="text-align: left;">568</td>
<td style="text-align: left;">Marcos Baghdatis</td>
<td style="text-align: left;">Go Soeda</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: left;">M</td>
<td style="text-align: left;">Hard</td>
</tr>
<tr class="odd">
<td style="text-align: left;">216</td>
<td style="text-align: left;">Mandy Minella</td>
<td style="text-align: left;">Anastasia Pavlyuchenkova</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">Hard</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>We have data for 943 matches and for each match we have 44 columns, including names of the players, their gender, surface type and match statistics. Let’s look at the number of break points won by each player. We will plot BPW (break points won) by each player on the scatter plot and will colorize each dot according to the outcome</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">dim</span>(d)[<span class="dv">1</span>]</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d<span class="sc">$</span>BPW<span class="fl">.1</span><span class="sc">+</span><span class="fu">rnorm</span>(n),d<span class="sc">$</span>BPW<span class="fl">.2</span><span class="sc">+</span><span class="fu">rnorm</span>(n), <span class="at">pch=</span><span class="dv">21</span>, <span class="at">col=</span>d<span class="sc">$</span>Result<span class="sc">+</span><span class="dv">2</span>, <span class="at">cex=</span><span class="fl">0.6</span>, <span class="at">bg=</span><span class="st">"yellow"</span>, <span class="at">lwd=</span><span class="fl">0.8</span>,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"BPW by Player 1"</span>, <span class="at">ylab=</span><span class="st">"BPW by Player 2"</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomright"</span>, <span class="fu">c</span>(<span class="st">"P1 won"</span>, <span class="st">"P2 won"</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">2</span>), <span class="at">pch=</span><span class="dv">21</span>, <span class="at">bg=</span><span class="st">"yellow"</span>, <span class="at">bty=</span><span class="st">'n'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>We can clearly see that number of the break points won is a clear predictor of the match outcome. Which is obvious and follows from the rules, to win a match, a player must win break points. Now, we want to understand the impact of a winning a break point on the overall match outcome. We do it by building a logistic regression model</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which</span>(<span class="fu">is.na</span>(d<span class="sc">$</span>BPW<span class="fl">.1</span>)) <span class="co"># there is one row with NA value for the BPW.1 value and we remove it</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 171</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> d[<span class="sc">-</span><span class="dv">171</span>,]; n <span class="ot">=</span> <span class="fu">dim</span>(d)[<span class="dv">1</span>]</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="fu">glm</span>(Result <span class="sc">~</span> BPW<span class="fl">.1</span> <span class="sc">+</span> BPW<span class="fl">.2</span><span class="dv">-1</span>, <span class="at">data=</span>d, <span class="at">family =</span> <span class="st">"binomial"</span> )</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>m <span class="sc">%&gt;%</span> <span class="fu">tidy</span>() <span class="sc">%&gt;%</span> <span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">BPW.1</td>
<td style="text-align: right;">0.40</td>
<td style="text-align: right;">0.03</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">BPW.2</td>
<td style="text-align: right;">-0.42</td>
<td style="text-align: right;">0.03</td>
<td style="text-align: right;">-15</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The predicted values are stored in the <code>fitted.values</code> field of the model object. Those are the probabilities of player 1 winning the match. We need to convert them to binary predictions using <span class="math inline">\(0.5\)</span> as a threshold for our classification.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(d<span class="sc">$</span>Result, <span class="fu">as.integer</span>(m<span class="sc">$</span>fitted.values<span class="sc">&gt;</span><span class="fl">0.5</span>), <span class="at">dnn=</span><span class="fu">c</span>(<span class="st">"Actual"</span>, <span class="st">"Predicted"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##       Predicted
## Actual   0   1
##      0 416  61
##      1  65 400</code></pre>
</div>
</div>
<p>This table shows the number of correct and incorrect predictions for each class. The rows are the actual outcomes and the columns are the predicted outcomes. The first row shows the number of matches where player 1 won and the model predicted that player 1 won. The second row shows the number of matches where player 1 lost and the model predicted that player 1 lost. Thus, our model got (416+416)/942 = 0.8832272% of the predictions correctly! The accuracy is the ratio of the number of correct predictions to the total number of predictions.</p>
<p>This table is called <strong>confusion matrix</strong>. It is a table that shows the number of correct and incorrect predictions for each class. The rows are the actual outcomes and the columns are the predicted outcomes. Formally, it is defined as</p>
<table class="caption-top table">
<caption>Confusion Matrix. TPR - True Positive Rate, FPR - False Positive Rate, TNR - True Negative Rate, FNR - False Negative Rate.</caption>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;">Predicted: YES</th>
<th style="text-align: center;">Predicted: NO</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Actual: YES</td>
<td style="text-align: center;">TPR</td>
<td style="text-align: center;">FNR</td>
</tr>
<tr class="even">
<td>Actual: NO</td>
<td style="text-align: center;">FPR</td>
<td style="text-align: center;">TNR</td>
</tr>
</tbody>
</table>
<p>Essentially, the logistic regresion is trying to draw a line that separates the red observations from the green one. In out case, we have two predictors <span class="math inline">\(x_1\)</span> = BPW.1 and <span class="math inline">\(x_2\)</span> = BPW.2 and our model is <span class="math display">\[
\log\left(\dfrac{p}{1-p}\right) = \beta_1x_1 + \beta_2 x_2,
\]</span> where <span class="math inline">\(p\)</span> is the probability of player 1 winning the match. We want to find the line along which the probability is 1/2, meaning that <span class="math inline">\(p/(1-p) = 1\)</span> and log-odds <span class="math inline">\(\log(p/(1-p)) = 0\)</span>, thus the equation for the line is <span class="math inline">\(\beta_1x_1 + \beta_2 x_2 = 0\)</span> or <span class="math display">\[
x_2 = \dfrac{-\beta_1}{\beta_2}x_1
\]</span></p>
<p>Let’s see the line found by the <code>glm</code> function</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomright"</span>, <span class="fu">c</span>(<span class="st">"P1 won"</span>, <span class="st">"P2 won"</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">2</span>), <span class="at">pch=</span><span class="dv">21</span>, <span class="at">bg=</span><span class="st">"yellow"</span>, <span class="at">bty=</span><span class="st">'n'</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">30</span>,<span class="at">length.out =</span> <span class="dv">200</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>y  <span class="ot">=</span>  <span class="sc">-</span>m<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">*</span>x<span class="sc">/</span>m<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,y, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">"red"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>There are a couple of observations. First, effect of a break point on the game outcome is significant and symmetric, effect of loosing break point is the same as the effect of winning one. We also can interpret the effect of winning a break point in the following way. We will keep BPW.2 = 0 and will calculate what happens to the probability of winning when BPW.1 changes from 0 to 1. The odds ration for player 1 winning when BPW.1 = 0 is <code>exp(0)</code> which is 1, meaning that the probability that P1 wins is 1/2. Now when BPW.1 = 1, the odds ratio is 1.5</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fl">0.4019</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 1.5</code></pre>
</div>
</div>
<p>We can calculate probability of winning from the regression equation <span class="math display">\[
\dfrac{p}{1-p} = 1.5,~~~p = 1.5(1-p),~~~2.5p = 1.5,~~~p = 0.6
\]</span> Thus probability of winning goes from 50% to 60%, we can use <code>predict</code> function to get this result</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.glm</span>(m,<span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">BPW.1 =</span> <span class="fu">c</span>(<span class="dv">0</span>), <span class="at">BPW.2 =</span> <span class="fu">c</span>(<span class="dv">0</span>)), <span class="at">type=</span><span class="st">"response"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##   1 
## 0.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.glm</span>(m,<span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">BPW.1 =</span> <span class="fu">c</span>(<span class="dv">1</span>), <span class="at">BPW.2 =</span> <span class="fu">c</span>(<span class="dv">0</span>)), <span class="at">type=</span><span class="st">"response"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##   1 
## 0.6</code></pre>
</div>
</div>
<p>What happens to the chances of winning when P1 wins three more break points compared to the opponent</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.glm</span>(m,<span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">BPW.1 =</span> <span class="fu">c</span>(<span class="dv">0</span>), <span class="at">BPW.2 =</span> <span class="fu">c</span>(<span class="dv">0</span>)), <span class="at">type=</span><span class="st">"response"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##   1 
## 0.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.glm</span>(m,<span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">BPW.1 =</span> <span class="fu">c</span>(<span class="dv">3</span>), <span class="at">BPW.2 =</span> <span class="fu">c</span>(<span class="dv">0</span>)), <span class="at">type=</span><span class="st">"response"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##    1 
## 0.77</code></pre>
</div>
</div>
<p>Chances go up by 27%.</p>
<p>Tennis is arguably the sport in which mean and women are treated equally. Both man and women matches are shown during the prime-time on TV, they both have the same prize money. However, one of the comments you hear often is that Women’s matches are “less predictable”, meaning that an upset (when the favorite looses) is more likely to happen in a women’s match compared to man Matches. We can test thus statement by looking at the residuals. The large the residual the less accurate our prediction was.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>outlind <span class="ot">=</span> <span class="fu">which</span>(d<span class="sc">$</span>res<span class="sc">&lt;</span><span class="dv">2</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(d<span class="sc">$</span>res[outlind] <span class="sc">~</span> d<span class="sc">$</span>gender[outlind], <span class="at">col=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), <span class="at">xlab=</span><span class="st">"Gender"</span>,<span class="at">ylab=</span><span class="st">"Residual"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Let’s do a formal T-test on the residuals foe men’s and women’s matches</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>men <span class="ot">=</span> d <span class="sc">%&gt;%</span> <span class="fu">filter</span>(res<span class="sc">&lt;</span><span class="dv">2</span>, gender<span class="sc">==</span><span class="st">"M"</span>) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(res)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>women <span class="ot">=</span> d <span class="sc">%&gt;%</span> <span class="fu">filter</span>(res<span class="sc">&lt;</span><span class="dv">2</span>, gender<span class="sc">==</span><span class="st">"W"</span>) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(res)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(men, women, <span class="at">alternative =</span> <span class="st">"two.sided"</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>() <span class="sc">%&gt;%</span> <span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 7%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 21%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">estimate1</th>
<th style="text-align: right;">estimate2</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
<th style="text-align: right;">parameter</th>
<th style="text-align: right;">conf.low</th>
<th style="text-align: right;">conf.high</th>
<th style="text-align: left;">method</th>
<th style="text-align: left;">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">-0.07</td>
<td style="text-align: right;">1.2</td>
<td style="text-align: right;">1.3</td>
<td style="text-align: right;">-4.7</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">811</td>
<td style="text-align: right;">-0.11</td>
<td style="text-align: right;">-0.04</td>
<td style="text-align: left;">Welch Two Sample t-test</td>
<td style="text-align: left;">two.sided</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The difference of <span class="math inline">\(0.07\)</span> between men and women and the static value of <span class="math inline">\(-4.7\)</span> means that the crowd wisdom that Women’s matches are less predictable is correct. The difference is statistically significant!</p>
</div>
</section>
<section id="roc-curve-and-confounding-variables" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="roc-curve-and-confounding-variables"><span class="header-section-number">14.3</span> ROC Curve and Confounding Variables</h2>
<p>Using default data set, we will illustrate the concept of ROC curve and confounding variables.</p>
<div id="exm-Default" class="theorem example">
<p><span class="theorem-title"><strong>Example 14.3 (Credit Card Default)</strong></span> We will use the <code>Default</code> data set from the <code>ISLR</code> package to illustrate the logistic regression. The data set contains information on credit card defaults. Credit risk assessment is a major application of logistic regression and is widely used in the financial industry. In fact, the banks with the best credit risk assessment models are the ones that are able to offer the best interest rates to their customers and are winning the market.</p>
<p>We will also use this example to illustrate the concept of ROC (Receiver Operating Characteristic) curve. That helps us to understand the trade-off between sensitivity and specificity by varying the threshold <span class="math inline">\(\alpha\)</span>.</p>
<p>First, load the data set. We have 10,000 observations.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>Default <span class="ot">=</span> <span class="fu">read.csv</span>(<span class="st">"../data/CreditISLR.csv"</span>, <span class="at">stringsAsFactors =</span> T)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="kable-table">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">default</th>
<th style="text-align: left;">student</th>
<th style="text-align: right;">balance</th>
<th style="text-align: right;">income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">730</td>
<td style="text-align: right;">44362</td>
</tr>
<tr class="even">
<td style="text-align: left;">No</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">817</td>
<td style="text-align: right;">12106</td>
</tr>
<tr class="odd">
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1074</td>
<td style="text-align: right;">31767</td>
</tr>
<tr class="even">
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">529</td>
<td style="text-align: right;">35704</td>
</tr>
<tr class="odd">
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">786</td>
<td style="text-align: right;">38464</td>
</tr>
<tr class="even">
<td style="text-align: left;">No</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">920</td>
<td style="text-align: right;">7492</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>There are three predictors in the data set: <code>balance</code>, <code>income</code> and <code>student</code>. The <code>balance</code> variable represents the average credit card balance in dollars for each individual. This is the amount of money that a person owes on their credit card, which is a key predictor of whether they are likely to default on their credit card payments.</p>
<p>In the context of credit risk assessment, balance is one of the most important variables because it directly measures the amount of credit being utilized. Credit card companies and banks use this information, along with other factors like income and student status, to assess the likelihood that a customer will default on their payments. The logistic regression model we’re building will use this balance information to predict the probability of default, helping financial institutions make informed decisions about credit limits, interest rates, and risk management.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>glm.fit<span class="ot">=</span><span class="fu">glm</span>(default<span class="sc">~</span>balance,<span class="at">data=</span>Default,<span class="at">family=</span>binomial)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>glm.fit <span class="sc">%&gt;%</span> <span class="fu">tidy</span>() <span class="sc">%&gt;%</span> <span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">-10.65</td>
<td style="text-align: right;">0.36</td>
<td style="text-align: right;">-29</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">balance</td>
<td style="text-align: right;">0.01</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We use it now to predict default for a new individual with a balance of $1000.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.glm</span>(glm.fit,<span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">balance=</span><span class="dv">1000</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##    1 
## -5.2</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">1.065e+01</span> <span class="sc">+</span> <span class="fl">5.499e-03</span><span class="sc">*</span><span class="dv">1000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] -5.2</code></pre>
</div>
</div>
<p>Notice, that by default the <code>predict</code> function returns the log-odds. We can convert it to the probability using the logistic function.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.glm</span>(glm.fit,<span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">balance=</span><span class="dv">1000</span>), <span class="at">type=</span><span class="st">"response"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##      1 
## 0.0058</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.065e+01</span> <span class="sc">+</span> <span class="fl">5.499e-03</span><span class="sc">*</span><span class="dv">1000</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">1.065e+01</span> <span class="sc">+</span> <span class="fl">5.499e-03</span><span class="sc">*</span><span class="dv">1000</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.0058</code></pre>
</div>
</div>
<p>Now, let’s plot the predicted probability of default for a range of balances between 1000 and 3000.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">list</span>(<span class="at">balance=</span><span class="fu">seq</span>(<span class="dv">1000</span>,<span class="at">to =</span> <span class="dv">3000</span>,<span class="at">length.out =</span> <span class="dv">100</span>))</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">predict.glm</span>(glm.fit,<span class="at">newdata =</span> x, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x<span class="sc">$</span>balance,y, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">col=</span><span class="st">"red"</span>, <span class="at">xlab =</span> <span class="st">"balance"</span>, <span class="at">ylab=</span><span class="st">"Default"</span>)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(Default<span class="sc">$</span>balance, <span class="fu">as.integer</span>(Default<span class="sc">$</span>default)<span class="sc">-</span><span class="dv">1</span>, <span class="at">type=</span><span class="st">'p'</span>,<span class="at">pch=</span><span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-27-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>We can calculate the confusion matrix for the model to see how well it predicts the default.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">predict.glm</span>(glm.fit,<span class="at">newdata =</span> Default, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="ot">=</span> <span class="fu">table</span>(Default<span class="sc">$</span>default, <span class="fu">as.integer</span>(y<span class="sc">&gt;</span><span class="fl">0.2</span>), <span class="at">dnn=</span><span class="fu">c</span>(<span class="st">"Actual"</span>, <span class="st">"Predicted"</span>))</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>confusion_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>##       Predicted
## Actual    0    1
##    No  9404  263
##    Yes  134  199</code></pre>
</div>
</div>
<p>Notice, that instead of using the default threshold of 0.5, we used 0.2. This is a common practice in the financial industry. The lower the threshold, the more likely the model is to predict a default. In other words, we only approve a loan to a person if model predicts a default with probability 0.2 or lower.</p>
<p>Instead of using counts in the confusion matrix, we can use rates</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to rates by dividing by row totals</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>confusion_matrix[<span class="dv">1</span>,] <span class="ot">=</span> confusion_matrix[<span class="dv">1</span>,] <span class="sc">/</span> <span class="fu">sum</span>(confusion_matrix[<span class="dv">1</span>,])  <span class="co"># Actual: NO row</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>confusion_matrix[<span class="dv">2</span>,] <span class="ot">=</span> confusion_matrix[<span class="dv">2</span>,] <span class="sc">/</span> <span class="fu">sum</span>(confusion_matrix[<span class="dv">2</span>,])  <span class="co"># Actual: YES row</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="sc">%&gt;%</span> <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">0</th>
<th style="text-align: right;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">No</td>
<td style="text-align: right;">0.97</td>
<td style="text-align: right;">0.027</td>
</tr>
<tr class="even">
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">0.40</td>
<td style="text-align: right;">0.598</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Using the rates (proportions) is a more typical way to present the confusion matrix.</p>
<!-- 
                 Predicted: YES   Predicted: NO
  ------------- ---------------- ---------------
   Actual: YES      TPR=0.6          FNR=0.4
   Actual: NO       FPR=0.03        TNR=0.97 -->
<p>For our predictions, we used the value of <span class="math inline">\(\alpha=0.2\)</span> as a cut-off. What if I use smaller or larger <span class="math inline">\(\alpha\)</span>, e.g.&nbsp;<span class="math inline">\(\alpha=0\)</span>? We wil use ROC curve to unswer this question. ROC curve shows the relationship between sensitivity (true positive rate) and 1 - specificity (false positive rate) for different classification thresholds. Here, 1 - specificity the proportion of negative cases that are incorrectly classified as positive. Thus, ROC curve shows both types of errors for different values of <span class="math inline">\(\alpha\)</span>.</p>
<p>First, we define a function, that calculates the ROC curve.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>roc <span class="ot">&lt;-</span> <span class="cf">function</span>(p,y, ...){</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">factor</span>(y)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(p)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(p)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>  alpha <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>  Q <span class="ot">&lt;-</span> p <span class="sc">&gt;</span> <span class="fu">matrix</span>(<span class="fu">rep</span>(alpha,n),<span class="at">ncol=</span><span class="dv">100</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>  specificity <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(<span class="sc">!</span>Q[y<span class="sc">==</span><span class="fu">levels</span>(y)[<span class="dv">1</span>],])</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>  sensitivity <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(Q[y<span class="sc">==</span><span class="fu">levels</span>(y)[<span class="dv">2</span>],])</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">specificity=</span>specificity, <span class="at">sensitivity=</span>sensitivity, <span class="at">alpha=</span>alpha))</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, let’s plot the ROC curve.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="do">## roc curve and fitted distributions</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict.glm</span>(glm.fit,<span class="at">newdata =</span> Default, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>res <span class="ot">=</span> <span class="fu">roc</span>(<span class="at">p=</span>pred, <span class="at">y=</span>Default<span class="sc">$</span>default)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">-</span>res<span class="sc">$</span>specificity, res<span class="sc">$</span>sensitivity, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">bty=</span><span class="st">"n"</span>, <span class="at">main=</span><span class="st">"in-sample"</span>)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>,<span class="at">b=</span><span class="dv">1</span>,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">col=</span><span class="dv">8</span>)</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>def <span class="ot">=</span> Default<span class="sc">$</span>default</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="co"># our 1/5 rule cutoff</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x=</span> <span class="dv">1</span><span class="sc">-</span><span class="fu">mean</span>((pred<span class="sc">&lt;</span>.<span class="dv">2</span>)[def<span class="sc">==</span><span class="st">"No"</span>]), </span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">y=</span><span class="fu">mean</span>((pred<span class="sc">&gt;</span>.<span class="dv">2</span>)[def<span class="sc">==</span><span class="st">"Yes"</span>]), </span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">cex=</span><span class="fl">1.5</span>, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">col=</span><span class="st">'red'</span>) </span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a><span class="do">## a standard `max prob' (p=.5) rule</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x=</span> <span class="dv">1</span><span class="sc">-</span><span class="fu">mean</span>((pred<span class="sc">&lt;</span>.<span class="dv">5</span>)[def<span class="sc">==</span><span class="st">"No"</span>]), </span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">y=</span><span class="fu">mean</span>((pred<span class="sc">&gt;</span>.<span class="dv">5</span>)[def<span class="sc">==</span><span class="st">"Yes"</span>]), </span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">cex=</span><span class="fl">1.5</span>, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">col=</span><span class="st">'blue'</span>) </span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomright"</span>,<span class="at">fill=</span><span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"blue"</span>),</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend=</span><span class="fu">c</span>(<span class="st">"alpha=1/5"</span>,<span class="st">"alpha=1/2"</span>),<span class="at">bty=</span><span class="st">"n"</span>,<span class="at">title=</span><span class="st">"cutoff"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-31-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>ROC curve shows the trade-off between sensitivity and specificity for different values of <span class="math inline">\(\alpha\)</span>. The closer the curve is to the top-left corner, the better the model is. The diagonal line represents the random classifier (flip a coin for each prediction). The curve above the diagonal line is better than random, the curve below the diagonal line is worse than random.</p>
<p>Now, let’s look at other predictors. We will add <code>income</code> and <code>student</code> to the model.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>glm.fit<span class="ot">=</span><span class="fu">glm</span>(default<span class="sc">~</span>balance<span class="sc">+</span>income<span class="sc">+</span>student,<span class="at">data=</span>Default,<span class="at">family=</span>binomial)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>glm.fit <span class="sc">%&gt;%</span> <span class="fu">tidy</span>() <span class="sc">%&gt;%</span> <span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">-10.87</td>
<td style="text-align: right;">0.49</td>
<td style="text-align: right;">-22.08</td>
<td style="text-align: right;">0.00</td>
</tr>
<tr class="even">
<td style="text-align: left;">balance</td>
<td style="text-align: right;">0.01</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">24.74</td>
<td style="text-align: right;">0.00</td>
</tr>
<tr class="odd">
<td style="text-align: left;">income</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.37</td>
<td style="text-align: right;">0.71</td>
</tr>
<tr class="even">
<td style="text-align: left;">studentYes</td>
<td style="text-align: right;">-0.65</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: right;">-2.74</td>
<td style="text-align: right;">0.01</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The p-values indicate that <code>student</code> is significant and <code>income</code> is not. However, the coefficient for <code>student</code> is negative. Meaning that students have lower probability of defaulting! This is counterintuitive, as one would expect that students have higher probability of defaulting. This is because the <code>student</code> variable and <code>balance</code> are <strong>confounded</strong>. We can see this by plotting the balance vs student.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(balance<span class="sc">~</span>student,<span class="at">data=</span>Default, <span class="at">ylab =</span> <span class="st">"balance"</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-33-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>We can see that students have higher balance on average. This is not surprising, as students are typically younger and have lower income and many have student loans.</p>
<p>Confounding occurs when the effect of one variable on the outcome is mixed with the effect of another variable, making it difficult to separate their individual contributions. In our case, <code>student</code> and <code>balance</code> are confounded.</p>
<p>Let’s adjust for balance. We will plot the predicted probability of default for a range of balances between 1000 and 2500 for students and non-students.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">balance =</span> <span class="fu">seq</span>(<span class="dv">1000</span>,<span class="dv">2500</span>,<span class="at">length.out =</span> <span class="dv">100</span>), <span class="at">student =</span> <span class="fu">as.factor</span>(<span class="fu">rep</span>(<span class="st">"Yes"</span>,<span class="dv">100</span>)), <span class="at">income=</span><span class="fu">rep</span>(<span class="dv">40</span>,<span class="dv">100</span>))</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">balance =</span> <span class="fu">seq</span>(<span class="dv">1000</span>,<span class="dv">2500</span>,<span class="at">length.out =</span> <span class="dv">100</span>), <span class="at">student =</span> <span class="fu">as.factor</span>(<span class="fu">rep</span>(<span class="st">"No"</span>,<span class="dv">100</span>)), <span class="at">income=</span><span class="fu">rep</span>(<span class="dv">40</span>,<span class="dv">100</span>))</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">=</span> <span class="fu">predict.glm</span>(glm.fit,<span class="at">newdata =</span> x1, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">=</span> <span class="fu">predict.glm</span>(glm.fit,<span class="at">newdata =</span> x2, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1<span class="sc">$</span>balance,y1, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">col=</span><span class="st">"red"</span>, <span class="at">xlab=</span><span class="st">"Balance"</span>, <span class="at">ylab =</span> <span class="st">"P(Default)"</span>)</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x2<span class="sc">$</span>balance,y2, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">col=</span><span class="st">"black"</span>)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>,<span class="at">bty=</span><span class="st">"n"</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">"Not Student"</span>, <span class="st">"Student"</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="st">"black"</span>,<span class="st">"red"</span>), <span class="at">lwd=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-34-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>We can see that for a given balance, students are actually less likely to default than non-students. This is because students have higher balance on average.</p>
<p>To summarise, what we’ve learned in this example, thus far. ROC curves visualize the trade-off between sensitivity (true positive rate) and specificity (1 - false positive rate) across different classification thresholds. Curves closer to the top-left corner indicate better model performance, while the diagonal line represents random classification (AUC = 0.5). Curves above the diagonal are better than random, below are worse. ROC curves help choose optimal classification thresholds based on business requirements rather than default 0.5 cutoff.</p>
<p>Confounding occurs when the effect of one variable on the outcome is mixed with the effect of another variable. In the Default dataset, student status and balance are confounded. Students have higher average balances due to student loans and lower income. Without controlling for balance, students appear more likely to default. After adjusting for balance, students are actually less likely to default. The solution is to include confounding variables in the model to isolate individual effects. Always consider variable relationships when interpreting coefficients.</p>
</div>
<p>Now, a natural question is how to choose the cut-off value <span class="math inline">\(\alpha\)</span>? Assume a bank is using our logistic regression model to predict probability of a loan default and would issue a loan if <span class="math inline">\(p(y=1) &lt; \alpha\)</span>. Here <span class="math inline">\(\alpha\)</span> is the level of risk bank is willing to take. If bank chooses <span class="math inline">\(\alpha=1\)</span> and gives loans to everyone it is likely to loose a lot of money from defaulted accounts. If it chooses <span class="math inline">\(\alpha = 0\)</span> it will not issue loan to anyone and wont make any money. In order to choose an appropriate <span class="math inline">\(\alpha\)</span>, we need to know what are the risks. Assume, bank makes $0.25 on every $1 borrowed in interest in fees and loose the entire amount of $1 if account defaults. This leads to the following pay-off matrix</p>
<table class="caption-top table">
<caption>Pay-off matrix for a loan</caption>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">payer</th>
<th style="text-align: right;">defaulter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>loan</td>
<td style="text-align: right;">0.25</td>
<td style="text-align: right;">-1</td>
</tr>
<tr class="even">
<td>no loan</td>
<td style="text-align: right;">-0.25</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
<p>We are making 25 cents on a dollar on a good loan and loose everything on a default!</p>
<p>Given this pay-off matrix, we can calculate the expected profit for the bank.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict.glm</span>(glm.fit,<span class="at">newdata =</span> Default, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>res <span class="ot">=</span> <span class="fu">roc</span>(<span class="at">p=</span>pred, <span class="at">y=</span>Default<span class="sc">$</span>default)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> res<span class="sc">$</span>alpha</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>specificity <span class="ot">=</span> res<span class="sc">$</span>specificity <span class="co"># correctly detect default</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>sensitivity <span class="ot">=</span> res<span class="sc">$</span>sensitivity <span class="co"># correctly detect non-default</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="co"># We loose money when we make a mistake. If we issue a loan to a non-defaulting customer, we loose $0.25. If we dont issue a loan to a defaulting customer, we loose $1.</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>profit <span class="ot">=</span> <span class="dv">0</span><span class="sc">*</span>specificity <span class="sc">-</span> <span class="dv">1</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>specificity) <span class="sc">+</span> <span class="fl">0.25</span><span class="sc">*</span>sensitivity <span class="sc">-</span> <span class="fl">0.25</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>sensitivity)</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(alpha, profit, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">xlab =</span> <span class="st">"alpha"</span>, <span class="at">ylab =</span> <span class="st">"profit"</span>)</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>, <span class="at">lty=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-35-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Let’s find the values of <span class="math inline">\(\alpha\)</span> for which profit is positive.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(alpha[profit<span class="sc">&gt;</span><span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.02</code></pre>
</div>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(alpha[profit<span class="sc">&gt;</span><span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.25</code></pre>
</div>
</div>
<p>We have to be prudent and choose <span class="math inline">\(\alpha\)</span> in this range. Now let’s find <span class="math inline">\(\alpha\)</span> that maximises the profit.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find index of max value in profit</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>alpha[<span class="fu">which.max</span>(profit)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.051</code></pre>
</div>
</div>
<p>Thus, to maximise the profit, we only approve the loan if we are 95% sure that the customer will not default.</p>
<!-- 
## Default
Let's consider an example. We want to predict default given
attributes of the loan applicant. We have 1000 observations of 9
variables

::: {.cell layout-align="center"}

```{.r .cell-code}
credit = read.csv("../data/credit.csv")
credit$history = factor(credit$history, levels=c("A30","A31","A32","A33","A34"))
levels(credit$history) = c("good","good","poor","poor","terrible")
credit$foreign <- factor(credit$foreign, levels=c("A201","A202"), labels=c("foreign","german"))
credit$rent <- factor(credit$housing=="A151")
credit$purpose <- factor(credit$purpose, levels=c("A40","A41","A42","A43","A44","A45","A46","A47","A48","A49","A410"))
levels(credit$purpose) <- c("newcar","usedcar",rep("goods/repair",4),"edu",NA,"edu","biz","biz")

credit <- credit[,c("Default", "duration", "amount",
                    "installment", "age", "history",
                    "purpose", "foreign", "rent")]
knitr::kable(head(credit))
```

::: {.cell-output-display}


| Default| duration| amount| installment| age|history  |purpose      |foreign |rent  |
|-------:|--------:|------:|-----------:|---:|:--------|:------------|:-------|:-----|
|       0|        6|   1169|           4|  67|terrible |goods/repair |foreign |FALSE |
|       1|       48|   5951|           2|  22|poor     |goods/repair |foreign |FALSE |
|       0|       12|   2096|           2|  49|terrible |edu          |foreign |FALSE |
|       0|       42|   7882|           2|  45|poor     |goods/repair |foreign |FALSE |
|       1|       24|   4870|           3|  53|poor     |newcar       |foreign |FALSE |
|       0|       36|   9055|           2|  35|poor     |edu          |foreign |FALSE |


:::
:::


We build a logistic regression model using all of the 8 predictors and
their interactions
```
credscore = glm(Default~.^2,data=credit,family=binomial)
```
Then we plot ROC curve (FPR vs TPR) for different values of $p$ and
compare the curve with the naive


::: {.cell layout-align="center"}
::: {.cell-output-display}
![ROC curve for logistic regression model for repearting defualts](fig/roc-example.svg){fig-align='center' width=100%}
:::
:::

 -->
<!-- 
## Multinomial logistic regression


Softmax regression (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. In logistic regression we assumed that the labels were binary: $y_i \in \{0,1\}$ . We used such a classifier to distinguish between two kinds of hand-written digits. Softmax regression allows us to handle $y_i \in \{1,\ldots ,K\}$ where $K$ is the number of classes. Our model took the form:
$$
f(x\mid \beta)=\dfrac{1}{1+\exp(-\beta^Tx)}~,
$$
and the model parameters $\beta$ were trained to minimize the loss function (negative log-likelihood)
$$
J(\beta) = -\left[ \sum_{i=1}^m y_i \log f(x\mid \beta) + (1-y_i) \log (1-f(x\mid \beta)) \right]
$$

Given a test input $x$, we want our model to estimate the probability that $p(y=k|x)$ for each value of $k=1,\ldots ,K$ Thus, our model will output a $K$-dimensional vector (whose elements sum to 1) giving us our K estimated probabilities. Concretely, our model $f(x\mid \beta)$ takes the form: 
$$
\begin{aligned}
f(x\mid \beta) =
\begin{bmatrix}
p(y = 1 | x; \beta) \\
p(y = 2 | x; \beta) \\
\vdots \\
p(y = K | x; \beta)
\end{bmatrix}
=
\frac{1}{ \sum_{j=1}^{K}{\exp(\beta_k^T x) }}
\begin{bmatrix}
\exp(\beta_1^{T} x ) \\
\exp(\beta_2^{T} x ) \\
\vdots \\
\exp(\beta_k^T x ) \\
\end{bmatrix}\end{aligned}
$$

Here $\beta_i \in R^n, i=1,\ldots,K$ are the parameters of our model. Notice that the term $1/ \sum_{j=1}^{K}{\exp(\beta_k^T x) }$ normalizes the distribution, so that it sums to one.

For convenience, we will also write $\beta$ to denote all the parameters of our model. When you implement softmax regression, it is usually convenient to represent $\beta$ as an $n$-by-$K$ matrix obtained by concatenating $\beta_1,\beta_2,\ldots ,\beta_K$ into columns, so that
$$
\beta = \left[\begin{array}{cccc}| & | & | & | \\
\beta_1 & \beta_2 & \cdots & \beta_K \\
| & | & | & |
\end{array}\right].
$$

We now describe the cost function that we'll use for softmax regression. In the equation below, $1$ is the indicator function, so that $1$(a true statement)=1, and $1$(a false statement)=0. For example, 1(2+3 \> 4) evaluates to 1; whereas 1(1+1 == 5) evaluates to 0. Our cost function will be: 
$$
\begin{aligned}
J(\beta) = - \left[ \sum_{i=1}^{m} \sum_{k=1}^{K}  1\left\{y_i = k\right\} \log \frac{\exp(\beta_k^T x_i)}{\sum_{j=1}^K \exp(\beta_k^T x_i)}\right]
\end{aligned}
$$

Notice that this generalizes the logistic regression cost function, which could also have been written: 
$$
\begin{aligned}
J(\beta) &= - \left[ \sum_{i=1}^m   (1-y_i) \log (1-f(x\mid \beta)) + y_i \log f(x\mid \beta) \right] \\
&= - \left[ \sum_{i=1}^{m} \sum_{k=0}^{1} 1\left\{y_i = k\right\} \log p(y_i = k | x_i ; \beta) \right]\end{aligned}
$$
The softmax cost function is similar, except that we now sum over the $K$ different possible values of the class label. Note also that in softmax regression, we have that
$$
p(y_i = k | x_i ; \beta) = \frac{\exp(\beta_k^T x_i)}{\sum_{j=1}^K \exp(\beta_k^T x_i) }.
$$

Softmax regression has an unusual property that it has a redundant set of parameters. To explain what this means, suppose we take each of our parameter vectors $\beta_j$, and subtract some fixed vector $\psi$. Our model now estimates the class label probabilities as
$$
\begin{aligned}
p(y_i = k | x_i ; \beta)
&= \frac{\exp((\beta_k-\psi)^T x_i)}{\sum_{j=1}^K \exp( (\beta_j-\psi)^T x_i)}  \\
&= \frac{\exp(\beta_k^T x_i) \exp(-\psi^T x_i)}{\sum_{j=1}^K \exp(\beta_k^T x_i) \exp(-\psi^T x_i)} \\
&= \frac{\exp(\beta_k^T x_i)}{\sum_{j=1}^K \exp(\beta_k^T x_i)}.\end{aligned}
$$
In other words, subtracting $\psi$ does not affect our model' predictions at all! This shows that softmax regression's parameters are redundant. More formally, we say that our softmax model is overparameterized, meaning that for any model we might fit to the data, there are multiple parameter settings that give rise to exactly the same model function $f(x \mid \beta)$ mapping from inputs $x$ to the predictions.  

Further, if the cost function $J(\beta)$ is minimized by some setting of the parameters $(\beta_1,\ldots,\beta_K)$, then it is also minimized by $(\beta_1-\psi,\ldots,\beta_K-\psi)$ for any value of $\psi$. Thus, the minimizer of $J(\beta)$ is not unique. Interestingly, $J(\beta)$ is still convex, and thus gradient descent will not run into local optima problems. But the Hessian is singular/non-invertible, which causes a straightforward implementation of Newton's method to run into numerical problems. We can just set $\psi$ to $\beta_i$ and remove $\beta_i$. -->
<div id="exm-LinkedIn" class="theorem example">
<p><span class="theorem-title"><strong>Example 14.4 (LinkedIn Study)</strong></span> How to Become an Executive<span class="citation" data-cites="irwin2016how gan2016how">(<a href="references.html#ref-irwin2016how" role="doc-biblioref">Irwin 2016</a>; <a href="references.html#ref-gan2016how" role="doc-biblioref">Gan and Fritzler 2016</a>)</span>?</p>
<p>Logistic regression was used to analyze the career paths of about <span class="math inline">\(459,000\)</span> LinkedIn members who worked at a <a href="http://www.vault.com/company-rankings/consulting/best-consulting-firms-prestige?sRankID=77">top 10 consultancy</a> between 1990 and 2010 and became a VP, CXO, or partner at a company with at least 200 employees. About <span class="math inline">\(64,000\)</span> members reached this milestone, <span class="math inline">\(\hat{p} = 0.1394\)</span>, conditional on making it into the database. The goals of the analysis were the following</p>
<ol type="1">
<li>Look at their profiles – educational background, gender, work experience, and career transitions.</li>
<li>Build a predictive model of the probability of becoming an executive</li>
<li>Provide a tool for analysis of “what if” scenarios. For example, if you are to get a master’s degree, how your jobs perspectives change because of that.</li>
</ol>
<p>Let’s build a logistic regression model with <span class="math inline">\(8\)</span> key features (a.k.a. covariates): <span class="math display">\[
\log\left ( \frac{p}{1-p} \right ) = \beta_0 + \beta_1x_1 + \beta_2x_2 + ... + \beta_8x_8
\]</span></p>
<ol type="1">
<li><p><span class="math inline">\(p\)</span>: Probability of “success” – reach VP/CXO/Partner seniority at a company with at least 200 employees.</p></li>
<li><p>Features to predict the “success” probability: <span class="math inline">\(x_i (i=1,2,\ldots,8)\)</span>.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Variable</th>
<th style="text-align: center;">Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(x_1\)</span></td>
<td style="text-align: center;">Metro region: whether a member has worked in one of the top 10 largest cities in the U.S. or globally.</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(x_2\)</span></td>
<td style="text-align: center;">Gender: Inferred from member names: ‘male’, or ‘female’</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(x_3\)</span></td>
<td style="text-align: center;">Graduate education type: whether a member has an MBA from a top U.S. program / a non-top program / a top non-U.S. program / another advanced degree</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(x_4\)</span></td>
<td style="text-align: center;">Undergraduate education type: whether a member has attended a school from the U.S. News national university rankings / a top 10 liberal arts college /a top 10 non-U.S. school</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(x_5\)</span></td>
<td style="text-align: center;">Company count: # different companies in which a member has worked</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(x_6\)</span></td>
<td style="text-align: center;">Function count: # different job functions in which a member has worked</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(x_7\)</span></td>
<td style="text-align: center;">Industry sector count: # different industries in which a member has worked</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(x_8\)</span></td>
<td style="text-align: center;">Years of experience: # years of work experience, including years in consulting, for a member.</td>
</tr>
</tbody>
</table></li>
</ol>
<p>The following estimated <span class="math inline">\(\hat\beta\)</span>s of features were obtained. With a sample size of 456,000 thy are measured rather accurately. Recall, given each location/education choice in the “Choice and Impact” is a unit change in the feature.</p>
<ol type="1">
<li>Location: <span style="color: blue">Metro region</span>: 0.28</li>
<li>Personal: <span style="color: blue">Gender(Male)</span>: 0.31</li>
<li>Education: <span style="color: blue">Graduate education type</span>: 1.16, <span style="color: blue">Undergraduate education type</span>: 0.22</li>
<li>Work Experience: <span style="color: blue">Company count</span>: 0.14, <span style="color: blue">Function count</span>: 0.26, <span style="color: blue">Industry sector count</span>: -0.22, <span style="color: blue">Years of experience</span>: 0.09</li>
</ol>
<p>Here are three main findings</p>
<ol type="1">
<li>Working across job functions, like marketing or finance, is good. Each additional job function provides a boost that, on average, is equal to three years of work experience. Switching industries has a slight negative impact. Learning curve? lost relationships?</li>
<li>MBAs are worth the investment. But pedigree matters. <em>Top five program equivalent to <span class="math inline">\(13\)</span> years of work experience!!!</em></li>
<li>Location matters. For example, NYC helps.</li>
</ol>
<p>We can also personalize the prediction for predict future possible future executives. For example, <span style="color: blue">Person A (p=6%)</span>: Male in Tulsa, Oklahoma, Undergraduate degree, 1 job function for 3 companies in 3 industries, 15-year experience.</p>
<p><span style="color: blue">Person B (p=15%)</span>: Male in London, Undergraduate degree from top international school, Non-MBA Master, 2 different job functions for 2 companies in 2 industries, 15-year experience.</p>
<p><span style="color: blue">Person C (p=63%)</span>: Female in New York City, Top undergraduate program, Top MBA program, 4 different job functions for 4 companies in 1 industry, 15-year experience.</p>
<p>Let’s re-design Person B.</p>
<p><span style="color: blue">Person B (p=15%)</span>: Male in London, Undergraduate degree from top international school, Non-MBA Master, 2 different job functions for 2 companies in 2 industries, 15-year experience.</p>
<ol type="1">
<li>Work in one industry rather than two. Increase <span class="math inline">\(3\)</span>%</li>
<li>Undergrad from top <span class="math inline">\(10\)</span> US program rather than top international school. <span class="math inline">\(3\)</span>%</li>
<li>Worked for <span class="math inline">\(4\)</span> companies rather than <span class="math inline">\(2\)</span>. Another <span class="math inline">\(4\)</span>%</li>
<li>Move from London to NYC. <span class="math inline">\(4\)</span>%</li>
<li>Four job functions rather than two. <span class="math inline">\(8\)</span>%. A <span class="math inline">\(1.5\)</span>x effect.</li>
<li>Worked for <span class="math inline">\(10\)</span> more years. <span class="math inline">\(15\)</span>%. A <span class="math inline">\(2\)</span>X effect.</li>
</ol>
<p>Choices and Impact (Person B) are shown below <img src="fig/choice.png" id="fig-choice" class="img-fluid" style="width:70.0%" alt="Choices and Impact (Person B)"></p>
</div>
</section>
<section id="imbalanced-data" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="imbalanced-data"><span class="header-section-number">14.4</span> Imbalanced Data</h2>
<p>Often, you have much more observations with a specific label, such a sample is called imbalanced. This is a common problem in real-world classification tasks where one class significantly outnumbers the other(s). For example, in fraud detection, legitimate transactions vastly outnumber fraudulent ones; in medical diagnosis, healthy patients often outnumber those with rare diseases; and in manufacturing, defective products are typically much rarer than non-defective ones.</p>
<p>When dealing with imbalanced data, you should avoid using accuracy as a metric to choose a model. Consider a binary classification problem with 95% of samples labeled as class 1. A naive classifier that simply assigns label 1 to every input will achieve 95% accuracy, making it appear deceptively good while being completely useless for practical purposes.</p>
<p>Instead, more appropriate evaluation metrics should be used. The Receiver Operating Characteristic (ROC) curve plots the true positive rate (sensitivity) against the false positive rate (1-specificity) at various classification thresholds. The Area Under the Curve (AUC) provides a single scalar value that measures the model’s ability to distinguish between classes, regardless of the chosen threshold. An AUC of 0.5 indicates random guessing, while 1.0 represents perfect classification.</p>
<p>The F1 score combines precision and recall into a single score, providing a balanced measure that penalizes models that are either too conservative or too aggressive: <span class="math display">\[
F1 = 2\dfrac{\mathrm{precision} \times \mathrm{recall}}{\mathrm{precision} + \mathrm{recall}}
\]</span> where precision measures the proportion of true positives among predicted positives, and recall measures the proportion of true positives that were correctly identified.</p>
<p>The precision-recall curve is particularly useful for imbalanced datasets, as it plots precision against recall at various thresholds, focusing on the performance of the positive class. Cohen’s Kappa measures agreement between predicted and actual classifications while accounting for agreement by chance, making it more robust to class imbalance than accuracy.</p>
<p>To address imbalanced data, several strategies can be employed. Data-level approaches include oversampling, where you synthetically generate more samples of the minority class using techniques like bootstrap sampling with replacement, SMOTE (Synthetic Minority Over-sampling Technique) which creates synthetic examples by interpolating between existing minority class samples, or generative models like GANs or variational autoencoders to create realistic synthetic data. Undersampling reduces the majority class samples, which is particularly effective when the dataset is large enough. Hybrid approaches combine both oversampling and undersampling techniques.</p>
<p>Algorithm-level approaches include cost-sensitive learning, where you assign different misclassification costs to different classes, ensemble methods using techniques like bagging or boosting that can naturally handle imbalanced data, and threshold adjustment to modify the classification threshold to optimize for specific metrics like F1-score.</p>
<p>The choice of approach depends on the specific problem, available data, and computational resources. It’s often beneficial to experiment with multiple techniques and evaluate their performance using appropriate metrics rather than relying solely on accuracy.</p>
</section>
<section id="kernel-trick" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="kernel-trick"><span class="header-section-number">14.5</span> Kernel Trick</h2>
<p>The kernel trick is particularly valuable when dealing with complex, non-linear patterns in data that cannot be separated by simple linear boundaries. Many real-world classification problems exhibit such non-linear relationships, making the kernel trick an essential tool in machine learning.</p>
<p>The key insight is that whilemany problems appear intractable in their original feature space, they often become linearly separable when mapped to higher-dimensional spaces using appropriate kernel functions. This transformation allows us to apply powerful linear classification methods to solve complex non-linear problems efficiently.</p>
<p>Kernel trick is a method of using a linear classifier to solve a non-linear problem. The idea is to map the data into a higher dimensional space, where it becomes linearly separable. The kernel trick is to use a kernel function <span class="math inline">\(K(x_i,x_j)\)</span> to calculate the inner product of two vectors in the higher dimensional space without explicitly calculating the mapping <span class="math inline">\(\phi(x_i)\)</span> and <span class="math inline">\(\phi(x_j)\)</span>. The kernel function is defined as <span class="math inline">\(K(x_i,x_j) = \phi(x_i)^T\phi(x_j)\)</span>. The most popular kernel functions are polynomial kernel <span class="math inline">\(K(x_i,x_j) = (x_i^Tx_j)^d\)</span> and Gaussian kernel <span class="math inline">\(K(x_i,x_j) = \exp(-\gamma||x_i-x_j||^2)\)</span>. The kernel trick is used in Support Vector Machines (SVM) and Gaussian Processes (GP).</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>gencircledata <span class="ot">=</span> <span class="cf">function</span>(numSamples,radius,noise) {</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    d <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">nrow =</span> numSamples); <span class="co"># matrix to store our generated data</span></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate positive points inside the circle.</span></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(numSamples<span class="sc">/</span><span class="dv">2</span>) ) {</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>, radius <span class="sc">*</span> <span class="fl">0.4</span>);</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    angle <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>, <span class="dv">2</span> <span class="sc">*</span> pi);</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">=</span> r <span class="sc">*</span> <span class="fu">sin</span>(angle);</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">=</span> r <span class="sc">*</span> <span class="fu">cos</span>(angle);</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>    noiseX <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="sc">-</span>radius, radius) <span class="sc">*</span> noise;</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>    noiseY <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="sc">-</span>radius, radius) <span class="sc">*</span> noise;</span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>    d[i,] <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,x,y)</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate negative points outside the circle.</span></span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> (numSamples<span class="sc">/</span><span class="dv">2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>numSamples ) {</span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,radius <span class="sc">*</span> <span class="fl">0.8</span>, radius);</span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a>    angle <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>, <span class="dv">2</span> <span class="sc">*</span> pi);</span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">=</span> r <span class="sc">*</span> <span class="fu">sin</span>(angle);</span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">=</span> r <span class="sc">*</span> <span class="fu">cos</span>(angle);</span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>    noiseX <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="sc">-</span>radius, radius) <span class="sc">*</span> noise;</span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>    noiseY <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="sc">-</span>radius, radius) <span class="sc">*</span> noise;</span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>    d[i,] <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>,x,y)</span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">colnames</span>(d) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"label"</span>, <span class="st">"x1"</span>, <span class="st">"x2"</span>)</span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(d)</span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="fu">gencircledata</span>(<span class="at">numSamples=</span><span class="dv">200</span>, <span class="at">radius=</span><span class="dv">1</span>, <span class="at">noise=</span><span class="fl">0.001</span>)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d[,<span class="dv">2</span>],d[,<span class="dv">3</span>], <span class="at">col=</span>d[,<span class="dv">1</span>]<span class="sc">+</span><span class="dv">1</span>, <span class="at">pch=</span><span class="dv">19</span>, <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab=</span><span class="st">"y"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-circle-data" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="576">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-circle-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="13-logistic_files/figure-html/fig-circle-data-1.png" id="fig-circle-data" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-circle-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.1
</figcaption>
</figure>
</div>
</div>
</div>
<p>The data on the left in Figure <a href="#fig-circle-data" class="quarto-xref">Figure&nbsp;<span>14.1</span></a> is clearly not linearly separable. However, if we map it to a three-dimensional space using the transformation: <span class="math display">\[
\begin{aligned}
\phi: R^{2} &amp; \longrightarrow R^{3} \\
\left(x_{1}, x_{2}\right) &amp; \longmapsto\left(z_{1}, z_{2}, z_{3}\right)=\left(x_{1}^{2}, \sqrt{2} x_{1} x_{2}, x_{2}^{2}\right),
\end{aligned}
\]</span> and attempt to linearly separate the transformed data, the decision boundaries become hyperplanes in <span class="math inline">\(R^{3}\)</span>, expressed as <span class="math inline">\(\omega^{T} z + b = 0\)</span>. In terms of the original variables <span class="math inline">\(x\)</span>, these boundaries take the form: <span class="math display">\[
\omega_{1} x_{1}^{2} + \omega_{2} \sqrt{2} x_{1} x_{2} + \omega_{3} x_{2}^{2} = 0,
\]</span> which corresponds to the equation of an ellipse. This demonstrates that we can apply a linear algorithm to transformed data to achieve a non-linear decision boundary with minimal effort.</p>
<p>Now, consider what the algorithm is actually doing. It relies solely on the Gram matrix <span class="math inline">\(K\)</span> of the data. Once <span class="math inline">\(K\)</span> is computed, the original data can be discarded: <span class="math display">\[
\begin{aligned}
K &amp; = \left[\begin{array}{ccc}
x_{1}^{T} x_{1} &amp; x_{1}^{T} x_{2} &amp; \cdots \\
x_{2}^{T} x_{1} &amp; \ddots &amp; \\
\vdots &amp; &amp;
\end{array}\right]_{n \times n} = X X^{T}, \\
\text{where} \quad X &amp; = \left[\begin{array}{c}
x_{1}^{T} \\
\vdots \\
x_{n}^{T}
\end{array}\right]_{n \times d}.
\end{aligned}
\]</span> Here, <span class="math inline">\(X\)</span>, which contains all the data, is referred to as the design matrix.</p>
<p>When we map the data using <span class="math inline">\(\phi\)</span>, the Gram matrix becomes: <span class="math display">\[
K = \left[\begin{array}{ccc}
\phi\left(x_{1}\right)^{T} \phi\left(x_{1}\right) &amp; \phi\left(x_{1}\right)^{T} \phi\left(x_{2}\right) &amp; \cdots \\
\phi\left(x_{2}\right)^{T} \phi\left(x_{1}\right) &amp; \ddots &amp; \\
\vdots &amp; &amp;
\end{array}\right].
\]</span></p>
<p>Let us compute these inner products explicitly. For vectors <span class="math inline">\(r\)</span> and <span class="math inline">\(s\)</span> in <span class="math inline">\(R^{3}\)</span> corresponding to <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, respectively: <span class="math display">\[
\begin{aligned}
\langle r, s \rangle &amp; = r_{1} s_{1} + r_{2} s_{2} + r_{3} s_{3} \\
&amp; = a_{1}^{2} b_{1}^{2} + 2 a_{1} a_{2} b_{1} b_{2} + a_{2}^{2} b_{2}^{2} \\
&amp; = \langle a, b \rangle^{2}.
\end{aligned}
\]</span></p>
<p>Thus, instead of explicitly mapping the data via <span class="math inline">\(\phi\)</span> and then computing the inner product, we can compute it directly in one step, leaving the mapping <span class="math inline">\(\phi\)</span> implicit. In fact, we do not even need to know <span class="math inline">\(\phi\)</span> explicitly; all we require is the ability to compute the modified inner product. This modified inner product is called a kernel, denoted <span class="math inline">\(K(x, y)\)</span>. The matrix <span class="math inline">\(K\)</span>, which contains the kernel values for all pairs of data points, is also referred to as the kernel matrix.</p>
<p>Since the kernel itself is the primary object of interest, rather than the mapping <span class="math inline">\(\phi\)</span>, we aim to characterize kernels without explicitly relying on <span class="math inline">\(\phi\)</span>. Mercer’s Theorem provides the necessary framework for this characterization.</p>
<p>Let’s implement it</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"scatterplot3d"</span>)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>phi <span class="ot">&lt;-</span> <span class="cf">function</span>(x1, x2) {</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>    z1 <span class="ot">&lt;-</span> x1<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>    z2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">2</span>) <span class="sc">*</span> x1 <span class="sc">*</span> x2</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>    z3 <span class="ot">&lt;-</span> x2<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">cbind</span>(z1, z2, z3))</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate sample 2D data (you can replace this with your actual data)</span></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the transformation</span></span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>transformed_data <span class="ot">&lt;-</span> <span class="fu">phi</span>(d[,<span class="dv">2</span>], d[,<span class="dv">3</span>])</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a><span class="fu">scatterplot3d</span>(transformed_data, <span class="at">color =</span> <span class="fu">ifelse</span>(d[,<span class="dv">1</span>] <span class="sc">==</span> <span class="dv">0</span>, <span class="st">"red"</span>, <span class="st">"blue"</span>), <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a>                <span class="at">xlab =</span> <span class="st">"z1 (x1^2)"</span>, <span class="at">ylab =</span> <span class="st">"z2 (sqrt(2) * x1 * x2)"</span>, <span class="at">zlab =</span> <span class="st">"z3 (x2^2)"</span>,</span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>                <span class="at">main =</span> <span class="st">"3D Scatter Plot of Transformed Data"</span>, <span class="at">angle=</span><span class="dv">222</span>, <span class="at">grid=</span><span class="cn">FALSE</span>, <span class="at">box=</span><span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13-logistic_files/figure-html/unnamed-chunk-40-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="polya-gamma" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="polya-gamma"><span class="header-section-number">14.6</span> Polya-Gamma</h2>
<p>Bayesian inference for logistic regression has long been recognized as a computationally challenging problem due to the analytically inconvenient form of the binomial likelihood function<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>. While the probit model enjoys simple latent-variable methods for posterior sampling, the logistic model has historically required more complex approaches involving multiple layers of auxiliary variables or approximations<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>. The breakthrough work of Polson, Scott, and Windle (2013) introduced a revolutionary data-augmentation strategy using a novel class of distributions called P{'o}lya-Gamma distributions, which enables simple and exact Gibbs sampling for Bayesian logistic regression<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>.</p>
<p>This methodology represents a significant advancement in Bayesian computation, providing a direct analog to the Albert and Chib (1993) method for probit regression while maintaining both exactness and simplicity<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>. The approach has proven particularly valuable for complex hierarchical models where traditional Metropolis-Hastings samplers are difficult to tune and implement effectively<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Innovation
</div>
</div>
<div class="callout-body-container callout-body">
<p>The P{'o}lya-Gamma methodology provides exact Gibbs sampling for Bayesian logistic regression, eliminating the need for complex Metropolis-Hastings tuning while maintaining theoretical guarantees.</p>
</div>
</div>
</section>
<section id="the-polya-gamma-distribution" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="the-polya-gamma-distribution"><span class="header-section-number">14.7</span> The P{'o}lya-Gamma Distribution</h2>
<p>The P{'o}lya-Gamma distribution, denoted as PG(b,c), is carefully constructed as a subset of infinite convolutions of gamma distributions<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>. A random variable X follows a P{'o}lya-Gamma distribution with parameters <span class="math inline">\(b &gt; 0\)</span> and <span class="math inline">\(c \in \mathbb{R}\)</span> if:</p>
<p><span class="math display">\[
X \stackrel{d}{=} \frac{1}{2\pi^2} \sum_{k=1}^{\infty} \frac{g_k}{(k-1/2)^2 + c^2/(4\pi^2)}
\]</span> where <span class="math inline">\(g_k \sim \text{Ga}(b,1)\)</span> are independent gamma random variables, and <span class="math inline">\(\stackrel{d}{=}\)</span> indicates equality in distribution<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>.</p>
<p>The P{'o}lya-Gamma family exhibits several remarkable properties that make it ideal for data augmentation:</p>
<ol type="1">
<li><p><strong>Laplace Transform</strong>: For <span class="math inline">\(\omega \sim \text{PG}(b,0)\)</span>, the Laplace transform is <span class="math inline">\(E\{\exp(-\omega t)\} = \cosh^{-b}(\sqrt{t}/2)\)</span><span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span></p></li>
<li><p><strong>Exponential Tilting</strong>: The general PG(b,c) distribution arises through exponential tilting of the PG(b,0) density:</p></li>
</ol>
<p><span class="math display">\[p(x|b,c) = \frac{\exp(-c^2x/2)p(x|b,0)}{E[\exp(-c^2\omega/2)]}\]</span></p>
<p>where the expectation is taken with respect to PG(b,0)<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span></p>
<ol start="3" type="1">
<li><p><strong>Convolution Property</strong>: The family is closed under convolution for random variates with the same tilting parameter<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span></p></li>
<li><p><strong>Known Moments</strong>: All finite moments are available in closed form, with the expectation given by:</p></li>
</ol>
<p><span class="math display">\[E(\omega) = \frac{b}{2c}\tanh(c/2) = \frac{b}{2c}\frac{e^c-1}{1+e^c}\]</span></p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Computational Advantage
</div>
</div>
<div class="callout-body-container callout-body">
<p>The known moments and convolution properties make the P{'o}lya-Gamma distribution computationally tractable and theoretically well-behaved.</p>
</div>
</div>
<section id="the-data-augmentation-strategy" class="level3">
<h3 class="anchored" data-anchor-id="the-data-augmentation-strategy">The Data-Augmentation Strategy</h3>
<p>The core of the P{'o}lya-Gamma methodology rests on a fundamental integral identity that represents binomial likelihoods as mixtures of Gaussians<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>. The key theorem states:</p>
<div class="theorem">
<p><strong>Theorem 1</strong>: For <span class="math inline">\(b &gt; 0\)</span> and <span class="math inline">\(a \in \mathbb{R}\)</span>, the following integral identity holds:</p>
<p><span class="math display">\[\frac{(e^\psi)^a}{(1+e^\psi)^b} = 2^{-b}e^{\kappa\psi} \int_0^{\infty} e^{-\omega\psi^2/2} p(\omega) d\omega\]</span></p>
<p>where <span class="math inline">\(\kappa = a - b/2\)</span>, and <span class="math inline">\(p(\omega)\)</span> is the density of <span class="math inline">\(\omega \sim \text{PG}(b,0)\)</span><span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>.</p>
<p>Moreover, the conditional distribution <span class="math inline">\(p(\omega|\psi)\)</span> is also in the P{'o}lya-Gamma class: <span class="math inline">\((\omega|\psi) \sim \text{PG}(b,\psi)\)</span><span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>.</p>
</div>
</section>
<section id="gibbs-sampling-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="gibbs-sampling-algorithm">Gibbs Sampling Algorithm</h3>
<p>This integral identity leads directly to a simple two-step Gibbs sampler for Bayesian logistic regression<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>. For a dataset with observations <span class="math inline">\(y_i \sim \text{Binom}(n_i, 1/(1+e^{-\psi_i}))\)</span> where <span class="math inline">\(\psi_i = x_i^T\beta\)</span>, and a Gaussian prior <span class="math inline">\(\beta \sim N(b,B)\)</span>, the algorithm iterates:</p>
<ol type="1">
<li><strong>Sample auxiliary variables</strong>: <span class="math inline">\((\omega_i|\beta) \sim \text{PG}(n_i, x_i^T\beta)\)</span> for each observation</li>
<li><strong>Sample parameters</strong>: <span class="math inline">\((\beta|y,\omega) \sim N(m_\omega, V_\omega)\)</span> where:
<ul>
<li><span class="math inline">\(V_\omega = (X^T\Omega X + B^{-1})^{-1}\)</span></li>
<li><span class="math inline">\(m_\omega = V_\omega(X^T\kappa + B^{-1}b)\)</span></li>
<li><span class="math inline">\(\kappa = (y_1-n_1/2, \ldots, y_n-n_n/2)\)</span></li>
<li><span class="math inline">\(\Omega = \text{diag}(\omega_1, \ldots, \omega_n)\)</span></li>
</ul></li>
</ol>
<p>This approach requires only Gaussian draws for the main parameters and P{'o}lya-Gamma draws for a single layer of latent variables, making it significantly simpler than previous methods<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>.</p>
</section>
<section id="the-pg1z-sampler" class="level3">
<h3 class="anchored" data-anchor-id="the-pg1z-sampler">The PG(1,z) Sampler</h3>
<p>The practical success of the P{'o}lya-Gamma method depends on efficient simulation of P{'o}lya-Gamma random variables<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>. The authors developed a sophisticated accept-reject sampler based on the alternating-series method of Devroye (1986)<span class="citation" data-cites="devroye1986nonuniform">(<a href="references.html#ref-devroye1986nonuniform" role="doc-biblioref">Devroye 1986</a>)</span>. For the fundamental PG(1,c) case, the sampler:</p>
<ul>
<li>Uses exponential and inverse-Gaussian draws as proposals</li>
<li>Achieves acceptance probability uniformly bounded below at 0.99919</li>
<li>Requires no tuning for optimal performance</li>
<li>Evaluates acceptance using iterative partial sums</li>
</ul>
</section>
<section id="general-pgbz-sampling" class="level3">
<h3 class="anchored" data-anchor-id="general-pgbz-sampling">General PG(b,z) Sampling</h3>
<p>For integer values of b, PG(b,z) random variables are generated by summing b independent PG(1,z) draws, exploiting the convolution property<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>. This approach maintains efficiency for moderate values of b, though computational cost scales linearly with the total number of counts in negative binomial applications<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>.</p>
</section>
</section>
<section id="implementation-with-bayeslogit-package" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="implementation-with-bayeslogit-package"><span class="header-section-number">14.8</span> Implementation with BayesLogit Package</h2>
<section id="package-overview" class="level3">
<h3 class="anchored" data-anchor-id="package-overview">Package Overview</h3>
<p>The <code>BayesLogit</code> package provides efficient tools for sampling from the P{'o}lya-Gamma distribution<span class="citation" data-cites="windle2023bayeslogit">(<a href="references.html#ref-windle2023bayeslogit" role="doc-biblioref">Windle 2023</a>)</span>. The current version (2.1) focuses on core functionality: sampling from the P{'o}lya-Gamma distribution through the <code>rpg()</code> function and its variants<span class="citation" data-cites="windle2023bayeslogit">(<a href="references.html#ref-windle2023bayeslogit" role="doc-biblioref">Windle 2023</a>)</span>.</p>
</section>
<section id="core-functions" class="level3">
<h3 class="anchored" data-anchor-id="core-functions">Core Functions</h3>
<p>The package offers several sampling methods:</p>
<ul>
<li><code>rpg()</code>: Main function that automatically selects the best method</li>
<li><code>rpg.devroye()</code>: Devroye-like method for integer h values</li>
<li><code>rpg.gamma()</code>: Sum of gammas method (slower but works for all parameters)</li>
<li><code>rpg.sp()</code>: Saddlepoint approximation method</li>
</ul>
</section>
<section id="installation-and-basic-usage" class="level3">
<h3 class="anchored" data-anchor-id="installation-and-basic-usage">Installation and Basic Usage</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install from CRAN</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"BayesLogit"</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(BayesLogit)</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Basic usage examples</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample from PG(1, 0)</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>samples1 <span class="ot">&lt;-</span> <span class="fu">rpg</span>(<span class="dv">1000</span>, <span class="at">h=</span><span class="dv">1</span>, <span class="at">z=</span><span class="dv">0</span>)</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample with tilting parameter</span></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>samples2 <span class="ot">&lt;-</span> <span class="fu">rpg</span>(<span class="dv">1000</span>, <span class="at">h=</span><span class="dv">1</span>, <span class="at">z=</span><span class="fl">2.5</span>)</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple shape parameters</span></span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>h_values <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>z_values <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>samples3 <span class="ot">&lt;-</span> <span class="fu">rpg</span>(<span class="dv">100</span>, <span class="at">h=</span>h_values, <span class="at">z=</span>z_values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="implementing-bayesian-logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="implementing-bayesian-logistic-regression">Implementing Bayesian Logistic Regression</h3>
<p>Here’s a complete implementation of Bayesian logistic regression using the P{'o}lya-Gamma methodology:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayesian Logistic Regression with P{\'o}lya-Gamma Data Augmentation</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>bayesian_logit_pg <span class="ot">&lt;-</span> <span class="cf">function</span>(y, X, <span class="at">n_iter=</span><span class="dv">5000</span>, <span class="at">burn_in=</span><span class="dv">1000</span>) {</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Prior specification (weakly informative)</span></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>  beta_prior_mean <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, p)</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>  beta_prior_prec <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="fl">0.01</span>, p)  <span class="co"># Precision matrix</span></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Storage for samples</span></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>  beta_samples <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, n_iter, p)</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>  omega_samples <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, n_iter, n)</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Initialize</span></span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>  beta <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, p)</span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(iter <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_iter) {</span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 1: Sample omega (auxiliary variables)</span></span>
<span id="cb75-19"><a href="#cb75-19" aria-hidden="true" tabindex="-1"></a>    psi <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta</span>
<span id="cb75-20"><a href="#cb75-20" aria-hidden="true" tabindex="-1"></a>    omega <span class="ot">&lt;-</span> <span class="fu">rpg</span>(n, <span class="at">h=</span><span class="dv">1</span>, <span class="at">z=</span>psi)</span>
<span id="cb75-21"><a href="#cb75-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-22"><a href="#cb75-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 2: Sample beta (regression coefficients)</span></span>
<span id="cb75-23"><a href="#cb75-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Posterior precision and mean</span></span>
<span id="cb75-24"><a href="#cb75-24" aria-hidden="true" tabindex="-1"></a>    V_omega <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> <span class="fu">diag</span>(omega) <span class="sc">%*%</span> X <span class="sc">+</span> beta_prior_prec)</span>
<span id="cb75-25"><a href="#cb75-25" aria-hidden="true" tabindex="-1"></a>    kappa <span class="ot">&lt;-</span> y <span class="sc">-</span> <span class="fl">0.5</span></span>
<span id="cb75-26"><a href="#cb75-26" aria-hidden="true" tabindex="-1"></a>    m_omega <span class="ot">&lt;-</span> V_omega <span class="sc">%*%</span> (<span class="fu">t</span>(X) <span class="sc">%*%</span> kappa <span class="sc">+</span> beta_prior_prec <span class="sc">%*%</span> beta_prior_mean)</span>
<span id="cb75-27"><a href="#cb75-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-28"><a href="#cb75-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample from multivariate normal</span></span>
<span id="cb75-29"><a href="#cb75-29" aria-hidden="true" tabindex="-1"></a>    beta <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(<span class="dv">1</span>, m_omega, V_omega)</span>
<span id="cb75-30"><a href="#cb75-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-31"><a href="#cb75-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store samples</span></span>
<span id="cb75-32"><a href="#cb75-32" aria-hidden="true" tabindex="-1"></a>    beta_samples[iter, ] <span class="ot">&lt;-</span> beta</span>
<span id="cb75-33"><a href="#cb75-33" aria-hidden="true" tabindex="-1"></a>    omega_samples[iter, ] <span class="ot">&lt;-</span> omega</span>
<span id="cb75-34"><a href="#cb75-34" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb75-35"><a href="#cb75-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb75-36"><a href="#cb75-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Return samples after burn-in</span></span>
<span id="cb75-37"><a href="#cb75-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb75-38"><a href="#cb75-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">beta =</span> beta_samples[(burn_in<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>n_iter, ],</span>
<span id="cb75-39"><a href="#cb75-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">omega =</span> omega_samples[(burn_in<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>n_iter, ],</span>
<span id="cb75-40"><a href="#cb75-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">n_samples =</span> n_iter <span class="sc">-</span> burn_in</span>
<span id="cb75-41"><a href="#cb75-41" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb75-42"><a href="#cb75-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb75-43"><a href="#cb75-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-44"><a href="#cb75-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage with simulated data</span></span>
<span id="cb75-45"><a href="#cb75-45" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb75-46"><a href="#cb75-46" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb75-47"><a href="#cb75-47" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n<span class="sc">*</span><span class="dv">2</span>), n, <span class="dv">2</span>))  <span class="co"># Intercept + 2 predictors</span></span>
<span id="cb75-48"><a href="#cb75-48" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">1.2</span>, <span class="sc">-</span><span class="fl">0.8</span>)</span>
<span id="cb75-49"><a href="#cb75-49" aria-hidden="true" tabindex="-1"></a>logits <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta_true</span>
<span id="cb75-50"><a href="#cb75-50" aria-hidden="true" tabindex="-1"></a>probs <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>logits))</span>
<span id="cb75-51"><a href="#cb75-51" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, probs)</span>
<span id="cb75-52"><a href="#cb75-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-53"><a href="#cb75-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model</span></span>
<span id="cb75-54"><a href="#cb75-54" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">bayesian_logit_pg</span>(y, X, <span class="at">n_iter=</span><span class="dv">3000</span>, <span class="at">burn_in=</span><span class="dv">500</span>)</span>
<span id="cb75-55"><a href="#cb75-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-56"><a href="#cb75-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior summaries</span></span>
<span id="cb75-57"><a href="#cb75-57" aria-hidden="true" tabindex="-1"></a>posterior_means <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(results<span class="sc">$</span>beta)</span>
<span id="cb75-58"><a href="#cb75-58" aria-hidden="true" tabindex="-1"></a>posterior_sds <span class="ot">&lt;-</span> <span class="fu">apply</span>(results<span class="sc">$</span>beta, <span class="dv">2</span>, sd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Computational Advantages</strong></p>
<p>Extensive benchmarking studies demonstrate the superior performance of the P{'o}lya-Gamma method across various scenarios<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>:</p>
<ol type="1">
<li><strong>Simple logistic models</strong>: Competitive with well-tuned Metropolis-Hastings samplers</li>
<li><strong>Hierarchical models</strong>: Significantly outperforms alternative methods</li>
<li><strong>Mixed models</strong>: Provides substantial efficiency gains over traditional approaches</li>
<li><strong>Spatial models</strong>: Shows dramatic improvements for Gaussian process spatial models</li>
</ol>
<p><strong>Theoretical Guarantees</strong></p>
<p>The P{'o}lya-Gamma Gibbs sampler enjoys strong theoretical properties<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>:</p>
<ul>
<li><strong>Uniform ergodicity</strong>: Proven by Choi and Hobert (2013), guaranteeing convergence and central limit theorems for Monte Carlo averages<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span></li>
<li><strong>No tuning required</strong>: Unlike Metropolis-Hastings methods, the sampler requires no manual tuning</li>
<li><strong>Exact sampling</strong>: Produces draws from the correct posterior distribution without approximation</li>
</ul>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The theoretical guarantees hold under standard regularity conditions, and the method requires proper prior specification for optimal performance.</p>
</div>
</div>
<p><strong>Beyond Binary Logistic Regression</strong></p>
<p>The P{'o}lya-Gamma methodology extends naturally to various related models<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>:</p>
<ol type="1">
<li>Negative binomial regression: Direct application using the same data-augmentation scheme</li>
<li>Multinomial logistic models: Extended through partial difference of random utility models<span class="citation" data-cites="windle2014sampling">(<a href="references.html#ref-windle2014sampling" role="doc-biblioref">Windle, Polson, and Scott 2014</a>)</span></li>
<li>Mixed effects models: Seamless incorporation of random effects structures</li>
<li>Spatial models: Efficient inference for spatial count data models</li>
</ol>
</section>
<section id="modern-applications" class="level3">
<h3 class="anchored" data-anchor-id="modern-applications">Modern Applications</h3>
<p>Recent developments have expanded the methodology’s applicability[<span class="citation" data-cites="windle2014sampling">Windle, Polson, and Scott (<a href="references.html#ref-windle2014sampling" role="doc-biblioref">2014</a>)</span>]<span class="citation" data-cites="zhang2018scalable">(<a href="references.html#ref-zhang2018scalable" role="doc-biblioref">Zhang, Datta, and Banerjee 2018</a>)</span>:</p>
<ul>
<li>Gaussian process classification: Scalable variational approaches using P{'o}lya-Gamma augmentation</li>
<li>Deep learning: Integration with neural network architectures for Bayesian deep learning</li>
<li>State-space models: Application to dynamic binary time series models</li>
</ul>
<p>The P{'o}lya-Gamma methodology represents a fundamental advancement in Bayesian computation for logistic models, combining theoretical elegance with practical efficiency<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>. Its introduction of the P{'o}lya-Gamma distribution class and the associated data-augmentation strategy has enabled routine application of Bayesian methods to complex hierarchical models that were previously computationally prohibitive<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>.</p>
<p>The <code>BayesLogit</code> package provides researchers and practitioners with efficient, well-tested implementations of these methods<span class="citation" data-cites="windle2023bayeslogit">(<a href="references.html#ref-windle2023bayeslogit" role="doc-biblioref">Windle 2023</a>)</span>. The combination of exact inference, computational efficiency, and theoretical guarantees makes the P{'o}lya-Gamma approach the method of choice for Bayesian logistic regression in most practical applications<span class="citation" data-cites="polson2013bayesian">(<a href="references.html#ref-polson2013bayesian" role="doc-biblioref">Polson, Scott, and Windle 2013</a>)</span>.</p>
<p>As computational demands continue to grow and models become increasingly complex, the P{'o}lya-Gamma methodology’s advantages become even more pronounced, establishing it as an essential tool in the modern Bayesian statistician’s toolkit (<span class="citation" data-cites="tiao2019polyagamma">Tiao (<a href="references.html#ref-tiao2019polyagamma" role="doc-biblioref">2019</a>)</span>). Ongoing research continues to extend the P{'o}lya-Gamma methodology to new domains, including high-dimensional settings, nonparametric models, and integration with modern machine learning frameworks.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-devroye1986nonuniform" class="csl-entry" role="listitem">
Devroye, Luc. 1986. <em>Non-Uniform Random Variate Generation</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-gan2016how" class="csl-entry" role="listitem">
Gan, Link, and Alan Fritzler. 2016. <span>“How to Become an Executive.”</span>
</div>
<div id="ref-irwin2016how" class="csl-entry" role="listitem">
Irwin, Neil. 2016. <span>“How to <span>Become</span> a <span>C</span>.<span>E</span>.<span>O</span>.? <span>The Quickest Path Is</span> a <span>Winding One</span>.”</span> <em>The New York Times</em>, September.
</div>
<div id="ref-polson2013bayesian" class="csl-entry" role="listitem">
Polson, Nicholas G., James G. Scott, and Jesse Windle. 2013. <span>“Bayesian <span>Inference</span> for <span class="nocase">Logistic Models Using P<span class="nocase">ó</span>lya</span>–<span>Gamma Latent Variables</span>.”</span> <em>Journal of the American Statistical Association</em> 108 (504): 1339–49.
</div>
<div id="ref-tiao2019polyagamma" class="csl-entry" role="listitem">
Tiao, Louis. 2019. <span>“P<span>ó</span>lya-<span>Gamma Bayesian</span> Logistic Regression.”</span> Blog post.
</div>
<div id="ref-windle2023bayeslogit" class="csl-entry" role="listitem">
Windle, Jesse. 2023. <span>“<span>BayesLogit</span>: <span>Bayesian</span> Logistic Regression.”</span> R package version 2.1.
</div>
<div id="ref-windle2014sampling" class="csl-entry" role="listitem">
Windle, Jesse, Nicholas G. Polson, and James G. Scott. 2014. <span>“Sampling <span>Polya-Gamma</span> Random Variates: Alternate and Approximate Techniques.”</span> arXiv.
</div>
<div id="ref-zhang2018scalable" class="csl-entry" role="listitem">
Zhang, Yichi, Anirban Datta, and Sudipto Banerjee. 2018. <span>“Scalable <span>Gaussian</span> Process Classification with <span class="nocase">P<span class="nocase">ó</span>lya-Gamma</span> Data Augmentation.”</span> <em>arXiv Preprint arXiv:1802.06383</em>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./12-regression.html" class="pagination-link" aria-label="Linear Regression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Linear Regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./14-tree.html" class="pagination-link" aria-label="Tree Models">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Tree Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>