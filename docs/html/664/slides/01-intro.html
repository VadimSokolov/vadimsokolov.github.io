<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-29e2c20b02301cfff04dc8050bf30c7e.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.37">

  <meta name="author" content="Vadim Sokolov   George Mason University   Spring 2025">
  <title>Bayes AI</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-bbe7401fe57d4b791b917637bb662036.css">
  <link rel="stylesheet" href="style.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="center">
  <h1 class="title" style="font-size:40px;">Bayes AI</h1>
  <p class="subtitle" style="color:blue;font-size:50px;">Unit 1: Introduction: AI Today and in the Past. Probability and Bayes Rule</p>
<img style="height: 350px;" src="fig/page/01-intro.jpg">
  <p class="author">Vadim Sokolov <br> George Mason University <br> Spring 2025</p>

<p style="font-size:10px;"> 
<a href="https://vsokolov.org/courses/664.html">Course Page</a>, <a href="https://vsokolov.org/html/664/slides/">Slides</a>
</p>


</section>
<section id="random-facts" class="slide level2">
<h2>Random facts</h2>
<p>On this Day (January 27):</p>
<ul>
<li>1888: The National Geographic Society is founded in Washington, D.C.</li>
<li>1945: The Red Army liberates the Auschwitz-Birkenau concentration</li>
<li>1967: The United States, United Kingdom, and Soviet Union sign the Outer Space Treaty in Washington, D.C.</li>
<li>1973: The Paris Peace Accords officially end the Vietnam War.</li>
<li>2010: Apple Inc.&nbsp;unveils the iPad.</li>
</ul>
</section>
<section>
<section id="brief-history-of-ai" class="title-slide slide level1 center">
<h1>Brief History of AI</h1>

</section>
<section id="the-first-thoughts-about-artificial-intelligence" class="slide level2">
<h2>The first thoughts about artificial intelligence</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li>Hephaestus created for himself Android robots, such as a giant human-like robot of Talos.</li>
<li>Pygmalion revived Galatea.</li>
<li>Jehovah and Allah - pieces of clay.1</li>
<li>Particularly wise rabbis could create golems.</li>
<li>Albert the Great made an artificial speaking head (which very upset Thomas Aquinas).</li>
</ul>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img data-src="fig/speakinghead.jpg"></p>
</div>
</div>
</div>
</section>
<section id="mechanical-machines" class="slide level2">
<h2>Mechanical machines</h2>
<p>Robots and Automatic Machines Were Generally Very Inventive: Al-Jazari (XII Century)</p>

<img data-src="fig/Al-Jazari.jpg" class="r-stretch"><p>Hesdin Castle (Robert II of Artois), Leonardo’s robot…</p>
</section>
<section id="mechanical-machines-1" class="slide level2">
<h2>Mechanical machines</h2>
<p>Jaquet-Droz automata (XVIII century):</p>

<img data-src="fig/Jaquet-Droz.jpg" class="r-stretch"></section>
<section id="mechanical-machines-2" class="slide level2">
<h2>Mechanical machines</h2>
<ul>
<li>But this is in mechanics, in mathematics/logic AI it was quite rudimentary for a long time</li>
</ul>

<img data-src="fig/Llull.jpg" class="r-stretch quarto-figure-center"><p class="caption">Logic machine of Ramon Llull (XIII-XIV centuries)</p><ul>
<li>Starting with Dr.&nbsp;Frankenstein, further AI in the literature appears constantly …</li>
</ul>
</section>
<section id="turing-test" class="slide level2">
<h2>Turing Test</h2>
<ul>
<li>AI as a science begins with a Turing test (1950).</li>
<li>The ides of the Turing test is to check if a machine can imitate a human in a conversation.</li>
<li>The original formulaiton was more nuancesd.</li>
</ul>

<img data-src="fig/turing.jpg" class="r-stretch"></section>
<section id="shennons-theseus" class="slide level2">
<h2>Shennon’s Theseus</h2>
<ul>
<li><a href="https://youtu.be/_9_AEVQ_p74?si=W3x-4sLSCUzdAeph">YouTube Video</a></li>
<li>Early 1950s, Claude Shannon (The father of Information Theory) demonstrates Theseus</li>
<li>A life-sized magnetic mouse controlled by relay circuits, learns its way around a maze.</li>
</ul>

<img data-src="fig/thesus.png" class="r-stretch"></section>
<section id="stanford-cart" class="slide level2">
<h2>Stanford Cart</h2>
<p><ber><ber></ber></ber></p>
<ul>
<li><a href="https://www.youtube.com/watch?v=dcS6Ol5xXqY">YouTube Video</a></li>
<li>Takes 2.6-second for signal to travel from earth to the moon</li>
<li>Latest iterations is automated with 3D vision capabilities</li>
<li>Pause after each meter of movement and take 10-15 minutes to reassess its surroundings and reevaluate its decided path.</li>
<li>In 1979, this cautious version of the cart successfully made its way 20 meters through a chair-strewn room in five hours without human intervention.</li>
</ul>
</section>
<section id="turing-test-1" class="slide level2">
<h2>Turing Test</h2>
<p>It takes a lot to create an AI system:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=MNuFcIRlwdc">Processing of a natural language</a></li>
<li>Sensors and actuators</li>
<li>Representation of knowledge</li>
<li><a href="https://www.wolframalpha.com/">Inference from the existing knowledge</a></li>
<li>Training on experience (Machine Learning).</li>
</ul>

<img data-src="fig/aisys.jpg" class="r-stretch"></section>
<section id="dartmouth-workshop" class="slide level2">
<h2>Dartmouth workshop</h2>
<ul>
<li>AI as a science appeared in 1956 at the Dartmouth workshop.</li>
<li>It was organized by John McCarthy, Marvin Minsky, Claude Shennon and Nathaniel Rochester.</li>
<li>It was probably the most ambitious grant proposal in the history of computer science.</li>
</ul>

<img data-src="fig/workshop.jpg" class="r-stretch"></section>
<section id="dartmouth-workshop-1" class="slide level2">
<h2>Dartmouth workshop</h2>
<p><br><br> We propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.</p>
</section>
<section id="great-hopes" class="slide level2">
<h2>1956-1960: Great hopes</h2>
<ul>
<li>Optimistic time. It seemed a that we were almost there…</li>
<li>Allen Newell, Herbert A. Simon, and Cliff Shaw: <em>Logic Theorist</em>.</li>
<li>Automated reasoning.</li>
<li>It was able to prof most of the Principia Mathematica, in some places even more elegant than Russell and Whitehead.</li>
</ul>

<img data-src="fig/simon.jpg" class="r-stretch"></section>
<section id="big-hopes" class="slide level2">
<h2>1956-1960: Big Hopes</h2>
<ul>
<li>General Problem Solver - a program that tried to think as a person</li>
<li>A lot of programs that have been able to do some limited things (MicroWorlds):
<ul>
<li>Analogy (IQ tests with multiple choice questions)</li>
<li>Student (algebraic verbal tasks)</li>
<li>Blocks World (rearranged 3D blocks).</li>
</ul></li>
</ul>
</section>
<section id="sknowledge-based-systems" class="slide level2">
<h2>1970s:Knowledge Based Systems</h2>
<ul>
<li>The bottom line: to accumulate a fairly large set of rules and knowledge about the subject area, then draw conclusions.</li>
<li>First success: MYCIN - Diagnosis of blood infections:
<ul>
<li>about 450 rules</li>
<li>The results are like an experienced doctor and significantly better than beginner doctors.</li>
</ul></li>
</ul>

<img data-src="fig/MYCIN.png" class="r-stretch"></section>
<section id="commercial-applications-industry-ai" class="slide level2">
<h2>1980-2010: Commercial applications Industry AI</h2>
<ul>
<li>The first AI department was at Dec (Digital Equipment Corporation)It is argued that by 1986 he saved the Dec about &nbsp;$ 10 million per year.</li>
<li>The boom ended by the end of the 80s, when many companies could not live up to high expectations.</li>
</ul>

<img data-src="fig/dec.png" class="r-stretch"></section>
<section id="data-mining-machine-learning" class="slide level2">
<h2>1990-2010: DATA MINING, MACHINE LEARNING</h2>
<ul>
<li>In recent decades, the main emphasis has shifted to machine training and search for patterns in the data.</li>
<li>Especially - with the development of the Internet.</li>
<li>Not too many people remember the original AI ideas, but Machine Learning is now everywhere.</li>
<li>But Robotics flourishes and uses Machine Learning at every step.</li>
</ul>
</section>
<section id="rule-based-system-vs-bayes" class="slide level2">
<h2>Rule-Based System vs Bayes</h2>
<ul>
<li>Since 1956, the field of artificial intelligence (AI) has undergone significant transformations</li>
<li><em>traditional AI</em> was mostly focused on rule-based systems and boolean logic programming, with limited learning capabilities. - It lead to them being brittle in changing environments.</li>
<li>On the other hand, <em>emerging AI</em> is focused on modeling uncertainties, pattern matching, and deep learning.</li>
<li>All of those are data-driven approaches.</li>
<li>These approaches are more adaptable and can handle complex and unstructured data. They are also more data-dependent and lack interpretability.</li>
</ul>
</section>
<section id="rule-based-system-vs-bayes-1" class="slide level2 smaller">
<h2>Rule-Based System vs Bayes</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[48,-4,48]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 48.0%;justify-content: flex-start;">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Old AI</strong></p>
</div>
<div class="callout-content">
<p><br> <em>If rain outside, then take umbrella</em></p>
<p>This rule cannot be learned from data. It does not allow inference. Cannot say anything about rain outside if I see an umbrella.</p>
<p><br></p>
</div>
</div>
</div>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 4.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 48.0%;justify-content: flex-start;">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>New AI</strong></p>
</div>
<div class="callout-content">
<p><em>Probability of taking umbrella, given there is rain</em></p>
<p>Conditional probability rule can be learned from data. Allows for inference. We can calculate the probability of rain outside if we see an umbrella.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<ul>
<li>Bayesian approach is a powerful statistical framework based on the work of Thomas Bayes and later Laplace.</li>
<li>It provides a probabilistic approach to reasoning and learning</li>
<li>Allowing us to update our beliefs about the world as we gather new data.</li>
<li>This makes it a natural fit for artificial intelligence, where we often need to deal with uncertainty and incomplete information.</li>
</ul>
</section>
<section id="definition" class="slide level2">
<h2>DEFINITION</h2>
<ul>
<li>How to determine “learning”?</li>
</ul>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Definition:</strong></p>
</div>
<div class="callout-content">
<p>The computer program learns as the data is accumulating relative to a certain problem class <span class="math inline">\(T\)</span> and the target function of <span class="math inline">\(P\)</span> if the quality of solving these problems (relative to <span class="math inline">\(P\)</span>) improves with gaining new experience.</p>
</div>
</div>
</div>
<ul>
<li>The definition is very (too?) General.</li>
<li>What specific examples can be given?</li>
</ul>
</section>
<section id="tasks-and-concepts-of-ml" class="slide level2">
<h2>Tasks and concepts of ML</h2>

<img data-src="fig/book-ml-tasks.drawio.svg" class="r-stretch"></section>
<section id="tasks-and-concepts-of-ml-supervised-learning" class="slide level2">
<h2>Tasks and concepts of ML: Supervised Learning</h2>
<ul>
<li>training sample – a set of examples, each of which consists of input features (attributes) and the correct “answers” - the response variable</li>
<li>Learn a rule that maps input features to the response variable</li>
<li>Then this rule is applied to new examples (deployment)</li>
<li>The main thing is to train a model that explains not only examples from the training set, but also new examples (generalizes)</li>
<li>Otherwise - overfitting</li>
</ul>
</section>
<section id="tasks-and-concepts-of-ml-unsupervised-learning" class="slide level2">
<h2>Tasks and concepts of ML: unsupervised learning</h2>
<p>There are no correct answers, only data, e.g.&nbsp;<em>clustering</em>:</p>
<ul>
<li>We need to divide the data into pre -unknown classes to some extent similar:</li>
<li>highlight the family of genes from the sequences of nucleotides</li>
<li>cluster users and personalize the application for them</li>
<li>cluster the mass spectrometric image to parts with different composition</li>
</ul>
</section>
<section id="tasks-and-concepts-of-ml-unsupervised-learning-1" class="slide level2">
<h2>Tasks and concepts of ML: unsupervised learning</h2>
<ul>
<li>Dimensionality reduction: data have a high dimension, it is necessary to reduce it, select the most informative features so that all of the above algorithms can work</li>
<li>Matrix Compition: There is a sparse matrix, we must predict what is in the missing positions.</li>
<li>Anomaly detection: find anomalies in the data, e.g.&nbsp;fraud detection. -Often the outputs answers are given for a small part of the data, then we call it semi -supervised Learning.</li>
</ul>
</section>
<section id="tasks-and-concepts-of-ml-reinforcement-learning" class="slide level2">
<h2>Tasks and concepts of ML: reinforcement learning</h2>
<ul>
<li>Multi-armed bandits: there is a certain set of actions, each of which leads to random results, you need to get as much rewardas possible</li>
<li>Exploration vs.Exploitation: how and when to proceed from the study of the new to use what has already studied</li>
<li>Credit Assignment: You get rewarded at the very end (won the game), and we must somehow distribute this reward on all the moves that led to victory.</li>
</ul>
</section>
<section id="tasks-and-concepts-of-ml-active-learning" class="slide level2">
<h2>Tasks and concepts of ML: active learning</h2>
<ul>
<li>Active Learning - how to choose the following (relatively expensive) test</li>
<li>Boosting - how to combine several weak classifiers so that it turns out good</li>
<li>Model Selection - where to draw a line between models with many parameters and with a few.</li>
<li>Ranking: response list is ordered (internet search)</li>
</ul>
</section>
<section id="tasks-and-concepts-of-ai" class="slide level2">
<h2>Tasks and concepts of AI</h2>

<img data-src="fig/book-ai-tasks.drawio.svg" class="r-stretch"></section>
<section id="tasks-and-concepts-of-ai-reasoning" class="slide level2">
<h2>Tasks and concepts of AI: Reasoning</h2>
<ul>
<li>Bayesian networks: given conditional probabilities, calculate the probability of the event</li>
<li>o1 by OpenAI: a family of AI models that are designed to perform complex reasoning tasks, such as math, coding, and science. o1 models placed among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME)</li>
<li>Gemini 2.0: model for the agentic era</li>
</ul>
</section>
<section id="tasks-and-concepts-of-ai-representation" class="slide level2">
<h2>Tasks and concepts of AI: Representation</h2>
<ul>
<li>Knowledge Graphs: a graph database that uses semantic relationships to represent knowledge</li>
<li>Embeddings: a way to represent data in a lower-dimensional space</li>
<li>Transformers: a deep learning model that uses self-attention to process sequential data</li>
</ul>
</section>
<section id="tasks-and-concepts-of-ai-generation" class="slide level2">
<h2>Tasks and concepts of AI: Generation</h2>
<p>In shadows of data, uncertainty reigns,<br>
Bayesian whispers, where knowledge remains.<br>
With prior beliefs, we start our quest,<br>
Updating with evidence, we strive for the best.</p>
<p>A dance of the models, predictions unfold,<br>
Inferences drawn, from the new and the old.<br>
Through probabilities, we find our way,<br>
In the world of AI, it’s the Bayesian sway.</p>
<p>So gather your data, let prior thoughts flow,<br>
In the realm of the unknown, let your insights grow.<br>
For in this approach, with each little clue,<br>
We weave understanding, both rich and true.</p>
<p><a href="https://suno.com/song/b716f67d-8fe9-44b9-8445-719b2f38abb2">Music</a></p>
</section>
<section id="tasks-and-concepts-of-ai-generation-1" class="slide level2">
<h2>Tasks and concepts of AI: Generation</h2>
<div id="c3230d1e" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb1-2"><a></a>client <span class="op">=</span> OpenAI(api_key<span class="op">=</span><span class="st">"your-api-key"</span>)</span>
<span id="cb1-3"><a></a>response <span class="op">=</span> client.images.generate(</span>
<span id="cb1-4"><a></a>    model<span class="op">=</span><span class="st">"dall-e-3"</span>,</span>
<span id="cb1-5"><a></a>    prompt<span class="op">=</span><span class="st">"a hockey player trying to understand the Bayes rule"</span>,</span>
<span id="cb1-6"><a></a>    size<span class="op">=</span><span class="st">"1024x1024"</span>,</span>
<span id="cb1-7"><a></a>    quality<span class="op">=</span><span class="st">"standard"</span>,</span>
<span id="cb1-8"><a></a>    n<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb1-9"><a></a>)</span>
<span id="cb1-10"><a></a></span>
<span id="cb1-11"><a></a><span class="bu">print</span>(response.data[<span class="dv">0</span>].url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tasks-and-concepts-of-ai-generation-2" class="slide level2">
<h2>Tasks and concepts of AI: Generation</h2>
<p>A humorous and illustrative scene of a hockey player sitting on a bench in full gear, holding a hockey stick in one hand and a whiteboard marker in th</p>

<img data-src="fig/dalle-hockey.svg" class="r-stretch"></section>
<section id="chess-and-ai" class="slide level2">
<h2>Chess and AI</h2>
<p>Old AI: Deep Blue (1997) vs.&nbsp;Garry Kasparov</p>

<img data-src="figup/deepblue.png" class="r-stretch quarto-figure-center"><p class="caption">Kasparov vs IBM’s DeepBlue in 1997</p></section>
<section id="alphago-zero" class="slide level2">
<h2>AlphaGo Zero</h2>
<ul>
<li>Remove all human knowledge from training process - only uses self play,</li>
<li>Takes raw board as input and neural network predicts the next move.</li>
<li>Uses Monte Carlo tree search to evaluate the position.</li>
<li>The algorithm was able to beat AlphaGo 100-0. The algorithm was then used to play chess and shogi and was able to beat the best human players in those games as well.</li>
</ul>

<img data-src="figup/move37.jpeg" style="width:30.0%" class="r-stretch quarto-figure-center"><p class="caption">Alpha GO vs Lee Sedol: Move 37 by AlphaGo in Game Two</p></section>
<section id="probability-in-machine-learning" class="slide level2">
<h2>Probability in machine learning</h2>
<ul>
<li>In all methods and approaches, it is useful not only generate an answer, but also evaluate how confident in this answer, how well the model describes the data, how these values ​​will change in further experiments, etc.</li>
<li>Therefore, the central role in machine learning is played by the theory of probability - and we will also actively use it.</li>
</ul>
</section>
<section id="references" class="slide level2">
<h2>References</h2>
<ul>
<li>Christopher M. Bishop, Pattern Recognition and Machine Learning, Springer, 2007.</li>
<li>Kevin Murphy, Machine Learning: A Probabilistic Perspective, MIT Press, 2013.</li>
<li>Trevor Hastie, Robert Tibshirani, and Jerome Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd ed., Springer, 2009.</li>
</ul>
</section></section>
<section>
<section id="bayes-approach" class="title-slide slide level1 center">
<h1>Bayes Approach</h1>

</section>
<section id="probability" class="slide level2 smaller scrollable">
<h2>Probability</h2>
<p>Subjective Probability (de Finetti, Ramsey, Savage, von Neumann, ... )</p>
<p>Principle of Coherence:</p>
<p><em>A set of subjective probability beliefs must avoid sure loss</em></p>
<ol type="1">
<li>If an event <span class="math inline">\(A\)</span> is certain to occur, it has probability 1</li>
<li>Either an event <span class="math inline">\(A\)</span> occurs or it does not. <span class="math display">\[
P(A) = 1 - P(\mbox{not }A)
\]</span></li>
<li>If two events are mutually exclusive (both cannot occur simultaneously) then <span class="math display">\[
P(A \mbox{ or } B) = P(A) + P(B)
\]</span></li>
<li>Joint probability, when events are independent <span class="math display">\[
P(A \mbox{ and } B) = P( A) P(B)
\]</span></li>
</ol>
</section>
<section id="conditional-joint-and-marginal-distributions" class="slide level2">
<h2>Conditional, Joint and Marginal Distributions</h2>
<p>Use probability to describe outcomes involving more than one variable at a time. Need to be able to measure what we think will happen to one variable relative to another</p>
<p>In general the notation is ...</p>
<ul>
<li><span class="math inline">\(P(X=x, Y=y )\)</span> is the <span style="color: blue">joint probability</span> that <span class="math inline">\(X =x\)</span> <span style="color: red">and</span> <span class="math inline">\(Y=y\)</span></li>
<li><span class="math inline">\(P(X=x  \mid  Y=y )\)</span> is the <span style="color: blue">conditional probability</span> that <span class="math inline">\(X\)</span> equals <span class="math inline">\(x\)</span> <span style="color: red">given</span> <span class="math inline">\(Y=y\)</span></li>
<li><span class="math inline">\(P(X=x)\)</span> is the <span style="color: blue">marginal probability</span> of <span class="math inline">\(X=x\)</span></li>
</ul>
</section>
<section id="conditional-joint-and-marginal-distributions-1" class="slide level2">
<h2>Conditional, Joint and Marginal Distributions</h2>
<p>Relationship between the joint and conditional ... <span class="math display">\[
\begin{aligned}
P(x,y) &amp; = P(x) P(y \mid x) \\
&amp; =  P(y) P(x \mid y)
\end{aligned}
\]</span></p>
<p>Relationship between the joint and marginal ... <span class="math display">\[
\begin{aligned}
P(x) &amp; = \sum_y P(x,y) \\
P(y) &amp; =  \sum_x P(x,y)
\end{aligned}
\]</span></p>
</section>
<section id="bayes-rule" class="slide level2">
<h2>Bayes Rule</h2>
<p>The computation of <span class="math inline">\(P(x \mid y)\)</span> from <span class="math inline">\(P(x)\)</span> and <span class="math inline">\(P(y \mid x)\)</span> is called Bayes theorem ... <span class="math display">\[
P(x \mid y) = \frac{P(y,x)}{P(y)} = \frac{P(y,x)}{\sum_x P(y,x)} = \frac{P(y \mid x)P(x)}{\sum_x P(y \mid x)P(x)}
\]</span></p>
<p>This shows now the conditional distribution is related to the joint and marginal distributions.</p>
<p>You’ll be given all the quantities on the r.h.s.</p>
</section>
<section id="bayes-rule-1" class="slide level2">
<h2>Bayes Rule</h2>
<p>Key fact: <span class="math inline">\(P(x \mid y)\)</span> is generally different from <span class="math inline">\(P(y \mid x)\)</span>!</p>
<p><span style="color: blue">Example:</span> Most people would agree <span class="math display">\[
\begin{aligned}
Pr  &amp; \left ( Practice \; hard  \mid  Play \; in \; NBA \right ) \approx  1\\
Pr  &amp; \left ( Play \; in \; NBA  \mid  Practice \; hard  \right ) \approx  0
\end{aligned}
\]</span></p>
<p>The main reason for the difference is that <span class="math inline">\(P( Play \; in \; NBA ) \approx 0\)</span>.</p>
</section>
<section id="independence" class="slide level2">
<h2>Independence</h2>
<p>Two random variable <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <span style="color: blue">independent</span> if <span class="math display">\[
P(Y = y  \mid X = x) = P (Y = y)
\]</span> for all possible <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> values. <span style="color: red">Knowing <span class="math inline">\(X=x\)</span> tells you nothing about <span class="math inline">\(Y\)</span>!</span></p>
<p><span style="color: blue">Example:</span> Tossing a coin twice. What’s the probability of getting <span class="math inline">\(H\)</span> in the second toss given we saw a <span class="math inline">\(T\)</span> in the first one?</p>
</section>
<section id="bookies-vs-betters-the-battle-of-probabilistic-models" class="slide level2">
<h2>Bookies vs Betters: The Battle of Probabilistic Models</h2>

<img data-src="figup/online-betting-strategy.png" style="width:100.0%" class="r-stretch quarto-figure-center"><p class="caption">image</p><p><a href="www.technologyreview.com/s/609168/the-secret-betting-strategy-that-beats-online-bookmakers/?utm_campaign=site_visitor.unpaid.engagement&amp;utm_source=twitter&amp;utm_medium=tr_social">Source: The Secret Betting Strategy That Beats Online Bookmakers</a></p>
</section>
<section id="bookies-vs-betters-the-battle-of-probabilistic-models-1" class="slide level2">
<h2>Bookies vs Betters: The Battle of Probabilistic Models</h2>
<ul>
<li>Bookies set odds that reflect their best guess on probabilities of a win, draw, or loss. Plus their own margin</li>
<li>Bookies have risk aversion bias. When many people bet for an underdog (more popular team)</li>
<li>Bookies hedge their bets by offering more favorable odds to the opposed team</li>
<li>Simple algorithm: calculate average odds across many bookies and find outliers with large deviation from the mean</li>
</ul>
</section>
<section id="odds-oddschecker" class="slide level2">
<h2>Odds: Oddschecker</h2>
<p>We can express probabilities in terms of Odds via <span class="math display">\[
O(A) = \frac{ 1- P(A) }{ P(A) }
\; \; {\rm or} \; \; P(A) = \frac{ 1 }{ 1 + O(A) }
\]</span></p>
<ul>
<li>For example if <span class="math inline">\(O(A) = 1\)</span> then for ever $1 bet you will payout $1. An event with probability <span class="math inline">\(\frac{1}{2}\)</span>.</li>
<li>If <span class="math inline">\(O(A) = 2\)</span> or <span class="math inline">\(2:1\)</span>, then for a $1 bet you’ll payback $3.</li>
</ul>
<p>In terms of probability <span class="math inline">\(P = \frac{1}{3}\)</span>.</p>
</section>
<section id="envelope-paradox" class="slide level2">
<h2>Envelope Paradox</h2>
<p>The following problem is known as the “exchange paradox”.</p>
<ul>
<li>A swami puts <span class="math inline">\(m\)</span> dollars in one envelope and <span class="math inline">\(2 m\)</span> in another. He hands on envelope to you and one to your opponent.</li>
<li>The amounts are placed randomly and so there is a probability of <span class="math inline">\(\frac{1}{2}\)</span> that you get either envelope.</li>
<li>You open your envelope and find <span class="math inline">\(x\)</span> dollars. Let <span class="math inline">\(y\)</span> be the amount in your opponent’s envelope.</li>
</ul>
</section>
<section id="envelope-paradox-1" class="slide level2">
<h2>Envelope Paradox</h2>
<p>You know that <span class="math inline">\(y = \frac{1}{2} x\)</span> or <span class="math inline">\(y = 2 x\)</span>. You are thinking about whether you should switch your opened envelope for the unopened envelope of your friend. It is tempting to do an expected value calculation as follows <span class="math display">\[
E( y) = \frac{1}{2} \cdot  \frac{1}{2} x + \frac{1}{2} \cdot 2 x = \frac{5}{4} x &gt; x
\]</span> Therefore, it looks as if you should switch no matter what value of <span class="math inline">\(x\)</span> you see. A consequence of this, following the logic of backwards induction, that even if you didn’t open your envelope that you would want to switch!</p>
</section>
<section id="bayes-rule-2" class="slide level2 smaller">
<h2>Bayes Rule</h2>
<ul>
<li><p>Where’s the flaw in this argument? Use Bayes rule to update the probabilities of which envelope your opponent has! Assume <span class="math inline">\(p(m)\)</span> of dollars to be placed in the envelope by the swami.</p></li>
<li><p>Such an assumption then allows us to calculate an odds ratio <span class="math display">\[
\frac{ p \left ( y = \frac{1}{2} x | x \right ) }{ p \left ( y = 2 x | x \right ) }
\]</span> concerning the likelihood of which envelope your opponent has.</p></li>
<li><p>Then, the expected value is given by</p></li>
</ul>
<p><span class="math display">\[
E(y) =  p \left ( y = \frac{1}{2} x \; \vert \;  x \right ) \cdot  \frac{1}{2} x +
p \left ( y = 2 x | x \right ) \cdot 2 x
\]</span> and the condition <span class="math inline">\(E( y) &gt; x\)</span> becomes a decision rule.</p>
</section>
<section id="prisoners-dilemma" class="slide level2">
<h2>Prisoner’s Dilemma</h2>
<p>Three prisoners <span class="math inline">\(A , B , C\)</span>.</p>
<p>Each believe are equally likely to be set free.</p>
<p>Prisoner <span class="math inline">\(A\)</span> goes to the warden <span class="math inline">\(W\)</span> and asks if s/he is getting axed.</p>
<ul>
<li><p>The Warden can’t tell <span class="math inline">\(A\)</span> anything about him.</p></li>
<li><p>He provides the new information: <span class="math inline">\(WB\)</span> = “<span class="math inline">\(B\)</span> is to be executed”</p></li>
</ul>
</section>
<section id="prisoners-dilemma-1" class="slide level2">
<h2>Prisoner’s Dilemma</h2>
<p>Uniform Prior Probabilities: <span class="math display">\[
\begin{array}{c|ccc}
Prior &amp; A  &amp; B  &amp; C  \\\hline
P ( {\rm Pardon} ) &amp; 0.33 &amp; 0.33 &amp; 0.33
\end{array}
\]</span></p>
<p>Posterior: <em>Compute</em> <span class="math inline">\(P ( A | WB )\)</span>?</p>
<p><br> What happens if <span class="math inline">\(C\)</span> overhears the conversation?</p>
<p><br> <em>Compute</em> <span class="math inline">\(P ( C | WB )\)</span>?</p>
</section>
<section id="game-show-problem" class="slide level2">
<h2>Game Show Problem</h2>
<p>Named after the host of the long-running TV show, <em>Let’s make a Deal</em>.</p>
<ul>
<li>A <span style="color: blue">contestant</span> is given the choice of 3 doors.</li>
</ul>
<p>There is a <span style="color: red">prize (a car, say)</span> behind one of the doors and something worthless behind the other two doors: two goats.</p>
<ul>
<li>The optimal strategy is <span style="color: blue">counter-intuitive</span></li>
</ul>
</section>
<section id="puzzle" class="slide level2">
<h2>Puzzle</h2>
<p>The game is as follows:</p>
<ul>
<li><p>You pick a door.</p></li>
<li><p>Monty then opens one of the other two doors, revealing a goat.</p></li>
<li><p>You have the choice of switching doors.</p></li>
</ul>
<p><br> Is it advantageous to switch?</p>
<p><br> Assume you pick door <span class="math inline">\(A\)</span> at random. Then <span class="math inline">\(P(A) = ( 1 /3 )\)</span>.</p>
<p>You need to figure out <span class="math inline">\(P( A | MB )\)</span> after Monte reveals <span class="math inline">\(B\)</span> is a goat.</p>
</section></section>
<section>
<section id="bayesian-updating" class="title-slide slide level1 center">
<h1>Bayesian Updating</h1>

</section>
<section id="bayes-rule-3" class="slide level2">
<h2>Bayes Rule</h2>
<p>In its simplest form.</p>
<ul>
<li>Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. Bayes rule <span class="math display">\[
P ( A | B ) = \frac{P (  A \cap  B )}{ P ( B )}
= \frac{P ( B | A ) P ( A )}{ P ( B )}
\]</span></li>
<li>Law of Total Probability <span class="math display">\[
P ( B ) = P ( B | A ) P ( A ) + P ( B | \bar{A} ) P ( \bar{A} )
\]</span> Hence we can calculate the denominator of Bayes rule.</li>
</ul>
</section>
<section id="bayes-theroem" class="slide level2">
<h2>Bayes Theroem</h2>
<p>Many problems in decision making can be solved using Bayes rule.</p>
<ul>
<li>AI: Rule-based decision making.</li>
<li>It’s counterintuitive! But gives the “right” answer.</li>
</ul>
<p>Bayes Rule: <span class="math display">\[
\mbox{P}(A|B) = \frac{\mbox{P}(A \cap B)}{\mbox{P}(B)} = \frac{  \mbox{P}(B|A) \mbox{P}(A)}{ \mbox{P}(B)}
\]</span> Law of Total Probability: <span class="math display">\[
\mbox{P}(B) =  \mbox{P}(B|A) \mbox{P}(A ) +  \mbox{P}(B| \bar{A} ) \mbox{P}(\bar{A} )
\]</span></p>
</section>
<section id="apple-watch" class="slide level2">
<h2><a href="https://ellisvalentiner.com/post/apple-watch-series-4-ecg-and-bayes-theorem/">Apple Watch</a></h2>
<p>The Apple Watch Series 4 can perform a single-lead ECG and detect atrial fibrillation. The software can correctly identify 98% of cases of atrial fibrillation (true positives) and 99% of cases of non-atrial fibrillation (true negatives).</p>
<p>However, what is the probability of a person having atrial fibrillation when atrial fibrillation is identified by the Apple Watch Series 4?</p>
<p>Bayes’ Theorem: <span class="math display">\[
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
\]</span></p>
</section>
<section id="apple-watch-1" class="slide level2">
<h2>Apple Watch</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Predicted</th>
<th style="text-align: center;">atrial fibrillation</th>
<th style="text-align: center;">no atrial fibrillation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">atrial fibrillation</td>
<td style="text-align: center;">1960</td>
<td style="text-align: center;">980</td>
</tr>
<tr class="even">
<td style="text-align: left;">no atrial fibrillation</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">97020</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[
0.6667
=
\frac{0.98\cdot 0.02}{
0.0294}
\]</span></p>
<p>The conditional probability of having atrial fibrillation when the Apple Watch Series 4 detects atrial fibrillation is about 67%.</p>
</section>
<section id="abraham-wald" class="slide level2 smaller">
<h2>Abraham Wald</h2>
<p>How Abraham Wald improved aircraft survivability. Raw Reports from the Field</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Type of damage suffered</th>
<th style="text-align: left;">Returned (316 total)</th>
<th style="text-align: left;">Shot down (60 total)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Engine</td>
<td style="text-align: left;">29</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="even">
<td style="text-align: left;">Cockpit</td>
<td style="text-align: left;">36</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Fuselage</td>
<td style="text-align: left;">105</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="even">
<td style="text-align: left;">None</td>
<td style="text-align: left;">146</td>
<td style="text-align: left;">0</td>
</tr>
</tbody>
</table>
<p>This fact would allow Wald to estimate: <span class="math display">\[
P(\text{damage on fuselage} \mid \text{returns safely}) = 105/316 \approx 32\%
\]</span> You need the inverse probability : <span class="math display">\[
P(\text{returns safely} \mid \text{damage on fuselage})
\]</span> Completely different!</p>
</section>
<section id="abraham-wald-1" class="slide level2 smaller">
<h2>Abraham Wald</h2>
<p>Imputation: fill-in missing data.</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Type of damage suffered</th>
<th style="text-align: left;">Returned (316 total)</th>
<th style="text-align: left;">Shot down (60 total)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Engine</td>
<td style="text-align: left;">29</td>
<td style="text-align: left;">31</td>
</tr>
<tr class="even">
<td style="text-align: left;">Cockpit</td>
<td style="text-align: left;">36</td>
<td style="text-align: left;">21</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Fuselage</td>
<td style="text-align: left;">105</td>
<td style="text-align: left;">8</td>
</tr>
<tr class="even">
<td style="text-align: left;">None</td>
<td style="text-align: left;">146</td>
<td style="text-align: left;">0</td>
</tr>
</tbody>
</table>
<p>Then Wald got: <span class="math display">\[
\begin{aligned}
P(\text{returns safely} \mid \text{damage on fuselage}) &amp; =\frac{105}{105+8}\approx 93\%\\
P(\text{returns safely} \mid \text{damage on engine}) &amp; =\frac{29}{29+31}\approx 48\%
\end{aligned}
\]</span></p>
</section>
<section id="personalization-conditional-probability" class="slide level2">
<h2>“Personalization" <span class="math inline">\(=\)</span>”Conditional Probability"</h2>
<ul>
<li>Conditional probability is how AI systems express judgments in a way that reflects their partial knowledge.</li>
<li>Personalization runs on conditional probabilities, all of which must be estimated from massive data sets in which you are the conditioning event.</li>
</ul>
<p><br> Many Business Applications!! Suggestions vs Search….</p>
</section>
<section id="probability-as-evidence" class="slide level2">
<h2>Probability as Evidence</h2>
<p><span style="color: blue"><code>evidence:</code></span> known facts about criminal (e.g. blood type, DNA, ...)</p>
<p><span style="color: blue"><code>suspect:</code></span> matches a trait with evidence at scene of crime</p>
<p>Let <span class="math inline">\(G\)</span> denote the event that the suspect is the criminal.</p>
<p>Bayes computes the conditional probability of guilt</p>
<p><span class="math display">\[
P ( G | {\rm evidence} )
\]</span> Evidence <span class="math inline">\(E\)</span>: suspect and criminal possess a common trait</p>
</section>
<section id="probability-as-evidence-1" class="slide level2">
<h2>Probability as Evidence</h2>
<p>Bayes Theorem yields <span class="math display">\[
P ( G | {\rm evidence} )
= \frac{ P ( {\rm evidence} | G ) P ( G ) }{ P ( {\rm evidence} )}
\]</span></p>
<p>In terms of <span style="color: blue">relative</span> odds <span class="math display">\[
\frac{ P ( I | {\rm evidence} ) }{ P ( G | {\rm evidence} ) }
= \frac{ P ( {\rm evidence} | I ) }{ P ( {\rm evidence} | G ) }
\frac{ P ( I ) }{ P ( G ) }
\]</span></p>
</section>
<section id="bayes-factors" class="slide level2 scrollable">
<h2>Bayes Factors</h2>
<p>There are two terms:</p>
<ol type="1">
<li>Prior Odds of Guilt <span class="math inline">\(O ( G ) = P ( I ) / P ( G )\)</span> ?</li>
</ol>
<p>How many people on the island?</p>
<p>Sensitivity “what if” analysis?</p>
<ol start="2" type="1">
<li>The Bayes factor <span class="math display">\[
\frac{ P ( {\rm evidence} | I ) }{ P ( {\rm evidence} | G ) }
\]</span> is common to all observers and updates everyone’s initials odds</li>
</ol>
</section>
<section id="prosecutors-fallacy" class="slide level2">
<h2>Prosecutor’s Fallacy</h2>
<p>The most common fallacy is confusing <span class="math display">\[
P ( {\rm evidence} | G ) \; \; {\rm with} \; \;
P ( G | {\rm evidence} )
\]</span></p>
<p>Bayes rule yields <span class="math display">\[
P ( G | {\rm evidence} ) = \frac{ P ( {\rm evidence} | G ) p( G )}{ P ( {\rm evidence}  )}
\]</span> Your assessment of <span class="math inline">\(P( G )\)</span> will matter.</p>
</section>
<section id="island-problem" class="slide level2">
<h2>Island Problem</h2>
<p>Suppose there’s a criminal on a island of <span class="math inline">\(N+1\)</span> people.</p>
<ul>
<li>Let <span class="math inline">\(I\)</span> denote innocence and <span class="math inline">\(G\)</span> guilt.</li>
<li>Evidence <span class="math inline">\(E\)</span>: the suspect matches a trait with the criminal.</li>
<li>The probabilities are <span class="math display">\[
p(E|I)=p\;\;\mathrm{and}\;\;p(E|G)=1
\]</span></li>
</ul>
</section>
<section id="bayes-factor" class="slide level2">
<h2>Bayes factor</h2>
<p>Bayes factors are likelihood ratios</p>
<ul>
<li><p>The Bayes factor is given by <span class="math display">\[
\frac{p(E|I)}{p(E|G)}=p
\]</span></p></li>
<li><p>If we start with a uniform prior distribution we have</p></li>
</ul>
<p><span class="math display">\[
p(I)=\frac{1}{N+1}\;\;\mathrm{and}\;\;odds(I)=N
\]</span></p>
<ul>
<li>Priors will matter!</li>
</ul>
</section>
<section id="island-problem-1" class="slide level2">
<h2>Island Problem</h2>
<p>Posterior Probability related to Odds <span class="math display">\[
p(I|y)=\frac
{1}{1+odds(I|y)}%
\]</span></p>
<ul>
<li><em>Prosecutors’ fallacy</em></li>
</ul>
<p>The posterior probability <span class="math inline">\(p(I|y)\neq p(y|I)=p\)</span>.</p>
<ul>
<li>Suppose that <span class="math inline">\(N=10^{3}\)</span> and <span class="math inline">\(p=10^{-3}\)</span>. Then</li>
</ul>
<p><span class="math display">\[
p( I|y) = \frac{1}{1 + 10^3 \cdot 10^{-3}} = \frac{1}{2}
\]</span></p>
<p>The odds on innocence are <span class="math inline">\(odds(I|y)=1\)</span>.</p>
<p>There’s a <span class="math inline">\(50/50\)</span> chance that the criminal has been found.</p>
</section>
<section id="sally-clark-case-independence-or-bayes" class="slide level2">
<h2>Sally Clark Case: Independence or Bayes?</h2>
<p>Sally Clark was accused and convicted of killing her two children</p>
<p>They could have both died of SIDS.</p>
<ul>
<li><p>The chance of a family which are non-smokers and over 25 having a SIDS death is around 1 in <span class="math inline">\(8,500\)</span>.</p></li>
<li><p>The chance of a family which has already had a SIDS death having a second is around 1 in 100.</p></li>
<li><p>The chance of a mother killing her two children is around 1 in <span class="math inline">\(1,000,000\)</span>.</p></li>
</ul>
</section>
<section id="bayes-or-independence" class="slide level2 smaller scrollable">
<h2>Bayes or Independence</h2>
<ol type="1">
<li><p>Under Bayes <span class="math display">\[
\begin{aligned}
P \left(  \mathrm{both} \; \; \mathrm{SIDS} \right)   &amp;  = P \left(
\mathrm{first} \; \mathrm{SIDS} \right)  P \left(  \mathrm{Second} \; \;
\mathrm{SIDS} | \mathrm{first} \; \mathrm{SIDS} \right) \\
&amp;  = \frac{1}{8500} \cdot \frac{1}{100} = \frac{1}{850,000}
\end{aligned}
\]</span> The <span class="math inline">\(\frac{1}{100}\)</span> comes from taking into account genetics.</p></li>
<li><p>Independence, as the court did, gets you</p></li>
</ol>
<p><span class="math display">\[
P \left(  \mathrm{both} \; \; \mathrm{SIDS} \right)  = (1/8500) (1/8500) = (1/73,000,000)
\]</span></p>
<ol start="3" type="1">
<li>By Bayes rule</li>
</ol>
<p><span class="math display">\[
\frac{p(I|E)}{p(G|E)} = \frac{P( E \cap I)}{P( E \cap G)}
\]</span> <span class="math inline">\(P( E \cap I) = P(E|I )P(I)\)</span> needs discussion of <span class="math inline">\(p(I)\)</span>.</p>
</section>
<section id="comparison" class="slide level2 smaller">
<h2>Comparison</h2>
<ul>
<li>Hence putting these two together gives the odds of guilt as</li>
</ul>
<p><span class="math display">\[
\frac{p(I|E)}{p(G|E)} = \frac{1/850,000}{1/1,000,000} = 1.15
\]</span> In terms of posterior probabilities</p>
<p><span class="math display">\[
p( G|E) = \frac{1}{1 + O(G|E)} = 0.465
\]</span></p>
<ul>
<li>If you use independence</li>
</ul>
<p><span class="math display">\[
\frac{p(I|E)}{p(G|E)} = \frac{1}{73} \; {\rm and} \; p( G|E) \approx 0.99
\]</span> The suspect looks guilty.</p>
</section>
<section id="oj-simpson" class="slide level2">
<h2>OJ Simpson</h2>
<p>The O.J. Simpson trial was possibly the trail of the century</p>
<p>The murder of his wife Nicole Brown Simpson, and a friend, Ron Goldman, in June 1994 and the trial dominated the TV networks</p>
<ul>
<li><p>DNA evidence and probability: <span class="math inline">\(p( E| G)\)</span></p></li>
<li><p>Bayes Theorem: <span class="math inline">\(p( G | E )\)</span></p></li>
<li><p>Prosecutor’s Fallacy: <span class="math inline">\(p( G|E ) \neq p(E|G)\)</span></p></li>
</ul>
<p>Odds ratio with gives <span class="math display">\[
\frac{ p( I|E) }{ p ( G | E ) } = \frac{ p( E|I )}{ p( E|G) } \frac{ p(I) }{p(G ) }
\]</span> Prior odds conditioned on background information.</p>
</section>
<section id="oj-simpson-bayes-theorem" class="slide level2 scrollable">
<h2>OJ Simpson: Bayes Theorem</h2>
<p>Suppose that you are a juror in a murder case of a husband who is accused of killing his wife.</p>
<p>The husband is known is have battered her in the past.</p>
<p>Consider the three events:</p>
<ol type="1">
<li><p><span class="math inline">\(G\)</span> “husband murders wife in a given year”</p></li>
<li><p><span class="math inline">\(M\)</span> “wife is murdered in a given year”</p></li>
<li><p><span class="math inline">\(B\)</span> “husband is known to batter his wife”</p></li>
</ol>
</section>
<section id="oj-simpson-bayes-theorem-1" class="slide level2">
<h2>OJ Simpson: Bayes Theorem</h2>
<ul>
<li>Only <span class="math inline">\(1/10\)</span>th of one percent of husbands who batter their wife actually murder them.</li>
</ul>
<p>Conditional on eventually murdering their wife, there a one in ten chance it happens in a given year.</p>
<p>In 1994, 5000 women were murdered, 1500 by their husband</p>
<p>Given a population of 100 million women at the time <span class="math display">\[
p( M | I ) = \frac{ 3500 }{ 10^8 } \approx \frac{1}{30,000} .
\]</span> We’ll also need <span class="math inline">\(p( M | I , B )  = p( M | I )\)</span></p>
</section>
<section id="oj-simpson-prosecutors-fallacy" class="slide level2">
<h2>OJ Simpson: Prosecutor’s Fallacy</h2>
<ul>
<li>Let <span class="math inline">\(G =\)</span> Guilt and <span class="math inline">\(E=\)</span> Evidence</li>
<li><em>Prosecutor’s Fallacy:</em> <span class="math inline">\(P(G|E) \neq P(E|G)\)</span>.</li>
<li>DNA evidience gives <span class="math inline">\(P( E | I )\)</span> – the <span class="math inline">\(p\)</span>-value.</li>
</ul>
<p>What’s the “match probability” for a rare event?</p>
<p>Bayes theorem in Odds <span class="math display">\[
\frac{p(G|M,B)}{p(I|M,B)} = \frac{p(M|G,B)}{p(M|I,B)} \frac{p(G|B)}{p(I|B)}
\]</span></p>
</section>
<section id="oj-simpson-bayes-theorem-2" class="slide level2">
<h2>OJ Simpson: Bayes Theorem</h2>
<p>By assumption,</p>
<ul>
<li><span class="math inline">\(p(M|G,B)=1\)</span></li>
<li><span class="math inline">\(p(M|I,B)= \frac{1}{30,000}\)</span></li>
<li><span class="math inline">\(p( G|B) = \frac{1}{1000}\)</span> and so</li>
</ul>
<p><span class="math display">\[
\frac{p(G|B)}{p(I|B)} = \frac{1}{999}
\]</span></p>
<p>Therefore, <span class="math display">\[
\frac{p(G|M,B)}{p(I|M,B)} \approx 30 \; {\rm and} \; p(G|M,B) = \frac{30}{31} \approx 97\%
\]</span> More than a 50/50 chance that your spouse murdered you!</p>
</section>
<section id="fallacy-p-g-b-neq-p-g-b-m" class="slide level2 smaller">
<h2>Fallacy <span class="math inline">\(p ( G | B ) \neq p( G | B , M )\)</span></h2>
<p>The defense stated to the press: in any given year</p>
<p><em>“Fewer than 1 in 2000 of batterers go on to murder their wives”</em>.</p>
<ul>
<li><p>Now estimate <span class="math inline">\(p( M | \bar{G} , B ) = p( M| \bar{G} ) = \frac{1}{20,000}\)</span>.</p></li>
<li><p>The Bayes factor is then</p></li>
</ul>
<p><span class="math display">\[
\frac{ p( G | M , B ) }{ p( \bar{G} | M , B ) } = \frac{ 1/999 }{1 /20,000} = 20
\]</span> which implies posterior probabilities</p>
<p><span class="math display">\[
p( \bar{G} | M , B ) = \frac{1}{1+20} \; {\rm and} \; p( G | M , B ) = \frac{20}{21}
\]</span> Hence its over 95% chance that O.J. is guilty based on this information!</p>
<p>Defense intended this information to exonerate O.J.</p>
</section>
<section id="base-rate-fallacies" class="slide level2">
<h2>Base Rate Fallacies</h2>
<p>“Witness” 80 % certain saw a “checker” <span class="math inline">\(C\)</span> taxi in the accident.</p>
<ul>
<li><p>What’s your <span class="math inline">\(P ( C | E )\)</span> ?</p></li>
<li><p>Need <span class="math inline">\(P ( C )\)</span>. Say <span class="math inline">\(P( C ) = 0.2\)</span> and <span class="math inline">\(P( E  | C) = 0.8\)</span>.</p></li>
<li><p>Then your posterior is</p></li>
</ul>
<p><span class="math display">\[
P ( C | E ) = \frac{0.8 \cdot 0.2}{ 0.8 \cdot 0.2 + 0.2 \cdot 0.8 } = 0.5
\]</span></p>
<p>Therefore <span class="math inline">\(O ( C ) = 1\)</span> a 50/50 bet.</p>
</section>
<section id="updating-fallacies" class="slide level2">
<h2>Updating Fallacies</h2>
<p>Most people don’t update quickly enough in light of new data</p>
<p>Wards Edwards 1960s</p>
<p>When you have a small sample size, Bayes rule still updates probabilities</p>
<ul>
<li><p>Two players: either 70 % A or 30 % A</p></li>
<li><p>Observe <span class="math inline">\(A\)</span> beats <span class="math inline">\(B\)</span> 3 times out of 4.</p></li>
<li><p>What’s <span class="math inline">\(P ( A = 70 \% \; {\rm player} )\)</span> ?</p></li>
</ul>
</section>
<section id="a-random-image" class="slide level2">
<h2>A Random Image</h2>



<img data-src="fig/gencat.jpg" class="r-stretch"></section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1226,

        height: 920,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>