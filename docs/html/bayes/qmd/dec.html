<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bayes, AI and Deep Learning - 4&nbsp; Utility and Decisions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../qmd/bl.html" rel="next">
<link href="../qmd/bayes.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
</head><body class="nav-sidebar floating fullcontent"><div class="hidden">
<p><span class="math display">\[
\newcommand{\prob}[1]{\operatorname{P}\left(#1\right)}
\newcommand{\Var}[1]{\operatorname{Var}\left(#1\right)}
\newcommand{\sd}[1]{\operatorname{sd}\left(#1\right)}
\newcommand{\Cor}[1]{\operatorname{Corr}\left(#1\right)}
\newcommand{\Cov}[1]{\operatorname{Cov}\left(#1\right)}
\newcommand{\E}[1]{\operatorname{E}\left(#1\right)}
\newcommand{\defeq}{\overset{\text{\tiny def}}{=}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\mini}{minimize}
\]</span></p>
</div>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>





<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../qmd/prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="../qmd/dec.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility and Decisions</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Bayes, AI and Deep Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Principles of Data Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/dec.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility and Decisions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/bl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Parameter Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/ab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">AB Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/hyp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Field vs Observational</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/sp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/rl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../qmd/prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="../qmd/dec.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility and Decisions</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-Decisions" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility and Decisions</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p><em>It is remarkable that a science which began with the consideration of games of chance should have become the most important object of human knowledge.</em> Laplace, Pierre Simon, 1812</p>
</blockquote>
<p>Life is about making decisions under uncertainty. We always prefer informed decisions Statistical decision theory studies the process of finding a reasonable course of action when faced with statistical uncertainty–uncertainty that can in part be quantified from observed data. In most cases, the problem can be separated into two problems:&nbsp;a learning problem or parameter estimation problem and then a decision problem that uses the output of the learning problem. In finance, a classic example of this is finding optimal portfolios with a mean-variance utility/criterion function assuming the underlying means, variances and covariances are unknown based on a historical sample of data. In statistics, the classic problem is using decision theory to evaluate the relative merits of different parameter estimators hypothesis tests.</p>
<p>To a Bayesian, the solution to these decision problems are rather obvious: compute posterior distributions, and then make decisions by maximizing expected utility, where the posterior distribution is used to calculate the expectations. Classical solutions to these problems are different, and use repeated sampling ideas, whereby the performance of a decision rule is judged on its performance if the same decision problem were repeated infinitely. Thus, the decisions are made based on their population properties. One of the main uses of statistical decision theory is to compare different estimators or hypothesis testing procedures. This theory generates many important findings, most notably that many of the common classical estimators are “bad”,in some sense, and that Bayesian estimators are always “good”.</p>
<p>These results have major implications for empirical work and practical applications, as they provide a guide for forecasting.</p>
<section id="statistical-decisions-and-risk" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="statistical-decisions-and-risk"><span class="header-section-number">4.1</span> Statistical Decisions and Risk</h2>
<p>The statistical decision making problem can be posed as follows. A decision maker (you) has to chose from a set of decisions or acts. The consequences of these decisions depend on an unknown state of the world. Let <span class="math inline">\(d\in\mathcal{D}\)</span> denote the decision and <span class="math inline">\(\theta\in\Theta\)</span> the state of the world. As an example, think of <span class="math inline">\(\theta\)</span> as the unknown parameter and the decision as choosing a parameter estimation or hypothesis testing procedure. To provide information about the parameter, the decision maker obtains a sample <span class="math inline">\(y\in\mathcal{Y}\)</span> that is generated from the likelihood function <span class="math inline">\(p\left(y|\theta\right)\)</span>. The resulting decision depends on the observed data, is denoted as <span class="math inline">\(d\left(  y\right)\)</span>, and is commonly called the decision rule.</p>
<p>To make the decision, the decision maker uses a “loss” function as a quantitative metric to assesses the consequences or performance of different decisions. For each state of the world <span class="math inline">\(\theta\)</span>, and decision <span class="math inline">\(d\)</span>, <span class="math inline">\(L\left(  \theta,d\right)\)</span> quantifies the “loss” made by choosing <span class="math inline">\(d\)</span> when the state of the world is <span class="math inline">\(\theta.\)</span> Common loss functions include a quadratic loss, <span class="math inline">\(L(\theta,d)=(\theta-d)^{2},\)</span> an absolute loss, <span class="math inline">\(L(\theta,d)=|\theta-d|\)</span>, and a <span class="math inline">\(0-1\)</span> loss, <span class="math display">\[
L(\theta,d)=L_{0}1_{\left[  \theta\in\Theta_{0}\right]  }+L_{1}1_{\left[  \theta\in\Theta_{1}\right]  }.
\]</span> For Bayesians, the utility function provides a natural loss function. Historically, decision theory was developed by classical statisticians, thus the development in terms of “objective” loss functions instead of “subjective” utility.</p>
<p>Classical decision theory takes a frequentist approach, treating parameters as “fixed but unknown” and evaluating decisions based on their population properties. Intuitively, this thought experiment entails drawing a dataset <span class="math inline">\(y\)</span> of given length and applying the same decision rule in a large number of repeated trials and averaging the resulting loss across those hypothetical samples. Formally, the classical risk function is defined as <span class="math display">\[
R(\theta,d)=\int_{\mathcal{Y}}L\left[  \theta,d(y)\right]  p(y|\theta )dy=\mathbb{E}\left[  L\left[  \theta,d(y)\right]  |\theta\right]  .
\]</span> Since the risk function integrates over the data, it does not depend on a given observed sample and is therefore an ex-ante or a-priori metric. In the case of quadratic loss, the risk function is the mean-squared error (MSE) and is <span class="math display">\[\begin{align*}
R(\theta,d)  &amp;  =\int_{\mathcal{Y}}\left[  \theta-d\left(  y\right)  \right]
^{2}p(y|\theta)dy\\
&amp;  =\mathbb{E}\left[  \left(  d\left(  y\right)  -E\left[  d\left(  y\right)
|\theta\right]  \right)  ^{2}|\theta\right]  +\mathbb{E}\left[  \left(
E\left[  d\left(  y\right)  |\theta\right]  -\theta\right)  ^{2}|\theta\right]
\\
&amp;  =Var\left(  d\left(  y\right)  |\theta\right)  +\left[  bias\left(
d\left(  y\right)  -\theta\right)  \right]  ^{2}%
\end{align*}\]</span> which can be interpreted as the bias of the decision/estimator plus the variance of the decision/estimator. Common frequentist estimators choose unbiased estimators so that the bias term is zero, which in most settings leads to unique estimators.</p>
<p>The goal of the decision maker is to minimize risk. Unfortunately, rarely is there a decision that minimizes risk uniformly for all parameter values. To see this, consider a simple example of <span class="math inline">\(y\sim N\left(  \theta,1\right)\)</span>, a quadratic loss, and two decision rules, <span class="math inline">\(d_{1}\left(  y\right)  =0\)</span> or <span class="math inline">\(d_{2}\left(  y\right)  =y\)</span>. Then, <span class="math inline">\(R\left(  \theta,d_{1}\right)  =\theta^{2}\)</span> and <span class="math inline">\(R\left(  \theta,d_{2}\right)  =1\)</span>. If <span class="math inline">\(\left\vert \theta\right\vert &lt;1\)</span>, then <span class="math inline">\(R\left(  \theta,d_{1}\right)  &lt;R\left(  \theta,d_{2}\right)\)</span>, with the ordering reversed for <span class="math inline">\(\left\vert \theta\right\vert &gt;1\)</span>. Thus, neither rule uniformly dominates the other.</p>
<p>One way to deal with the lack of uniform domination is to use the minimax principle:&nbsp;first maximize risk as function of <span class="math inline">\(\theta\)</span>, <span class="math display">\[
\theta^{\ast}=\underset{\theta\in\Theta}{\arg\max}R(\theta,d)\text{,}%
\]</span> and then minimize the resulting risk by choosing a decision:<br>
<span class="math display">\[
d_{m}^{\ast}=\underset{d\in\mathcal{D}}{\arg\min}\left[  R(\theta^{\ast },d)\right]  \text{.}%
\]</span> The resulting decision is known as a minimax decision rule. The motivation for minimax is game theory, with the idea that the statistician chooses the best decision rule against the other player, mother nature, who chooses the worst parameter.</p>
<p>The Bayesian approach treats parameters as random and specifies both a likelihood and prior distribution, denoted here by <span class="math inline">\(\pi\left(  \theta\right)\)</span>. The Bayesian decision maker recognizes that both the data and parameters are random, and accounts for both sources of uncertainty when calculating risk. The Bayes risk is defined as<br>
<span class="math display">\[\begin{align*}
r(\pi,d)  &amp;  =\int_{\mathcal{\Theta}}\int_{\mathcal{Y}}L\left[  \theta ,d(y)\right]  p(y|\theta)\pi\left(  \theta\right)  dyd\theta\\
&amp;  =\int_{\mathcal{\Theta}}R(\theta,d)\pi\left(  \theta\right)  d\theta =\mathbb{E}_{\pi}\left[  R(\theta,d)\right]  ,
\end{align*}\]</span> and thus the Bayes risk is an average of the classical risk, with the expectation taken under the prior distribution. The Bayes decision rule minimizes expected risk:<br>
<span class="math display">\[
d_{\pi}^{\ast}=\underset{d\in\mathcal{D}}{\arg\min}\text{ }r(\pi,d)\text{.}%
\]</span> The classical risk of a Bayes decision rule is defined as <span class="math inline">\(R\left(
\theta,d_{\pi}^{\ast}\right)\)</span>, where <span class="math inline">\(d_{\pi}^{\ast}\)</span> does not depend on <span class="math inline">\(\theta\)</span> or <span class="math inline">\(y\)</span>. Minimizing expected risk is consistent with maximizing posterior expected utility or, in this case, minimizing expected loss. Expected posterior risk is <span class="math display">\[
r(\pi,d)=\int_{\mathcal{Y}}\left[  \int_{\mathcal{\Theta}}L\left[
\theta,d(y)\right]  p(y|\theta)\pi\left(  \theta\right)  d\theta\right]  dy,
\]</span> where the term in the brackets is posterior expected loss. Minimizing posterior expected loss for every <span class="math inline">\(y\in\mathcal{Y},\)</span> is clearly equivalent to minimizing posterior expected risk, provided it is possibility to interchange the order of integration.</p>
<p>The previous definitions did not explicitly state that the prior distribution was proper, that is, that <span class="math inline">\(\int_{\mathcal{\Theta}}\pi\left(  \theta\right)d\theta=1\)</span>. In some applications and for some parameters, researchers may use priors that do not integrate, <span class="math inline">\(\int_{\Theta}\pi\left(  \theta\right)d\theta=\infty\)</span>, commonly called improper priors. A generalized Bayes rule is one that minimizes <span class="math inline">\(r(\pi,d),\)</span> where <span class="math inline">\(\pi\)</span> is not necessarily a distribution, if such a rule exists. If <span class="math inline">\(r(\pi,d)&lt;\infty\)</span>, then the mechanics of this rule is clear, although its meaning is less clear.</p>
</section>
<section id="expectation-and-variance-reward-and-risk" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="expectation-and-variance-reward-and-risk"><span class="header-section-number">4.2</span> Expectation and Variance (Reward and Risk)</h2>
<p>An expected value of a random variable, denoted by <span class="math inline">\(\E{X}\)</span> is a weighted average. Each possible value of a random variable is weighted by its probability. For example, Google map uses expected value when calculating travel times. We might compute two different routes by their expected travel time. Typically, a forecast or expected value is all that is required — there expected values can be updated in real time as we travel. Say I am interested in travel time from Washington National airport to Fairfax in Virginia. The histogram below shows the travel times observed for a work day evening and were obtained from <a href="https://movement.uber.com/">Uber</a>.</p>
<div id="exm-Uber" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.1 (Uber)</strong></span> Let’s look at the histogram of travel times from Fairfax, VA to Washington, DC</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="fu">read.csv</span>(<span class="st">"../../data/dc_travel_time.csv"</span>) </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># use eventing travel times (column 18) and convert from seconds to minutes </span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>evening_tt <span class="ot">=</span> d[,<span class="dv">18</span>]<span class="sc">/</span><span class="dv">60</span>; day_tt <span class="ot">=</span> d[,<span class="dv">15</span>]<span class="sc">/</span><span class="dv">60</span>; </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>evening_tt <span class="ot">=</span> evening_tt[<span class="sc">!</span><span class="fu">is.na</span>(evening_tt)] <span class="co"># remove missing observations </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(evening_tt, <span class="at">freq =</span> F,<span class="at">main=</span><span class="st">""</span>, <span class="at">xlab=</span><span class="st">"Travel Time [min]"</span>, <span class="at">nclass=</span><span class="dv">20</span>, <span class="at">col=</span><span class="st">"blue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dec_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Travel times in the evening</figcaption>
</figure>
</div>
</div>
</div>
<p>From this dataset, we can empirically estimate the probabilities of observing different values of travel times</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>bins <span class="ot">=</span> <span class="fu">hist</span>(evening_tt, <span class="at">breaks =</span> <span class="dv">3</span>, <span class="at">plot =</span> F) </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="fu">data.frame</span>(<span class="st">"tt"</span> <span class="ot">=</span> bins<span class="sc">$</span>mids, <span class="st">"Probability"</span> <span class="ot">=</span> bins<span class="sc">$</span>counts<span class="sc">/</span><span class="fu">length</span>(evening_tt)),<span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"Travel Time"</span>,<span class="st">"Probability"</span>),<span class="at">digits=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">Travel Time</th>
<th style="text-align: right;">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">17.5</td>
<td style="text-align: right;">0.05</td>
</tr>
<tr class="even">
<td style="text-align: right;">22.5</td>
<td style="text-align: right;">0.77</td>
</tr>
<tr class="odd">
<td style="text-align: right;">27.5</td>
<td style="text-align: right;">0.18</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>There is a small chance (5%) I can get to Fairfax in 18 minutes, which probably happens on a holiday and a non-trivial chance (18%) to travel for 28 minutes, possibly due to a sports game or bad weather. Most of the times (77%) our travel time is 22 minutes. However, when Uber shows you the travel time, it uses the expected value as a forecast rather than the full distribution. Specifically, you will be given an expected travel of 23 minutes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fl">0.05</span><span class="sc">*</span><span class="dv">18</span> <span class="sc">+</span> <span class="fl">0.77</span><span class="sc">*</span><span class="dv">22</span> <span class="sc">+</span> <span class="fl">0.18</span><span class="sc">*</span><span class="dv">28</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 22.88</code></pre>
</div>
</div>
<p>It is a simple summary takes into account travel accidents and other events that can effect travel time as best as it can.</p>
</div>
<p>The expected value <span class="math inline">\(\E{X}\)</span> of discrete random variable <span class="math inline">\(X\)</span> which takes possible values <span class="math inline">\(\{x_1,\ldots x_n\}\)</span> is calculated using</p>
<p><span class="math display">\[
\E{X} =\sum_{i=1}^{n}x_i\prob{X = x_i}
\]</span></p>
<p>For example, in a binary scenario, if <span class="math inline">\(X\in \{0,1\}\)</span> and <span class="math inline">\(P(X=1)=p\)</span>, then <span class="math inline">\(\E{X} = 0\times(1-p)+1\times p = p\)</span>. Expected value of a Bernoulli random variable is simply the probability of success. In many binary scenarios, probabilistic forecast is sufficient.</p>
<p>If <span class="math inline">\(X\)</span> is continuous with probability distribution <span class="math inline">\(p(x)\)</span>, then we have to calculate the expectation as an integral <span class="math display">\[
\E{X} = \int xp(x)d x  = \ \text{ and } \int p(x)dx = 1.
\]</span> When you have a random variable <span class="math inline">\(x\)</span> that has a support that is non-negative (that is, the variable has nonzero density/probability for only positive values), you can use the following property: <span class="math display">\[
E(X) = \int_0^\infty \left( 1 - F(x) \right) \,\mathrm{d}x,
\]</span> where <span class="math inline">\(F(x)\)</span> is the cumulative distribution function (CDF) of <span class="math inline">\(X\)</span>. The proof is as follows: <span class="math display">\[
E(X) = \int_0^\infty \left( 1 - F(x) \right) \,\mathrm{d}x = \int_0^\infty \int_x^\infty f(y) \,\mathrm{d}y \,\mathrm{d}x = \int_0^\infty \int_0^y \,\mathrm{d}x f(y) \,\mathrm{d}y = \int_0^\infty y f(y) \,\mathrm{d}y,
\]</span> where <span class="math inline">\(f(x)\)</span> is the probability density function (PDF) of <span class="math inline">\(X\)</span>. Moreover <span class="math display">\[
E(X) = \int_{0}^1 F^{-1}(p) \,\mathrm{d}p,
\]</span> where <span class="math inline">\(F^{-1}(p)\)</span> is the inverse CDF of <span class="math inline">\(X\)</span>. The proof is as follows: <span class="math display">\[
E(X) = \int_{0}^1 F^{-1}(p) \,\mathrm{d}p = \int_{0}^1 \int_{-\infty}^{F^{-1}(p)} f(x) \,\mathrm{d}x \,\mathrm{d}p = \int_{-\infty}^{\infty} \int_{0}^{F(x)} \,\mathrm{d}p f(x) \,\mathrm{d}x = \int_{-\infty}^{\infty} x f(x) \,\mathrm{d}x.
\]</span></p>
<section id="standard-deviation-and-covariance" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="standard-deviation-and-covariance"><span class="header-section-number">4.2.1</span> Standard Deviation and Covariance</h3>
<p>Variance measures the spread of a random variable around its expected value <span class="math display">\[
\Var{X} = \E{(X-\E{X})^2} =  \sum_{i=1}^n (x_i-\mu)^2 \prob{X=x_i}dx.
\]</span> In the continious case, we have <span class="math display">\[
\Var{X} = \int_{-\infty}^\infty (x-\mu) ^2 p(x)dx,
\]</span> where <span class="math inline">\(\mu = \mathbb{E}(X)=\int_{-\infty}^{\infty}p_X(x)dx\)</span>. The standard deviation is more convenient and is a square root of variance <span class="math inline">\(\sd{X} = \sqrt{\Var{X}}\)</span>. Standard deviation has the desirable property that it is measured in the same units as the random variable <span class="math inline">\(X\)</span> itself and is a more useful measure.</p>
<p>Suppose that we have two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. We need to measure whether they move together or in opposite directions. The <strong>covariance</strong> is defined by <span class="math display">\[
\Cov{X,Y} = \E{\left[ X- \E{X})(Y- \E{Y}\right]}.
\]</span></p>
<p>When <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are discrete and we are given the joint probability distribution, we need to calculate <span class="math display">\[
\Cov{X,Y} = \sum_{x,y}  ( x - \E{X} )(y - \E{Y})p(x,y).
\]</span> Covariance is measured in unit of <span class="math inline">\(X^2\times\)</span>unit of <span class="math inline">\(Y^2\)</span>. This can be inconvenient and makes it hard to compare covariances of different pairs of variables. A more convenient metric is the <strong>correlation</strong>, which is defined by <span class="math display">\[
\Cor{X,Y}= \frac{ \Cov{X,Y} }{ \sd{X} \sd{Y} }.
\]</span> Correlation, <span class="math inline">\(\Cor{X,Y}\)</span>, is unites and takes values between 0 and 1.</p>
<p>In the case of joint continuous distribution it is convenient to use the covariance matrix <span class="math inline">\(\Sigma\)</span> which is defined as <span class="math display">\[
\Sigma = \begin{bmatrix}
\Var{X} &amp; \Cov{X,Y} \\
\Cov{X,Y} &amp; \Var{Y}
\end{bmatrix}.
\]</span> If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, then <span class="math inline">\(\Cov{X,Y} = 0\)</span> and <span class="math inline">\(\Sigma\)</span> is diagonal. The correlation matrix is defined as <span class="math display">\[
\rho = \begin{bmatrix}
1 &amp; \Cor{X,Y} \\
\Cor{X,Y} &amp; 1
\end{bmatrix}.
\]</span> If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have an exact linear relationship, then <span class="math inline">\(\Cor{X,Y} = 1\)</span> and <span class="math inline">\(\Cov{X,Y}\)</span> is the product of standard deviations. In matrix notations, the relation between the covariance matrix and correlation matrix is given by <span class="math display">\[
\rho = \mathrm{diag}\left(\Sigma\right)^{-1/2} \Sigma\mathrm{diag}\left(\Sigma\right)^{-1/2},
\]</span> where <span class="math inline">\(\sigma\)</span> is a diagonal matrix with standard deviations on the diagonal.</p>
</section>
<section id="portfolios-linear-combinations" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="portfolios-linear-combinations"><span class="header-section-number">4.2.2</span> Portfolios: Linear combinations</h3>
<p>Calculating means and standard deviations of combination of random variables is central tool in probability. It is known as the portfolio problem. Let <span class="math inline">\(P\)</span> be your portfolio, which comprises a mix of two assets <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, typically stocks and bonds, <span class="math display">\[
P = aX + bY,
\]</span> where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are the portfolio weights, typically <span class="math inline">\(a+b=1\)</span>, as we are allocating our total capital. Imagine, that you have placed <span class="math inline">\(a\)</span> dollars on the random outcome <span class="math inline">\(X\)</span>, and <span class="math inline">\(b\)</span> dollars on <span class="math inline">\(Y\)</span>. The portfolio <span class="math inline">\(P\)</span> measures your total weighted outcome.</p>
<p>Key portfolio rules: The expected value and variance follow the relations <span class="math display">\[\begin{align*}
\E{aX + bY} = &amp;      a\E{X}+b\E{Y}\\
\Var{ aX + bY }  = &amp; a^2 \Var{X} + b^2 \Var{Y} + 2 ab \Cov{X,Y },
\end{align*}\]</span> with <strong>covariance</strong> defined by <span class="math display">\[
\Cov{X,Y} = \E{ ( X- \E{X} )(Y- \E{Y})}.
\]</span> Expectation and variance help us to understand the long-run behavior. When we make long-term decisions, we need to use the expectations to avoid biases.</p>
<p>The covariance is related to the correlation by <span class="math inline">\(\Cov{X,Y} = \text{Corr}(X, Y) \cdot \sqrt{\text{Var}{X} \cdot \text{Var}{Y}}\)</span>.</p>
<div id="exm-Tortoise" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.2 (Tortoise and Hare)</strong></span> Tortoise and Hare who are selling cars. Say <span class="math inline">\(X\)</span> is the number of cars sold and probability distributions, means and variances is given by the following table</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;"><span class="math inline">\(X\)</span></th>
<th></th>
<th></th>
<th></th>
<th style="text-align: center;">Mean</th>
<th style="text-align: center;">Variance</th>
<th style="text-align: center;">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td style="text-align: center;">0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td style="text-align: center;"><span class="math inline">\(\E{X}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\Var{X}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\sqrt{\Var{X}}\)</span></td>
</tr>
<tr class="even">
<td>Tortoise</td>
<td style="text-align: center;">0</td>
<td>0.5</td>
<td>0.5</td>
<td>0</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr class="odd">
<td>Hare</td>
<td style="text-align: center;">0.5</td>
<td>0</td>
<td>0</td>
<td>0.5</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">2.25</td>
<td style="text-align: center;">1.5</td>
</tr>
</tbody>
</table>
<p>Let’s do Tortoise expectations and variances <span class="math display">\[\begin{align*}
\E{T} &amp; = (1/2) (1) + (1/2)(2) = 1.5 \\
\Var{T} &amp; = \E{T^2} - \E{T}^2 \\
&amp; =  (1/2)(1)^2 + (1/2)(2)^2 - (1.5)^2 = 0.25
\end{align*}\]</span></p>
<p>Now the Hare’s <span class="math display">\[\begin{align*}
\E{H} &amp; = (1/2)(0) + (1/2)(3) = 1.5 \\
\Var{H} &amp; =  (1/2)(0)^2 + (1/2)(3)^2- (1.5)^2 = 2.25
\end{align*}\]</span></p>
<p>What do these tell us about the long run behavior?</p>
<ol type="1">
<li><p>Tortoise and Hare have the same expected number of cars sold.</p></li>
<li><p>Tortoise is more predictable than Hare. He has a smaller variance.</p></li>
</ol>
<p>The standard deviations <span class="math inline">\(\sqrt{\Var{X}}\)</span> are <span class="math inline">\(0.5\)</span> and <span class="math inline">\(1.5\)</span>, respectively. Given two equal means, you always want to pick the lower variance. If we are to invest into one of those, we prefer Tortoise.</p>
</div>
<p>Often, it is easier to communicate uncertainties in a form of odds. In terms of betting odds of <span class="math inline">\(1:1\)</span> gives <span class="math inline">\(P = \frac{1}{2}\)</span>, odds on <span class="math inline">\(2:1\)</span> (I give <span class="math inline">\(2\)</span> for each <span class="math inline">\(1\)</span> you bet) is <span class="math inline">\(P = \frac{1}{3}\)</span>.</p>
<p>Remember, odds, <span class="math inline">\(O(A)\)</span>, is the ratio of the probability of not happening over happening, <span class="math display">\[
O(A) = (1 - P(A)) / P(A),
\]</span> equivalently, <span class="math display">\[
P(A) = \frac{1}{1 + O(A)}.
\]</span></p>
<p>The odds of patriot winning sequence in then 1 to 199</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">1</span><span class="fl">-0.005</span>)<span class="sc">/</span><span class="fl">0.005</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 199</code></pre>
</div>
</div>
</section>
</section>
<section id="bellman-principle-of-optimality" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="bellman-principle-of-optimality"><span class="header-section-number">4.3</span> Bellman Principle of Optimality</h2>
<div id="exm-secretary" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.3 (Secretary Problem)</strong></span> The Secretary Problem, also known as the “marriage problem” or “sultan’s dowry problem,” is a classic problem in decision theory and probability theory. The scenario involves making a decision on selecting the best option from a sequence of candidates or options. The problem is often framed as hiring a secretary, but it can be applied to various situations such as choosing a house, a spouse, or any other scenario where you sequentially evaluate options and must make a decision.</p>
<p>In this problem, you receive <span class="math inline">\(T\)</span> offers and must either accept (or reject) the offer “on the spot”. You cannot return to a previous offer once you have moved on to the next one. Offers are in random order and can be ranked against those previously seen. The aim is to maximize the probability of choosing the offer with the greatest rank. There is an optimal <span class="math inline">\(r\)</span> (<span class="math inline">\(1 \le r &lt; T\)</span>) to be determined such that where we examine and reject the first <span class="math inline">\(r\)</span> offers. Then of the remaining <span class="math inline">\(T - r\)</span> offers we choose the first one that is best seen to date.</p>
<p>A decision strategy involves setting a threshold such that the first candidate above this threshold is hired, and all candidates below the threshold are rejected. The optimal strategy, known as the “37% rule,” suggests that one should reject the first <span class="math inline">\(r=T/e\)</span> candidates and then select the first candidate who is better than all those seen so far.</p>
<p>The reasoning behind the 37% rule is based on the idea of balancing exploration and exploitation. By rejecting the first <span class="math inline">\(T/e\)</span> candidates, you gain a sense of the quality of the candidates but avoid committing too early. After that point, you select the first candidate who is better than the best among the initial <span class="math inline">\(r\)</span> candidates.</p>
<p>It’s important to note that the 37% rule provides a probabilistic guarantee of selecting the best candidate with a probability close to 1/e (approximately 37%) as <span class="math inline">\(T\)</span> becomes large.</p>
</div>
<p>To solve the secretary problem, we will use the principle of optimality due to Richard Bellman. The principle states that an optimal policy has the property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision. In other words, the policy is optimal from the first decision onwards.</p>
<p>The solution to the secretary problem can be found via dynamic programming. Given an agent with utility function <span class="math inline">\(u(x,d)\)</span>, with current state <span class="math inline">\(x\)</span>, and decision <span class="math inline">\(d\)</span>. The law of motion of <span class="math inline">\(x_t\)</span> is given by <span class="math inline">\(x_{t+1} = p(x_t,d_t)\)</span>. Bellman principle of optimality states that the optimal policy is given by the following recursion <span class="math display">\[
V(x_t) = \max_{d_t} \left \{ u(x_t,d_t) + \gamma \mathbb{E} \left [ V(x_{t+1}) \right ] \right \}
\]</span> where <span class="math inline">\(\gamma\)</span> is the discount factor. The optimal policy is given by <span class="math display">\[
d_t^* = \arg \max_{d_t} \left \{ u(x_t,d_t) + \gamma \mathbb{E} \left [ V(x_{t+1}) \right ] \right \}.
\]</span></p>
<p>Now, back to the secretary problem. Let <span class="math inline">\(y^t = (y_1,\ldots,y_t)\)</span> denote the history of observations up to time <span class="math inline">\(t\)</span>. State <span class="math inline">\(x_t=1\)</span> if the <span class="math inline">\(t\)</span>th candidate is the best seen so far and <span class="math inline">\(x_t=0\)</span> otherwise. The decision <span class="math inline">\(d_t=1\)</span> if the <span class="math inline">\(t\)</span>th candidate is hired and <span class="math inline">\(d_t=0\)</span> otherwise. The utility function is given by <span class="math inline">\(u(x_t,d_t) = x_t d_t\)</span>. <!-- The law of motion is given by $x_{t+1} = \max \{ x_t, x_{t+1} \}$.  --> The Bellman equation is given by <span class="math display">\[
P(\text{best of T}\mid x_t=1) = \dfrac{P(\text{best of T})}{P(x_t=1)} = \dfrac{1/T}{1/t} = \dfrac{t}{T}.
\]</span> The <span class="math inline">\(t\)</span>th offer is the best seen so far places no restriction on the relative ranks of the first <span class="math inline">\(t-1\)</span> offers. Therefore, <span class="math display">\[
p(x_t=1,y^{t-1}) = p(x_t=1)p(y^{t-1})
\]</span> by the independence assumption. Hence, we have <span class="math display">\[
p(x_t=1 \mid y^{t-1}) = p(x_t=1) = \dfrac{1}{t}.
\]</span></p>
<p>Let <span class="math inline">\(p^*(x_{t-1}=0)\)</span> be the probability under the optimal strategy. Now we have to select the best candidate, given we have seen <span class="math inline">\(t-1\)</span> offers so far and the last one was not the best or worse. The probability satisfies the Bellman equation <span class="math display">\[
p^*(x_{t-1}=0) = \frac{t-1}{t} p^*(x_{t}=0) + \frac{1}{t}\max\left(t/T, p^*(x_{t}=0)\right).
\]</span> This leads to <span class="math display">\[
p^*(x_{t-1}=0) = \frac{t-1}{T} \sum_{\tau=t-1}^{T-1}\dfrac{1}{\tau}.
\]</span></p>
<p>Remember, the strategy is to reject the first <span class="math inline">\(r\)</span> candidates and then select the first. The probability of selecting the best candidate is given by <span class="math display">\[
P(\text{success}) = \dfrac{1}{T}\sum_{a=r+1}^T \dfrac{r}{a} \approx  \dfrac{1}{T}\int_{r}^{T}\dfrac{r}{a} = \dfrac{r}{T} \log \left ( \dfrac{T}{r} \right ).
\]</span> We optimize over <span class="math inline">\(r\)</span> by setting the derivative <span class="math display">\[
\frac{\log \left(\frac{T}{r}\right)}{T}-\frac{1}{T}
\]</span> to zero, to find the optimal <span class="math inline">\(r=T/e\)</span>.</p>
<p>If we plug in <span class="math inline">\(r=T/e\)</span> back to the probability of success, we get <span class="math display">\[
P(\text{success}) \approx \dfrac{1}{e} \log \left ( e \right ) = \dfrac{1}{e}.
\]</span></p>
</section>
<section id="monte-carlo-simulations" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="monte-carlo-simulations"><span class="header-section-number">4.4</span> Monte Carlo Simulations</h2>
<p>Simulations are a powerful tool for making decisions when we deal with a complex system, which is difficult or impossible to analyze mathematically. They are used in many fields, including finance, economics, and engineering. They can also be used to test hypotheses about how a system works and to generate data for statistical analysis.</p>
<p>We start by showing how the secretary problem can be analyses using simulations rather than alanytical derivations provided above.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">17</span>) <span class="co"># Kharlamov</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>nmc <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>sz <span class="ot">=</span> <span class="dv">300</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>rules <span class="ot">=</span> <span class="fu">round</span>(n<span class="sc">*</span><span class="fu">seq</span>(<span class="fl">0.002</span>,<span class="fl">0.8</span>,<span class="at">length.out =</span> sz))</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>rules <span class="ot">=</span> <span class="fu">unique</span>(rules[rules<span class="sc">&gt;</span><span class="dv">0</span>])</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>sz <span class="ot">=</span> <span class="fu">length</span>(rules)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>cnt <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>,sz)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>quality <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>,sz)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>sz)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nmc){</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n,n)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    screen <span class="ot">=</span> x[<span class="dv">1</span><span class="sc">:</span>(rules[i]<span class="sc">-</span><span class="dv">1</span>)]</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    best_screen <span class="ot">=</span> <span class="fu">max</span>(screen)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    xchoice <span class="ot">=</span> x[(rules[i])<span class="sc">:</span>n]</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    better_candidates <span class="ot">=</span> <span class="fu">which</span>(xchoice <span class="sc">&gt;</span> best_screen)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">length</span>(better_candidates)<span class="sc">==</span><span class="dv">0</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>      choice <span class="ot">=</span> x[n]</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>      choice <span class="ot">=</span> xchoice[<span class="fu">min</span>(better_candidates)]</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    cnt[i] <span class="ot">=</span> cnt[i] <span class="sc">+</span> (choice <span class="sc">==</span> <span class="fu">max</span>(x))</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    quality[i] <span class="ot">=</span> quality[i] <span class="sc">+</span> choice</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">cnt=</span>cnt, <span class="at">quality=</span>quality,<span class="at">nmc=</span>nmc, <span class="at">rules=</span>rules)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d<span class="sc">$</span>rules, d<span class="sc">$</span>cnt<span class="sc">/</span>d<span class="sc">$</span>nmc, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">col=</span><span class="dv">3</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">xlab=</span><span class="st">"Number of Candidates Screend"</span>, </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Probability of Picking the Best"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="dec_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d<span class="sc">$</span>rules, d<span class="sc">$</span>quality<span class="sc">/</span><span class="dv">1000</span>, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">col=</span><span class="dv">3</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">xlab=</span><span class="st">"Number of Candidates Screend"</span>, </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Average Quality of Candidate"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="dec_files/figure-html/unnamed-chunk-6-2.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div id="exm-mc-portfolio" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.4 (Yahoo Stock Price Simulation)</strong></span> Investing in volatile stocks can be very risky. The Internet stocks during the late 1990’s were notorious for their volatility. For example, the leading Internet stock Yahoo! started 1999 at $62,rose to $122, then fell back to $55 in August, only to end the year at $216. Even more remarkable is the fact that byJanuary 2000, Yahoo! has risen more than 100-fold from its offering price of $1.32 on April 15, 1996. In comparison, theNasdaq 100, a benchmark market index, was up about 5-fold during the same period.</p>
<p>Stock prices fluctuate somewhat randomly. Maurice Kendall, in his seminal 1953 paper on the random walk nature of stock and commodity prices, observed that “<em>The series looks like a wandering one, almost as if once a week the Demon of Chance drew a random number from a symmetrical population of fixed dispersion and added to it the current price to determine next week’s price (p.&nbsp;87).</em>” While a pure random walk model for Yahoo!’s stock price is in fact not reasonable since its price cannot fall below zero, an alternative model tha appears to provide reasonable results assumes that the logarithms o price changes, or returns, follow a random walk. This alternative mode is the basis for the results in this article.</p>
<p>To evaluate a stock investment, we take the initial price as <span class="math inline">\(S(0)\)</span> and then we need to determine what the stock price might be in year <span class="math inline">\(T\)</span>, namely <span class="math inline">\(S(T)\)</span>. Our approach draws from the Black-Scholes Model for valuing stock options. Technically, the Black-Scholes Model assumes that <span class="math inline">\(S(T)\)</span> is determined by the solution to a stochastic differential equation (see sidebar). The important consequence of the model for predicting future prices is that <span class="math inline">\(\log(S(T)/S(0))\)</span> has a normal distribution with mean <span class="math inline">\((\mu-\frac{1}{2} \sigma^2)T\)</span> and variance <span class="math inline">\(\sigma^2 T\)</span> which is equivalent to saying that the ratio <span class="math inline">\(S(T)/S(0)\)</span> has a log-normal distribution. It is interesting that although the Black-Scholes result is a standard tool for valuing options in finance the log-normal predictive distribution that follows from its assumptions is not commonly studied. In order to forecast <span class="math inline">\(S(T)\)</span> we need to estimate the unknowns <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> (recall <span class="math inline">\(S(0)\)</span> is known). The unknown parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> can be interpreted as the instantaneous expected rate of return and the volatility, respectively. The mean parameter <span class="math inline">\(\mu\)</span> is known as the expected rate of return because the expected value of <span class="math inline">\(S(T)\)</span> is <span class="math inline">\(S(0)e^{\mu T}\)</span>. There are a number of ways of estimating the unknown parameters. One approach is to use an equilibrium model for returns, such as the Capital Asset Pricing Model or CAPM.</p>
<p>Rather than estimate <span class="math inline">\(\mu\)</span> directly, the CAPM estimates the difference between <span class="math inline">\(\mu\)</span> and the risk-free rate <span class="math inline">\(r_f\)</span>. This quantity <span class="math inline">\(\mu-r_f\)</span> is known as the expected excess return (excess relative to a risk-free investment). The CAPM relates the expected excess return of a stock to that of an underlying benchmark, typically a broad-based market index. Let <span class="math inline">\(\mu_M\)</span> and <span class="math inline">\(\sigma_M\)</span> denote the return and volatility on the market index. The implication of CAPM is that there is a linear relationship between the expected excess return of a stock, <span class="math inline">\(\mu-r_f\)</span>, and the excess return of the market, <span class="math inline">\(\mu_M-r_f\)</span>.<br>
<span class="math display">\[
\text{Excess \; Return}_{\text{Stock}} =  \beta \;  \text{Excess \;
Return}_{\text{Market}}
\]</span> <span class="math display">\[
\mu-r_f = \beta(\mu_M - r_f )
\]</span> Put simply, the expected excess return of a stock is <span class="math inline">\(\beta\)</span> times the excess expected return of the market. Beta (<span class="math inline">\(\beta\)</span>) is a measure of a stock’s risk in relation to the market. A beta of 1.3 implies that the excess return on the stock is expected to move up or down 30% more than the market. A beta bigger than one implies the stock is riskier than the market and goes up (and down) faster than the market goes up (and down). A beta less than one implies the stock is less risky than the market.</p>
<p>Using the CAPM, the expected return of the stock can now be defined as the risk free interest rate plus beta times the expected excess return of the market, <span class="math display">\[
\mu = \text{Expected \; Return}_{\text{Stock}} = r_f+\beta (\mu_M-r_f)
\]</span> Beta is typically estimated from a regression of the individual stock’s returns on those of the market. The other parameters are typically measured as the historical average return on the market <span class="math inline">\(\mu_M\)</span> and the yield on Treasury Bills <span class="math inline">\(r_f\)</span>. Together these form an estimate of <span class="math inline">\(\mu\)</span>. The volatility parameter <span class="math inline">\(\sigma\)</span> is estimated by the standard deviation of historical returns.</p>
<p>Our qualitative discussion implicitly took the year as the unit of time. For our example, we make one minor change and consider daily returns so that <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are interpreted as a daily rate of return and daily volatility (or standard deviation). We use an annual risk-free rate of 5%; this makes a daily risk-free rate of .019%, <span class="math inline">\(r_f = 0.00019\)</span>, assuming there are 252 trading days in a year. A simple historical average is used to estimate the market return (<span class="math inline">\(\mu_M\)</span>) for the Nasdaq 100. The average annual return is about 23%, with corresponding daily mean <span class="math inline">\(\mu_M = 0.00083\)</span>. A regression using daily returns from 1996-2000 leads to an estimate of <span class="math inline">\(\beta = 1.38\)</span>. Combining these (pieces) leads to an estimated expected return of Yahoo!, <span class="math inline">\(\mu_{Yahoo} = 0.00019+1.38(0.00083-0.00019) = 0.00107\)</span> on a daily basis. Note that the CAPM model estimates a future return that is much lower than the observed rate over the last three-plus years of .42% per day or 289% per year.</p>
<p>To measure the riskiness of Yahoo! notice that the daily historical volatility is 5%, i.e.&nbsp;<span class="math inline">\(\sigma = 0.05\)</span>. On an annual basis this implies a volatility of <span class="math inline">\(\sigma \sqrt{T} = 0.05 \sqrt{252} = 0.79\)</span>, that is 79%. For comparison, the benchmark Nasdaq 100 has historical daily volatility 1.9% and an annual historical volatility of 30%. The estimates of all the parameters are recorded in <a href="#tbl-returns" class="quarto-xref">Table&nbsp;<span>4.1</span></a>.</p>
<div id="tbl-returns" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-returns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4.1: Key Parameter Estimates Based on Daily Returns 1996–2000
</figcaption>
<div aria-describedby="tbl-returns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<colgroup>
<col style="width: 19%">
<col style="width: 23%">
<col style="width: 24%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Asset</th>
<th>Expected return</th>
<th>Volatility</th>
<th>Regression coefft (s.e.)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Yahoo!</td>
<td><span class="math inline">\(\mu = 0.00107\)</span></td>
<td><span class="math inline">\(\sigma = 0.050\)</span></td>
<td><span class="math inline">\(\beta = 1.38 (.07)\)</span></td>
</tr>
<tr class="even">
<td>Nasdaq 100</td>
<td><span class="math inline">\(\mu_M = 0.00083\)</span></td>
<td><span class="math inline">\(\sigma_M = 0.019\)</span></td>
<td>1</td>
</tr>
<tr class="odd">
<td>Treasury Bills</td>
<td><span class="math inline">\(r_f = 0.00019\)</span></td>
<td>–</td>
<td>–</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</section>
<section id="expected-utility" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="expected-utility"><span class="header-section-number">4.5</span> Expected Utility</h2>
<p>Let <span class="math inline">\(P,Q\)</span> be two possible <em>risky gambles</em> or probability bets. An agents preferences can then be specified as an ordering on probability bets where we write <span class="math inline">\(P\)</span> is preferred to <span class="math inline">\(Q\)</span> as <span class="math inline">\(P \succeq Q\)</span> and indifference as <span class="math inline">\(P \sim Q\)</span>. A compound or mixture bet is defined by the probability assignment <span class="math inline">\(p P + (1 - p ) Q\)</span> for a prospected weight <span class="math inline">\(0 \leq p \leq 1\)</span>.</p>
<p>Ramsey-de Finetti-Savage show that if an agents’ preferences satisfy a number of plausible axioms – completeness, transitivity, continuity and independence – then they can be represented by the expectation of a utility function. The theory is a <em>normative</em> one and not necessarily <em>descriptive</em>. It suggests how a rational agent should formulate beliefs and preferences and not how they actually behave.</p>
<p>This representation of preferences in terms of expected utility <span class="math inline">\(U(P)\)</span> of a risky gamble is then equivalent to <span class="math display">\[
P \succeq Q \; \; \iff \; \; U (P) \geq U (Q )
\]</span> Therefore, the higher the value taken by the utility function the more the gamble is preferred. Specifically, the axioms lead to existence of expected utility and uniqueness of probability.</p>
<p>The two key facts then are uniqueness of probability and existence of expected utility. Formally,</p>
<ol type="1">
<li>If <span class="math inline">\(P \succeq R \succeq Q\)</span> and <span class="math inline">\(w P + (1 - w ) Q \sim R\)</span> then <span class="math inline">\(w\)</span> is unique.</li>
<li>There exists an expected utility <span class="math inline">\(U(\cdot )\)</span> such that <span class="math inline">\(P \succeq Q \; \; \iff \; \; U (P) \geq U (Q)\)</span>. Furthermore <span class="math display">\[
U \left (w P + (1 - w ) Q \right ) = wU (P) +(1 - w ) U(Q)
\]</span> for any <span class="math inline">\(P, Q\)</span> and <span class="math inline">\(0 \leq w \leq 1\)</span>.</li>
</ol>
<p>This implies that <span class="math inline">\(U\)</span> is additive and it is also unique up to affine transformation.</p>
<p>Proof: If <span class="math inline">\(w\)</span> is not unique then <span class="math inline">\(\exists w_1\)</span> such that <span class="math inline">\(w_1 P + (1 - w_1 ) Q \sim R\)</span>. Without loss of generality assume that <span class="math inline">\(w_1 &lt; w\)</span> and so <span class="math inline">\(0 &lt; w - w_1 &lt; 1 - w_1\)</span>. However, we can write the bet <span class="math inline">\(Q\)</span> as <span class="math display">\[
Q = \left ( \frac{w-w_1}{1-w_1} \right ) Q + \left ( \frac{1-w}{1-w_1} \right ) Q
\]</span> By transitivity, as <span class="math inline">\(P \succeq Q\)</span> we have <span class="math display">\[
\left ( \frac{w-w_1}{1-w_1} \right ) P + \left ( \frac{1-w}{1-w_1} \right ) Q \succeq Q
\]</span> However, <span class="math display">\[
w P + ( 1 - w) Q = w_1 P + (1 - w_1 ) \left (  \left ( \frac{w-w_1}{1-w_1} \right ) P + \left ( \frac{1-w}{1-w_1} \right ) Q
\right )
\]</span> implying by transitivity that <span class="math display">\[
w P + (1 - w ) Q \succeq w_1 P + (1 - w_1 ) Q
\]</span> which is a contradiction.</p>
<p>This can be used together with the axioms to then prove the existence and uniqueness of a utility function.</p>
<div id="thm-existence" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.1</strong></span> If <span class="math inline">\(V\)</span> is any other function satisfying these results then <span class="math inline">\(V\)</span> is an affine function of <span class="math inline">\(U\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>If <span class="math inline">\(\forall P , Q\)</span> we have <span class="math inline">\(P \sim Q\)</span>, then define <span class="math inline">\(u(P) \equiv 0\)</span>. Hence suppose that there exists <span class="math inline">\(S \succ T\)</span>. Define <span class="math inline">\(U(S) =1\)</span> and <span class="math inline">\(U(T)=0\)</span>. For any <span class="math inline">\(P \in \mathcal{P}\)</span> there are five possibilities: <span class="math inline">\(P \succ T\)</span> or <span class="math inline">\(P \sim S\)</span> or <span class="math inline">\(S \succ P \succ T\)</span> or <span class="math inline">\(P \sim T\)</span> or <span class="math inline">\(T \succ P\)</span>.</p>
<p>In the first case define <span class="math inline">\(1/U(P)\)</span> to be the unique <span class="math inline">\(p\)</span> (see previous theorem) defined by <span class="math inline">\(p P + ( 1 -p )T \sim S\)</span>. In the second case, define <span class="math inline">\(U(P) =1\)</span>. In the third, there exists a unique <span class="math inline">\(q\)</span> with <span class="math inline">\(q S + ( 1 -q )T \sim P\)</span> and then define <span class="math inline">\(U(P)=q\)</span>. In the fourth case, define <span class="math inline">\(U(P)=0\)</span> and finally when <span class="math inline">\(T \succ P\)</span> there exists a unique <span class="math inline">\(r\)</span> with <span class="math inline">\(r S + ( 1-r )P \sim T\)</span> and then we define <span class="math inline">\(U(P) = - r / (1 - r)\)</span>.</p>
<p>Then check that <span class="math inline">\(U(P)\)</span> satisfies the conditions. See Savage (1954), Ramsey (1927) and de Finetti (1931)</p>
</div>
<p>Other interesting extensions: how do people come to a consensus (DeGroot, 1974, Morris, 1994, 1996). Ramsey (1926) observation that if someone is willing to offer you a bet then that’s conditioning information for you. All probabilities are conditional probabilities.</p>
<p>If the bet outcome <span class="math inline">\(P\)</span> is a monetary value, then the utility functions <span class="math inline">\(P, P^2, \sqrt{P}, \ln P\)</span> are all monotonically increasing (the more the better). However, the utility function <span class="math inline">\(P^2\)</span> is concave and the utility function <span class="math inline">\(\ln P\)</span> is convex. The concavity of the utility function implies that the agent is risk averse and the convexity implies that the agent is risk seeking.</p>
<div id="exm-stpetersburg" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.5 (Saint Petersburg Paradox)</strong></span> The Saint Petersburg paradox is a concept in probability and decision theory that was first introduced by Daniel Bernoulli in 1738. It revolves around the idea of how individuals value risky propositions and how those valuations may not align with classical expected utility theory.</p>
<p>The paradox is named after the city of Saint Petersburg, where the problem was formulated. Here’s a simplified version of the paradox:</p>
<p>Imagine a gambling game where a fair coin is flipped repeatedly until it lands on heads. The payoff for the game is <span class="math inline">\(2^n\)</span>, where n is the number of tosses needed for the coin to land on heads. The expected value of this game, calculated by multiplying each possible payoff by its probability and summing the results, is infinite:</p>
<p><span class="math display">\[
E(X) = \frac{1}{2} \cdot 2 + \frac{1}{4} \cdot 4 + \frac{1}{8} \cdot 8 + \ldots = \infty
\]</span></p>
<p>This means that, in theory, a rational person should be willing to pay any finite amount to play this game, as the expected value is infinite. However, in reality, most people would be unwilling to pay a large amount to play such a game.</p>
<p>The paradox arises because traditional expected utility theory assumes that individuals make decisions based on maximizing their expected gain. Bernoulli argued that people do not maximize expected monetary value but rather expected utility, where utility is a subjective measure of satisfaction or happiness. He proposed that individuals exhibit diminishing marginal utility for wealth, meaning that the additional satisfaction gained from an extra unit of wealth decreases as total wealth increases.</p>
<p>In the case of the Saint Petersburg paradox, although the expected monetary value is infinite, the utility gained from each additional dollar diminishes rapidly, leading to a reluctance to pay large amounts to play the game.</p>
<p>In modern decision theory and economics, concepts like diminishing marginal utility and expected utility are fundamental in understanding how individuals make choices under uncertainty and risk. The Saint Petersburg paradox highlights the limitations of relying solely on expected monetary value in explaining human behavior in such situations.</p>
<p>One common approach is to consider aspects of potential players, such as their possible risk aversion, available funds, etc., through a utility function <span class="math inline">\(U(x)\)</span>. Applying a utility function in this situation means changing our focus to the quantity <span class="math display">\[
E[U(X)] = \sum^\infty_{k=1} 2^{-k} U(2^k).   
\]</span></p>
<p>Some examples of utility functions are,</p>
<ul>
<li><span class="math inline">\(U(x) = V_0 (1-x^{-\alpha})\)</span>, <span class="math inline">\(\alpha &gt; 0\)</span>, which gives an expected utility of <span class="math inline">\(V_0 \left(1-\frac{1}{2^{\alpha+1}-1}\right)\)</span></li>
<li>Log utility, <span class="math inline">\(U(x) = \log(x)\)</span>, with expected value <span class="math inline">\(2 \log(2)\)</span>.</li>
</ul>
<p>Notice that after obtaining an expected utility value, you’ll have to find the corresponding reward/dollar amount.</p>
</div>
<p>Now, consider a more general situation, when you have three gambles 1: get <span class="math inline">\(P_1\)</span> for sure, 2: get <span class="math inline">\(P_2 = P_1+k\)</span> and <span class="math inline">\(P_3 = P_1-k\)</span> with probability 1/2. Then we will compare the utility of those gambles <span class="math display">\[
1/2U(P_2) + 1/2U(P_3) \text{ and } U(P_1).
\]</span> If the utility function is linear then we should be indifferent between the two gambles. However, if the utility function is concave then we should prefer the sure thing. This is known as the <strong>certainty effect</strong>. <span class="math display">\[
1/2U(P_2) + 1/2U(P_3) &lt; U(P_1).
\]</span></p>
<p>The usual situation can be described as follows. Let <span class="math inline">\(\Omega\)</span> be a finite set of possible outcomes with <span class="math inline">\(\Omega = \{ \omega_1 , \ldots , \omega_n \}\)</span>. Let <span class="math inline">\(P_i\)</span> be the consequence that assigns one to outcome <span class="math inline">\(\omega_i\)</span> and zero otherwise and let <span class="math inline">\(P = ( p_1 , \ldots , p_n )\)</span> assign probability <span class="math inline">\(p_i\)</span> to outcome <span class="math inline">\(\omega_i\)</span>. Then we can write the expected utility, <span class="math inline">\(U(P)\)</span>, of the gamble <span class="math inline">\(P\)</span> as <span class="math inline">\(U(P) = \sum_{i=1}^n p_i U( P_i )\)</span>. That is, the utility of <span class="math inline">\(P\)</span> is the expected value of a random variable <span class="math inline">\(X\)</span> that takes the value <span class="math inline">\(U(P_i)\)</span> if the outcome is <span class="math inline">\(\omega_i\)</span>. Therefore, we can write <span class="math inline">\(U(P) = \mathbb{E}_P \left ( U( X ) \right)\)</span>.</p>
<p>This leads us to the notion of <em>risk aversion</em> and a categorization of agents according to their risk tolerance: the agent is said to be</p>
<ol type="1">
<li><strong>Risk Averse</strong> if <span class="math inline">\(\mathbb{E}_P \left ( u(X) \right ) \leq u \left (  \mathbb{E}_P  ( X)  \right )\)</span></li>
<li><strong>Risk Neutral</strong> if <span class="math inline">\(\mathbb{E}_P \left ( u(X) \right ) = u \left (  \mathbb{E}_P  ( X)  \right )\)</span></li>
<li><strong>Risk Seeking</strong> if <span class="math inline">\(\mathbb{E}_P \left ( u(X) \right ) \geq u \left (  \mathbb{E}_P  ( X)  \right )\)</span></li>
</ol>
<p>under the assumption that these hold for all probabilities and random variables. Risk aversion is equivalent to the agent having concave utility and risk seeking convex.</p>
<div id="exm-kelly" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.6 (Kelly Criterion)</strong></span> Suppose you have $1000 to invest. With probability <span class="math inline">\(0.55\)</span> you will win whatever you wager and with probability <span class="math inline">\(0.45\)</span> you lose whatever you wager. What’s the proportion of capital that leads to the fastest compounded growth rate?</p>
<p>Quoting Kelly (1956), the exponential rate of growth, <span class="math inline">\(G\)</span>, of a gambler’s capital is <span class="math display">\[
G = \lim_{N\to \infty} \frac{1}{N} \log_2 \frac{V_N}{V_0}
\]</span> for initial capital <span class="math inline">\(V_0\)</span> and capital after <span class="math inline">\(N\)</span> bets <span class="math inline">\(V_N\)</span>.</p>
<p>Under the assumption that a gambler bets a fraction of his capital, <span class="math inline">\(\omega\)</span>, each time, we use <span class="math display">\[
V_N = (1+\omega)^W (1-\omega)^L V_0
\]</span> where <span class="math inline">\(W\)</span> and <span class="math inline">\(L\)</span> are the number of wins and losses in <span class="math inline">\(N\)</span> bets. We get <span class="math display">\[
G = p \log_2(1+\omega)+ q \log_2(1-\omega)
\]</span> in which the limit(s) of <span class="math inline">\(\frac{W}{N}\)</span> and <span class="math inline">\(\frac{L}{N}\)</span> are the probabilities <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>, respectively.</p>
<p>This also comes about by considering the sequence of i.i.d. bets with <span class="math display">\[
p ( X_t = 1 ) = p \; \; \text{ and} \; \; p ( X_t = -1 ) = q=1-p
\]</span> We want to find an optimal allocation <span class="math inline">\(\omega^*\)</span> that maximizes the expected long-run growth rate: <span class="math display">\[\begin{align*}
\max_\omega \mathbb{E} \left ( \ln ( 1 + \omega W_T ) \right )
&amp; = p \ln ( 1 + \omega ) + (1 -p) \ln (1 - \omega ) \\
&amp; \leq p \ln p + q \ln q + \ln 2 \; \text{ and} \; \omega^\star = p - q
\end{align*}\]</span></p>
<p>The solution is <span class="math inline">\(w^* = 0.55 - 0.45 = 0.1\)</span>.</p>
<p>Both approaches give the same optimization problem, which, when solved, give the optimal fraction rate <span class="math inline">\(\omega^* = p-q\)</span>, thus, with <span class="math inline">\(p=0.55\)</span>, the optimal allocation is 10% of capital.</p>
<p>We can generalize the rule to the case of asymmetric payouts <span class="math inline">\((a,b)\)</span>. Then the expected utility function is <span class="math display">\[
p \ln ( 1 + b \omega ) + (1 -p) \ln (1 - a \omega )
\]</span> The optimal solution is <span class="math display">\[
\omega^\star = \frac{bp - a q}{ab}
\]</span></p>
<p>If <span class="math inline">\(a=b=1\)</span> this reduces to the pure Kelly criterion.</p>
<p>A common case occurs when <span class="math inline">\(a=1\)</span> and market odds <span class="math inline">\(b=O\)</span>. The rule becomes <span class="math display">\[
\omega^* = \frac{p \cdot O  -q }{O}.
\]</span></p>
<p>Let’s consider another scenario. You have two possible market opportunities: one where it offers you <span class="math inline">\(4/1\)</span> when you have personal odds of <span class="math inline">\(3/1\)</span> and a second one when it offers you <span class="math inline">\(12/1\)</span> while you think the odds are <span class="math inline">\(9/1\)</span>.</p>
<p>In expected return these two scenarios are identical both offering a 33% gain. In terms of maximizing long-run growth, however, they are not identical.</p>
<p><a href="#tbl-kelly" class="quarto-xref">Table&nbsp;<span>4.2</span></a> shows the Kelly criteria advises an allocation that is twice as much capital to the lower odds proposition: <span class="math inline">\(1/16\)</span> weight versus <span class="math inline">\(1/40\)</span>.</p>
<div id="tbl-kelly" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-kelly-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4.2: Kelly rule
</figcaption>
<div aria-describedby="tbl-kelly-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th>Market</th>
<th>You</th>
<th><span class="math inline">\(p\)</span></th>
<th><span class="math inline">\(\omega^\star\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(4/1\)</span></td>
<td><span class="math inline">\(3/1\)</span></td>
<td><span class="math inline">\(1/4\)</span></td>
<td><span class="math inline">\(1/16\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(12/1\)</span></td>
<td><span class="math inline">\(9/1\)</span></td>
<td><span class="math inline">\(1/10\)</span></td>
<td><span class="math inline">\(1/40\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The optimal allocation <span class="math inline">\(\omega^\star = ( p O - q ) / O\)</span> is <span class="math display">\[
\frac{ (1/4) \times 4 - (3/4) }{4} = \frac{1}{16} \; \text{ and} \;
\frac{ (1/10) \times 12 - (9/10) }{12} = \frac{1}{40}.
\]</span></p>
</div>
<p><strong>Power utility</strong> and log-utilities allow to model constant relative risk aversion (CRRA). The main advantage that the optimal rule is unaffected by wealth effects. The CRRA utility of wealth takes the form <span class="math display">\[
U_\gamma (W) = \frac{ W^{1-\gamma} -1 }{1-\gamma}
\]</span></p>
<p>The special case <span class="math inline">\(U(W) = \log (W )\)</span> for <span class="math inline">\(\gamma = 1\)</span>.</p>
<p>This leads to a myopic Kelly criterion rule.</p>
</section>
<section id="unintuitive-nature-of-decision-making" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="unintuitive-nature-of-decision-making"><span class="header-section-number">4.6</span> Unintuitive Nature of Decision Making</h2>
<div id="exm-ellberg" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.7 (Ellsberg Paradox: Ambiguity Aversion)</strong></span> The Ellsberg paradox is a thought experiment that was first proposed by Daniel Ellsberg in 1961. It is a classic example of a situation where individuals exhibit ambiguity aversion, meaning that they prefer known risks over unknown risks. The paradox highlights the importance of considering ambiguity when making decisions under uncertainty.</p>
<p>There are two urns each containing 100 balls. It is known that urn A contains 50 red and 50 black, but urn B contains an unknown mix of red and black balls. The following bets are offered to a participant:</p>
<ul>
<li>Bet 1A: get $1 if red is drawn from urn A, $0 otherwise</li>
<li>Bet 2A: get $1 if black is drawn from urn A, $0 otherwise</li>
<li>Bet 1B: get $1 if red is drawn from urn B, $0 otherwise</li>
<li>Bet 2B: get $1 if black is drawn from urn B, $0 otherwise</li>
</ul>
</div>
<div id="exm-allias" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.8 (Allais Paradox: Independence Axiom)</strong></span> The Allais paradox is a choice problem designed by Maurice Allais to show an inconsistency of actual observed choices with the predictions of expected utility theory. The paradox is that the choices made in the second problem seem irrational, although they can be explained by the fact that the independence axiom of expected utility theory is violated.</p>
<p>We run two experiments. In each experiment a participant has to make a choice between two gambles.</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Experiment 1</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Gamble <span class="math inline">\({\cal G}_1\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gamble <span class="math inline">\({\cal G}_2\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Chance</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Chance</td>
</tr>
<tr class="odd">
<td style="text-align: center;">$25m</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$25m</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="even">
<td style="text-align: center;">$5m</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">$5m</td>
<td style="text-align: center;">0.89</td>
</tr>
<tr class="odd">
<td style="text-align: center;">$0m</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$0m</td>
<td style="text-align: center;">0.01</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Experiment 2</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Gamble <span class="math inline">\({\cal G}_3\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gamble <span class="math inline">\({\cal G}_4\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Chance</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Chance</td>
</tr>
<tr class="odd">
<td style="text-align: center;">$25</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$25m</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="even">
<td style="text-align: center;">$5</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">$5m</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">$0m</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">$0m</td>
<td style="text-align: center;">0.9</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>The difference in expected gains is identical in two experiments</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>E1 <span class="ot">=</span> <span class="dv">5</span><span class="sc">*</span><span class="dv">1</span> </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>E2 <span class="ot">=</span> <span class="dv">25</span><span class="sc">*</span><span class="fl">0.1</span> <span class="sc">+</span> <span class="dv">5</span><span class="sc">*</span><span class="fl">0.89</span> <span class="sc">+</span> <span class="dv">0</span><span class="sc">*</span><span class="fl">0.01</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>E3 <span class="ot">=</span> <span class="dv">5</span><span class="sc">*</span><span class="fl">0.11</span> <span class="sc">+</span> <span class="dv">0</span><span class="sc">*</span><span class="fl">0.89</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>E4 <span class="ot">=</span> <span class="dv">25</span><span class="sc">*</span><span class="fl">0.1</span> <span class="sc">+</span> <span class="dv">0</span><span class="sc">*</span><span class="fl">0.9</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">c</span>(E1<span class="sc">-</span>E2,E3<span class="sc">-</span>E4))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] -1.95 -1.95</code></pre>
</div>
</div>
<p>However, typically a person prefers <span class="math inline">\({\cal G}_1\)</span> to <span class="math inline">\({\cal G}_2\)</span> and <span class="math inline">\({\cal G}_4\)</span> to <span class="math inline">\({\cal G}_3\)</span>, we can conclude that the expected utilities of the preferred is greater than the expected utilities of the second choices. The fact is that if <span class="math inline">\({\cal G}_1 \geq {\cal G}_2\)</span> then <span class="math inline">\({\cal G}_3 \geq {\cal G}_4\)</span> and vice-versa.</p>
<p>Assuming the subjective probabilities <span class="math inline">\(P = ( p_1 , p_2 , p_3)\)</span>. The expected utility <span class="math inline">\(E ( U | P )\)</span> is <span class="math inline">\(u ( 0 ) = 0\)</span> and for the high prize set <span class="math inline">\(u ( \$ 25 \; \text{million} ) = 1\)</span>. Which leaves one free parameter <span class="math inline">\(u = u ( \$ 5 \; \text{million} )\)</span>.</p>
<p>Hence to compare gambles with probabilities <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> we look at the difference <span class="math display">\[
E ( u | P ) - E ( u | Q ) = ( p_2 - q_2 ) u + ( p_3 - q_3 )
\]</span></p>
<p>For comparing <span class="math inline">\({\cal G}_1\)</span> and <span class="math inline">\({\cal G}_2\)</span> we get <span class="math display">\[\begin{align*}
E ( u | {\cal G}_1 ) - E ( u | {\cal G}_2 ) &amp;= 0.11 u - 0.1 \\
E ( u | {\cal G}_3 ) - E ( u | {\cal G}_4 ) &amp;= 0.11 u - 0.1
\end{align*}\]</span> The order is the same, given your <span class="math inline">\(u\)</span>. If your utility satisfies <span class="math inline">\(u &lt; 0.1/0.11 = 0.909\)</span> you take the “riskier” gamble.</p>
</div>
<div id="exm-Curse" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.9 (Winner’s Curse)</strong></span> One of the interesting facts about expectation is that when you are in a competitive auctioning game then you shouldn’t value things based on pure expected value. You should take into consideration the event that you win <span class="math inline">\(W\)</span>. Really you should be calculating <span class="math inline">\(E(X\mid W)\)</span> rather than <span class="math inline">\(E(X)\)</span>.</p>
<p>The winner’s curse: given that you win, you should feel regret: <span class="math inline">\(E(X\mid W) &lt; E(X)\)</span>.</p>
<p>A good example is claiming racehorse whose value is uncertain.</p>
<table class="table">
<thead>
<tr class="header">
<th>Value</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>horse never wins</td>
</tr>
<tr class="even">
<td>50,000</td>
<td>horse improves</td>
</tr>
</tbody>
</table>
<p>Simple expected value tells you <span class="math display">\[
E(X) = \frac{1}{2} \cdot 0 + \frac{1}{2} \cdot 50,000 = \$25,000.
\]</span> In a $20,000 claiming race (you can buy the horse for this fixed fee ahead of time from the owner) it looks like a simple decision to claim the horse.</p>
<p>Its not so simple! We need to calculate a conditional expectation. What’s <span class="math inline">\(E( X\mid W )\)</span>, given you win event (<span class="math inline">\(W\)</span>)? This is the expected value of the horse given that you win that is relevant to assessing your bid. In most situations <span class="math inline">\(E(X\mid W) &lt; 20,000\)</span>.</p>
<p>Another related feature is this problem is . The owner or trainer of the horse maybe know something that you don’t know. There’s a reason why they are entering the horse into a claiming race in the first place.</p>
<p>Winner’s curse implies that immediately after you have win, you should feel a little regret, as the object is less valuable to you after you have won! Or put another way, in an auction nobody else in the room is willing to offer more than you at that time.</p>
</div>
<div id="exm-hat" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.10 (The Hat Problem)</strong></span> There are <span class="math inline">\(N\)</span> prisoners in a forward facing line. Each guy is wearing a blue or red hat. Everyone can see all the hats in front of him, but cannot see his own hat. The hats can be in any combination of red and blue, from all red to all blue and every combination in between. The first guy doesn’t know his own hat.</p>
<p>A guard is going to walk down the line, starting in the back, and ask each prisoner what color hat they have on. They can only answer “blue” or “red.” If they answer incorrectly, or say anything else, they will be shot dead on the spot. If they answer correctly, they will be set free. Each prisoner can hear all of the other prisoners’ responses, as well as any gunshots that indicate an incorrect response. They can remember all of this information.</p>
<p>There is a rule that all can agree to follow such that the first guy makes a choice (“My hat is …”) and everyone after that, including the last guy, will get their color right with probability <span class="math inline">\(1\)</span>. You have a <span class="math inline">\(100\)</span>% chance of saving all but the last prisoner, and a <span class="math inline">\(50\)</span>% chance of saving that one. Here’s the strategy the prisoners have agreed on. The last prisoner counts the number of blue hats worn; if the number is even, the last prisoner yells “blue”, if odd, yells “red”. If the <span class="math inline">\(99\)</span>th prisoner hears “blue”, but counts an odd number of blue hats, then his hat must be blue so that the total number of blue hats is even. If he counts an even number of blue hats, then his hat must be red. If the last prisoner yells red, then 99 knows that there are an odd number of blue hats. So 99 counts the number of blue hats he can see. Again, if they are even, his hat is blue, if odd, his hat is red. The 99th prisoner then yells out the color of his hat and is spared. The next prisoner now knows whether the remaining number of blue hats, including his own, is odd or even, by taking into account whether 99 had a blue hat or not. Then by counting the number of blue hats he sees, he knows the color of his hat. So he yells out the color of his hat and is spared. This saves all but the last prisoner, and there is a <span class="math inline">\(50\)</span>% chance that his hat is the color he shouted out.</p>
<p>One hundred prisoners are too many to work with. Suppose there are two. The last person can save the guy in front of him by shouting out the color of his hat. OK, how about if there are three? The third prisoner can see 0,1, or 2 blue hats. There seem to be three possibilities but only two choices of things to say. But, two of the possibilities have something in common namely the number of blue hats is even. So if the last prisoner yells “blue” then he can tell 1 and 2 that he sees an even number of blue hats. Then the second prisoner, by looking ahead and counting the number of blue hats, knows his must be blue if he sees one blue hat, and red if he sees no blue hats. The last prisoner agrees to yell “red” if the number of blue hats seen is odd. Then if 2 sees a blue hat on 1, his must be red, and if 1 has a red hat, his must be blue. By shouting out the color of his hat, 1 also knows his hat color. Two “blues” or two “reds” in a row mean he wears blue, while one blue and one red means he wears red. OK. This looks like this always works, because there are always only two possibilities as far as the number of blue hats worn they are either even or odd. So, check as in the three-person case that using this strategy (“blue” for an even number of blue hats “red” for an odd number) tells 99 the color of his hat, and then each prisoner in turn can learn the color of his hat by taking into account the parity of the number of blue hats he can see, the parity of the number of blue hats 100 saw and the number of prisoners behind him wearing blue hats.</p>
</div>
<div id="exm-lemons" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.11 (Lemon’s Problem)</strong></span> The lemon problem is an interesting conditional probability puzzle and is a classic example of asymmetric information in economics. It was first proposed by George Akerlof in his 1970 paper “The Market for Lemons: Quality Uncertainty and the Market Mechanism.” The problem highlights the importance of information in markets and how it can lead to adverse selection, where the quality of goods or services is lower than expected.</p>
<p>The basic tenet of the lemons principle is that low-value cars force high-value cars out of the market because of the asymmetrical information available to the buyer and seller of a used car. This is primarily due to the fact that a seller does not know what the true value of a used car is and, therefore, is not willing to pay a premium on the chance that the car might be a lemon. Premium-car sellers are not willing to sell below the premium price so this results in only lemons being sold.</p>
<p>Suppose that a dealer pays $20K for a car and wants to sell for $25K. Some cars on the market are Lemons. The dealer knows whether a car is a lemon. A lemon is only worth $5K. There is asymmetric information as the customer doesn’t know if the particular new car is a lemon. S/he estimates the probability of lemons on the road by using the observed frequency of lemons. We will consider two separate cases:</p>
<ul>
<li>Let’s first suppose only 10% of cars are lemons.</li>
<li>We’ll then see what happens if 50% are lemons.</li>
</ul>
<p>The question is how does the market clear (ie. at what price do car’s sell). Or put another way does the customer buy the car and if so what price is agreed on? This is very similar to winner’s curse: when computing an expected value what conditioning information should I be taking into account?</p>
<p>In the case where the customer thinks that <span class="math inline">\(p=0.10\)</span> of the car’s are lemons, they are willing to pay <span class="math display">\[
E (X)= \frac{9}{10} \cdot 25 + \frac{1}{10} \cdot 5 = \$ 23 K
\]</span> This is greater than the initial $20 that the dealer paid. The car then sells at $23K <span class="math inline">\(&lt;\)</span> $25K.</p>
<p>Of course, the dealer is disappointed that there are lemons on the road as he is not achieving the full value – missing $2000. Therefore, they should try and persuade the customer its not a lemon by offering a warranty for example.</p>
<p>The more interesting case is when <span class="math inline">\(p=0.5\)</span>. The customer now values the car at <span class="math display">\[
E (X)  = \frac{1}{2} \cdot 25 + \frac{1}{2} \cdot 5 = \$ 15K
\]</span> This is lower than the $20K – the reservation price that the dealer would have for a good car. Now what type of car and at what price do they sell?</p>
<p>The key point in asymmetric information is that the customer must condition on the fact that if the dealer still wants to sell the car, the customer must update his probability of the type of the car. We already know that if the car is not a lemon, the dealer won’t sell under his initial cost of $20K. So at $15K he is only willing to sell a lemon. But then if the customer computes a conditional expectation <span class="math inline">\(E( X \mid \mathrm{Lemon})\)</span> – conditioning on new information that the car is a lemon <span class="math inline">\(L\)</span> we het the valuation <span class="math display">\[
E ( X \mid L ) = 1 \cdot  5 = \$ 5K
\]</span> Therefore only lemons sell, at $ 5K, even if the dealer has a perfectly good car the customer is not willing to buy!</p>
<p>Again what should the dealer do? Try to raise the quality and decrease the frequency of lemons in the observable market. They type of modeling has all been used to understand credit markets and rationing in periods of loss of confidence.</p>
</div>
<div id="exm-envelope" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.12 (Envelope Paradox)</strong></span> The envelope paradox is a thought experiment or puzzle related to decision-making under uncertainty. It is also known as the “exchange paradox” or the “two-envelope paradox.” The paradox highlights the importance of carefully considering the information available when making decisions under uncertainty and the potential pitfalls of making assumptions about unknown quantities.</p>
<p>A swami puts <span class="math inline">\(m\)</span> dollars in one envelope and <span class="math inline">\(2 m\)</span> in another. He hands on envelope to you and one to your opponent. The amounts are placed randomly and so there is a probability of <span class="math inline">\(\frac{1}{2}\)</span> that you get either envelope.</p>
<p>You open your envelope and find <span class="math inline">\(x\)</span> dollars. Let <span class="math inline">\(y\)</span> be the amount in your opponent’s envelope. You know that <span class="math inline">\(y = \frac{1}{2} x\)</span> or <span class="math inline">\(y = 2 x\)</span>. You are thinking about whether you should switch your opened envelope for the unopened envelope of your friend. It is tempting to do an expected value calculation as follows <span class="math display">\[
E( y) = \frac{1}{2} \cdot  \frac{1}{2} x + \frac{1}{2} \cdot 2 x = \frac{5}{4} x &gt; x
\]</span> Therefore, it looks as if you should switch no matter what value of <span class="math inline">\(x\)</span> you see. A consequence of this, following the logic of backwards induction, that even if you didn’t open your envelope that you would want to switch!</p>
<p>Where’s the flaw in this argument? Use Bayes rule to update the probabilities of which envelope your opponent has! Assume <span class="math inline">\(p(m)\)</span> of dollars to be placed in the envelope by the swami.</p>
<p>Such an assumption then allows us to calculate an odds ratio <span class="math display">\[
\frac{ p \left ( y = \frac{1}{2} x | x \right ) }{ p \left ( y = 2 x | x \right ) }
\]</span> concerning the likelihood of which envelope your opponent has.</p>
<p>Then, the expected value is given by <span class="math display">\[
E(y) =  p \left ( y = \frac{1}{2} x \; \vert \;  x \right ) \cdot  \frac{1}{2} x +
  p \left ( y = 2 x | x \right ) \cdot 2 x
\]</span> and the condition <span class="math inline">\(E( y) &gt; x\)</span> becomes a decision rule.</p>
<p>This is an open-ended problem, but it will not be very confusing if we well understand both the frequentist and bayesian approaches. Actually, this is a very good example to show how these two approaches are different and to check if we understand them correctly. There many conditions in this problem, so we cannot argue everything in this example; instead, we are going to focus on some interesting cases. First, assume we’re risk-neutral (although, we can simply change “money” with “utility” in this paradox, so it doesn’t matter). We will compare frequentist/bayesian, open/not open, and discrete/continuous. The finite, or bounded space, case will not be considered here since they are not very interesting.</p>
<p>Now, let <span class="math inline">\(X\)</span> be the amount of money in my envelope, <span class="math inline">\(Y\)</span> be the amount in my opponents. Let <span class="math inline">\(M_1\)</span> be the amount of money in the first envelope and <span class="math inline">\(M_2(= 2 M_1)\)</span> in the second one. <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are random variables while <span class="math inline">\(M_1\)</span> and <span class="math inline">\(M_2\)</span> are parameters.</p>
<p>If I DO NOT look in my envelope, in this case, even from a frequentist viewpoint, we can find a fallacy in this naive expectation reasoning <span class="math inline">\(E[trade] = 5X/4\)</span> . First, the right answer from a frequentist view is, loosely, as follows. If we switch the envelope, we can obtain <span class="math inline">\(M_1\)</span> (when <span class="math inline">\(X = M_1\)</span>) or lose <span class="math inline">\(M_1\)</span> (when <span class="math inline">\(X = M_2\)</span>) with the same probability <span class="math inline">\(1/2\)</span>. Thus, the value of a trade is zero, so that trading matters not for my expected wealth.</p>
<p>Instead, naive reasoning is confusing the property of variable <span class="math inline">\(X\)</span> and <span class="math inline">\(M_1\)</span> . <span class="math inline">\(X\)</span> is a random variable and <span class="math inline">\(M_1\)</span> is a fixed parameter which is constant (again, from a frequentist viewpoint). By trading, we can obtain <span class="math inline">\(X\)</span> (when <span class="math inline">\(X = M_1\)</span>) or lose <span class="math inline">\(X/2\)</span> (when <span class="math inline">\(X = 2 M_1\)</span>) with the same probability <span class="math inline">\(1/2\)</span>. Here, the former <span class="math inline">\(X(= M_1)\)</span> is different from the latter <span class="math inline">\(X(= 2 M_1 )\)</span>. Actually, the former <span class="math inline">\(X = M_1\)</span> equals to the half of the latter <span class="math inline">\(X = 2 M_1 = M_2\)</span>. Thus, <span class="math inline">\(X \frac{1}{2} - \frac{X}{2} \frac{1}{2} = \frac{X}{4}\)</span> is the wrong expected value of trading. On the other hand, from a bayesian view, since we have no information, we are indifferent to either trading or not.</p>
<p>The second scenario is if I DO look in my envelope. As the Christensen &amp; Utts (1992) article said, the classical view cannot provide a completely reasonable resolution to this case. It is just ignoring the information revealed. Also, the arbitrary decision rule introduced at the end of the paper or the extension of it commented by Ross (1996) are not the results of reasoning from a classical approach. However, the bayesian approach provides a systematic way of finding an optimal decision rule using the given information. Most of the arguments in the Christensen &amp; Utts (1992) paper are right, but there is one serious error in the article which is corrected in Bachman-Christensen-Utts (1996) and discussed in Brams &amp; Kilgour (1995).</p>
<p>Let <span class="math inline">\(M_1\)</span> be the amount of money in the first envelope and <span class="math inline">\(M_2(= 2 M_1)\)</span> in the second one. The prior distribution of <span class="math inline">\(M_1\)</span> is <span class="math inline">\(g(m)\)</span>. Applying Bayes’ theorem, we have <span class="math display">\[
p(M_1 = x \mid X = x) = \frac{p(X = x \mid M_1 = x) g(x)}{p(X = x)} = \frac{g(x)}{g(x)+g(x/2)}.
\]</span> Similarly, we have <span class="math display">\[
p(M_1 = x/2 \mid X = x) = \frac{p(X = x \mid M_1 = x/2) g(x/2)}{p(X = x/2)} = \frac{g(x/2)}{g(x)+g(x/2)}.
\]</span> The Bayesian can now compute his expected winnings from the two actions. If he keeps the envelope he has, he wins <span class="math inline">\(x\)</span> dollars. If he trades envelopes, he wins <span class="math inline">\(x/2\)</span> if he currently has the envelope with <span class="math inline">\(2M\)</span> dollars, i.e., if <span class="math inline">\(M = x/2\)</span> and he wins <span class="math inline">\(2\)</span>x if he currently has the envelope with <span class="math inline">\(M\)</span> dollars, i.e., <span class="math inline">\(M = x\)</span>. His expected winnings from a trade are <span class="math display">\[
E(W\mid Trade) = E(Y\mid X = x) = \frac{g(x/2)}{g(x)+g(x/2)} \frac{x}{2} + \frac{g(x)}{g(x)+g(x/2)} 2x.
\]</span> It is easily seen that when <span class="math inline">\(g(x/2) = 2g(x)\)</span>, <span class="math inline">\(E(W\mid Trade) =
x\)</span>. Therefore, if <span class="math inline">\(g(x/2) &gt; 2g(x)\)</span> it is optimal to keep the envelope and if <span class="math inline">\(g(x/2) &lt; 2g(x)\)</span> it is optimal to trade envelopes. For example, if your prior distribution on M is exponential <span class="math inline">\(\lambda\)</span>, so that <span class="math inline">\(g(m) = e^{\lambda m}\)</span>, then it is easily seen that it is optimal to keep your envelope if <span class="math inline">\(x &gt; 2\log(2)/\lambda\)</span>.</p>
<p>The intuitive value of the expected winnings when trading envelopes was shown to be <span class="math inline">\(5x/4\)</span>. This value can be obtained by assuming that <span class="math inline">\(g(x)/[g(x) + g(x/2)] =
1/2\)</span> for all <span class="math inline">\(x\)</span>. . In particular, this implies that <span class="math inline">\(g(x) = g(x/2)\)</span> for all x, i.e., <span class="math inline">\(g(x)\)</span> is a constant function. In other words, the intuitive expected winnings assumes an improper “noninformative” uniform density on <span class="math inline">\([0, \infty)\)</span>. It is of interest to note that the improper noninformative prior for this problem gives a truly noninformative (maximum entropy) posterior distribution.</p>
<p>The paper calculated the marginal density of <span class="math inline">\(X\)</span> like below. <span class="math display">\[\begin{align*}
p(X = x) &amp;= p(M_1 = x)g(x) + p(M_2 = x)g(x/2) \\
&amp;= \frac{1}{2} g(x) + \frac{1}{2} g(x/2)
\end{align*}\]</span> where <span class="math inline">\(g(x)\)</span> is the prior distribution of <span class="math inline">\(M_1\)</span>. However, integrating <span class="math inline">\(p(X = x)\)</span> with respect to <span class="math inline">\(x\)</span> from <span class="math inline">\(0\)</span> to <span class="math inline">\(\infty\)</span> gives <span class="math inline">\(3/2\)</span> instead of <span class="math inline">\(1\)</span>. In fact, their calculation of <span class="math inline">\(p(X = x)\)</span> can hold only when the prior distribution <span class="math inline">\(g(x)\)</span> is discrete and <span class="math inline">\(p(X = x)\)</span>, <span class="math inline">\(g(m)\)</span>, <span class="math inline">\(g(m/2)\)</span> represent the probabilities that <span class="math inline">\(X = x\)</span>, <span class="math inline">\(M_1 = m\)</span>, <span class="math inline">\(M_1 = m/2\)</span>, respectively.</p>
<p>For the correct calculation of the continuous <span class="math inline">\(X\)</span> case, one needs to properly transform the distribution. That can be done by remembering to include the Jacobian term alongside the transformed PDF, or by working with the CDF of <span class="math inline">\(X\)</span> instead. The latter forces one to properly consider the transform, and we proceed with that method.</p>
<p>Let <span class="math inline">\(G(x)\)</span> be the CDF of the prior distribution of <span class="math inline">\(M_1\)</span> corresponding to <span class="math inline">\(g(x)\)</span>. <span class="math display">\[\begin{align*}
p(x &lt; X \leq x+dx) &amp;= p(M_1 = x)dG(x)+ p(M_2 = x)dG(x/2) \\
&amp;= \frac{1}{2} \left( dG(x)+ dG(x/2) \right)
\end{align*}\]</span> where <span class="math inline">\(g(x) = dG(x)/dx\)</span>. Now, the PDF of <span class="math inline">\(X\)</span> is <span class="math display">\[\begin{align*}
f_X(x) &amp;= \frac{d}{dx} p(x &lt; X \leq x + dx) \\
&amp;= \frac{1}{2} \left(g(x) + \frac{1}{2} g(x/2) \right)
\end{align*}\]</span> We have an additional <span class="math inline">\(1/2\)</span> in the last term due to the chain rule, or the Jacobian in the change-in-variable formula. Therefore, the expected amount of a trade is <span class="math display">\[\begin{align*}
E(Y\mid X = x) &amp;= \frac{x}{2} p(M_2 = x\mid X = x) + 2 x \, p(M_1 = x\mid X = x) \\
&amp;= \frac{x}{2} \frac{g(x)}{g(x) + g(x/2)/2} + 2 x \frac{g(x/2)/2}{g(x) + g(x/2)/2} \\
&amp;=  \frac{\frac{x}{2}g(x) + x g(x/2)}{g(x) + g(x/2)/2}
\end{align*}\]</span></p>
<p>Thus, for the continuous case, trading is advantageous whenever <span class="math inline">\(g(x/2) &lt; 4g(x)\)</span>, instead of the decision rule for the discrete case <span class="math inline">\(g(x/2) &lt; 2g(x)\)</span>.</p>
<p>Now, think about which prior will give you the same decision rule as the frequentist result. In the discrete case, <span class="math inline">\(g(x)\)</span> such that <span class="math inline">\(g(x/2) = 2g(x)\)</span>, and in the continuous case <span class="math inline">\(g(x)\)</span> such that <span class="math inline">\(g(x/2) = 4g(x)\)</span>. However, both do not look like useful, non-informative priors. Therefore, the frequentist approach does not always equal the Bayes approach with a non-informative prior. At the moment you start to treat <span class="math inline">\(x\)</span> as a given number, and consider <span class="math inline">\(p(M_1 \mid X = x)\)</span> (or <span class="math inline">\(p(Y \mid X = x)\)</span>), you are thinking in a bayesian way, and need to understand the implications and assumptions in that context.</p>
</div>
<p>Leonard Jimmie Savage, an American statistician, developed a decision theory framework known as the “Savage axioms” or the “Sure-Thing Principle.” This framework is a set of axioms that describe how a rational decision-maker should behave in the face of uncertainty. These axioms provide a foundation for subjective expected utility theory.</p>
<p>The Savage axioms consist of three main principles:</p>
<ol type="1">
<li><strong>Completeness Axiom:</strong>
<ul>
<li>This axiom assumes that a decision-maker can compare and rank all possible outcomes or acts in terms of preferences. In other words, for any two acts (or lotteries), the decision-maker can express a preference for one over the other, or consider them equally preferable.</li>
</ul></li>
<li><strong>Transitivity Axiom:</strong>
<ul>
<li>This axiom states that if a decision-maker prefers act A to act B and prefers act B to act C, then they must also prefer act A to act C. It ensures that the preferences are consistent and do not lead to cycles or contradictions.</li>
</ul></li>
<li><strong>Continuity Axiom (or Archimedean Axiom):</strong>
<ul>
<li>The continuity axiom introduces the concept of continuity in preferences. It implies that if a decision-maker prefers act A to act B, and B to C, then there exists some probability at which the decision-maker is indifferent between A and some lottery that combines B and C. This axiom helps to ensure that preferences are not too “discontinuous” or erratic.</li>
</ul></li>
</ol>
<p>Savage’s axioms provide a basis for the development of subjective expected utility theory. In this theory, decision-makers are assumed to assign subjective probabilities to different outcomes and evaluate acts based on the expected utility, which is a combination of the utility of outcomes and the subjective probabilities assigned to those outcomes.</p>
<p>Savage’s framework has been influential in shaping the understanding of decision-making under uncertainty. It allows for a more flexible approach to decision theory that accommodates subjective beliefs and preferences. However, it’s worth noting that different decision theorists may have alternative frameworks, and there are ongoing debates about the appropriateness of various assumptions in modeling decision-making.</p>
</section>
<section id="decision-trees" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="decision-trees"><span class="header-section-number">4.7</span> Decision Trees</h2>
<p>Decision trees can effectively model and visualize conditional probabilities. They provide a structured way to break down complex scenarios into smaller, more manageable steps, allowing for clear calculations and interpretations of conditional probabilities.</p>
<p>Each node in a decision tree, including thr root represents an event or condition. The branches represent the possible outcomes of that condition. Along each branch, you’ll often see a probability. This is the chance of that outcome happening, given the condition at the node. As you move down the tree, you’re looking at more specific conditions and their probabilities. The leaves of the tree show the final probabilities of various outcomes, considering all the conditions along the path to that leaf. Thus, the probabilities of the leaves need to sum to 1.</p>
<div id="exm-medical" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.13 (Medical Testing)</strong></span> A patient goes to see a doctor. The doctor performs a test which is 95% sensitive – that is 95 percent of people who are sick test positive and 99% specific – that is 99 percent of the healthy people test negative. The doctor also knows that only 1 percent of the people in the country are sick. Now the question is: if the patient tests positive, what are the chances the patient is sick? The intuitive answer is 99 percent, but the correct answer is 66 percent.</p>
<p>Formally, we have two binary variables, <span class="math inline">\(D=1\)</span> that indicates you have a disease and <span class="math inline">\(T=1\)</span> that indicates that you test positive for it. The estimates we know already are given by <span class="math inline">\(P(D) = 0.02\)</span>, <span class="math inline">\(P(T\mid D) = 0.95\)</span>, and <span class="math inline">\(P(\bar T \mid \bar D) = 0.99\)</span>. Here we used shortcut notations, instead of writing <span class="math inline">\(P(D=1)\)</span> we used <span class="math inline">\(P(D)\)</span> and instead of <span class="math inline">\(P(D=0)\)</span> we wrote <span class="math inline">\(P(\bar D)\)</span>.</p>
<p>Sometimes it is more intuitive to describe probabilities using a tree rather than tables. The tree below shows the conditional distribution of <span class="math inline">\(D\)</span> and <span class="math inline">\(T\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-medtree" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-medtree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<pre class="mermaid mermaid-js" data-label="fig-medtree">flowchart LR
  D[D] --&gt;|0.02| D1(D=1)
  D --&gt;|0.98| D0(D=0)
  D1 --&gt;|0.95| D1T1(T=1)
  D1 --&gt;|0.05| D1T0(T=0)
  D0 --&gt;|0.01| D0T1(T=1)
  D0 --&gt;|0.99| D0T0(T=0)
</pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-medtree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: Medical Diagnostics Decision Tree.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The result is not as intuitive as in the NBA example. Let’s think about this intuitively. Rather than relying on Bayes’s math to help us with this, let us consider another illustration. Imagine that the above story takes place in a small town, with <span class="math inline">\(1,000\)</span> people. From the prior <span class="math inline">\(P(D)=0.02\)</span>, we know that 2 percent, or 20 people, are sick, and <span class="math inline">\(980\)</span> are healthy. If we administer the test to everyone, the most probable result is that 19 of the 20 sick people test positive. Since the test has a 1 percent error rate, however, it is also probable that 9.8 of the healthy people test positive, we round it to 10.</p>
<p>Now if the doctor sends everyone who tests positive to the national hospital, there will be 10 healthy and 19 sick patients. If you meet one, even though you are armed with the information that the patient tested positive, there is only a 66 percent chance this person is sick.</p>
<p>Let’s extend the example and add the utility of the test and the utility of the treatment. Then the decision problem is to treat <span class="math inline">\(a_T\)</span> or not to treat <span class="math inline">\(a_N\)</span>. The Q-function is the function of the state <span class="math inline">\(S \in \{D_0,D_1\}\)</span> and the action <span class="math inline">\(A \in \{a_T,a_N\}\)</span></p>
<table class="table">
<caption>Utility of the test and the treatment.</caption>
<thead>
<tr class="header">
<th>A/S</th>
<th><span class="math inline">\(a_T\)</span></th>
<th><span class="math inline">\(a_N\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(D_0\)</span></td>
<td>90</td>
<td>100</td>
</tr>
<tr class="even">
<td><span class="math inline">\(D_1\)</span></td>
<td>90</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Then expected utility of the treatment is 90 and no treatment is 98. A huge difference. Given our prior knowledge, we should not treat everyone.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fl">0.02</span><span class="sc">*</span><span class="dv">90</span> <span class="sc">+</span> <span class="fl">0.98</span><span class="sc">*</span><span class="dv">90</span>  <span class="co"># treat</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 90</code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fl">0.02</span><span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> (<span class="dv">1</span><span class="fl">-0.02</span>)<span class="sc">*</span><span class="dv">100</span> <span class="co"># do not treat</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 98</code></pre>
</div>
</div>
<p>However, the expected utility will change when our probability of disease changes. Let’s say that we are in a country where the probability of disease is 0.1 or we performed a test and updated our prior probability of disease to some number <span class="math inline">\(p\)</span>. Then the expected utility of the treatment is <span class="math inline">\(E\left[U(a_T)\right]\)</span> is 90 and no treatment is <span class="math display">\[
E\left[U(a_N)\right] = 0\cdot p + 100 \cdot (1-p) = 100(1-p)
\]</span> When we are unsure about the value of <span class="math inline">\(p\)</span> we may want to explore how the optimal decision changes as we vary <span class="math inline">\(p\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p, <span class="dv">100</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">xlab =</span> <span class="st">"p"</span>, <span class="at">ylab =</span> <span class="fu">TeX</span>(<span class="st">"$E[U(a)]$"</span>))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">90</span>, <span class="at">col=</span><span class="st">"red"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomleft"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="fu">TeX</span>(<span class="st">"$E[U(a_N)]$"</span>), <span class="fu">TeX</span>(<span class="st">"$E[U(a_T)]$"</span>)), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="st">"red"</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">bty=</span><span class="st">'n'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dec_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Expected utility of the treatment and no treatment as a function of the prior probability of disease.</figcaption>
</figure>
</div>
</div>
</div>
<p>If our estimate at the crossover point, then we should be indifferent between treatment and no treatment, if on the left of the crossover point, we should treat, and if on the right, we should not treat. The crossover point is. <span class="math display">\[
100(1-p) = 90, ~p = 0.1
\]</span></p>
<p>The gap of of <span class="math inline">\(0.9-100(1-p)\)</span> is the expected gain from treatment.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p, <span class="dv">90-100</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">xlab =</span> <span class="st">"p"</span>, <span class="at">ylab =</span> <span class="fu">TeX</span>(<span class="st">"Utility gain from treatment"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="dec_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Now, let us calculate the value of test, e.g.&nbsp;the change in expected utility from the test. We will need to calculate the posterior probabilities</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(D | T = 0) = P(T = 0 | D) P(D) / P(T = 0)</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>pdt0 <span class="ot">=</span> <span class="fl">0.05</span><span class="sc">*</span><span class="fl">0.02</span><span class="sc">/</span>(<span class="fl">0.05</span><span class="sc">*</span><span class="fl">0.02</span> <span class="sc">+</span> <span class="fl">0.99</span><span class="sc">*</span><span class="fl">0.98</span>) </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pdt0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.001029654</code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected utility given the test is negative </span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># E[U(a_N | T=0)]</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>UN0 <span class="ot">=</span> pdt0<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>pdt0)<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(UN0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 99.89703</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># E[U(a_T | T=0)]</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>UT0 <span class="ot">=</span> pdt0<span class="sc">*</span><span class="dv">90</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>pdt0)<span class="sc">*</span><span class="dv">90</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(UT0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 90</code></pre>
</div>
</div>
<p>Given test is negative, our best action is not to treat. Our utility is 100. What if the test is positive?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(D | T = 1) = P(T = 1 | D) P(D) / P(T = 1)</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>pdt <span class="ot">=</span> <span class="fl">0.95</span><span class="sc">*</span><span class="fl">0.02</span><span class="sc">/</span>(<span class="fl">0.95</span><span class="sc">*</span><span class="fl">0.02</span> <span class="sc">+</span> <span class="fl">0.01</span><span class="sc">*</span><span class="fl">0.98</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pdt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.6597222</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># E[U(a_N | T=1)]</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>UN1 <span class="ot">=</span> pdt<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>pdt)<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(UN1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 34.02778</code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># E[U(a_T | T=1)]</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>UT1 <span class="ot">=</span> pdt<span class="sc">*</span><span class="dv">90</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>pdt)<span class="sc">*</span><span class="dv">90</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(UT1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 90</code></pre>
</div>
</div>
<p>The best option is to treat now! Given the test our strategy is to treat if the test is positive and not treat if the test is negative. Let’s calculate the expected utility of this strategy.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(T=1) = P(T=1 | D) P(D) + P(T=1 | D=0) P(D=0)</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>pt <span class="ot">=</span> <span class="fl">0.95</span><span class="sc">*</span><span class="fl">0.02</span> <span class="sc">+</span> <span class="fl">0.01</span><span class="sc">*</span><span class="fl">0.98</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.0288</code></pre>
</div>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(T=0) = P(T=0 | D) P(D) + P(T=0 | D=0) P(D=0)</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>pt0 <span class="ot">=</span> <span class="fl">0.05</span><span class="sc">*</span><span class="fl">0.02</span> <span class="sc">+</span> <span class="fl">0.99</span><span class="sc">*</span><span class="fl">0.98</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pt0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 0.9712</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected utility of the strategy</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>pt<span class="sc">*</span>UT1 <span class="sc">+</span> pt0<span class="sc">*</span>UN0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>## [1] 99.612</code></pre>
</div>
</div>
<p>The utility of out strategy of 100 is above of the strategy prior to testing (98), this difference of 2 is called the <em>value of information</em>.</p>
</div>
<div id="exm-slide" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.14 (Mudslide)</strong></span> I live in in a house that is at risk of being damaged by a mudslide. I can build a wall to protect it. The wall costs $10,000. If there is a mudslide, the wall will protect the house with probability <span class="math inline">\(0.95\)</span>. If there is no mudslide, the wall will not cause any damage. The prior probability of a mudslide is <span class="math inline">\(0.01\)</span>. If there is a mudslide and the wall does not protect the house, the damage will cost $100,0000. Should I build the wall?</p>
<p>Let’s formally solve this as follows:</p>
<ul>
<li>Build a decision tree.</li>
<li>The tree will list the probabilities at each node. It will also list any costs there are you going down a particular branch.</li>
<li>Finally, it will list the expected cost of going down each branch, so we can see which one has the better risk/reward characteristics.</li>
</ul>
<div class="cell" data-fig-width="6" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    R(( )) --&gt;|Build: $40, $40.5| B(( ))
    R --&gt;|Don't Build: $0, $10| D(( ))
    B --&gt;|Slide: $0, $90| BS(( ))
    B --&gt;|No Slide: $0, $40| BN[40]
    BS --&gt;|Hold: $0, $40| BSH[40]
    BS --&gt;|Not Hold: $1000, $1040| BSN[1040]
    D --&gt;|Slide: $1000, $1000| DS[1000]
    D --&gt;|No Slide: $0, $0| DN[0]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The first dollar value is the cost of the edge, e.g.&nbsp;the cost of building the wall is $40,000. The second dollar value is the expected cost of going down that branch. For example, if you build the wall and there is a mudslide, the expected cost is $90,000. If you build the wall and there is no mudslide, the expected cost is $40,000. The expected cost of building the wall is $40,500. The expected cost of not building the wall is $10. The expected cost of building the wall is greater than the expected cost of not building the wall, so you should not build the wall. The dollar value at the leaf nodes is the expected cost of going down that branch. For example, if you build the wall and there is a mudslide and the wall does not hold, the expected cost is $1004000.</p>
<p>There’s also the possibility of a further test to see if the wall will hold. Let’s include the geological testing option. The test costs $3000 and has the following accuracies. <span class="math display">\[
P( T  \mid  \mathrm{Slide} ) = 0.90 \; \; \mathrm{and } \; \; P( \mathrm{not~}T  \mid
\mathrm{No \; Slide} ) = 0.85
\]</span> If you choose the test, then should you build the wall?</p>
<p>Let’s use the Bayes rule. The initial prior probabilities are <span class="math display">\[
P( Slide ) = 0.01  \; \; \mathrm{and} \; \; P ( \mathrm{No \; Slide} ) = 0.99
\]</span></p>
<p><span class="math display">\[\begin{align*}
P( T) &amp; = P( T  \mid  \mathrm{Slide} ) P( \mathrm{Slide} ) +
P( T  \mid  \mathrm{No \;  Slide} ) P( \mathrm{No \; Slide} ) \\
P(T)&amp; = 0.90 \times 0.01 + 0.15 \times 0.99 = 0.1575
\end{align*}\]</span> We’ll use this to find our optimal course of action.</p>
<p>The posterior probability given a positive test is <span class="math display">\[\begin{align*}
P ( Slide  \mid  T ) &amp; = \frac{ P ( T  \mid  Slide ) P ( Slide )}{P(T)} \\
&amp; = \frac{ 0.90 \times 0.01}{ 0.1575} = 0.0571
\end{align*}\]</span></p>
<p>The posterior probability given a negative test is <span class="math display">\[\begin{align*}
P \left ( \mathrm{Slide}  \mid  \mathrm{not~}T \right ) &amp; = \frac{ P ( \mathrm{not~}T  \mid  \mathrm{Slide} ) P ( \mathrm{Slide} )}{P(\mathrm{not~}T)} \\
&amp; = \frac{0.1 \times 0.01 }{0.8425} \\
&amp; =0.001187
\end{align*}\]</span></p>
<p>Compare this to the initial base rate of a <span class="math inline">\(1\)</span>% chance of having a mud slide.</p>
<p>Given that you build the wall without testing, what is the probability that you’ll lose everything? With the given situation, there is one path (or sequence of events and decisions) that leads to losing everything:</p>
<ul>
<li>Build without testing (given) Slide (<span class="math inline">\(0.01\)</span>)</li>
<li>Doesn’t hold (<span class="math inline">\(0.05\)</span>) <span class="math display">\[
P ( \mathrm{losing} \; \mathrm{everything}  \mid  \mathrm{build} \; \mathrm{w/o} \;
\mathrm{testing} ) = 0.01 \times 0.05 = 0.0005
\]</span></li>
</ul>
<p>Given that you choose the test, what is the probability that you’ll lose everything? There are two paths that lead to losing everything:</p>
<ul>
<li><p>There are three things that have to happen to lose everything. Test +ve (<span class="math inline">\(P=0.1575\)</span>), Build, Slide (<span class="math inline">\(P= 0.0571\)</span>), Doesn’t Hold (<span class="math inline">\(P=0.05\)</span>)</p></li>
<li><p>Now you lose everything if Test -ve (<span class="math inline">\(P=0.8425\)</span>), Don’t Build, Slide given negative (<span class="math inline">\(P=0.001187\)</span>).</p></li>
</ul>
<p>The conditional probabilities for the first path <span class="math display">\[
P ( \mathrm{first} \; \mathrm{path} ) = 0.1575 \times 0.0571 \times 0.05
= 0.00045
\]</span></p>
<p>For the second path <span class="math display">\[
P ( \mathrm{second} \; \mathrm{path} ) = 0.8425 \times 0.001187 = 0.00101
\]</span></p>
<p>Hence putting it all together <span class="math display">\[
P ( \mathrm{losing} \; \mathrm{everything}  \mid  \mathrm{testing} ) = 0.00045 + 0.00101 = 0.00146
\]</span></p>
<p>Putting these three cases together we can build a risk/reward table</p>
<table class="table">
<thead>
<tr class="header">
<th>Choice</th>
<th>Expected Cost</th>
<th>Risk</th>
<th>P</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Don’t Build</td>
<td>$10,000</td>
<td>0.01</td>
<td>1 in 100</td>
</tr>
<tr class="even">
<td>Build w/o testing</td>
<td>$40,500</td>
<td>0.0005</td>
<td>1 in 2000</td>
</tr>
<tr class="odd">
<td>Test</td>
<td>$10,760</td>
<td>0.00146</td>
<td>1 in 700</td>
</tr>
</tbody>
</table>
<p>The expected cost with the test is <span class="math inline">\(3+40\times 0.1575+1000\times 0.001187 = 10,760\)</span></p>
<p>What do you choose?</p>
</div>
</section>
<section id="nash-equilibrium" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="nash-equilibrium"><span class="header-section-number">4.8</span> Nash Equilibrium</h2>
<p>When multiple decision makers interact with each other, meaning the decision of one player changes the state of the “world” and thus affects the decision of another player, then we need to consider the notion of equilibrium. It is a central concept in economics and game theory. The most widely used type of equilibrium is the Nash equilibrium, named after John Nash, who introduced it in his 1950 paper “Equilibrium Points in N-Person Games.” It was popularized by the 1994 film “A Beautiful Mind,” which depicted Nash’s life and work.</p>
<p>It is defined as a set of strategies where no player can improve their payoff by unilaterally changing their strategy, assuming others keep their strategies constant. In other words, a Nash equilibrium is a set of strategies where no player has an incentive to deviate from their current strategy, given the strategies of the other players.</p>
<p>Here are a few examples of Nash equilibria:</p>
<ul>
<li>Prisoner’s Dilemma: Two prisoners must decide whether to cooperate with each other or defect. The Nash equilibrium is for both to defect, even though they would be better off if they both cooperated.</li>
<li>Pricing Strategies: Firms in a market choose prices to maximize profits, taking into account their competitors’ pricing decisions. The equilibrium is the set of prices where no firm can increase profits by changing its price unilaterally.</li>
<li>Traffic Flow: Drivers choose routes to minimize travel time, based on their expectations of other drivers’ choices. The equilibrium is the pattern of traffic flow where no driver can reduce their travel time by choosing a different route.</li>
</ul>
<div id="exm-titfortat" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.15 (Marble Game)</strong></span> Here is a subtle marble game where players have to call out (or present) either red or blue with different payoffs according to how things match. Two players <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have both a red and a blue marble. They present one marble to each other. The payoff table is as follows:</p>
<ul>
<li>If both present red, <span class="math inline">\(A\)</span> wins $3.</li>
<li>If both present blue, <span class="math inline">\(A\)</span> wins $1.</li>
<li>If the colors do not match, <span class="math inline">\(B\)</span> wins $2</li>
</ul>
<p>The question is whether it is better to be <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> or does it matter? Moreover, what kind of strategy should you play? A lot depends on how much credit you give your opponent. A lot of empirical research has studying the <em>tit-for-tat</em> strategy, where you cooperate until your opponent defects. Then you match his last response.</p>
<p>Nash equilibrium will also allow us to study the concept of a <em>randomized strategy</em> (ie. picking a choice with a certain probability) which turns out to be optimal in many game theory problems.</p>
<p>First, assume that the players have a <span class="math inline">\(\frac{1}{2}\)</span> probability of playing Red or Blue. Thus each player has the same expected payoff <span class="math inline">\(E(A) = \$1\)</span> <span class="math display">\[\begin{align*}
    E(A) &amp;= \frac{1}{4} \cdot 3 + \frac{1}{4} \cdot 1 =1 \\
    E(B) &amp;= \frac{1}{4} \cdot 2 + \frac{1}{4} \cdot 2 =1
\end{align*}\]</span> We might go one step further and look at the risk (and measured by a standard deviation) and calculate the variances of each players payout <span class="math display">\[\begin{align*}
    Var (A) &amp; = (1-1)^2 \cdot \frac{1}{4} +(3-1)^2 \cdot \frac{1}{4} + (0-1)^2 \cdot \frac{1}{2} = 1.5 \\
    Var(B) &amp; = 1^2 \cdot \frac{1}{2} + (2-1)^2 \cdot \frac{1}{2} = 1
\end{align*}\]</span> Therefore, under this scenario, if you are risk averse, player <span class="math inline">\(B\)</span> position is favored.</p>
<p>The matrix of probabilities with equally likely choices is given by</p>
<table class="table">
<thead>
<tr class="header">
<th><span class="math inline">\(A,B\)</span></th>
<th>Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P( red, red )\)</span></td>
<td>(1/2)(1/2)=1/4</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P( red, blue )\)</span></td>
<td>(1/2)(1/2)=1/4</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(P( blue, red )\)</span></td>
<td>(1/2)(1/2)=1/4</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P( blue, blue )\)</span></td>
<td>(1/2)(1/2)=1/4</td>
</tr>
</tbody>
</table>
<p>Now they is no reason to assume ahead of time that the players will decide to play <span class="math inline">\(50/50\)</span>. We will show that there’s a mixed strategy (randomized) that is a <em>Nash equilibrium</em> that is, both players won’t deviate from the strategy. We’ll prove that the following equilibrium happens:</p>
<ul>
<li><span class="math inline">\(A\)</span> plays Red with probability 1/2 and blue 1/2</li>
<li><span class="math inline">\(B\)</span> plays Red with probability 1/4 and blue 3/4</li>
</ul>
<p>In this case the expected payoff to playing Red equals that of playing Blue for each player. We can simply calculate: <span class="math inline">\(A\)</span>’s expected payoff is 3/4 and <span class="math inline">\(B\)</span>’s is $1 <span class="math display">\[
E(A) = \frac{1}{8} \cdot 3 + \frac{3}{8} \cdot 1 = \frac{3}{4}
\]</span> Moreover, <span class="math inline">\(E(B) =1\)</span>, thus <span class="math inline">\(E(B) &gt; E(A)\)</span>. We see that <span class="math inline">\(B\)</span> is the favored position. It is simple that if I know that you are going to play this strategy and vice-versa, neither of us will deviate from this strategy – hence the Nash equilibrium concept.</p>
<p>Nash equilibrium probabilities are: <span class="math inline">\(p=P( A \; red )= 1/2, p_1 = P( B \; red ) = 1/4\)</span> with payout matrix</p>
<table class="table">
<thead>
<tr class="header">
<th><span class="math inline">\(A,B\)</span></th>
<th>Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P( red, red )\)</span></td>
<td>(1/2)(1/4)=1/8</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P( red, blue )\)</span></td>
<td>(1/2)(3/4)=3/8</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(P( blue, red )\)</span></td>
<td>(1/2)(1/4)=1/8</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P( blue, blue )\)</span></td>
<td>(1/2)(3/4)=3/8</td>
</tr>
</tbody>
</table>
<p>We have general payoff probabilities: <span class="math inline">\(p=P( A \; red ), p_1 = P( B \; red )\)</span></p>
<p><span class="math display">\[\begin{align*}
    f_A ( p , p_1 ) =&amp; 3 p p_1 + ( 1 -p ) ( 1 - p_1 ) \\
    f_B ( p , p_1 ) =&amp; 2 \{ p(1 - p_1) + ( 1 -p ) p_1 \}
\end{align*}\]</span></p>
<p>To find the equilibrium point <span class="math display">\[\begin{align*}
    ( \partial / \partial p ) f_A ( p , p_1 ) =&amp; 3 p_1 - ( 1 - p_1 ) = 4 p_1 -1 \; \; \mathrm{so} \; \; p_1= 1/4 \\
    ( \partial / \partial p_1 ) f_B ( p , p_1 ) =&amp; 2 ( 1 - 2p ) \; \; \mathrm{so} \; \; p= 1/2
\end{align*}\]</span></p>
<p>Much research has been directed to repeated games versus the one-shot game and is too large a topic to discuss further.</p>
</div>
<p>Equilibrium analysis helps predict the likely outcomes of strategic interactions, even when individuals are acting in their own self-interest. Further, we can use it to understand how markets function and how firms make pricing and production decisions or to design mechanisms (e.g., auctions, voting systems) that incentivize desired behavior and achieve efficient outcomes.</p>
<p>One major drawback is that equilibrium analysis relies on assumptions about rationality and common knowledge of preferences and strategies, which may not always hold in real-world situations. Furthermore, some games may have multiple equilibria, making it difficult to predict which one will be reached. The problem of dynamic strategies, when individuals may learn and adjust their strategies as they gain experience is hard.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../qmd/bayes.html" class="pagination-link  aria-label=" &lt;span="" rule&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../qmd/bl.html" class="pagination-link" aria-label="<span class='chapter-number'>5</span>&nbsp; <span class='chapter-title'>Bayesian Parameter Learning</span>">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Parameter Learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js" type="text/javascript"></script>
<script type="text/javascript">
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    let pseudocodeOptions = {
      indentSize: el.dataset.indentSize || "1.2em",
      commentDelimiter: el.dataset.commentDelimiter || "//",
      lineNumber: el.dataset.lineNumber === "true" ? true : false,
      lineNumberPunc: el.dataset.lineNumberPunc || ":",
      noEnd: el.dataset.noEnd === "true" ? true : false,
      titlePrefix: el.dataset.algTitle || "Algorithm"
    };
    pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
  });
})(document);
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
    titlePrefix = el.dataset.algTitle;
    titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
    titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
  });
})(document);
</script>




</body></html>