<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.544">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bayes, AI and Deep Learning - 7&nbsp; Bayesian Hypothesis Testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../qmd/rct.html" rel="next">
<link href="../qmd/ab.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head><body class="nav-sidebar floating fullcontent"><div class="hidden">
<p><span class="math display">\[
\newcommand{\prob}[1]{\operatorname{P}\left(#1\right)}
\newcommand{\Var}[1]{\operatorname{Var}\left(#1\right)}
\newcommand{\sd}[1]{\operatorname{sd}\left(#1\right)}
\newcommand{\Cor}[1]{\operatorname{Corr}\left(#1\right)}
\newcommand{\Cov}[1]{\operatorname{Cov}\left(#1\right)}
\newcommand{\E}[1]{\operatorname{E}\left(#1\right)}
\newcommand{\defeq}{\overset{\text{\tiny def}}{=}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\mini}{minimize}
\]</span></p>
</div>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>





<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../qmd/prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="../qmd/hyp.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Bayes, AI and Deep Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Principles of Data Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/dec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility and Decisions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/bl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Parameter Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/ab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">AB Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/hyp.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Field vs Observational</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/sp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/rl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../qmd/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../qmd/prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="../qmd/hyp.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The hypothesis testing problem is as follows. Based on a sample of data, <span class="math inline">\(y\)</span>, generated from <span class="math inline">\(p\left( y \mid \theta\right)\)</span> for <span class="math inline">\(\theta\in\Theta\)</span>, the goal is to determine if <span class="math inline">\(\theta\)</span> lies in <span class="math inline">\(\Theta_{0}\)</span> or in <span class="math inline">\(\Theta_{1}\)</span>, two disjoint subsets of <span class="math inline">\(\Theta\)</span>. In general, the hypothesis testing problem involves an action: accepting or rejecting a hypothesis. The problem is described in terms of a null, <span class="math inline">\(\mathcal{H}_{0}\)</span>, and alternative hypothesis, <span class="math inline">\(\mathcal{H}_{1}\)</span>, which are defined as <span class="math display">\[
\mathcal{H}_{0}:\theta\in\Theta_{0}\;\;\mathrm{and}\;\;\mathcal{H}_{1}%
:\theta\in\Theta_{1}\text{.}%
\]</span></p>
<p>Different types of regions generate different types of hypothesis tests. If the null hypothesis assumes that <span class="math inline">\(\theta_{0}\)</span> is a single point, <span class="math inline">\(\Theta _{0}=\theta_{0}\)</span>, this is known as a simple or “sharp” null hypothesis. If the region consists of multiple points than the hypothesis is called a composite, which occurs if the space is unconstrained or an interval of the real line. In the case of a single parameter, one-sided tests are of the form <span class="math inline">\(\mathcal{H}_{0}:\theta&lt;\theta_{0}\)</span> and <span class="math inline">\(\mathcal{H}_{1}:\theta&gt;\theta_{0}\)</span>.</p>
<p>There are correct decisions and two types of possible errors. The correct decisions are accepting a null or alternative that is true. A Type I error incorrectly rejects a true null, and a Type II error incorrectly accepts a false null.</p>
<table class="table">
<colgroup>
<col style="width: 36%">
<col style="width: 31%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(\theta\in\Theta_{0}\)</span></th>
<th><span class="math inline">\(\theta\in\Theta_{1}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Accept <span class="math inline">\(\mathcal{H}_{0}\)</span></td>
<td>Correct decision</td>
<td>Type II error</td>
</tr>
<tr class="even">
<td>Accept <span class="math inline">\(\mathcal{H}_{1}\)</span></td>
<td>Type I error</td>
<td>Correct decision</td>
</tr>
</tbody>
</table>
<p>Formally, the probabilities of Type I (<span class="math inline">\(\alpha\)</span>) and Type II (<span class="math inline">\(\beta\)</span>) errors are defined as: <span class="math display">\[
\alpha=P \left[  \text{reject }\mathcal{H}_{0} \mid \mathcal{H}_{0}\text{
is true }\right]  \text{ and }\beta=P \left[  \text{accept
}\mathcal{H}_{0} \mid \mathcal{H}_{1}\text{ is true }\right]  \text{.}%
\]</span></p>
<p>It is useful to think of the decision to accept or reject as a decision rule, <span class="math inline">\(d\left( y\right)\)</span>. In many cases, the decision rules form a critical region <span class="math inline">\(R\)</span>, such that <span class="math inline">\(d\left( y\right) =d_{1}\)</span> if <span class="math inline">\(y\in R\)</span>. These regions are often take the form of simple inequalities. Next, defining the decision to accept the null is <span class="math inline">\(d\left( y\right) =d_{0}\)</span>, and the decision to accept the alternative is <span class="math inline">\(d_{1},\)</span> the error types are <span class="math display">\[\begin{align*}
\alpha_{\theta}\left(  d\right)   &amp;  =P \left[  d\left(  y\right)
=d_{1} \mid \theta\right]  \text{ if }\theta\in\Theta_{0}\text{ }(\mathcal{H}_{0}\text{ is true})\\
\beta_{\theta}\left(  d\right)   &amp;  =P \left[  d\left(  y\right)
=d_{0} \mid \theta\right]  \text{ if }\theta\in\Theta_{1}\text{ }(\mathcal{H}_{1}\text{ is true})\text{.}%
\end{align*}\]</span> where both types of errors explicitly depend on the decision and the true parameter value. Notice that both of these quantities are determined by the population properties of the data. Size of the test is defined as <span class="math inline">\(\underset{\theta\in\Theta_{0}}{sup}\alpha_{\theta}\left( d\right)\)</span> and the power is defined as <span class="math inline">\(1-\beta_{\theta}\left( d\right)\)</span>. It is always possible to set either <span class="math inline">\(\alpha_{\theta}\left( d\right)\)</span> or <span class="math inline">\(\beta_{\theta }\left( d\right)\)</span> equal to zero, by finding a test that always rejects alternative or null, respectively.</p>
<p>The total probability of making an error is <span class="math inline">\(\alpha_{\theta}\left(d\right) +\beta_{\theta}\left(d\right)\)</span>, and ideally one would seek to minimize the total error probability, absent additional information. In thinking of these tradeoffs, it is important to note that the easiest way to reduce the error probability is to gather more data, as the additional evidence should lead to more accurate decisions. In some cases, it is easy to characterize optimal&nbsp;tests, those that minimize the sum of the errors. Simple hypothesis tests of the form <span class="math inline">\(\mathcal{H}_{0}:\theta=\theta_{0}\)</span> versus <span class="math inline">\(\mathcal{H}_{1}:\theta=\theta_{1}\)</span>, are one such case admiting optimal tests. Defining <span class="math inline">\(d^{\ast}\)</span> as a test accepting <span class="math inline">\(\mathcal{H}_{0}\)</span> if <span class="math inline">\(a_{0}f\left( y \mid \theta_{0}\right) &gt;a_{1}f\left( y \mid \theta_{1}\right)\)</span> and <span class="math inline">\(\mathcal{H}_{1}\)</span> if <span class="math inline">\(a_{0}f\left( y \mid \theta_{0}\right) &lt;a_{1}f\left( y \mid \theta _{1}\right)\)</span>, for some <span class="math inline">\(a_{0}\)</span> and <span class="math inline">\(a_{1}\)</span>. Either <span class="math inline">\(\mathcal{H}_{0}\)</span> or <span class="math inline">\(\mathcal{H}_{1}\)</span> can be accepted if <span class="math inline">\(a_{0}f\left(y \mid \theta_{0}\right) =a_{1}f\left( y \mid \theta_{1}\right)\)</span>. Then, for any other test <span class="math inline">\(d\)</span>, it is not hard to show that <span class="math display">\[
a_{0}\alpha\left(  d^{\ast}\right)  +a_{1}\beta\left(  d^{\ast}\right)  \leq
a_{0}\alpha\left(  d\right)  +a_{1}\beta\left(  d\right),
\]</span> where <span class="math inline">\(\alpha_{d}=\alpha_{d}\left( \theta\right)\)</span> and <span class="math inline">\(\beta_{d}=\beta_{d}\left( \theta\right)\)</span>. This result highlights the optimality of tests defining rejection regions in terms of the likelihood ratio statistic, <span class="math inline">\(f\left( y \mid \theta_{0}\right)/f\left( y \mid \theta_{1}\right)\)</span>. It turns out that the results are in fact stronger. In terms of decision theoretic properties, tests that define rejection regions based on likelihood ratios are not only admissible decisions, but form a minimal complete class, the strongest property possible.</p>
<p>One of the main problems in hypothesis testing is that there is often a tradeoff between the two goals of reducing type I and type II errors: decreasing <span class="math inline">\(\alpha\)</span> leads to an increase in <span class="math inline">\(\beta\)</span>, and vice-versa. Because of this, it is common to fix <span class="math inline">\(\alpha_{\theta}\left( d\right)\)</span>, or <span class="math inline">\(sup\alpha_{\theta}\left( d\right)\)</span>, and then find a test to minimize <span class="math inline">\(\beta_{d}\left( \theta\right)\)</span>. This leads to “most powerful” tests. In thinking of these tests, there is an important result from decision theory: test procedures that use the same size level of <span class="math inline">\(\alpha\)</span> in problems with different sample sizes are inadmissible. This is commonly done where significance is indicated by a fixed size, say 5%. The implications of this will be clearer below in examples.</p>
<section id="the-bayesian-approach" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="the-bayesian-approach"><span class="header-section-number">7.1</span> The Bayesian Approach</h2>
<p>Formally, the Bayesian approach to hypothesis testing is a special case of the model comparison results discussed earlier. The Bayesian approach just computes the posterior distribution of each hypothesis. By Bayes rule, for <span class="math inline">\(i=0,1\)</span> <span class="math display">\[
P \left(  \mathcal{H}_{i} \mid y\right)  =\frac{p\left(  y \mid \mathcal{H}_{i}\right)  P \left(  \mathcal{H}_{i}\right)  }{p\left(  y\right)
}\text{,}%
\]</span> where <span class="math inline">\(P \left( \mathcal{H}_{i}\right)\)</span> is the prior probability of <span class="math inline">\(\mathcal{H}_{i}\)</span>, <span class="math inline">\(p\left( y \mid \mathcal{H}_{i}\right) =\int p\left( y \mid \theta,\mathcal{H}_{i}\right) p\left( \theta \mid \mathcal{H}_{i}\right) d\theta\)</span> is the marginal likelihood under <span class="math inline">\(\mathcal{H}_{i}\)</span>, <span class="math inline">\(p\left( \theta \mid \mathcal{H}_{i}\right)\)</span> is the parameter prior under <span class="math inline">\(\mathcal{H}_{i}\)</span>, and <span class="math display">\[
p\left(  y\right)  =p\left(  y \mid \mathcal{H}_{0}\right)  P \left( \mathcal{H}_{0}\right)  +p\left(  y \mid \mathcal{H}_{1}\right)  P \left( \mathcal{H}_{1}\right)  .
\]</span></p>
<p>If the hypothesis are mutually exclusive, <span class="math inline">\(P \left( \mathcal{H}_{0}\right) =1-P \left( \mathcal{H}_{1}\right)\)</span>.</p>
<p>The posterior <em>odds</em> of the null to the alternative is <span class="math display">\[
\text{Odds}_{0,1}=\frac{P \left(  \mathcal{H}_{0} \mid y\right)  }{P %
\left(  \mathcal{H}_{1} \mid y\right)  }=\frac{p\left(  y \mid \mathcal{H}_{0}\right)
}{p\left(  y \mid \mathcal{H}_{1}\right)  }\frac{P \left(  \mathcal{H}_{0}\right)  }{P \left(  \mathcal{H}_{1}\right)  }\text{.}%
\]</span></p>
<p>The odds ratio updates the prior odds, <span class="math inline">\(P \left( \mathcal{H}_{0}\right) /P \left( \mathcal{H}_{1}\right)\)</span>, using the Bayes Factor, <span class="math inline">\(\mathcal{BF}_{0,1}=p\left(y \mid \mathcal{H}_{0}\right) /p\left( y \mid \mathcal{H}_{1}\right) .\)</span> With exhaustive competing hypotheses<span class="math inline">\(,\)</span> <span class="math inline">\(P \left( \mathcal{H}_{0} \mid y\right)\)</span> simplifies to <span class="math display">\[
P \left(  \mathcal{H}_{0} \mid y\right)  =\left(  1+\left(  \mathcal{BF}_{0,1}\right)  ^{-1}\frac{\left(  1-P \left(  \mathcal{H}_{0}\right)
\right)  }{P \left(  \mathcal{H}_{0}\right)  }\right)  ^{-1}\text{,}%
\]</span> and with equal prior probability, <span class="math inline">\(p\left( \mathcal{H}_{0} \mid y\right) =\left( 1+\left( \mathcal{BF}_{0,1}\right) ^{-1}\right) ^{-1}\)</span>. Both Bayes factors and posterior probabilities can be used for comparing hypotheses. Jeffreys (1961) advocated using Bayes factors, and provided a scale for measuring the strength of evidence that was given earlier. Bayes factors merely indicate that the null hypothesis is more likely if <span class="math inline">\(\mathcal{BF}_{0,1}&gt;1\)</span>, <span class="math inline">\(p\left( y \mid \mathcal{H}_{0}\right) &gt;p\left( y \mid \mathcal{H}_{1}\right)\)</span>. The Bayesian approach merely compares density ordinates of <span class="math inline">\(p\left( y \mid \mathcal{H}_{0}\right)\)</span> and <span class="math inline">\(p\left( y \mid \mathcal{H}_{1}\right)\)</span>, which mechanically involves plugging in the observed data into the functional form of the marginal likelihood.</p>
<p>For a point null, <span class="math inline">\(\mathcal{H}_{0}:\theta=\theta_{0}\)</span>, the parameter prior is <span class="math inline">\(p\left( \theta \mid \mathcal{H}_{0}\right) =\delta_{\theta_{0}}\left( \theta\right)\)</span> (a Dirac mass at <span class="math inline">\(\theta_{0}\)</span>), which implies that <span class="math inline">\(p\left( y \mid \mathcal{H}_{0}\right) =\int p\left( y \mid \theta_{0}\right) p\left( \theta \mid \mathcal{H}_{0}\right) d\theta=p\left( y \mid \theta_{0}\right)\)</span>. With a general alternative, <span class="math inline">\(\mathcal{H}_{1}:\theta\neq\theta_{0}\)</span>, the probability of the null is <span class="math display">\[
P \left(  \theta=\theta_{0} \mid y\right)  =\frac{p\left(  y \mid \theta
_{0}\right)  P \left(  \mathcal{H}_{0}\right)  }{p\left(  y \mid \theta
_{0}\right)  P \left(  \mathcal{H}_{0}\right)  +\left(  1-p\left( \mathcal{H}_{0}\right)  \right)  \int_{\Theta}p\left(  y \mid \theta,\mathcal{H}_{1}\right)  p\left(  \theta \mid \mathcal{H}_{1}\right)  d\theta},
\]</span> where <span class="math inline">\(p\left( \theta \mid \mathcal{H}_{1}\right)\)</span> is the parameter prior under the alternative. This formula will be used below.</p>
<p>Bayes factors and posterior null probabilities measure the relative weight of evidence of the hypotheses. Traditional hypothesis involves an additional decision or action: to accept or reject the null hypothesis. For Bayesian, this typically requires some statement of the utility/loss codifies the benefits/costs of making a correct or incorrect decisision. The simplest situation occurs if one assumes a zero loss of making a correct decision. The loss incurred when accepting the null (alternative) when the alternative is true (false) is <span class="math inline">\(L\left( d_{0} \mid \mathcal{H}_{1}\right)\)</span> and <span class="math inline">\(L\left( d_{0} \mid \mathcal{H}_{1}\right)\)</span>, respectively.</p>
<p>The Bayesian will accept or reject based on the posterior expected loss. If the expected loss of accepting the null is less than the alternative, the rational decision maker will accept the null. The posterior loss of accepting the null is <span class="math display">\[
\mathbb{E}\left[  \text{Loss}\ mid d_{0},y\right]  =L\left(  d_{0} \mid \mathcal{H}_{0}\right)
P \left(  \mathcal{H}_{0} \mid y\right)  +L\left(  d_{0} \mid \mathcal{H}_{1}\right)  P \left(  \mathcal{H}_{1} \mid y\right)  =L\left( d_{0} \mid \mathcal{H}_{1}\right)  P \left(  \mathcal{H}_{1} \mid y\right)  ,
\]</span> since the loss of making a correct decision, <span class="math inline">\(L\left( d_{0} \mid \mathcal{H}_{0}\right)\)</span>, is zero. Similarly, <span class="math display">\[
\mathbb{E}\left[  \text{Loss} \mid d_{1},y\right]  =L\left(  d_{1} \mid \mathcal{H}_{0}\right)
P \left(  \mathcal{H}_{0} \mid y\right)  +L\left(  d_{1} \mid \mathcal{H}_{1}\right)  P \left(  \mathcal{H}_{1} \mid y\right)  =L\left( d_{1} \mid \mathcal{H}_{0}\right)  P \left(  \mathcal{H}_{0} \mid y\right)  .
\]</span> Thus, the null is accepted if <span class="math display">\[
\mathbb{E}\left[  \text{Loss} \mid d_{0},y\right]  &lt;\mathbb{E}\left[  \text{Loss} \mid d_{1},y\right]
\Longleftrightarrow L\left(  d_{0} \mid \mathcal{H}_{1}\right)  P \left( \mathcal{H}_{1} \mid y\right)  &lt;L\left(  d_{1} \mid \mathcal{H}_{0}\right)
P \left(  \mathcal{H}_{0} \mid y\right)  ,
\]</span> which further simplifies to <span class="math display">\[
\frac{L\left(  d_{0} \mid \mathcal{H}_{1}\right)  }{L\left(  d_{1} \mid \mathcal{H}_{0}\right)  }&lt;\frac{P \left(  \mathcal{H}_{0} \mid y\right)  }%
{P \left(  \mathcal{H}_{1} \mid y\right)  }\text{.}%
\]</span> In the case of equal losses, this simplifies to accept the null if <span class="math inline">\(P \left( \mathcal{H}_{1} \mid y\right) &lt;P \left( \mathcal{H}_{0} \mid y\right)\)</span>. One advantage of Bayes procedures is that the resulting estimators and decisions are always admissible.</p>
<div id="exm-snigma" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.1 (Enigma machine: Code-breaking)</strong></span> Consider an alphabet of <span class="math inline">\(26\)</span> letters. Let <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> be two codes of length <span class="math inline">\(T\)</span>. We will look to see how many letters match (<span class="math inline">\(M\)</span>) and don’t match <span class="math inline">\(N\)</span>. In these sequences. Even though the codes are describing different sentences, when letters are the same, if the same code is being used then the coed sequence will have a match. To compute the bayes factor we need the joint <strong>probabilities</strong> <span class="math display">\[
P( x,y\mid  \mathcal{H}_0 ) \; \; \mathrm{ and} \; \; P( x,y\mid  \mathcal{H}_1 ),
\]</span> where under <span class="math inline">\(\mathcal{H}_0\)</span> they are different codes, in which case the joint prob is <span class="math inline">\(( 1 / A )^{2T}\)</span>. For <span class="math inline">\(\mathcal{H}_1\)</span> we first need to know the chance of the same letter matching. If <span class="math inline">\(p_t\)</span> denotes the frequencies of the use of English letters, then we have this match probability <span class="math inline">\(m = \sum_{i} p_i^2\)</span> which is about <span class="math inline">\(2/26\)</span>. Hence for a particular set of letters <span class="math display">\[
P( x_i , y_i \mid \mathcal{H}_1 ) = \frac{m}{A} \; \mathrm{ if} \; x_i =y_i \; \; \mathrm{ and} \; \;  P( x_i , y_i \mid \mathcal{H}_1 ) = \frac{1-m}{A(A-1)} \; \mathrm{ if} \; x_i \neq y_i.
\]</span> Hence the log Bayes factor is <span class="math display">\[\begin{align*}
\ln \frac{P( x,y\mid  \mathcal{H}_1 )}{P( x,y\mid  \mathcal{H}_0 )} &amp; = M \ln \frac{ m/A}{1/A^2} +N \ln \frac{ ( 1-m ) / A(A-1) }{ 1/ A^2} \\
&amp; = M \ln mA  + N \ln \frac{ ( 1-m )A }{A-1 }
\end{align*}\]</span> The first term comes when you get a match and the increase in the Bayes factor is large, <span class="math inline">\(3.1\)</span> (on a <span class="math inline">\(log_{10}\)</span>)-scale, otherwise you get a no-match and the Bayes factor decreases by <span class="math inline">\(- 0.18\)</span>.</p>
<p>Example, <span class="math inline">\(N=4\)</span>, <span class="math inline">\(M=47\)</span> out of <span class="math inline">\(T=51\)</span>, then gives evidence of $2.5 $ to <span class="math inline">\(1\)</span> in favor of <span class="math inline">\(\mathcal{H}_1\)</span></p>
<p>How long a sequence do you need to look at? Calculate the expected log odds. Turing and Good figured you needed sequences of about length <span class="math inline">\(400\)</span>. Can also look at doubles and triples.</p>
</div>
</section>
<section id="alternative-approaches" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="alternative-approaches"><span class="header-section-number">7.2</span> Alternative Approaches</h2>
<p>The two main alternatives to the Bayesian approach are significance testing using <span class="math inline">\(p-\)</span>values, developed by Ronald Fisher, and the Neyman-Pearson approach.</p>
<section id="significance-testing-using-p-values" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="significance-testing-using-p-values"><span class="header-section-number">7.2.1</span> Significance testing using p-values</h3>
<p>Fisher’s approach posits a test statistic, <span class="math inline">\(T\left( y\right)\)</span>, based on the observed data. In Fisher’s mind, if the value of the statistic was highly unlikely to have occured under <span class="math inline">\(\mathcal{H}_{0}\)</span>, then the <span class="math inline">\(\mathcal{H}_{0}\)</span> should be rejected. Formally, the <span class="math inline">\(p-\)</span>value is defined as <span class="math display">\[
p=P \left[  T\left(  Y\right)  &gt;T\left(  y\right)   \mid \mathcal{H}_{0}\right]  ,
\]</span> where <span class="math inline">\(y\)</span> is the observed sample and <span class="math inline">\(Y=\left( Y_{1}, \ldots ,Y_{T}\right)\)</span> is a random sample generated from model <span class="math inline">\(p\left( Y \mid \mathcal{H}_{0}\right)\)</span>, that is, the null distribution of the test-statistic in repeated samples. Thus, the <span class="math inline">\(p-\)</span>value is the probability that a data set would generate a more extreme statistic under the null hypothesis, and not the probability of the null, conditional on the data.</p>
<p>The testing procedure is simple. Fisher (1946, p.&nbsp;80) argues that: *“If P (the p-value) is between* <span class="math inline">\(0.1\)</span> and <span class="math inline">\(0.9\)</span>, there is is certainly no reason to suspect the hypothesis tested. If it is below <span class="math inline">\(0.02\)</span>, it is strongly indicated that the hypothesis fails to account for the whole of the facts. We shall not be astray if we draw a line at 0.05 and consider that higher values of <span class="math inline">\(\mathcal{X}^{2}\)</span> indicate a real discrepancy.” Defining <span class="math inline">\(\alpha\)</span> as the significance level, the tests rejects <span class="math inline">\(\mathcal{H}_{0}\)</span> if <span class="math inline">\(p&lt;\alpha\)</span>. Fisher advocated a fixed significance level of <span class="math inline">\(5\%\)</span>, based largely that <span class="math inline">\(5\%\)</span> is roughly the tail area of a mean zero normal distribution more than two standard deviations from <span class="math inline">\(0\)</span>, indicating a statistically significant departure. In practice, testing with <span class="math inline">\(p-\)</span>values involves identifying a critical value, <span class="math inline">\(t_{\alpha}\)</span>, and rejecting the null if the observed statistic <span class="math inline">\(t\left( y\right)\)</span> is more extreme than <span class="math inline">\(t_{\alpha}\)</span>. For example, for a significance test of the sample mean, <span class="math inline">\(t\left( y\right) =\left( \overline{y}-\theta_{0}\right) /se\left( \overline{y}\right)\)</span>, where <span class="math inline">\(se\left( \overline{y}\right)\)</span> is the standard error of <span class="math inline">\(\overline{y}\)</span>; the <span class="math inline">\(5\%\)</span> critical value is 1.96; and Fisher would reject the null if <span class="math inline">\(t\left( y\right) &gt;t_{\alpha}\)</span>.</p>
<p>Fisher interpreted the <span class="math inline">\(p-value\)</span> as the weight or measure of evidence of the null hypothesis. The alternative hypothesis is noticeable in its absence in&nbsp;Fisher’s approach. Fisher largely rejected the consideration of alternatives, believing that researchers should weigh the evidence or draw conclusions about the observed data rather than making decisions such as accepting or rejecting hypotheses based on it.</p>
<p>There are a number of issues with Fisher’s approach. The first and most obvious criticism is that it is possible to reject the null, when the alternative hypothesis is less likely. This is an inherent problem in using population tail probabilities–essentially rare events. Just because a rare event has occurred does not mean the null is incorrect, unless there is a more likely alternative. This situation often arises in court cases, where a rare event like a murder has occurred. Decisions based on p-values generates a problem called prosecutor’s Fallacy, which is discussed below. Second, Fisher’s approach relies on population properties (the distribution of the statistic under the null) that would only be revealed in repeated samples or asymptotically. Thus, the testing procedure relies on data that is not yet seen, a violation of what is known as the likelihood principle. As noted by Jeffreys’ (1939, pp.&nbsp;315-316): “<em>What the use of P implies, therefore, is that a hypothesis that may be true may be rejected because it has not predicted observable data that have not occurred. This seems a remarkable procedure</em>” <!-- \label{Jeffreys, p. 385}   --></p>
<p>Third, Fisher is agnostic regarding the source of the test statistics, providing no discussion of how the researcher decides to focus on one test statistic over another. In some simple models, the distribution of properly scaled sufficient statistics provides natural test statistics (e.g., the <span class="math inline">\(t-\)</span>test). In more complicated models, Fisher is silent on the sources. In many cases, there are numerous test statistics (e.g., testing for normality), and test choice is clearly subjective. For example, in GMM tests, the choice of test moments is clearly a subjective choice. Finally, from a practical perspective, <span class="math inline">\(p-\)</span>values have a serious deficiency:&nbsp;tests using <span class="math inline">\(p\)</span>-values often appear to give the wrong answer, in the sense that they provide a highly misleading impression of the weight of evidence in many samples. A number of examples of this will be given below, but in all cases, Fisher’s approach tends to over-reject the null hypotheses.</p>
</section>
<section id="neyman-pearson" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="neyman-pearson"><span class="header-section-number">7.2.2</span> Neyman-Pearson</h3>
<p>The motivation for the Neyman-Pearson (NP) approach was W.S. Gosset, the famous `Student’ who invented the <span class="math inline">\(t-\)</span>test. In analyzing a hypothesis, Student argued that a hypothesis is not rejected unless an alternative is available that provides a more plausible explanation of the data, in which case. Mathematically, this suggests analyzing the likelihood ratio, <span class="math display">\[
\mathcal{LR}_{0,1}=\frac{p\left(  y \mid \mathcal{H}_{0}\right)  }{p\left( y \mid \mathcal{H}_{1}\right)  }\text{,}%
\]</span> and rejecting the null in favor of the alternative when the likelihood ratio is small enough, <span class="math inline">\(\mathcal{LR}_{0,1}&lt;k\)</span>. This procedures conforms in spirit with the Bayesian approach.</p>
<p>The main problem was one of finding a value of the cut off parameter <span class="math inline">\(k.\)</span> From the discussion above, by varying <span class="math inline">\(k\)</span>, one varies the probabilities of type one and type two errors in the testing procedure. Originally, NP argued this tradeoff should be subjectively specified: “<em>how the balance (between the type I and II errors) should be struck must be left to the investigator</em>” (Neyman and Pearson (1933a, p.&nbsp;296) and “<em>we attempt to adjust the balance between the risks</em> <span class="math inline">\(P_{1}\)</span><span class="math inline">\(P_{2}\)</span> to meet the type of problem before us” (1933b, p.&nbsp;497). This approach, however, was not “objective *, and they then advocated fixing <span class="math inline">\(\alpha\)</span>, the probability of a type I error, in order to determine <span class="math inline">\(k\)</span>. This led to their famous lemma:</p>
<div id="lem-np" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 7.1 (Neyman-Pearson Lemma)</strong></span> Consider the simple hypothesis test of <span class="math inline">\(\mathcal{H}_{0}:\theta=\theta_{0}\)</span> versus <span class="math inline">\(\mathcal{H}_{1}:\theta =\theta_{1}\)</span> and suppose that the null is rejected if <span class="math inline">\(\mathcal{LR}_{0,1}&lt;k_{\alpha}\)</span>, where <span class="math inline">\(k_{\alpha}\)</span> is chosen to fix the probability of a type I error at <span class="math inline">\(\alpha:\)</span>% <span class="math display">\[
\alpha=P \left[  y:\mathcal{LR}_{0,1}&lt;k_{\alpha} \mid \mathcal{H}_{0}\right]  \text{.}%
\]</span> Then, this test is the most powerful test of size <span class="math inline">\(\alpha\)</span> in the sense that any other test with greater power, must have a higher size.</p>
</div>
<p>In the case of composite hypothesis tests, parameter estimation is required under the alternative, which can be done via maximum likelihood, leading to the likelihood ratio <span class="math display">\[
\mathcal{LR}_{0,1}=\frac{p\left(  y \mid \mathcal{H}_{0}\right)  }{\underset
{\theta\in\Theta}{\sup}p\left(  y \mid \Theta\right)  }=\frac{p\left( y \mid \mathcal{H}_{0}\right)  }{p\left(  y \mid \widehat{\theta}\right)  }\text{,}%
\]</span> where <span class="math inline">\(\widehat{\theta}\)</span> is the MLE. Because of this, <span class="math inline">\(0\leq\mathcal{LR}_{0,1}\leq 1\)</span> for composite hypotheses. In multi-parameter cases, finding the distribution of the likelihood ratio is more difficult, requiring asymptotic approximations to calibrate <span class="math inline">\(k_{\alpha}.\)</span></p>
<p>At first glance, the NP&nbsp;approach appears similar to the Bayesian approach, as it takes into account the likelihood ratio. However, like the <span class="math inline">\(p-\)</span>value, the NP approach has a critical flaw. Neyman and Pearson fix the Type I error, and then minimizes the type II error. In many practical cases, <span class="math inline">\(\alpha\)</span> is set at <span class="math inline">\(5\%\)</span> and the resulting <span class="math inline">\(\beta\)</span> is often very small, close to 0. Why is this a reasonable procedure?&nbsp;Given the previous discussion, this is essentially a very strong prior over the relative benefits/costs of different types of errors. While these assumptions may be warranted in certain settings, it is difficult to a priori understand why this procedure would generically make sense. The next section highlights how the <span class="math inline">\(p-\)</span>value and NP approaches can generate counterintuitive and even absurd results in standard settings.</p>
</section>
</section>
<section id="examples-and-paradoxes" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="examples-and-paradoxes"><span class="header-section-number">7.3</span> Examples and Paradoxes</h2>
<p>This section provides a number of paradoxes arising when using different hypothesis testing procedures. The common strands of the examples will be discussed at the end of the section.</p>
<div id="exm-nptest" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.2 (Neyman-Pearson tests)</strong></span> Consider testing <span class="math inline">\(\mathcal{H}_{0}:\mu=\mu_{0}\)</span> versus <span class="math inline">\(\mathcal{H}_{1}:\mu=\mu_{1}\)</span>, <span class="math inline">\(y_{t}\sim\mathcal{N}\left( \mu,\sigma^{2}\right)\)</span> and <span class="math inline">\(\mu_{1}&gt;\mu_{0}\)</span>. For this simple test, the likelihood ratio is given by <span class="math display">\[
\mathcal{LR}_{0,1}=\frac{\exp\left(  -\frac{1}{2\sigma^{2}}%
%TCIMACRO{\tsum \nolimits_{t=1}^{T}}%
%BeginExpansion
{\textstyle\sum\nolimits_{t=1}^{T}}
%EndExpansion
\left(  y_{t}-\mu_{0}\right)  ^{2}\right)  }{\exp\left(  -\frac{1}{2\sigma
^{2}}%
%TCIMACRO{\tsum \nolimits_{t=1}^{T}}%
%BeginExpansion
{\textstyle\sum\nolimits_{t=1}^{T}}
%EndExpansion
\left(  y_{t}-\mu_{1}\right)  ^{2}\right)  }=\exp\left(  -\frac{T}{\sigma^{2}%
}\left(  \mu_{1}-\mu_{0}\right)  \left(  \overline{y}-\frac{1}{2}\left( \mu_{0}+\mu_{1}\right)  \right)  \right)  \text{.}%
\]</span> Since <span class="math inline">\(\mathcal{BF}_{0,1}=\mathcal{LR}_{0,1}\)</span>, assuming equal prior probabilities and symmetric losses, the Bayesian accepts <span class="math inline">\(\mathcal{H}_{0}\)</span> if <span class="math inline">\(\mathcal{BF}_{0,1}&gt;1\)</span>. Thus, the Bayes procedure rejects <span class="math inline">\(\mathcal{H}_{0}\)</span> if <span class="math inline">\(\overline{y}&gt;\frac{1}{2}\left( \mu_{0}+\mu_{1}\right)\)</span> for any <span class="math inline">\(T\)</span> and <span class="math inline">\(\sigma^{2}\)</span>, with <span class="math inline">\(\mu_{0}\)</span>,<span class="math inline">\(\mu_{1}\)</span>, <span class="math inline">\(T,\)</span>and <span class="math inline">\(\sigma^{2}\)</span> determining the strength of the rejction. If <span class="math inline">\(\mathcal{BF}_{0,1}=1\)</span>, there is equal evidence for the two hypotheses.</p>
<p>The NP procedure proceeds by first setting <span class="math inline">\(\alpha=0.05,\)</span> and rejects when <span class="math inline">\(\mathcal{LR}_{0,1}\)</span> is large. This is equivalent to rejecting when <span class="math inline">\(\overline{y}\)</span> is large, generating an `optimal’ rejection region of the form <span class="math inline">\(\overline{y}&gt;c\)</span>. The cutoff value <span class="math inline">\(c\)</span> is calibrated via the size of the test, <span class="math display">\[
P \left[  reject\text{ }\mathcal{H}_{0} \mid \mathcal{H}_{0}\right]
=P \left[  \overline{y}&gt;c \mid \mu_{0}\right]  =P \left[
\frac{\left(  \overline{y}-\mu_{0}\right)  }{\sigma/\sqrt{T}}&gt;\frac{\left( c-\mu_{0}\right)  }{\sigma/\sqrt{T}} \mid \mathcal{H}_{0}\right] .
\]</span> The size equals <span class="math inline">\(\alpha\)</span> if <span class="math inline">\(\sqrt{T}\left( c-\mu_{0}\right) /\sigma =z_{\alpha}\)</span>. Thus, the NP test rejects if then if <span class="math inline">\(\overline{y}&gt;\mu _{0}+\sigma z_{\alpha}/\sqrt{T}\)</span>. Notice that the tests rejects regardless of the value of <span class="math inline">\(\mu_{1}\)</span>, which is rather odd, since <span class="math inline">\(\mu_{1}\)</span> does not enter into the size of the test only the power. The probability of a type II error is <span class="math display">\[
\beta=P \left[  \text{accept }\mathcal{H}_{0} \mid \mathcal{H}_{1}\right]
=P \left[  \overline{y}\leq\mu_{0}+\frac{\sigma}{\sqrt{T}}z_{\alpha
} \mid \mathcal{H}_{1}\right]  =\int_{-\infty}^{\mu_{0}+\frac{\sigma}{\sqrt{T}%
}z_{\alpha}}p\left(  \overline{y} \mid \mu_{1}\right)  d\overline{y}\text{,}%
\]</span> where <span class="math inline">\(p\left( \overline{y} \mid \mu_{1}\right) \sim\mathcal{N}\left( \mu _{1},\sigma^{2}/T\right)\)</span>.</p>
<p>These tests can generate strikingly different conclusions. Consider a test of <span class="math inline">\(\mathcal{H}_{0}:\mu=0\)</span> versus <span class="math inline">\(\mathcal{H}_{1}:\mu=5\)</span>, based on <span class="math inline">\(T=100\)</span> observations drawn from <span class="math inline">\(y_{t}\sim\mathcal{N}\left( \mu,10^{2}\right)\)</span> with <span class="math inline">\(\overline{y}=2\)</span>. For NP, since <span class="math inline">\(\sigma/\sqrt{T}=1\)</span>, <span class="math inline">\(\overline{y}\)</span> is two standard errors away from <span class="math inline">\(0\)</span>, thus <span class="math inline">\(\mathcal{H}_{0}\)</span> is rejected at the 5% level (the same conclusion holds for <span class="math inline">\(p-\)</span>values). Since <span class="math inline">\(p(\overline {y}=2 \mid \mathcal{H}_{0})=0.054\)</span> and <span class="math inline">\(p(\overline{y}=2 \mid \mathcal{H}_{1})=0.0044\)</span>, the Bayes factor is <span class="math inline">\(\mathcal{BF}_{0,1}=12.18\)</span> and <span class="math inline">\(P \left( \mathcal{H}_{0} \mid y\right) =92.41\%\)</span>. Thus, the Bayesian is quite sure the null is true, while Neyman-Pearson reject the null.</p>
<p>The paradox can be seen in two different ways. First, although <span class="math inline">\(\overline{y}\)</span> is actually closer to <span class="math inline">\(\mu_{0}\)</span> than <span class="math inline">\(\mu_{1}\)</span>, the NP test rejects <span class="math inline">\(\mathcal{H}_{0}\)</span>. This is counterintuitive and makes little sense. The problem is one of calibration. The classical approach develops a test such that 5% of the time, a correct null would be rejected. The power of the test is easy to compute and implies that <span class="math inline">\(\beta=0.0012\)</span>. Thus, this testing procedure will virtually never accept the null if the alternative is correct. For Bayesian procedure, assuming the prior odds is <span class="math inline">\(1\)</span> and <span class="math inline">\(L_{0}=L_{1}\)</span>, then <span class="math inline">\(\alpha=\beta=0.0062\)</span>. Notice that the overall probability of making an error is 1.24% in the Bayesian procedure compared to 5.12% in the classical procedure. It should seem clear that the Bayesian approach is more reasonably, absent a specific motivation for inflating <span class="math inline">\(\alpha\)</span>. Second, suppose the null and alternative were reversed, testing <span class="math inline">\(\mathcal{H}_{0}:\mu=\mu_{1}\)</span> versus <span class="math inline">\(\mathcal{H}_{1}:\mu=\mu_{0}\)</span> In the previous example, the Bayes approach gives the same answer, while NP once again rejects the null hypothesis! Again, this result is counterintuitive and nonsensical, but is common when arbitrarily fixing <span class="math inline">\(\alpha\)</span>, which essentially hardwires the test to over-reject the null.</p>
</div>
<div id="exm-lindleyparadox" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.3 (Lindley’s paradox)</strong></span> Consider the case of testing whether or not a coin is fair, based on observed coin flips, <span class="math display">\[
\mathcal{H}_{0}:\theta=\frac{1}{2}\text{ versus }\mathcal{H}_{1}:\theta
\neq\frac{1}{2}\text{,}%
\]</span> based on <span class="math inline">\(T\)</span> observations from <span class="math inline">\(y_{t}\sim Ber\left( \theta\right)\)</span>. As an example, <a href="#tbl-lindley" class="quarto-xref">Table&nbsp;<span>7.1</span></a> provides 4 datasets of differing lengths. Prior to considering the formal hypothesis tests, form your own opinion on the strength of evidence regarding the hypothesis in each data set. It is common for individuals, when confronted with this data to conclude that the fourth sample provides the strongest of evidence for the null and the first sample the weakest.</p>
<div id="tbl-lindley" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-lindley-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.1: Lindley’s paradox
</figcaption>
<div aria-describedby="tbl-lindley-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>#1</th>
<th>#2</th>
<th>#3</th>
<th>#4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td># Flips</td>
<td>50</td>
<td>100</td>
<td>400</td>
<td>10,000</td>
</tr>
<tr class="even">
<td># Heads</td>
<td>32</td>
<td>60</td>
<td>220</td>
<td>5098</td>
</tr>
<tr class="odd">
<td>Percentage of heads</td>
<td>64</td>
<td>60</td>
<td>55</td>
<td>50.98</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Fisher’s solution to the problem posits an unbiased estimator, the sample mean, and computes the <span class="math inline">\(t-\)</span>statistic, which is calculated under <span class="math inline">\(\mathcal{H}_{0}\)</span>: <span class="math display">\[
t\left(  y\right)  =\frac{\overline{y}-E\left[  \overline{y} \mid \theta
_{0}\right]  }{se\left(  \overline{y}\right)  }=\sqrt{T}\left(  2\widehat
{\theta}-1\right)  \text{,}%
\]</span> where <span class="math inline">\(se\left(\overline{y}\right)\)</span> is the standard error of <span class="math inline">\(\overline{y}\)</span>. The Bayesian solution requires marginal likelihood under the null and alternative, which are <span id="eq-Bernoulli_marginal"><span class="math display">\[
p\left(  y \mid \theta_{0}=1/2\right)  =\prod_{t=1}^{T}p\left(  y_{t} \mid \theta
_{0}\right)  =\left(  \frac{1}{2}\right)  ^{\sum_{t=1}^{T}y_{t}}\left( \frac{1}{2}\right)  ^{T-\sum_{t=1}^{T}y_{t}}=\left(  \frac{1}{2}\right)  ^{T},
\tag{7.1}\]</span></span> and, from <a href="#eq-Bernoulli_marginal" class="quarto-xref">Equation&nbsp;<span>7.1</span></a>, <span class="math inline">\(p\left( y \mid \mathcal{H}_{1}\right) =B\left( a_{T},A_{T}\right) /B\left(a,A\right)\)</span> assuming a beta prior distribution.</p>
<p>To compare the results, note first that in the datasets given above, <span class="math inline">\(\widehat{\theta}\)</span> and <span class="math inline">\(T\)</span> generate <span class="math inline">\(t_{\alpha}=1.96\)</span> in each case. Thus, for a significance level of <span class="math inline">\(\alpha=5\%\)</span>, the null is rejected for each sample size. Assuming a flat prior distribution, the Bayes factors are <span class="math display">\[
\mathcal{BF}_{0,1}=\left\{
\begin{array}
[c]{l}%
0.8178\text{ for }N=50\text{ }\\
1.0952\text{ for }N=100\\
2.1673\text{ for }N=400\\
11.689\text{ for }N=10000
\end{array}
\right.  ,
\]</span> showing increasingly strong evidence in favor of <span class="math inline">\(\mathcal{H}_{0}\)</span>. Assuming equal prior weight for the hypotheses, the posterior probabilities are 0.45, 0.523, 0.684, and 0.921, respectively. For the smallest samples, the Bayes factor implies roughly equal odds of the null and alternative. As the sample size increase, the weight of evidence favors the null, with a 92% probabability for <span class="math inline">\(N=10K\)</span>.</p>
<p>Next, consider testing <span class="math inline">\(\mathcal{H}_{0}:\theta_{0}=0\)</span> vs.&nbsp;<span class="math inline">\(\mathcal{H}_{1}:\theta_{0}\neq0,\)</span> based on <span class="math inline">\(T\)</span> observations from <span class="math inline">\(y_{t}\sim \mathcal{N}\left( \theta_{0},\sigma^{2}\right)\)</span>, where <span class="math inline">\(\sigma^{2}\)</span> is known. This is the formal example used by Lindley to generate his paradox. Using <span class="math inline">\(p-\)</span>values, the hypothesis is rejected if the <span class="math inline">\(t-\)</span>statistic is greater than <span class="math inline">\(t_{\alpha}\)</span>. To generate the paradox, consider datasets that are exactly <span class="math inline">\(t_{\alpha}\)</span> standard errors away from <span class="math inline">\(\overline{y}\)</span>, that is, <span class="math inline">\(\overline {y}^{\ast}=\theta_{0}+\sigma t_{\alpha}/\sqrt{n}\)</span>, and a uniform prior over the interval <span class="math inline">\(\left( \theta_{0}-I/2,\theta_{0}+I/2\right)\)</span>. If <span class="math inline">\(p_{0}\)</span> is the probability of the null, then, <span class="math display">\[\begin{align*}
P \left(  \theta=\theta_{0} \mid \overline{y}^{\ast}\right)   &amp;
=\frac{\exp\left(  -\frac{1}{2}\frac{T\left(  \overline{y}^{\ast}-\theta
_{0}\right)  ^{2}}{\sigma^{2}}\right)  p_{0}}{\exp\left(  -\frac{1}{2}%
\frac{T\left(  \overline{y}^{\ast}-\theta_{0}\right)  ^{2}}{\sigma^{2}%
}\right)  p_{0}+\left(  1-p_{0}\right)  \int_{\theta_{0}-I/2}^{\theta_{0}%
+I/2}\exp\left(  -\frac{1}{2}\frac{T\left(  \overline{y}^{\ast}-\theta\right)
^{2}}{\sigma^{2}}\right)  I^{-1}d\theta}\\
&amp;  =\frac{\exp\left(  -\frac{1}{2}t_{\alpha}^{2}\right)  p_{0}}{\exp\left( -\frac{1}{2}t_{\alpha}^{2}\right)  p_{0}+\frac{\left(  1-p_{0}\right)  }%
{I}\int_{\theta_{0}-I/2}^{\theta_{0}+I/2}\exp\left(  -\frac{1}{2}\left( \frac{\left(  \overline{y}^{\ast}-\theta\right)  }{\sigma/\sqrt{T}}\right)
\right)  d\theta}\\
&amp;  \geq\frac{\exp\left(  -\frac{1}{2}t_{\alpha}^{2}\right)  p_{0}}{\exp\left( -\frac{1}{2}t_{\alpha}^{2}\right)  p_{0}+\frac{\left(  1-p_{0}\right)  }%
{I}\sqrt{2\pi\sigma^{2}/T}}\rightarrow1\text{ as }T\rightarrow\infty\text{.}%
\end{align*}\]</span> In large samples, the posterior probability of the null approaches 1, whereas Fisher always reject the null. It is important to note that this holds for any <span class="math inline">\(t_{\alpha}\)</span>, thus even if the test were performed at the 1% level or lower, the posterior probability would eventually reject the null.</p>
</div>
</section>
<section id="prior-sensitivity" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="prior-sensitivity"><span class="header-section-number">7.4</span> Prior Sensitivity</h2>
<p>One potential criticism of the previous examples is the choice of the prior distribution. How do we know that, somehow, the prior is not biased against rejecting the null generating the paradoxes? Under this interpretation, the problem is not with the <span class="math inline">\(p-\)</span>value but rather with the Bayesian procedure. One elegant way of dealing with the criticism is search over priors and prior parameters that minimize the probabability of the null hypothesis, thus biasing the Bayesian procedure against accepting the null hypothesis.</p>
<p>To see this, consider the case of testing <span class="math inline">\(\mathcal{H}_{0}:\mu_{0}=0\)</span> vs.&nbsp;<span class="math inline">\(\mathcal{H}_{1}:\mu_{0}\neq0\)</span> with observations drawn from <span class="math inline">\(y_{t} \sim\mathcal{N}\left( \theta_{0},\sigma^{2}\right)\)</span>, with <span class="math inline">\(\sigma\)</span> known. With equal prior null and alternative probability, the probability of the null is <span class="math inline">\(p\left( \mathcal{H}_{0} \mid y\right) =\left( 1+\left( \mathcal{BF}_{0,1}\right) ^{-1}\right) ^{-1}\)</span>. Under the null, <span class="math display">\[
p\left(  y \mid \mathcal{H}_{0}\right)  =\left(  \frac{1}{2\pi\sigma^{2}}\right)
^{\frac{T}{2}}\exp\left(  -\frac{1}{2}\left(  \frac{\left(  \overline
{y}-\theta_{0}\right)  }{\sigma/\sqrt{T}}\right)  ^{2}\right)  \text{.}%
\]</span> The criticism applies to the priors under the alternative. To analyze the sensitivity, consider four classes of priors under the alternative:&nbsp;(a) the class of normal priors, <span class="math inline">\(p\left( \theta \mid \mathcal{H}_{1}\right) \sim\mathcal{N}\left( a,A\right)\)</span>; (b) the class of all symmetric unimodal prior distributions; (c)&nbsp;the class of all symmetric prior distributions; and (d) the class of all proper prior distributions. These classes provide varying degrees of prior information, allowing a thorough examination of the strength of evidence.</p>
<p>In the first case, consider the standard conjugate prior distribution, <span class="math inline">\(p\left( \mu \mid \mathcal{H}_{1}\right) \sim\mathcal{N}\left( \mu_{0},A\right)\)</span>. Under the alternative, <span class="math display">\[\begin{align*}
p\left(  y \mid \mathcal{H}_{1}\right)   &amp;  =\int p\left(  y \mid \mu,\mathcal{H}_{1}\right)  p\left(  \mu \mid \mathcal{H}_{1}\right)  d\mu\\
&amp;  =\int p\left(  \overline{y} \mid \mu,\mathcal{H}_{1}\right)  p\left( \mu \mid \mathcal{H}_{1}\right)  d\mu\text{,}%
\end{align*}\]</span> using the fact that <span class="math inline">\(\overline{y}\)</span> is a sufficient statistic. Noting that <span class="math inline">\(p\left( \overline{y} \mid \mu,\mathcal{H}_{1}\right) \sim N\left( \mu ,\sigma^{2}/T\right)\)</span> and <span class="math inline">\(p\left( \mu \mid \mathcal{H}_{1}\right) \sim N\left( \mu_{0},A\right)\)</span>, we can use the “substitute” instead of integrate trick to assert that <span class="math display">\[
\overline{y}=\mu_{0}+\sqrt{A}\eta+\sqrt{\sigma^{2}/T}\varepsilon\text{,}%
\]</span> where <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\varepsilon\)</span> are standard normal. Then, <span class="math inline">\(p\left( \overline{y} \mid \mathcal{H}_{1}\right) \sim\mathcal{N}\left( \mu_{0},A+\sigma^{2}/T\right)\)</span>. Thus, <span class="math display">\[
\mathcal{BF}_{0,1}=\frac{p\left(  y \mid \mathcal{H}_{0}\right)  }{p\left( y \mid \mathcal{H}_{1}\right)  }=\frac{p\left(  \overline{y} \mid H_{0}\right)
}{p\left(  \overline{y} \mid H_{1}\right)  }=\frac{\left(  \sigma^{2}/T\right)
^{-\frac{1}{2}}}{\left(  \sigma^{2}/T+A\right)  ^{-\frac{1}{2}}}\frac
{\exp\left(  -\frac{1}{2}t^{2}\right)  }{\exp\left(  -\frac{1}{2}\frac
{z^{2}\sigma^{2}/T}{A+\sigma^{2}/T}\right)  }\text{.} \label{BF_normal}%
\]</span> To operationalize the test, <span class="math inline">\(A\)</span> must be selected. <span class="math inline">\(A\)</span> is chosen to minimizing the posterior probabilities of the null, with <span class="math inline">\(P_{norm}\left( \mathcal{H}_{0} \mid y\right)\)</span> being the resulting lower bound on the posterior probability of the null. For <span class="math inline">\(z\geq1\)</span>, the lower bound on the posterior probability of the null is <span class="math display">\[
P_{norm}\left(  \mathcal{H}_{0} \mid y\right)  =\left[
1+\sqrt{e}\exp\left(  -.5t^{2}\right)  \right]  ^{-1},
\]</span> which is derived in a reference cited in the notes. This choice provides a maximal bias of the Bayesian approach toward rejecting the null. It is important to note that this is not a reasonable prior, as it was intentionally constructed to bias the null toward rejection.</p>
<p>For the class of all proper prior distributions, it is also easy to derive the bound. From equation above, minimizing the posterior probability is equivalent to minimizing the Bayes factor, <span class="math display">\[
\mathcal{BF}_{0,1}=\frac{p\left(  y \mid \mathcal{H}_{0}\right)  }{p\left( y \mid \mathcal{H}_{1}\right)  }\text{.}%
\]</span> Since <span class="math display">\[
p\left(  y \mid \mathcal{H}_{1}\right)  =\int p\left(  y \mid \theta,\mathcal{H}_{1}\right)  p\left(  \theta \mid \mathcal{H}_{1}\right)  d\theta\leq p\left( y \mid \widehat{\theta}_{MLE},\mathcal{H}_{1}\right)  \text{,}%
\]</span> where <span class="math inline">\(\widehat{\theta}_{MLE}=\arg\underset{\theta\neq0}{\max}p\left( y \mid \theta\right)\)</span>. The maximum likelihood estimator, maximizes the probability of the alternative, and provides a lower bound on the Bayes factor, <span class="math display">\[
\underline{\mathcal{BF}}_{0,1}=\frac{p\left(  y \mid \mathcal{H}_{0}\right)
}{\underset{\theta\neq0}{\sup}p\left(  y \mid \theta\right)  }\text{.}%
\]</span> In this case, the bound is particularly easy to calculate and is given by <span class="math display">\[
P_{all}\left(  \mathcal{H}_{0} \mid y\right)  =\left( 1+\exp\left(  -\frac{t^{2}}{2}\right)  \right)  ^{-1}\text{.}%
\]</span> A reference cited in the notes provides the bounds for the second and third cases, generating <span class="math inline">\(P_{s,u}\left( \mathcal{H}_{0} \mid y\right)\)</span> and <span class="math inline">\(P_{s}\left( \mathcal{H}_{0} \mid y\right)\)</span>, respectively. All of the bounds only depend on the <span class="math inline">\(t-\)</span>statistic and constants.</p>
<p><a href="#tbl-berger" class="quarto-xref">Table&nbsp;<span>7.2</span></a> reports the <span class="math inline">\(t-\)</span>statistics and associated <span class="math inline">\(p-\)</span>values, with the remaining columns provide the posterior probability bounds. For the normal prior and choosing the prior parameter <span class="math inline">\(A\)</span> to minimize the probability of the null, the posterior probability of the null is much larger than the <span class="math inline">\(p-\)</span>value, in every case. For the standard case of a <span class="math inline">\(t-\)</span>statistic of 1.96, <span class="math inline">\(P\left( \mathcal{H}_{0} \mid y\right)\)</span> is more than six times greater than the <span class="math inline">\(p-\)</span>value. For <span class="math inline">\(t=2.576\)</span>, <span class="math inline">\(P\left( \mathcal{H}_{0} \mid y\right)\)</span> is almost 13 times greater than the <span class="math inline">\(p-\)</span>value. These probabilities fall slightly for more general priors. For example, for the class of all priors, a t-statistic of 1.96/2.576 generates a lower bound for the posterior probability of 0.128/0.035<span class="math inline">\(,\)</span> more than 2/3 times the <span class="math inline">\(p-\)</span>value.</p>
<div id="tbl-berger" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-berger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.2: Comparison of strength of evidence against the point null hypothesis. The numbers are reproduced from Berger (1986).
</figcaption>
<div aria-describedby="tbl-berger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(t\)</span>-stat</th>
<th style="text-align: center;"><span class="math inline">\(p\)</span>-value</th>
<th style="text-align: center;"><span class="math inline">\(P_{norm}\left(H_{0} \mid y\right)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(P_{s,u}\left( H_{0} \mid y\right)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(P_{s}\left(H_{0} \mid y\right)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(P_{all}\left(H_{0} \mid y\right)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1.645</td>
<td style="text-align: center;">0.100</td>
<td style="text-align: center;">0.412</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">0.205</td>
</tr>
<tr class="even">
<td style="text-align: center;">1.960</td>
<td style="text-align: center;">0.050</td>
<td style="text-align: center;">0.321</td>
<td style="text-align: center;">0.29</td>
<td style="text-align: center;">0.227</td>
<td style="text-align: center;">0.128</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.576</td>
<td style="text-align: center;">0.010</td>
<td style="text-align: center;">0.133</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">0.068</td>
<td style="text-align: center;">0.035</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.291</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0.0235</td>
<td style="text-align: center;">0.018</td>
<td style="text-align: center;">0.0088</td>
<td style="text-align: center;">0.0044</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../qmd/ab.html" class="pagination-link  aria-label=" &lt;span="" testing&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">AB Testing</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../qmd/rct.html" class="pagination-link" aria-label="<span class='chapter-number'>8</span>&nbsp; <span class='chapter-title'>Field vs Observational</span>">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Field vs Observational</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js" type="text/javascript"></script>
<script type="text/javascript">
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    let pseudocodeOptions = {
      indentSize: el.dataset.indentSize || "1.2em",
      commentDelimiter: el.dataset.commentDelimiter || "//",
      lineNumber: el.dataset.lineNumber === "true" ? true : false,
      lineNumberPunc: el.dataset.lineNumberPunc || ":",
      noEnd: el.dataset.noEnd === "true" ? true : false,
      titlePrefix: el.dataset.algTitle || "Algorithm"
    };
    pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
  });
})(document);
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
    titlePrefix = el.dataset.algTitle;
    titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
    titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
  });
})(document);
</script>




</body></html>