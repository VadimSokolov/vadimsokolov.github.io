{
  "hash": "9307f8934e6bdda97a98be9971b29a07",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nsubtitle: 'Introduction: AI Today and in the Past. Probability and Bayes Rule'\nimage: fig/01-intro.jpg\ntitle: 'Tasks and concepts of AI: Generation'\n---\n\n\n\n# Brief History of AI\n\n## The first thoughts about artificial intelligence\n\n:::{layout-ncol=2}\n- Hephaestus created for himself Android robots, such as a giant human-like robot of Talos.\n- Pygmalion revived Galatea.\n- Jehovah and Allah - pieces of clay\n- Particularly pious and learned rabbis could create golems.\n- Albert the Great made an artificial speaking head (which very upset Thomas Aquinas).\n\n \n:::\n\n## Mechanical machines\n\nRobots and Automatic Machines Were Generally Very Inventive: Al-Jazari (XII Century)\n\n![](fig/Al-Jazari.jpg){fig-align=\"center\"}\n\nHesdin Castle (Robert II of Artois), Leonardo's robot...\n \n\n## Mechanical machines\n\nJaquet-Droz automata (XVIII century):\n\n![](fig/Jaquet-Droz.jpg){fig-align=\"center\"}\n\n## Mechanical machines\n\n- But this is in mechanics, in mathematics/logic AI it was quite rudimentary for a long time\n\n\n![Logic machine of Ramon Llull (XIII-XIV centuries)](fig/Llull.jpg){fig-align=\"center\"}\n\n- Starting with Dr. Frankenstein, further AI in the literature appears constantly ...\n\n## Turing Test\n\n- AI as a science begins with a Turing test (1950).\n- The ides of the Turing test is to check if a machine can imitate a human in a conversation.\n- The original formulation was more nuanced. \n\n\n![](fig/turing.jpg){height=\"60%\" fig-align=\"center\"}\n\n## Shennon's Theseus\n\n- [YouTube Video](https://youtu.be/_9_AEVQ_p74?si=W3x-4sLSCUzdAeph)\n- Early 1950s, Claude Shannon (The father of Information Theory) demonstrates Theseus\n- A life-sized magnetic mouse controlled by relay circuits, learns its way around a maze.\n\n\n![](fig/thesus.png){height=\"60%\" fig-align=\"center\"}\n\n## Stanford Cart\n<ber><ber>\n\n- [YouTube Video](https://www.youtube.com/watch?v=dcS6Ol5xXqY)\n- Takes 2.6-second for signal to travel from earth to the moon\n- Latest iterations is automated with 3D vision capabilities\n- Pause after each meter of movement and take 10-15 minutes to reassess its surroundings and reevaluate its decided path. \n- In 1979, this cautious version of the cart successfully made its way 20 meters through a chair-strewn room in five hours without human intervention.\n\n## Turing Test\n\nIt takes a lot to create an  AI system:\n\n- [Processing of a natural language](https://www.youtube.com/watch?v=MNuFcIRlwdc)\n- Sensors and actuators\n- Representation of knowledge\n- [Inference from the existing knowledge](https://www.wolframalpha.com/)\n- Training on experience (Machine Learning).\n\n![](fig/aisys.jpg){height=\"40%\"fig-align=\"center\"}\n\n## Dartmouth workshop\n\n- AI as a science appeared in 1956 at the Dartmouth workshop.\n- It was organized by John McCarthy, Marvin Minsky, Claude Shennon and Nathaniel Rochester.\n- It was probably the most ambitious grant proposal in the history of computer science.\n\n![](fig/workshop.jpg){height=\"60%\"fig-align=\"center\"}\n\n## Dartmouth workshop\n<br><br>\nWe propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.\n\n## 1956-1960: Great hopes\n\n- Optimistic time. It seemed a that we were almost there...\n-  Allen Newell, Herbert A. Simon, and Cliff Shaw: *Logic Theorist*.\n  - Automated reasoning.\n  - It was able to prof most of the Principia Mathematica, in some places even more elegant than Russell and Whitehead.\n\n![](fig/simon.jpg){fig-align=\"center\"}\n\n## 1956-1960: Big Hopes\n\n- General Problem Solver - a program that tried to think as a person\n- A lot of programs that have been able to do some limited things (MicroWorlds):\n  - Analogy (IQ tests with multiple choice questions)\n  - Student (algebraic verbal tasks)\n  - Blocks World (rearranged 3D blocks).\n\n## 1970s: Knowledge Based Systems\n\n- The bottom line: to accumulate a fairly large set of rules and knowledge about the subject area, then draw conclusions.\n- First success: MYCIN - Diagnosis of blood infections:\n  - about 450 rules\n  - The results are like an experienced doctor and significantly better than beginner doctors.\n\n![](fig/MYCIN.png){height=\"60%\"fig-align=\"center\"}\n\n## 1980-2010: Commercial applications Industry AI\n\n- The first AI department was at Dec (Digital Equipment Corporation). It is argued that by 1986 he saved the Dec about \\$10 million per year.\n- The boom ended by the end of the 80s, when many companies could not live up to high expectations.\n\n![](fig/dec.png){fig-align=\"center\"}\n\n## 1990-2010: DATA MINING, MACHINE LEARNING\n\n- In recent decades, the main emphasis has shifted to machine training and search for patterns in the data.\n- Especially - with the development of the Internet.\n- Not too many people remember the original AI ideas, but Machine Learning is now everywhere.\n- But Robotics flourishes and uses Machine Learning at every step.\n\n## Rule-Based System vs Bayes\n\n- Since 1956, the field of artificial intelligence (AI) has undergone significant transformations \n- *traditional AI*  was mostly focused on rule-based systems and boolean logic programming, with limited learning capabilities. It lead to them being brittle in changing environments. \n- On the other hand, *emerging AI* is focused on modeling uncertainties, pattern matching, and deep learning. \n- All of those are data-driven approaches. \n- These approaches are more adaptable and can handle complex and unstructured data. They are also more data-dependent and lack interpretability. \n\n## Rule-Based System vs Bayes{.smaller}\n\\small\n:::: {layout=\"[48,-4,48]\"}\n::: {}\n::: {.callout-note icon=false}\n\n## Old AI\n\n<br>\n*If rain outside, then take umbrella*\n\nThis rule cannot be learned from data. It does not allow inference. Cannot say anything about rain outside if I see an umbrella.\n\n<br>\n:::\n:::\n\n::: {}\n::: {.callout-note icon=false}\n\n## New AI\n\n*Probability of taking umbrella, given there is rain*\n\nConditional probability rule  can be learned from data. Allows for inference. We can calculate the probability of rain outside if we see an umbrella.\n:::\n:::\n::::\n\n- Bayesian approach is a powerful statistical framework based on the work of Thomas Bayes and later Laplace. \n- It provides a probabilistic approach to reasoning and learning\n- Allowing us to update our beliefs about the world as we gather new data. \n- This makes it a natural fit for artificial intelligence, where we often need to deal with uncertainty and incomplete information.\n\n## DEFINITION\n-  How to determine \"learning\"?\n\n::: {.callout-note icon=false}\n\n## Definition:\n\nThe computer program learns as the data is accumulating relative to a certain problem class $T$ and the target function of $P$ if the quality of solving these problems (relative to $P$) improves with gaining new experience.\n:::\n\n- The definition is very (too?) General.\n- What specific examples can be given?\n\n## Tasks and concepts of ML\n\n![](fig/book-ml-tasks.drawio.svg){fig-align=\"center\"}\n\n## Tasks and concepts of ML: Supervised Learning\n\n- training sample -- a set of examples, each of which consists of input features (attributes) and  the correct \"answers\" - the response variable\n- Learn a rule that maps input features to the response variable\n- Then this rule is applied to new examples (deployment)\n- The main thing is to train a model that explains not only examples from the training set, but also new examples (generalizes)\n- Otherwise - overfitting\n\n## Tasks and concepts of ML: unsupervised learning\nThere are no correct answers, only data, e.g. *clustering*:\n\n- We need to divide the data into pre -unknown classes to some extent similar:\n  - highlight the family of genes from the sequences of nucleotides\n  - cluster users and personalize the application for them\n  - cluster the mass spectrometric image to parts with different composition\n\n## Tasks and concepts of ML: unsupervised learning\n\n- Dimensionality reduction: data have a high dimension, it is necessary to reduce it, select the most informative features so that all of the above algorithms can work\n- Matrix Competition: There is a sparse matrix, we must predict what is in the missing positions.\n- Anomaly detection: find anomalies in the data, e.g. fraud detection.\n- Often the outputs answers are given for a small part of the data, then we call it semi -supervised Learning.\n\n## Tasks and concepts of ML: reinforcement learning\n\n- Multi-armed bandits: there is a certain set of actions, each of which leads to random results, you need to get as much rewards possible\n- Exploration vs.Exploitation: how and when to proceed from the study of the new to use what has already studied\n- Credit Assignment: You get rewarded at the very end (won the game), and we must somehow distribute this reward on all the moves that led to victory.\n\n## Tasks and concepts of ML: active learning\n\n- Active Learning - how to choose the following (relatively expensive) test\n- Boosting - how to combine several weak classifiers so that it turns out good\n- Model Selection - where to draw a line between models with many parameters and with a few.\n- Ranking:  response list is ordered (internet search)\n\n## Tasks and concepts of AI\n\n![](fig/book-ai-tasks.drawio.svg){fig-align=\"center\"}\n\n## Tasks and concepts of AI: Reasoning\n\n- Bayesian networks: given conditional probabilities, calculate the probability of the event\n- o1 by OpenAI: a family of AI models that are designed to perform complex reasoning tasks, such as math, coding, and science. o1 models placed among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME)\n- Gemini 2.0: model for the agentic era\n\n## Tasks and concepts of AI: Representation\n\n- Knowledge Graphs: a graph database that uses semantic relationships to represent knowledge\n- Embeddings: a way to represent data in a lower-dimensional space\n- Transformers: a deep learning model that uses self-attention to process sequential data\n\n## Tasks and concepts of AI: Generation\n\nIn shadows of data, uncertainty reigns,  \nBayesian whispers, where knowledge remains.  \nWith prior beliefs, we start our quest,  \nUpdating with evidence, we strive for the best.  \n\nA dance of the models, predictions unfold,  \nInferences drawn, from the new and the old.  \nThrough probabilities, we find our way,  \nIn the world of AI, it's the Bayesian sway.  \n\nSo gather your data, let prior thoughts flow,  \nIn the realm of the unknown, let your insights grow.  \nFor in this approach, with each little clue,  \nWe weave understanding, both rich and true.  \n\n[Music](https://suno.com/song/b716f67d-8fe9-44b9-8445-719b2f38abb2)\n\n## Tasks and concepts of AI: Generation\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-fold=\"false\"}\nfrom openai import OpenAI\nclient = OpenAI(api_key=\"your-api-key\")\nresponse = client.images.generate(\n    model=\"dall-e-3\",\n    prompt=\"a hockey player trying to understand the Bayes rule\",\n    size=\"1024x1024\",\n    quality=\"standard\",\n    n=1,\n)\n\nprint(response.data[0].url)\n```\n:::\n\n\n \nA humorous and illustrative scene of a hockey player sitting on a bench in full gear, holding a hockey stick in one hand and a whiteboard marker in th\n\n![](fig/dalle-hockey.svg){height=\"60%\" fig-align=\"center\"}\n\n\n## Chess and AI\nOld AI: Deep Blue (1997) vs. Garry Kasparov\n\n![Kasparov vs IBM's DeepBlue in 1997](figup/deepblue.png){height=\"80%\" fig-align=\"center\"}\n\n## AlphaGo Zero\n\n- Remove all human knowledge from training process - only uses self play, \n- Takes raw board as input and neural network predicts the next move. \n- Uses Monte Carlo tree search to evaluate the position. \n- The algorithm was able to beat AlphaGo 100-0. The algorithm was then used to play chess and shogi and was able to beat the best human players in those games as well.\n\n![Alpha GO vs Lee Sedol: Move 37 by AlphaGo in Game Two](figup/move37.jpeg){width=30% fig-align=\"center\"}\n\n## Probability in machine learning\n\n- In all methods and approaches, it is useful not only generate an answer, but also evaluate how confident in this answer, how well the model describes the data, how these values will change in further experiments, etc.\n- Therefore, the central role in machine learning is played by the theory of probability - and we will also actively use it.\n\n\n# Bayes Approach\n\n## Review of Basic Probability Concepts\n\nProbability lets us talk efficiently about things that we are uncertain about.\n\n- What will Amazon's sales be next quarter?\n- What will the return be on my stocks next year?\n- How often will users click on a particular Google ad?\n\n*All these involve estimating or predicting unknowns!!*\n\n## Random Variables\n\n**Random Variables** are numbers that we are not sure about.\nThere's a list of potential outcomes. \nWe assign probabilities to each outcome.\n\n**Example:** Suppose that we are about to toss two coins.\nLet $X$ denote the number of heads.\nWe call $X$ the random variable that stands for the potential outcome.\n\n## Probability\n\n**Probability** is a language designed to help us communicate about uncertainty.\nWe assign a number between $0$ and $1$ measuring\nhow likely that event is to occur.\nIt's immensely useful, and there's only a few basic rules.\n\n1. If an event $A$ is certain to occur, it has probability $1$, denoted $P(A)=1$ \n2. Either an event $A$ occurs or it does not.\n   $$P(A) = 1 - P(\\text{not }A)$$\n3. If two events are mutually exclusive (both cannot occur simultaneously) then \n   $$P(A \\text{ or } B) = P(A) + P(B)$$\n4. Joint probability, when events are independent\n   $$P(A \\text{ and } B) = P( A) P(B)$$\n\n## Probability Distribution\n\nWe describe the behavior of random variables with a **Probability Distribution**\n\n**Example:** Suppose we are about to toss two coins.\nLet $X$ denote the number of heads.\n\n$$X = \\left\\{ \\begin{array}{ll}\n0 \\text{ with prob. } 1/4\\\\\n1 \\text{ with prob. } 1/2\\\\\n2 \\text{ with prob. } 1/4\n\\end{array}\n\\right.$$\n\n$X$ is called a **Discrete Random Variable**\n\n**Question:** What is $P(X=0)$? How about $P(X \\geq 1)$?\n\n## Pete Rose Hitting Streak\n\n**Pete Rose** of the Cincinnati Reds\nset a National League record of hitting safely in $44$ consecutive\ngames ...\n\n- Rose was a $300$ hitter.\n  Assume he comes to bat $4$ times each game.\n- Each at bat is assumed to be independent, i.e.,\n  the current at bat doesn't affect\n  the outcome of the next. \n\n*What probability might reasonably be\nassociated with that hitting streak?*\n\nJoe DiMaggio's record is $56$! His batting average was $.325$\n\n## Pete Rose Hitting Streak (Solution)\n\nLet $A_i$ denote the event that **\"Rose hits safely in the ith game\"** \n\n$P(\\text{Rose Hits Safely in 44 consecutive games}) = P(A_1 \\text{ and } A_2 \\ldots \\text{ and } A_{44}) = P(A_1) P(A_2) \\ldots P(A_{44})$\n\nWe now need to find $P(A_i) \\ldots$ where $P(A_i) = 1 - P(\\text{not } A_i)$\n\n\\begin{align*}\nP(A_1) &= 1 - P(\\text{not } A_1) \\\\\n &= 1 - P(\\text{Rose makes 4 outs}) \\\\\n &= 1 - (0.7)^4 = 0.76\n\\end{align*}\n\nSo for the **winning streak** we have $(0.76)^{44} = 0.0000057$!!!\n\n## Pete Rose Hitting Streak (Inference)\n\nThere are **three** basic inferences:\n\n- This means that the odds for a particular player as good as\n  Pete Rose starting a hitting streak today are **175,470 to 1**\n- Doesn't mean that the run of $44$ won't be beaten\n  by some player at some time: the **Law of Very Large Numbers**\n- Joe DiMaggio's record is 56!!!!\n  It's going to be hard to beat.\n  We have $(0.792)^{56} = 2.13 \\times 10^{-6}$ or **455,962 to 1**\n\n## Example: Happiness Index\n\n**\"happiness index\"** as a function of salary.\n\n| Salary ($X$) | Happiness ($Y$): 0 (low) | 1 (medium) | 2 (high) |\n|---|---|---|---|\n| low 0 | 0.03 | 0.12 | 0.07 |\n| medium 1 | 0.02 | 0.13 | 0.11 |\n| high 2 | 0.01 | 0.13 | 0.14 |\n| very high 3 | 0.01 | 0.09 | 0.14 |\n\nIs $P(Y=2 \\mid X=3) > P(Y=2)$?\n\n\n## Bayes Rule\nThe computation of $P(x \\mid y)$ from $P(x)$ and $P(y \\mid x)$ is called\nBayes theorem \\...\n$$\nP(x \\mid y) = \\frac{P(y,x)}{P(y)} = \\frac{P(y,x)}{\\sum_x P(y,x)} = \\frac{P(y \\mid x)P(x)}{\\sum_x P(y \\mid x)P(x)}\n$$\n\nThis shows now the conditional distribution is related to the joint and\nmarginal distributions.\n\nYou'll be given all the quantities on the r.h.s.\n\n## Bayes Rule\n\nKey fact: $P(x \\mid y)$ is generally different from $P(y \\mid x)$!\n\n[Example:]{style=\"color: blue\"} Most people would agree\n\n\\begin{align*}\nPr  & \\left ( Practice \\; hard  \\mid  Play \\; in \\; NBA \\right ) \\approx  1\\\\\nPr  & \\left ( Play \\; in \\; NBA  \\mid  Practice \\; hard  \\right ) \\approx  0\n\\end{align*}\n\n\nThe main reason for the difference is that\n$P( Play \\; in \\; NBA ) \\approx 0$.\n\n## Independence\n\nTwo random variable $X$ and $Y$ are [independent]{style=\"color: blue\"}\nif \n$$\nP(Y = y  \\mid X = x) = P (Y = y)\n$$\nfor all possible $x$ and $y$\nvalues. [Knowing $X=x$ tells you nothing about $Y$!]{style=\"color: red\"}\n\n[Example:]{style=\"color: blue\"} Tossing a coin twice. What's the\nprobability of getting $H$ in the second toss given we saw a $T$ in the\nfirst one?\n\n## Sally Clark Case: Independence or Bayes?\n\nSally Clark was accused and convicted of killing her two children\n\nThey could have both died of SIDS.\n\n-   The chance of a family which are non-smokers and over 25 having a\nSIDS death is around 1 in 8,500.\n\n-   The chance of a family which has already had a SIDS death having a\nsecond is around 1 in 100.\n\n-   The chance of a mother killing her two children is around 1 in\n1,000,000.\n\n## Bayes or Independence{.smaller}\n\\small\n\n1.  Under Bayes \n\\begin{align*}\nP \\left(  \\mathrm{both} \\; \\; \\mathrm{SIDS} \\right)   &  = P \\left(\n\\mathrm{first} \\; \\mathrm{SIDS} \\right)  P \\left(  \\mathrm{Second} \\; \\;\n\\mathrm{SIDS} | \\mathrm{first} \\; \\mathrm{SIDS} \\right) \\\\\n&  = \\frac{1}{8500} \\cdot \\frac{1}{100} = \\frac{1}{850,000}\n\\end{align*}\n\nThe $\\frac{1}{100}$ comes from taking into account\ngenetics.\n\n2.  Independence, as the court did, gets you\n\n$$\nP \\left(  \\mathrm{both} \\; \\; \\mathrm{SIDS} \\right)  = (1/8500) (1/8500) = (1/73,000,000)\n$$\n\n3.  By Bayes rule\n\n$$\n\\frac{p(I|E)}{p(G|E)} = \\frac{P( E \\cap I)}{P( E \\cap G)}\n$$\n$P( E \\cap I) = P(E|I )P(I)$ needs discussion of $p(I)$.\n\n## Comparison{.smaller}\n\\small\n\n-   Hence putting these two together gives the odds of guilt as\n\n$$\n\\frac{p(I|E)}{p(G|E)} = \\frac{1/850,000}{1/1,000,000} = 1.15\n$$\nIn\nterms of posterior probabilities\n\n$$\np( G|E) = \\frac{1}{1 + O(G|E)} = 0.465\n$$\n\n-   If you use independence\n\n$$\n\\frac{p(I|E)}{p(G|E)} = \\frac{1}{73} \\; \\text{and} \\; p( G|E) \\approx 0.99\n$$\nThe suspect looks guilty.\n\n## Random Variables: Expectation $E(X)$\n\nThe **expected value** of a random variable is simply a weighted\naverage of the possible values X can assume. \n\nThe weights are the probabilities of occurrence of those values.\n\n$$E(X) = \\sum_x xP(X=x)$$\n\nWith $n$ equally likely outcomes with values $x_1, \\ldots, x_n$, $P(X = x_i) = 1/n$ \n\n$$E(X) = \\frac{x_1+x_2+\\ldots+x_n}{n}$$\n\n## Roulette Expectation\n\n- European Odds: 36 numbers (red/black) + zero\n- You bet $1 on 11 Black (pays 35 to 1)\n- $X$ is the return on this bet\n\n$$E(X) = \\frac{1}{37}\\times 36 + \\frac{36}{37}\\times 0 = 0.97$$\n\n- If you bet $1 on Black (pays 1 to 1)\n\n$$E(X) = \\frac{18}{37}\\times 2 + \\frac{19}{37}\\times 0 = 0.97$$\n\nCasino is guaranteed to make money in the long run!\n\n## Standard Deviation $sd(X)$ and Variance $Var(X)$\n\nThe **variance** is calculated as\n\n$$Var(X) = E\\left((X - E(X))^2\\right)$$\n\nA simpler calculation is $Var(X) = E(X^2) - E(X)^2$.\n\nThe **standard deviation** is the square-root of variance.\n\n$$sd(X) = \\sqrt{Var(X)}$$\n\n## Roulette Variance\n\n- European Odds: 36 numbers (red/black) + zero\n- You bet $1 on 11 Black (pays 35 to 1)\n- $X$ is the return on this bet\n\n$$Var(X) = \\frac{1}{37}\\times (36 - 0.97)^2 + \\frac{36}{37}\\times (0 - 0.97)^2 = 34$$\n\n- If you bet $1 on Black (pays 1 to 1)\n\n$$Var(X) = \\frac{18}{37}\\times (2 - 0.97)^2+ \\frac{19}{37}\\times (0- 0.97)^2 = 1$$\n\nIf your goal is to spend as much time as possible in the casino (free drinks): place small bets on black/red\n\n## Example: $E(X)$ and $Var(X)$\n\n**Tortoise and Hare are selling cars.**\nProbability distributions, means and variances\nfor $X$, the number of cars sold\n\n| | 0 | 1 | 2 | 3 | Mean | Variance | sd |\n|---|---|---|---|---|---|---|---|\n| cars sold | | $X$ | | | $E(X)$ | $Var(X)$ | $\\sqrt{Var(X)}$ |\n| Tortoise | 0 | 0.5 | 0.5 | 0 | 1.5 | 0.25 | 0.5 |\n| Hare | 0.5 | 0 | 0 | 0.5 | 1.5 | 2.25 | 1.5 |\n\n## Expectation and Variance Calculations\n\nLet's do Tortoise **expectations** and **variances**\n\n- The Tortoise\n\\begin{align*}\n  E(T) &= (1/2)(1) + (1/2)(2) = 1.5 \\\\\n  Var(T) &= E(T^2) - E(T)^2 \\\\ \n       &= (1/2)(1)^2 + (1/2)(2)^2 - (1.5)^2 = 0.25 \n\\end{align*}\n\n- Now the Hare's\n\\begin{align*}\n  E(H) &= (1/2)(0) + (1/2)(3) = 1.5 \\\\ \n  Var(H) &= (1/2)(0)^2 + (1/2)(3)^2- (1.5)^2 = 2.25 \n \\end{align*}\n\n## Expectation and Variance Interpretation\n\nWhat do these tell us above the **long run behavior?**\n\n- Tortoise and Hare have the same expected number of cars sold.\n- Tortoise is more predictable than Hare.\n  He has a smaller variance\n  The standard deviations $\\sqrt{Var(X)}$ are $0.5$ and $1.5$, respectively\n- Given two equal means, you always want to pick the lower variance.\n\n## Linear Combinations of Random Variables\n\nTwo key properties:\n\nLet $a, b$ be given constants\n\n- Expectations and Variances\n  \\begin{align*}\n  E(aX + bY) &= a E(X) + b E(Y) \\\\\n  Var(aX + bY) &= a^2 Var(X) + b^2 Var(Y) + 2 ab Cov(X,Y) \n  \\end{align*}\n\nwhere $Cov(X,Y)$ is the covariance between random variables.\n\n## Tortoise and Hare Portfolio\n\nWhat about Tortoise and Hare?\nWe need to know $Cov(\\text{Tortoise, Hare})$. \nLet's take $Cov(T,H) = -1$ and see what happens\n\nSuppose $a = \\frac{1}{2}, b= \\frac{1}{2}$ \nExpectation and Variance\n\n\\begin{align*}\nE\\left(\\frac{1}{2} T + \\frac{1}{2} H\\right) &= \\frac{1}{2} E(T) + \\frac{1}{2} E(H) = \\frac{1}{2} \\times 1.5 + \\frac{1}{2} \\times 1.5 = 1.5 \\\\\nVar\\left(\\frac{1}{2} T + \\frac{1}{2} H\\right) &= \\frac{1}{4} 0.25 + \\frac{1}{4} 2.25 - 2 \\frac{1}{2} \\frac{1}{2} = 0.625 - 0.5 = 0.125 \n\\end{align*}\n\nMuch lower!\n\n\n\n\n# Bayesian Updating\n\n## \"Personalization\\\" $=$ \"Conditional Probability\\\"\n\n- Conditional probability is how AI systems express judgments in a way\nthat reflects their partial knowledge.\n- Personalization runs on conditional probabilities, all of which must be\nestimated from massive data sets in which you are the conditioning\nevent.\n\n<br>\nMany Business Applications!! Suggestions vs Search....\n\n\n## Bayes's Rule in Medical Diagnostics\n\nAlice is a 40-year-old women, what is the chance that she really has breast cancer when she gets positive mammogram result, given the conditions:\n\n1. The prevalence of breast cancer among people like Alice is 1%.\n2. The test has an 80% detection rate. \n3. The test has a 10% false-positive rate.\n\nThe posterior probability $P(\\text{cancer} \\mid \\text{positive mammogram})$?\n\n## Medical Diagnostics - Visualization\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n![Medical Screening](fig/14_squares_screening.png){width=\"90%\" fig-align=\"center\"}\n:::\n\n::: {.column width=\"50%\"}\nOf 1000 cases:\n\n- 108 positive mammograms. 8 are true positives. The remaining 100 are false positives.\n- 892 negative mammograms. 2 are false negatives. The other 890 are true negatives.\n:::\n\n::::\n\n## Test Marketing a New Product\n\n**Basic Problem:**\n\n- Your company is developing a new product and will be test\n  marketing to better gauge the sales of the new product.\n- Based on positive, neutral or negative reactions, \n  *what are the\n  probability of high and low sales?*\n\nNetflix [Bayes and AI](https://venturebeat.com/2017/10/13/netflix-went-up-a-personalization-hill-and-came-down-an-ai-mountain/)\n\n## Test Marketing - Setup\n\nSuppose **you** are given the following information\n\n- New products introduced in the marketplace have high sales\n  8% of the time and low sales 92% of the time. \n- A marketing\n  test has the following accuracies:\n  If sales are high, then\n  consumer test reaction is positive 70%, neutral 25% and negative\n  5%.\n  If sales are low, then consumer test reaction is positive\n  15%, neutral 35% and negative 50%.\n\n## Test Marketing - Solution Steps\n\n**Step 1:** Set-up your notation. Let\n$$H = \\text{high sales} \\quad L = \\text{low sales}$$\n$$\\text{Pos} = \\text{positive} \\quad \\text{Neu = Neutral} \\quad \\text{Neg} = \\text{Negative}$$\n\n**Step 2:** List the known conditional probabilities\nFor the marketing test we have\n\\begin{align*}\nP(\\text{Pos} \\mid H) &= 0.70, P(\\text{Neu} \\mid H)=0.25, P(\\text{Neg} \\mid H) = 0.05 \\\\\nP(\\text{Pos} \\mid L) &= 0.15, P(\\text{Neu} \\mid L)=0.35, P(\\text{Neg} \\mid L) = 0.50\n\\end{align*}\n\nFinally, the base rates are $P(H) = 0.08$ and $P(L) = 0.92$\n\n## Test Marketing - Calculation\n\n**Step 3:** Describe the posterior probabilities that are required:\n$$P(H \\mid \\text{Pos})$$\n\nThe probability of high sales given a positive marketing test.\nCompute the probability of a positive test\n\\begin{align*}\nP(\\text{Pos}) &= P(\\text{Pos} \\mid H)P(H) +P(\\text{Pos} \\mid L)P(L) \\\\\n&= 0.70 \\times 0.08 + 0.15 \\times 0.92 = 0.194\n\\end{align*}\n\n## Test Marketing - Final Answer\n\nNow use **Bayes Rule**\n\\begin{align*}\nP(H \\mid \\text{Pos}) &= \\frac{P(\\text{Pos} \\mid H)P(H)}{P(\\text{Pos})} \\\\\n&= \\frac{0.70 \\times 0.08}{0.194} = 0.288\n\\end{align*}\n\nHence 28.8% you'll have high sales in the market.\n\nWe should interpret this **relative** to our initial probability of only $8$%.\n\n\n\n## \"Personalization\" = \"Conditional Probability\"\n\nConditional probability is how AI systems express judgments in a way that reflects their partial knowledge. \n\nPersonalization runs on conditional probabilities, all of which must be estimated from massive data sets in which you are the conditioning event.\n\nMany Business Applications!! Suggestions vs Search, ....\n\n## How does Netflix Give Recommendations?\n\nWill a subscriber like Saving Private Ryan, given that he or she liked the HBO series Band of Brothers?\n\nBoth are epic dramas about the Normandy invasion and its aftermath.\n\n100 people in your database, and every one of them has seen both films. \n\nTheir viewing histories come in the form of a big \"ratings matrix\".\n\n| | Liked Band of Brothers | Didn't like it |\n|---|---|---|\n| Liked Saving Private Ryan | 56 subscribers | 6 subscribers |\n| Didn't like it | 14 subscribers | 24 subscribers |\n\n$$P(\\text{likes Saving Private Ryan} \\mid \\text{likes Band of Brothers})=\\frac{56}{56+14}=80\\%$$\n\n## How does Netflix Give Recommendations? - Complexity\n\nBut real problem is much more complicated:\n\n1. **Scale.** It has 100 million subscribers and ratings data on more than 10,000 shows. The ratings matrix has more than a trillion possible entries.\n2. **\"Missingness\".** Most subscribers haven't watched most films. Moreover, missingness pattern is informative.\n3. **Combinatorial explosion.** In a database with 10,000 films, no one else's history is exactly the same as yours.\n\nThe solution to all three issues is careful modeling.\n\n## How does Netflix Give Recommendations? - Fundamental Equation\n\nThe fundamental equation is:\n$$\\text{Predicted Rating} =\\text{Overall Average} + \\text{Film Offset} + \\text{User Offset} + \\text{User-Film Interaction}$$\n\nThese three terms provide a baseline for a given user/film pair:\n\n- The overall average rating across all films is 3.7.\n- Every film has its own offset. Popular movies have positive offsets.\n- Every user has an offset. Some users are more or less critical than average.\n\n## Netflix - Latent Features\n\nThe User-Film Interaction is calculated based on a person's ratings of similar films exhibit patterns because those ratings are all associated with a latent feature of that person.\n\nThere's not just one latent feature to describe Netflix subscribers, but dozens or even hundreds. There's a \"British murder mystery\" feature, a \"gritty character-driven crime drama\" feature, a \"cooking show\" feature, a \"hipster comedy films\" feature, ...\n\n## The Hidden Features Tell the Story\n\nThese latent features are the magic elixir of the digital economy--a special brew of data, algorithms, and human insight that represents the most perfect tool ever conceived for targeted marketing.\n\nYour precise combination of latent features--your tiny little corner of a giant multidimensional Euclidean space--makes you a demographic of one.\n\nNetflix spent $130 million for 10 episodes on The Crown. Other network television: $400 million commissioning 113 pilots, of which 13 shows made it to a second season.\n\n\n",
    "supporting": [
      "01-intro_files"
    ],
    "filters": []
  }
}