{
  "hash": "7cbc821ca097ad03716a8f4f36e9ba85",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chief AI Officer Program: ML Essentials\"\nauthor: \"Vadim Sokolov\"\ninstitute: \"George Mason University\"\nsubtitle: \"Machine Learning: From Probability to Prediction\"\nformat:\n  revealjs:\n    slide-number: true\n    height: 920\n    width: 1300\n    chalkboard: false\n    code-fold: true\n    echo: true\n    scrollable: true\n    embed-resources: true\n    self-contained: true\n    self-contained-math: true \n    template-partials:\n      - title-slide.html\n    fig-align: \"center\"\n    css: styles.css\n    include-in-header: \n      - file: preamble.html\n---\n\n\n# Probability Distributions\n\n## Why Distributions Matter\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n- Machine learning is built on probability\n- Distributions describe uncertainty in data\n- Three fundamental distributions:\n  - **Binomial**: Binary outcomes (yes/no, win/lose)\n  - **Poisson**: Count data (arrivals, events)\n  - **Normal**: Continuous measurements (heights, returns)\n:::\n::: {.column width=\"50%\"}\n**Why Should Executives Care?**\n\n| Business Question | Distribution |\n|-------------------|--------------|\n| Will the customer buy? | Binomial |\n| How many orders today? | Poisson |\n| What's the forecast error? | Normal |\n\n*Choosing the right distribution is the first step in building a reliable model. Wrong distribution = wrong predictions!*\n:::\n::::\n\n## Binomial Distribution\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nModels the number of successes in $n$ independent trials, each with probability $p$\n\n$$P(X=k) = \\binom{n}{k} p^k(1-p)^{n-k}$$\n\n**Key Parameters:**\n\n- $n$ = number of trials\n- $p$ = probability of success\n- Mean = $np$\n- Variance = $np(1-p)$\n\n**Examples:** A/B test conversions, click-through rates, quality defects\n:::\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n:::\n::::\n\n## NFL Patriots Coin Toss \n\n:::: {.columns}\n::: {.column width=\"50%\"}\nThe Patriots won 19 out of 25 coin tosses in 2014-15. How likely?\n\n- There are **177,100 ways** to arrange 19 wins in 25 games\n- Each specific sequence has probability $0.5^{25}$\n- Combined probability: **0.5%** or odds of **199 to 1** against\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\n# \"25 choose 19\" = number of ways to pick 19 wins from 25 games\nchoose(25, 19)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 177100\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\n# Probability = (ways to get 19 wins) × (probability of any specific sequence)\nchoose(25, 19) * 0.5^25\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.005277991\n```\n\n\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\n**The \"Law of Large Numbers\" Perspective:**\n\nWith 32 NFL teams over 20+ years, some team *will* have a suspicious streak!\n\n**Key insight:** Probability of Patriots specifically = 0.5%. But probability that *some team* has a streak ≈ much higher!\n\n**Business lesson:** When auditing for fraud or anomalies:\n\n- Don't just flag rare events\n- Consider how many opportunities for rare events exist\n- Adjust for \"multiple comparisons\"\n\n*Looking at enough data, you'll always find something \"unusual\"*\n:::\n::::\n\n## Predicting Premier League Goals\n\n:::: {.columns}\n::: {.column width=\"48%\"}\nHow many goals will a team score? Historical EPL data:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\nepl <- read.csv(\"data/epl.csv\")\nepl[1:5, c(\"home_team_name\", \"away_team_name\", \"home_score\", \"guest_score\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  home_team_name       away_team_name home_score guest_score\n1        Arsenal            Liverpool          3           4\n2    Bournemouth    Manchester United          1           3\n3        Burnley              Swansea          0           1\n4        Chelsea             West Ham          2           1\n5 Crystal Palace West Bromwich Albion          0           1\n```\n\n\n:::\n:::\n\n\nEach row = one match with final scores.\n:::\n::: {.column width=\"4%\"}\n:::\n::: {.column width=\"48%\"}\n**The Business Problem:**\n\nSports betting: **$200+ billion** industry.\n\n**Our approach:**\n\n1. Analyze historical data\n2. Model goals as random events\n3. Estimate team strengths\n4. Simulate matches\n\n**Who uses this?** FiveThirtyEight, ESPN, DraftKings, Betfair, team analytics\n:::\n::::\n\n## EPL Goals: Mean ≈ Variance \n\n:::: {.columns}\n::: {.column width=\"50%\"}\nA key signature of Poisson data: the **mean equals the variance**.\n\n- Teams score about **1.4 goals per match** on average\n- The variance is also ~1.4 — this is the Poisson fingerprint!\n- If variance were much larger, we'd need a different model\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\ngoals <- c(epl$home_score, epl$guest_score)\nmean(goals)  # Average goals per team per match\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.4\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\nvar(goals)   # Variance ≈ Mean suggests Poisson!\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.644796\n```\n\n\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\n**Model Diagnostics: Mean vs Variance**\n\n| Relationship | Suggests |\n|--------------|----------|\n| Variance ≈ Mean | Poisson ✓ |\n| Variance > Mean | Overdispersion (Negative Binomial) |\n| Variance < Mean | Underdispersion (rare) |\n\n**Other Poisson Applications:**\n\n- Call center arrivals per hour\n- Website clicks per minute\n- Insurance claims per year\n- Manufacturing defects per batch\n- Emails received per day\n\n*Poisson is the \"go-to\" for count data!*\n:::\n::::\n\n## Goals Follow a Poisson Distribution\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\ngoals <- c(epl$home_score, epl$guest_score)\nlambda <- mean(goals)\nx <- 0:8\nobserved <- table(factor(goals, levels = x)) / length(goals)\nexpected <- dpois(x, lambda = lambda)\n\nbarplot(rbind(observed, expected), beside = TRUE, \n        names.arg = x, col = c(\"steelblue\", \"coral\"),\n        xlab = \"Goals Scored\", ylab = \"Proportion\",\n        legend.text = c(\"Observed\", \"Poisson Model\"))\n```\n\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\n**Model Validation:**\n\nThe Poisson model (coral bars) fits the observed data (blue bars) remarkably well!\n\n**What this tells us:**\n\n- Goals are indeed *rare, independent events*\n- The Poisson assumption is justified\n- We can use this model for predictions\n\n**Slight discrepancy at 0 goals:** Real matches have slightly fewer 0-0 draws than Poisson predicts (teams try harder when level!)\n:::\n::::\n\n## Poisson Distribution\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nModels count of random events: goals, arrivals, defects, clicks\n\n$$P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$$\n\n- $\\lambda$ (lambda): expected rate of events\n- **Key property**: Mean = Variance = $\\lambda$\n- Events occur independently at a constant average rate\n:::\n::: {.column width=\"50%\"}\n**Business Applications:**\n\n- Customer arrivals per hour\n- Website clicks per day\n- Manufacturing defects per batch\n- Insurance claims per year\n- Server requests per minute\n\n*If events are rare and independent, Poisson is your model!*\n:::\n::::\n\n## Improving the Model: Team Strength\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nA single $\\lambda$ for all teams is too simple. Better model:\n\n$$\\lambda_{ij} = \\text{Attack}_i \\times \\text{Defense}_j \\times \\text{HomeAdvantage}$$\n\n- **Attack**: How good is team $i$ at scoring?\n- **Defense**: How weak is team $j$ at defending?\n- **Home advantage**: ~0.4 extra goals at home\n:::\n::: {.column width=\"50%\"}\n**This is how real sports analytics works:**\n\n1. Estimate each team's offensive/defensive strength from historical data\n2. Adjust for home/away effects\n3. Predict expected goals for each team\n4. Use Poisson to generate win/draw/loss probabilities\n\n**Same framework applies to:**\n\n- NBA point spreads\n- NFL betting lines\n- Cricket run predictions\n- Baseball run expectations\n:::\n::::\n\n## Team-Specific $\\lambda$: Arsenal vs Liverpool\n\nTo predict a specific match, we estimate each team's scoring rate:\n\n- **Arsenal's attack**: How many goals do they typically score at home?\n- **Liverpool's defense**: How many goals do they typically concede away?\n- **Adjustment**: Scale by league average to get relative strength\n\nFor Arsenal vs Liverpool at home, we estimate Arsenal will score about **1.8 goals** on average. Liverpool's away $\\lambda$ would be calculated similarly.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\n# Simple estimate: average goals scored and conceded\narsenal_attack <- mean(epl$home_score[epl$home_team_name == \"Arsenal\"])\nliverpool_defense <- mean(epl$home_score[epl$away_team_name == \"Liverpool\"])\nleague_avg <- mean(goals)\n\n# Arsenal's expected goals vs Liverpool (simplified)\nlambda_arsenal <- arsenal_attack * (liverpool_defense / league_avg)\nlambda_arsenal\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.851998\n```\n\n\n:::\n:::\n\n\n## Monte Carlo Simulation \n\nOnce we have $\\lambda$ for each team, we can **simulate** the match thousands of times.\n\nFor Arsenal ($\\lambda=1.8$) vs Liverpool ($\\lambda=1.5$), running 10,000 simulations gives:\n\n- **Arsenal wins**: ~42% of simulations\n- **Draw**: ~24% of simulations  \n- **Liverpool wins**: ~34% of simulations\n\nThis is how betting companies set their odds!\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\nset.seed(42)\nn_sims <- 10000\n# Simulate Arsenal vs Liverpool\narsenal_goals <- rpois(n_sims, lambda = 1.8)  # λ for Arsenal\nliverpool_goals <- rpois(n_sims, lambda = 1.5) # λ for Liverpool\n\n# Match outcomes\nc(Arsenal_Win = mean(arsenal_goals > liverpool_goals),\n  Draw = mean(arsenal_goals == liverpool_goals),\n  Liverpool_Win = mean(arsenal_goals < liverpool_goals))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Arsenal_Win          Draw Liverpool_Win \n       0.4538        0.2254        0.3208 \n```\n\n\n:::\n:::\n\n\n## Why Monte Carlo?\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nEach simulation draws random goals from Poisson distributions\n\n- Run 10,000 simulations → get probability of each outcome\n- Can extend to simulate entire season, league standings\n- Same approach used by betting companies and analytics firms\n\n*This is how FiveThirtyEight and bookmakers build their models!*\n:::\n::: {.column width=\"50%\"}\n**Monte Carlo Applications:**\n\n- **Finance**: Option pricing, portfolio risk (VaR)\n- **Insurance**: Claim projections, reserve calculations\n- **Operations**: Supply chain uncertainty, demand forecasting\n- **Engineering**: Reliability analysis, quality control\n- **AI**: Reinforcement learning, MCMC for Bayesian inference\n\n*When math is too hard, simulate!*\n:::\n::::\n\n## Central Limit Theorem (CLT)\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n**The most important theorem in statistics:**\n\n> The average of many independent random events tends toward a Normal distribution, regardless of the original distribution.\n\n*Why it matters*: Stock returns, measurement errors, test scores — all tend to be Normal because they're sums of many small effects.\n:::\n::: {.column width=\"50%\"}\n**Practical Implications:**\n\n- **Sample means** are approximately Normal (even if data isn't)\n- **Confidence intervals** work because of CLT\n- **A/B testing** relies on CLT for significance tests\n- **Quality control** uses CLT for process monitoring\n\n**Rule of thumb**: Sample size ≥ 30 usually sufficient for CLT to kick in\n\n*This is why the Normal distribution is everywhere!*\n:::\n::::\n\n## CLT in Action: Michigan Election Polls\n\nSuppose the true vote share in Michigan is 51%. What happens when we poll voters?\n\n- Each voter is like a coin flip (vote A or B)\n- Small samples are noisy; large samples converge to the truth\n- The *distribution of poll results* becomes Normal\n\n\n::: {.cell layout-ncol=\"3\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\nset.seed(42)\ntrue_p <- 0.51\n# Poll of 10 voters\nhist(replicate(1000, mean(rbinom(10, 1, true_p))), breaks = 20,\n     main = \"Poll: 10 Voters\", xlab = \"Vote Share\", col = \"steelblue\", \n     freq = FALSE, xlim = c(0.2, 0.8))\nabline(v = true_p, col = \"red\", lwd = 2, lty = 2)\n```\n\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\n# Poll of 100 voters\nhist(replicate(1000, mean(rbinom(100, 1, true_p))), breaks = 20,\n     main = \"Poll: 100 Voters\", xlab = \"Vote Share\", col = \"steelblue\", \n     freq = FALSE, xlim = c(0.2, 0.8))\nabline(v = true_p, col = \"red\", lwd = 2, lty = 2)\n```\n\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-9-2.png){width=960}\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\n# Poll of 1000 voters\nhist(replicate(1000, mean(rbinom(1000, 1, true_p))), breaks = 20,\n     main = \"Poll: 1000 Voters\", xlab = \"Vote Share\", col = \"steelblue\", \n     freq = FALSE, xlim = c(0.2, 0.8))\nabline(v = true_p, col = \"red\", lwd = 2, lty = 2)\n```\n\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-9-3.png){width=960}\n:::\n:::\n\n\nLarger samples → tighter Normal distribution around the true value (red line)\n\n## Normal Distribution\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nThe \"bell curve\" — the most important distribution in statistics\n\n**The 68-95-99.7 Rule:**\n\n- **68%** of data within 1 standard deviation\n- **95%** of data within 2 standard deviations\n- **99.7%** of data within 3 standard deviations\n\n**Why it's everywhere:** Central Limit Theorem guarantees that averages of many random events become Normal\n\n**Applications:** Quality control, financial risk, test scores, measurement error\n:::\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n:::\n::::\n\n## Normal: Heights of Adults\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nMale heights follow a Normal distribution: mean = 70 inches, sd = 3 inches\n\n- **68%** of men are between 67-73 inches (within 1 sd)\n- The **95th percentile** is about 75 inches — only 5% are taller\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\n# What proportion are between 67 and 73 inches (+/- 1 sd)?\npnorm(73, mean = 70, sd = 3) - pnorm(67, mean = 70, sd = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6826895\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\n# What height is taller than 95% of men?\nqnorm(0.95, mean = 70, sd = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 74.93456\n```\n\n\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\n**R Functions for Normal Distribution:**\n\n| Function | Purpose | Example |\n|----------|---------|---------|\n| `pnorm()` | Probability ≤ x | P(height ≤ 73) |\n| `qnorm()` | Find percentile | 95th percentile |\n| `dnorm()` | Density at x | Height of curve |\n| `rnorm()` | Random samples | Simulate data |\n\n**Business Applications:**\n\n- Setting size ranges for products\n- Establishing \"normal\" ranges for KPIs\n- Identifying outliers (> 2-3 sd)\n- Quality control limits\n:::\n::::\n\n## The 1987 Stock Market Crash: A 5-Sigma Event\n\nHow extreme was the October 1987 crash of **-21.76%**?\n\n- Prior to crash: $\\mu = 1.2\\%$, $\\sigma = 4.3\\%$ → Z-score = $\\frac{-21.76 - 1.2}{4.3} = -5.34$\n- Under Normal model: probability = **1 in 20 million** (once every 130,000 years!)\n- Yet 5+ sigma events happened in 1987, 2008, and 2020\n\n**Conclusion:** The model is wrong — stock returns have \"fat tails.\" Banks using Normal-based VaR dramatically underestimate risk.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\npnorm(-5.34)  # Probability of -5.34 sigma event\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.647329e-08\n```\n\n\n:::\n:::\n\n\n## Fat Tails: Reality vs Normal Model\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](fig/normal-sp500.png){fig-align=\"center\" width=\"100%\"}\n:::\n::: {.column width=\"50%\"}\n**The Problem with Normal Assumptions:**\n\nStock returns have more extreme events than the Normal distribution predicts.\n\n| Event | Normal Probability | Actually Happened |\n|-------|-------------------|-------------------|\n| 1987 Crash (-22%) | 1 in $10^{160}$ | Yes |\n| 2008 Crisis | \"Impossible\" | Yes |\n| 2020 COVID Crash | \"Impossible\" | Yes |\n\n**Implications for Risk Management:**\n\n- VaR models underestimate tail risk\n- Need \"fat-tailed\" distributions (t-distribution, etc.)\n- Stress testing is essential\n:::\n::::\n\n# Linear Regression\n\n## What is Regression?\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nFinding the relationship between variables\n\n$$y = \\beta_0 + \\beta_1 x + \\epsilon$$\n\n- $\\beta_0$: intercept (baseline value)\n- $\\beta_1$: slope (change in $y$ per unit change in $x$)\n- $\\epsilon$: unexplained variation\n\n**Goal**: Minimize sum of squared prediction errors\n:::\n::: {.column width=\"50%\"}\n**Business Questions Regression Answers:**\n\n- How much does price affect sales?\n- What's the ROI of advertising spend?\n- How does experience affect salary?\n- What drives customer lifetime value?\n- How does weather affect demand?\n\n*Regression quantifies relationships and enables prediction.*\n:::\n::::\n\n## Simple Example: House Prices\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nUsing Saratoga County housing data, we fit a model: \n\n**Price = f(Living Area)**\n\n- **Intercept**: Base price of ~$13,000 (land value)\n- **Slope**: Each additional square foot adds **~$113** to the price\n\nA 2,000 sq ft house: $13K + (2000 × $113) = **$239,000**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\nd <- read.csv(\"data/SaratogaHouses.csv\")\nmodel <- lm(price ~ livingArea, data = d)\ncoef(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)  livingArea \n 13439.3940    113.1225 \n```\n\n\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\n**Interpreting Coefficients:**\n\n| Coefficient | Meaning |\n|-------------|---------|\n| Intercept ($13K) | Value of land without house |\n| Slope ($113/sqft) | Price increase per sqft |\n\n**Making Predictions:**\n\n$$\\text{Price} = 13,439 + 113 \\times \\text{SqFt}$$\n\n| House Size | Predicted Price |\n|------------|-----------------|\n| 1,500 sqft | $183,000 |\n| 2,500 sqft | $296,000 |\n| 3,500 sqft | $409,000 |\n:::\n::::\n\n## Visualizing the Fit\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\n**What the plot shows:**\n\n- Each **blue dot** is a house\n- The **red line** is our prediction\n- **Vertical distance** from dot to line = prediction error\n\n**Key observations:**\n\n- Strong positive relationship\n- More scatter at higher prices (heteroskedasticity)\n- Some outliers (expensive small houses, cheap large houses)\n\n*The line minimizes the sum of squared vertical distances*\n:::\n::::\n\n## Google vs S&P 500 (CAPM)\n\nThe Capital Asset Pricing Model (CAPM) asks: Does a stock follow the market or beat it?\n\n$$\\text{Google Return} = \\alpha + \\beta \\times \\text{Market Return}$$\n\n- $\\beta$ (beta): How volatile is the stock relative to the market?\n- $\\alpha$ (alpha): Does the stock outperform after adjusting for risk?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\nlibrary(quantmod)\ngetSymbols(c(\"GOOG\", \"SPY\"), from = \"2017-01-01\", to = \"2023-12-31\") |> invisible()\ngoog <- as.numeric(dailyReturn(GOOG))\nspy <- as.numeric(dailyReturn(SPY))\nmodel <- lm(goog ~ spy)\nprint(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = goog ~ spy)\n\nCoefficients:\n(Intercept)          spy  \n  0.0003211    1.1705808  \n```\n\n\n:::\n:::\n\n\n## Google vs S&P 500: CAPM Results\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\n**Our Findings:**\n\n- **Beta** ($\\beta = 1.01$): Google moves 1:1 with market\n- **Alpha** ($\\alpha \\approx 0$): No significant outperformance ($p = 0.06$)\n\n| Beta&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | Interpretation |\n|:--------:|----------------|\n| $\\beta < 1$ | Less volatile (utilities, healthcare) |\n| $\\beta = 1$ | Moves with market (index funds) |\n| $\\beta > 1$ | More volatile (tech, small caps) |\n\n*Conclusion*: Google tracked the market without consistent alpha in 2017-2023. High beta = higher risk, potentially higher reward.\n:::\n::::\n\n## Orange Juice: Price & Advertising\n\nHow does advertising affect price sensitivity? We model sales as a function of price and whether the product was featured in ads.\n\nKey finding: The **interaction term** (log(price):feat) is negative and significant — advertising changes how customers respond to price!\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\noj <- read.csv(\"data/oj.csv\")\nmodel <- lm(logmove ~ log(price) * feat, data = oj)\ntidy(model) |> select(term, estimate, p.value) |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term            | estimate| p.value|\n|:---------------|--------:|-------:|\n|(Intercept)     |    9.659|       0|\n|log(price)      |   -0.958|       0|\n|feat            |    1.714|       0|\n|log(price):feat |   -0.977|       0|\n\n\n:::\n:::\n\n\n## The Advertising Paradox\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n**Finding**: Advertising *increases* price sensitivity\n\n| Condition | Price Elasticity |\n|-----------|------------------|\n| No advertising | -0.96 |\n| With advertising | -0.96 + (-0.98) = **-1.94** |\n\n*Why?* Ads coincide with promotions → attract price-sensitive shoppers\n:::\n::: {.column width=\"50%\"}\n**Key Lessons:**\n\n1. **Correlation ≠ Causation**: Ads don't *cause* sensitivity; they *coincide* with promotions\n\n2. **Selection effects**: Who responds to ads? Price hunters!\n\n3. **Confounding variables**: Promotions happen during ad campaigns\n\n4. **Managerial insight**: Don't blame advertising for price sensitivity — it's the promotion strategy\n\n*Always ask: What's really driving the relationship?*\n:::\n::::\n\n# Logistic Regression\n\n## From Regression to Classification\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nWhat if the outcome is **yes/no**?\n\n$$P(y=1 \\mid x) = \\frac{1}{1 + e^{-\\beta^T x}}$$\n\n**Why not just use linear regression?**\n\n- Linear regression can predict values < 0 or > 1\n- Probabilities must be between 0 and 1\n- Logistic function \"squashes\" any input to (0, 1)\n:::\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n:::\n::::\n\n## NBA Point Spread Example\n\nCan Vegas point spreads predict game outcomes? We fit a logistic regression using historical NBA data.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\nNBA <- read.csv(\"data/NBAspread.csv\")\nmodel <- glm(favwin ~ spread - 1, family = binomial, data = NBA)\ntidy(model) |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term   | estimate| std.error| statistic| p.value|\n|:------|--------:|---------:|---------:|-------:|\n|spread |    0.156|     0.014|    11.332|       0|\n\n\n:::\n:::\n\n\n**Interpretation:** For each additional point in the spread, log-odds of favorite winning increases by 0.16. The p-value < 0.001 confirms spreads are highly predictive.\n\n## Making Predictions\n\nUsing our model, we can predict win probability for any point spread:\n\n| Spread | P(Favorite Wins) |\n|--------|------------------|\n| 4 points | **65%** |\n| 8 points | **78%** |\n| 12 points | **87%** |\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\npredict(model, newdata = data.frame(spread = c(4, 8)), type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        1         2 \n0.6511238 0.7769474 \n```\n\n\n:::\n:::\n\n\n**Same approach used for:** credit scoring, churn prediction, marketing response, fraud detection — any binary outcome.\n\n## Confusion Matrix\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nHow accurate is our model? The confusion matrix shows predictions vs. actual outcomes.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show R code\"}\npred <- predict(model, type = \"response\") > 0.5\ntable(Actual = NBA$favwin, Predicted = as.integer(pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Predicted\nActual   1\n     0 131\n     1 422\n```\n\n\n:::\n:::\n\n\nOur model achieves about **66% accuracy** — better than a coin flip!\n:::\n::: {.column width=\"50%\"}\n**Reading the Matrix:**\n\n|  | Pred: 0 | Pred: 1 |\n|--|---------|---------|\n| Actual: 0 | TN (correct!) | FP (oops) |\n| Actual: 1 | FN (oops) | TP (correct!) |\n\n**Sports Betting Reality:**\n\n- 66% accuracy sounds good, but...\n- Vegas takes ~10% commission (\"vig\")\n- Need ~52.4% accuracy just to break even\n- Edge of 13.6% is excellent if it holds!\n\n*But past performance ≠ future results*\n:::\n::::\n\n## Understanding the Confusion Matrix\n\n|              | Predicted: Win | Predicted: Lose |\n|--------------|----------------|-----------------|\n| **Actual: Win**  | True Positive (TP) | False Negative (FN) |\n| **Actual: Lose** | False Positive (FP) | True Negative (TN) |\n\n**Key Metrics:**\n\n- **Accuracy** = (TP + TN) / Total — overall correctness\n- **Precision** = TP / (TP + FP) — \"Of predicted wins, how many were right?\"\n- **Recall** = TP / (TP + FN) — \"Of actual wins, how many did we catch?\"\n\n**Caution:** Accuracy can mislead! A spam filter predicting \"not spam\" for everything has 99% accuracy but catches zero spam. Choose metrics based on business costs.\n\n## ROC Curve: The Trade-off\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](02-ml_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\n**Understanding the ROC Curve:**\n\n- **X-axis**: False Positive Rate (false alarms)\n- **Y-axis**: True Positive Rate (catches)\n- **Diagonal**: Random guessing (AUC = 0.5)\n- **Upper-left corner**: Perfect classifier\n\n**Area Under Curve (AUC):**\n\n| AUC | Model Quality |\n|-----|---------------|\n| 0.5 | Random (useless) |\n| 0.6-0.7 | Poor |\n| 0.7-0.8 | Fair |\n| 0.8-0.9 | Good |\n| 0.9+ | Excellent |\n:::\n::::\n\n## Choosing the Right Threshold\n\n:::: {.columns}\n::: {.column width=\"50%\"}\nThe optimal threshold depends on **business costs**:\n\n- **Fraud detection**: Low threshold (catch more fraud, accept false alarms)\n- **Medical screening**: Low threshold (don't miss disease)\n- **Spam filter**: Higher threshold (don't lose important emails)\n\n*There is no universal \"correct\" threshold*\n:::\n::: {.column width=\"50%\"}\n**Framework for Threshold Selection:**\n\n1. **Quantify costs**: What's the cost of FP vs FN?\n2. **Calculate expected cost** at each threshold\n3. **Choose threshold** that minimizes total expected cost\n\n**Example — Credit Card Fraud:**\n\n- False Positive cost: $10 (customer inconvenience)\n- False Negative cost: $500 (fraud loss)\n- Optimal threshold: Much lower than 0.5!\n\n*Let business economics guide your model decisions*\n:::\n::::\n\n# Key Takeaways\n\n## Summary\n\n| Concept | Key Insight |\n|---------|-------------|\n| Distributions | Binomial (binary), Poisson (counts), Normal (continuous) |\n| Poisson | Mean = Variance — the fingerprint of count data |\n| Normal | CLT makes it universal for averages |\n| Linear Regression | Coefficients = effect sizes |\n| Logistic Regression | Outputs probabilities for classification |\n| ROC/AUC | Trade-off between false positives and false negatives |\n| Threshold | Business costs should drive the choice |\n\n*Statistics is the science of decision-making under uncertainty*\n\n## Supplemental Reading\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n**Online Articles:**\n\n- [The Surprising Power of Online Experiments](https://hbr.org/2017/09/the-surprising-power-of-online-experiments) - HBR\n- [Machine Learning, Explained](https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained) - MIT Sloan\n\n**Key Insight from HBR**: A simple A/B test at Bing generated over $100M annually by testing a \"low priority\" idea\n:::\n::: {.column width=\"50%\"}\n**Books for Further Study:**\n\n- *The Signal and the Noise* — Nate Silver\n- *Thinking, Fast and Slow* — Daniel Kahneman\n- *Naked Statistics* — Charles Wheelan\n- *Data Science for Business* — Provost & Fawcett\n\n**Online Courses:**\n\n- Andrew Ng's Machine Learning (Coursera)\n- Statistical Learning (Stanford Online)\n- Fast.ai Practical Deep Learning\n:::\n::::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}