<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; Utility, Risk and Decisions – Bayes, AI and Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./05-ab.html" rel="next">
<link href="./03-bl.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-680e7c22d93ef26f016bec9199f8e6d8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script>
  // Load MathJax with custom macros
  window.MathJax = {
    tex: {
      macros: {
        Cov: ["\\mathrm{Cov}\\left(#1\\right)", 1],
        Cor: ["\\mathrm{Cor}\\left(#1\\right)", 1],
        Var: ["\\mathrm{Var}\\left(#1\\right)", 1],
        sd: ["\\mathrm{sd}\\left(#1\\right)", 1],
        E: ["\\mathrm{E}_{#1}\\left(#2\\right)", 2, ""],
        prob: ["\\mathrm{P}\\left(#1\\right)", 1],
        defeq: "\\stackrel{\\mathrm{def}}{=}",
        mini: "\\operatorname*{minimize}"
      }
    }
  };
</script>

<style>
  /* Custom styling for math content */
  .MathJax {
    font-size: 1em !important;
  }
  
  /* Ensure consistent math rendering */
  mjx-container[jax="CHTML"] {
    line-height: 1.2;
  }
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="4&nbsp; Utility, Risk and Decisions – Bayes, AI and Deep Learning">
<meta property="og:description" content="">
<meta property="og:image" content="04-dec_files/figure-html/unnamed-chunk-1-1.png">
<meta property="og:site_name" content="Bayes, AI and Deep Learning">
<meta name="twitter:title" content="4&nbsp; Utility, Risk and Decisions – Bayes, AI and Deep Learning">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="04-dec_files/figure-html/unnamed-chunk-1-1.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="./04-dec.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayes, AI and Deep Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Modern AI Playbook</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-bl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-dec.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-ab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">AB Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-hyp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-sp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-rl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Unreasonable Effectiveness of Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-pattern.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Pattern Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Tree Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-forecasting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Forecasting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Randomized Controlled Trials</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-select.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-theoryai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Theory of AI: From MLE to Bayesian Regularization</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-theorydl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Theory of Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-sgd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-qnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Quantile Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-nlp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Natural Language Processing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Large Language Models: A Revolution in AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26-robots.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">AI Agents</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Exercises</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#expected-utility" id="toc-expected-utility" class="nav-link active" data-scroll-target="#expected-utility"><span class="header-section-number">4.1</span> Expected Utility</a></li>
  <li><a href="#unintuitive-nature-of-decision-making" id="toc-unintuitive-nature-of-decision-making" class="nav-link" data-scroll-target="#unintuitive-nature-of-decision-making"><span class="header-section-number">4.2</span> Unintuitive Nature of Decision Making</a></li>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link" data-scroll-target="#decision-trees"><span class="header-section-number">4.3</span> Decision Trees</a></li>
  <li><a href="#nash-equilibrium" id="toc-nash-equilibrium" class="nav-link" data-scroll-target="#nash-equilibrium"><span class="header-section-number">4.4</span> Nash Equilibrium</a></li>
  <li><a href="#statistical-decisions-and-risk" id="toc-statistical-decisions-and-risk" class="nav-link" data-scroll-target="#statistical-decisions-and-risk"><span class="header-section-number">4.5</span> Statistical Decisions and Risk</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="./04-dec.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-Decisions" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>“<em>I would never die for my beliefs because I might be wrong.</em>” – Bertrand Russell</p>
</blockquote>
<p>Life is about making decisions under uncertainty. We always prefer informed decisions. Statistical decision theory studies the process of finding a reasonable course of action when faced with statistical uncertainty–uncertainty that can in part be quantified from observed data. In most cases, the problem can be separated into two problems: a learning problem or parameter estimation problem and then a decision problem that uses the output of the learning problem. In finance, a classic example of this is finding optimal portfolios with a mean-variance utility/criterion function assuming the underlying means, variances and covariances are unknown based on a historical sample of data. In statistics, the classic problem is using decision theory to evaluate the relative merits of different parameter estimators and hypothesis tests.</p>
<section id="expected-utility" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="expected-utility"><span class="header-section-number">4.1</span> Expected Utility</h2>
<p>Let <span class="math inline">\(P,Q\)</span> be two possible <em>risky gambles</em> or probability bets. An agent’s preferences can then be specified as an ordering on probability bets where we write <span class="math inline">\(P\)</span> is preferred to <span class="math inline">\(Q\)</span> as <span class="math inline">\(P \succeq Q\)</span> and indifference as <span class="math inline">\(P \sim Q\)</span>. A compound or mixture bet is defined by the probability assignment <span class="math inline">\(p P + (1 - p ) Q\)</span> for a prospect weight <span class="math inline">\(0 \leq p \leq 1\)</span>.</p>
<p>Ramsey-de Finetti-Savage show that if an agent’s preferences satisfy a number of plausible axioms – completeness, transitivity, continuity and independence – then they can be represented by the expectation of a utility function. The theory is a <em>normative</em> one and not necessarily <em>descriptive</em>. It suggests how a rational agent should formulate beliefs and preferences and not how they actually behave.</p>
<p>This representation of preferences in terms of expected utility <span class="math inline">\(U(P)\)</span> of a risky gamble is then equivalent to <span class="math display">\[
P \succeq Q \; \; \iff \; \; U (P) \geq U (Q )
\]</span> Therefore, the higher the value taken by the utility function the more the gamble is preferred. Specifically, the axioms lead to existence of expected utility and uniqueness of probability.</p>
<p>The two key facts then are uniqueness of probability and existence of expected utility. Formally,</p>
<ol type="1">
<li>If <span class="math inline">\(P \succeq R \succeq Q\)</span> and <span class="math inline">\(w P + (1 - w ) Q \sim R\)</span> then <span class="math inline">\(w\)</span> is unique.</li>
<li>There exists an expected utility <span class="math inline">\(U(\cdot )\)</span> such that <span class="math inline">\(P \succeq Q ~ \iff ~ U (P) \geq U (Q)\)</span>. Furthermore <span class="math display">\[
U \left (w P + (1 - w ) Q \right ) = wU (P) +(1 - w ) U(Q)
\]</span> for any <span class="math inline">\(P, Q\)</span> and <span class="math inline">\(0 \leq w \leq 1\)</span>.</li>
</ol>
<p>This implies that <span class="math inline">\(U\)</span> is additive and it is also unique up to affine transformation.</p>
<p>Proof: If <span class="math inline">\(w\)</span> is not unique then <span class="math inline">\(\exists w_1\)</span> such that <span class="math inline">\(w_1 P + (1 - w_1 ) Q \sim R\)</span>. Without loss of generality assume that <span class="math inline">\(w_1 &lt; w\)</span> and so <span class="math inline">\(0 &lt; w - w_1 &lt; 1 - w_1\)</span>. However, we can write the bet <span class="math inline">\(Q\)</span> as <span class="math display">\[
Q = \left ( \frac{w-w_1}{1-w_1} \right ) Q + \left ( \frac{1-w}{1-w_1} \right ) Q
\]</span> By transitivity, as <span class="math inline">\(P \succeq Q\)</span> we have <span class="math display">\[
\left ( \frac{w-w_1}{1-w_1} \right ) P + \left ( \frac{1-w}{1-w_1} \right ) Q \succeq Q
\]</span> However, <span class="math display">\[
w P + ( 1 - w) Q = w_1 P + (1 - w_1 ) \left (  \left ( \frac{w-w_1}{1-w_1} \right ) P + \left ( \frac{1-w}{1-w_1} \right ) Q
\right )
\]</span> implying by transitivity that <span class="math display">\[
w P + (1 - w ) Q \succeq w_1 P + (1 - w_1 ) Q
\]</span> which is a contradiction.</p>
<p>This can be used together with the axioms to then prove the existence and uniqueness of a utility function.</p>
<div id="thm-existence" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.1</strong></span> If <span class="math inline">\(V\)</span> is any other function satisfying these results then <span class="math inline">\(V\)</span> is an affine function of <span class="math inline">\(U\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>If <span class="math inline">\(\forall P , Q\)</span> we have <span class="math inline">\(P \sim Q\)</span>, then define <span class="math inline">\(u(P) \equiv 0\)</span>. Hence suppose that there exists <span class="math inline">\(S \succ T\)</span>. Define <span class="math inline">\(U(S) =1\)</span> and <span class="math inline">\(U(T)=0\)</span>. For any <span class="math inline">\(P \in \mathcal{P}\)</span> there are five possibilities: <span class="math inline">\(P \succ T\)</span> or <span class="math inline">\(P \sim S\)</span> or <span class="math inline">\(S \succ P \succ T\)</span> or <span class="math inline">\(P \sim T\)</span> or <span class="math inline">\(T \succ P\)</span>.</p>
<p>In the first case define <span class="math inline">\(1/U(P)\)</span> to be the unique <span class="math inline">\(p\)</span> (see previous theorem) defined by <span class="math inline">\(p P + ( 1 -p )T \sim S\)</span>. In the second case, define <span class="math inline">\(U(P) =1\)</span>. In the third, there exists a unique <span class="math inline">\(q\)</span> with <span class="math inline">\(q S + ( 1 -q )T \sim P\)</span> and then define <span class="math inline">\(U(P)=q\)</span>. In the fourth case, define <span class="math inline">\(U(P)=0\)</span> and finally when <span class="math inline">\(T \succ P\)</span> there exists a unique <span class="math inline">\(r\)</span> with <span class="math inline">\(r S + ( 1-r )P \sim T\)</span> and then we define <span class="math inline">\(U(P) = - r / (1 - r)\)</span>.</p>
<p>Then check that <span class="math inline">\(U(P)\)</span> satisfies the conditions. See Savage (1954), Ramsey (1927) and de Finetti (1931)</p>
</div>
<p>Other interesting extensions: how do people come to a consensus (DeGroot, 1974, Morris, 1994, 1996). Ramsey (1926) observation that if someone is willing to offer you a bet then that’s conditioning information for you. All probabilities are conditional probabilities.</p>
<p>If the bet outcome <span class="math inline">\(P\)</span> is a monetary value, then the utility functions <span class="math inline">\(P, P^2, \sqrt{P}, \ln P\)</span> are all monotonically increasing (the more the better). However, the utility function <span class="math inline">\(P^2\)</span> is convex and the utility function <span class="math inline">\(\ln P\)</span> is concave. The concavity of the utility function implies that the agent is risk averse and the convexity implies that the agent is risk seeking.</p>
<div id="exm-stpetersburg" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.1 (Saint Petersburg Paradox)</strong></span> The Saint Petersburg paradox is a concept in probability and decision theory that was first introduced by Daniel Bernoulli in 1738. It revolves around the idea of how individuals value risky propositions and how those valuations may not align with classical expected utility theory.</p>
<p>The paradox is named after the city of Saint Petersburg, where the problem was formulated. Here’s a simplified version of the paradox:</p>
<p>Imagine a gambling game where a fair coin is flipped repeatedly until it lands on heads. The payoff for the game is <span class="math inline">\(2^N\)</span>, where <span class="math inline">\(N\)</span> is the number of tosses needed for the coin to land on heads. The expected value of this game, calculated by multiplying each possible payoff by its probability and summing the results, is infinite:</p>
<p><span class="math display">\[
E(X) = \frac{1}{2} \cdot 2 + \frac{1}{4} \cdot 4 + \frac{1}{8} \cdot 8 + \ldots = \infty
\]</span></p>
<p>This means that, in theory, a rational person should be willing to pay any finite amount to play this game, as the expected value is infinite. However, in reality, most people would be unwilling to pay a large amount to play such a game.</p>
<p>The paradox arises because traditional expected utility theory assumes that individuals make decisions based on maximizing their expected gain. Bernoulli argued that people do not maximize expected monetary value but rather expected utility, where utility is a subjective measure of satisfaction or happiness. He proposed that individuals exhibit diminishing marginal utility for wealth, meaning that the additional satisfaction gained from an extra unit of wealth decreases as total wealth increases.</p>
<p>In the case of the Saint Petersburg paradox, although the expected monetary value is infinite, the utility gained from each additional dollar diminishes rapidly, leading to a reluctance to pay large amounts to play the game.</p>
<p>In modern decision theory and economics, concepts like diminishing marginal utility and expected utility are fundamental in understanding how individuals make choices under uncertainty and risk. The Saint Petersburg paradox highlights the limitations of relying solely on expected monetary value in explaining human behavior in such situations.</p>
<p>One common approach is to consider aspects of potential players, such as their possible risk aversion, available funds, etc., through a utility function <span class="math inline">\(U(x)\)</span>. Applying a utility function in this situation means changing our focus to the quantity <span class="math display">\[
E[U(X)] = \sum^\infty_{k=1} 2^{-k} U(2^k).   
\]</span></p>
<p>Some examples of utility functions are,</p>
<ul>
<li><span class="math inline">\(U(x) = V_0 (1-x^{-\alpha})\)</span>, <span class="math inline">\(\alpha &gt; 0\)</span>, which gives an expected utility of <span class="math inline">\(V_0 \left(1-\frac{1}{2^{\alpha+1}-1}\right)\)</span></li>
<li>Log utility, <span class="math inline">\(U(x) = \log(x)\)</span>, with expected value <span class="math inline">\(2 \log(2)\)</span>.</li>
</ul>
<p>Notice that after obtaining an expected utility value, you’ll have to find the corresponding reward/dollar amount.</p>
<p>For the log utility case, we need to find the certain dollar amount <span class="math inline">\(x^*\)</span> that provides the same utility as playing the game. Setting <span class="math inline">\(U(x^*) = 2\log(2)\)</span>, we solve: <span class="math display">\[
\log(x^*) = 2\log(2) = \log(2^2) = \log(4)
\]</span> which gives <span class="math inline">\(x^* = 4\)</span>. Therefore, under log utility, a rational player would be willing to pay at most $4 to play the Saint Petersburg game, despite its infinite expected monetary value. This is a dramatic reduction from infinity and demonstrates how risk aversion (captured by the concave log utility function) resolves the paradox.</p>
<p>Similarly, for the power utility <span class="math inline">\(U(x) = V_0 (1-x^{-\alpha})\)</span> with <span class="math inline">\(\alpha &gt; 0\)</span>, we have an expected utility of <span class="math inline">\(V_0 \left(1-\frac{1}{2^{\alpha+1}-1}\right)\)</span>. To find the certainty equivalent <span class="math inline">\(x^*\)</span>, we solve: <span class="math display">\[
V_0 (1-(x^*)^{-\alpha}) = V_0 \left(1-\frac{1}{2^{\alpha+1}-1}\right)
\]</span> which simplifies to <span class="math inline">\((x^*)^{-\alpha} = \frac{1}{2^{\alpha+1}-1}\)</span>, giving: <span class="math display">\[
x^* = \left(2^{\alpha+1}-1\right)^{1/\alpha}
\]</span> For example, with <span class="math inline">\(\alpha = 1\)</span>, we get <span class="math inline">\(x^* = (2^2-1)^1 = 3\)</span> dollars. As risk aversion increases (larger <span class="math inline">\(\alpha\)</span>), the certainty equivalent further decreases.</p>
</div>
<p>Now, consider a more general situation, when you have two gambles 1: get <span class="math inline">\(P_1\)</span> for sure, 2: get <span class="math inline">\(P_2 = P_1+k\)</span> and <span class="math inline">\(P_3 = P_1-k\)</span> with probability 1/2. Then we will compare the utility of those gambles <span class="math display">\[
\dfrac{1}{2}U(P_2) + \dfrac{1}{2}U(P_3) \text{ and } U(P_1).
\]</span> If the utility function is linear then we should be indifferent between the two gambles. However, if the utility function is concave then we should prefer the sure thing. This is known as the <em>certainty effect</em>. <span class="math display">\[
\dfrac{1}{2}U(P_2) + \dfrac{1}{2}U(P_3) &lt; U(P_1).
\]</span></p>
<p>The usual situation can be described as follows. Let <span class="math inline">\(\Omega\)</span> be a finite set of possible outcomes with <span class="math inline">\(\Omega = \{ \omega_1 , \ldots , \omega_n \}\)</span>. Let <span class="math inline">\(P_i\)</span> be the consequence that assigns one to outcome <span class="math inline">\(\omega_i\)</span> and zero otherwise and let <span class="math inline">\(P = ( p_1 , \ldots , p_n )\)</span> assign probability <span class="math inline">\(p_i\)</span> to outcome <span class="math inline">\(\omega_i\)</span>. Then we can write the expected utility, <span class="math inline">\(U(P)\)</span>, of the gamble <span class="math inline">\(P\)</span> as <span class="math display">\[
U(P) = \sum_{i=1}^n p_i U( P_i ).
\]</span> That is, the utility of <span class="math inline">\(P\)</span> is the expected value of a random variable <span class="math inline">\(W\)</span> (wealth) that takes the value <span class="math inline">\(U(P_i)\)</span> if the outcome is <span class="math inline">\(\omega_i\)</span>. Therefore, we can write <span class="math inline">\(U(P) = \mathbb{E}_P \left ( U( W ) \right)\)</span>.</p>
<p>This leads us to the notion of <em>risk aversion</em> and a categorization of agents according to their risk tolerance: the agent is said to be</p>
<ol type="1">
<li><em>Risk Averse</em> if <span class="math inline">\(\mathbb{E}_P \left ( U(W) \right ) \leq u \left (  \mathbb{E}_P  (W)  \right )\)</span></li>
<li><em>Risk Neutral</em> if <span class="math inline">\(\mathbb{E}_P \left ( U(W) \right ) =    u \left (  \mathbb{E}_P  (W)  \right )\)</span></li>
<li><em>Risk Seeking</em> if <span class="math inline">\(\mathbb{E}_P \left ( U(W) \right ) \geq u \left (  \mathbb{E}_P  (W)  \right )\)</span></li>
</ol>
<p>Here we assume that these hold for all probabilities and random variables. Risk aversion is equivalent to the agent having concave utility and risk seeking convex.</p>
<div id="exm-risk" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.2 (Risk Aversion)</strong></span> Consider two concave utility functions log-utility (Kelly) <span class="math inline">\(U(W)=\log(W)\)</span> and fractional Kelly <span class="math inline">\(U(W)=\dfrac{W^{1-\gamma} - 1}{1-\gamma}\)</span>, when <span class="math inline">\(\gamma = 1\)</span>, we get the log-utility. Both correspond to different risk aversion levels. The log-utility is a special case of the power utility function, which is defined as <span class="math inline">\(U(W) = \frac{W^{1-\gamma} - 1}{1-\gamma}\)</span> for <span class="math inline">\(\gamma &gt; 0\)</span>. The fractional Kelly criterion is a specific case of the power utility function where <span class="math inline">\(\gamma = 2\)</span>.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.2</span>, <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">500</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>gamma<span class="ot">=</span><span class="dv">2</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a> <span class="co"># Plot this data frame</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">w =</span> w, </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">logu =</span> <span class="fu">log</span>(w), </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">kelly =</span> (w<span class="sc">^</span>(<span class="dv">1</span><span class="sc">-</span>gamma) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> (<span class="dv">1</span><span class="sc">-</span>gamma))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Plot use different y-scales for </span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> w)) <span class="sc">+</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> logu, <span class="at">color =</span> <span class="st">"log utility"</span>), <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> kelly, <span class="at">color =</span> <span class="st">"Kelly criterion"</span>), <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">1.5</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"log utility"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"Kelly criterion"</span> <span class="ot">=</span> <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Convex Utility Functions"</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Wealth (w)"</span>,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Utility"</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">"Utility Type"</span>) <span class="sc">+</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="04-dec_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>w2 <span class="ot">&lt;-</span> <span class="fl">1.5</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>gamme <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Utility function (example: log utility)</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>utility1 <span class="ot">&lt;-</span> <span class="cf">function</span>(w) <span class="fu">log</span>(w)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>utility2 <span class="ot">&lt;-</span> <span class="cf">function</span>(w) (w<span class="sc">^</span>(<span class="dv">1</span> <span class="sc">-</span> gamma) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> gamma)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate expected utility</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>expected_utility <span class="ot">&lt;-</span> p <span class="sc">*</span> <span class="fu">utility1</span>(w1) <span class="sc">+</span> p <span class="sc">*</span> <span class="fu">utility1</span>(w2)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>expected_utility2 <span class="ot">&lt;-</span> p <span class="sc">*</span> <span class="fu">utility2</span>(w1) <span class="sc">+</span> p <span class="sc">*</span> <span class="fu">utility2</span>(w2)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Print expected utility</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Expected utility for log utility:"</span>, expected_utility, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Expected utility for log utility: -0.14 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Expected utility for Kelly criterion:"</span>, expected_utility2, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Expected utility for Kelly criterion: -0.33 </code></pre>
</div>
</div>
<!-- https://www.princeton.edu/~dixitak/Teaching/EconomicsOfUncertainty/Slides&Notes/Notes03.pdf -->
<p>Geometrically, Jensen’s inequality explains the pattern: for a concave function the chord lies below the curve (risk aversion).</p>
</div>
<div id="exm-kelly" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.3 (Kelly Criterion)</strong></span> The Kelly criterion has been used effectively by many practitioners. Ed Thorp, in his book <em>Beat the Dealer</em>, pioneered its use in blackjack and later applied it to investing in financial markets. Since then, many market participants, such as Jim Simons, have stressed the importance of this money management approach. The criterion’s application extends to other domains: Phil Laak described its use for bet sizing in a game-theoretic approach to poker, and Bill Benter applied it to horse racing. Stewart Ethier provided a mathematical framework for multiple outcomes and analyzed a “play the winner” rule in roulette. Claude Shannon also developed a system to detect and exploit unintentionally biased roulette wheels, an endeavor chronicled in the book <em>The Eudaemonic Pie</em>.</p>
<p>Suppose you have $1000 to invest. With probability <span class="math inline">\(0.55\)</span> you will win whatever you wager and with probability <span class="math inline">\(0.45\)</span> you lose whatever you wager. What’s the proportion of capital that leads to the fastest compounded growth rate?</p>
<p>Quoting <span class="citation" data-cites="kelly1956new">Kelly (<a href="references.html#ref-kelly1956new" role="doc-biblioref">1956</a>)</span>, the exponential rate of growth, <span class="math inline">\(G\)</span>, of a gambler’s capital is <span class="math display">\[
G = \lim_{N\to \infty} \frac{1}{N} \log_2 \frac{W_N}{W_0}
\]</span> for initial capital <span class="math inline">\(W_0\)</span> and capital after <span class="math inline">\(N\)</span> bets <span class="math inline">\(W_N\)</span>.</p>
<p>Under the assumption that a gambler bets a fraction of his capital, <span class="math inline">\(\omega\)</span>, each time, we use <span class="math display">\[
W_N = (1+\omega)^W (1-\omega)^L W_0
\]</span> where <span class="math inline">\(W\)</span> and <span class="math inline">\(L\)</span> are the number of wins and losses in <span class="math inline">\(N\)</span> bets. We get <span class="math display">\[
G = p \log_2(1+\omega)+ q \log_2(1-\omega)
\]</span> in which the limit(s) of <span class="math inline">\(\frac{W}{N}\)</span> and <span class="math inline">\(\frac{L}{N}\)</span> are the probabilities <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>, respectively.</p>
<p>This also comes about by considering the sequence of i.i.d. bets with <span class="math display">\[
p ( X_t = 1 ) = p \; \; \text{ and} \; \; p ( X_t = -1 ) = q=1-p
\]</span> We want to find an optimal allocation <span class="math inline">\(\omega^*\)</span> that maximizes the expected long-run growth rate: <span class="math display">\[\begin{align*}
\max_\omega \mathbb{E} \left ( \ln ( 1 + \omega W_T ) \right )
&amp; = p \ln ( 1 + \omega ) + (1 -p) \ln (1 - \omega ) \\
&amp; \leq p \ln p + q \ln q + \ln 2 \; \text{ and} \; \omega^\star = p - q
\end{align*}\]</span></p>
<p>The solution is <span class="math inline">\(w^* = 0.55 - 0.45 = 0.1\)</span>.</p>
<p>Both approaches give the same optimization problem, which, when solved, give the optimal fraction rate <span class="math inline">\(\omega^* = p-q\)</span>, thus, with <span class="math inline">\(p=0.55\)</span>, the optimal allocation is 10% of capital.</p>
<p>We can generalize the rule to the case of asymmetric payouts <span class="math inline">\((a,b)\)</span>. Then the expected utility function is <span class="math display">\[
p \ln ( 1 + b \omega ) + (1 -p) \ln (1 - a \omega )
\]</span> The optimal solution is <span class="math display">\[
\omega^\star = \frac{bp - a q}{ab}
\]</span></p>
<p>If <span class="math inline">\(a=b=1\)</span> this reduces to the pure Kelly criterion.</p>
<p>A common case occurs when <span class="math inline">\(a=1\)</span> and market odds <span class="math inline">\(b=O\)</span>. The rule becomes <span class="math display">\[
\omega^* = \frac{p \cdot O  -q }{O}.
\]</span></p>
<p>Let’s consider another scenario. You have two possible market opportunities: one where it offers you <span class="math inline">\(4/1\)</span> when you have personal odds of <span class="math inline">\(3/1\)</span> and a second one when it offers you <span class="math inline">\(12/1\)</span> while you think the odds are <span class="math inline">\(9/1\)</span>.</p>
<p>In expected return these two scenarios are identical both offering a 33% gain. In terms of maximizing long-run growth, however, they are not identical.</p>
<p><a href="#tbl-kelly" class="quarto-xref">Table&nbsp;<span>4.1</span></a> shows the Kelly criterion advises an allocation that is twice as much capital to the lower odds proposition: <span class="math inline">\(1/16\)</span> weight versus <span class="math inline">\(1/40\)</span>.</p>
<div id="tbl-kelly" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-kelly-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4.1: Kelly rule
</figcaption>
<div aria-describedby="tbl-kelly-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Market</th>
<th>You</th>
<th><span class="math inline">\(\Delta\)</span></th>
<th><span class="math inline">\(\omega^\star\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(4/1\)</span></td>
<td><span class="math inline">\(3/1\)</span></td>
<td><span class="math inline">\(1/4\)</span></td>
<td><span class="math inline">\(1/16\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(12/1\)</span></td>
<td><span class="math inline">\(9/1\)</span></td>
<td><span class="math inline">\(1/10\)</span></td>
<td><span class="math inline">\(1/40\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The optimal allocation <span class="math inline">\(\omega^\star = ( p O - q ) / O\)</span> is <span class="math display">\[
\frac{ (1/4) \times 4 - (3/4) }{4} = \frac{1}{16} \; \text{ and} \;
\frac{ (1/10) \times 12 - (9/10) }{12} = \frac{1}{40}.
\]</span></p>
<p>Note, that although the expected return is the same, the risk is different. The first gamble has a higher variance than the second gamble.</p>
</div>
<p><em>Power utility</em> and log-utilities allow us to model constant relative risk aversion (CRRA). The main advantage is that the optimal rule is unaffected by wealth effects. The CRRA utility of wealth takes the form <span class="math display">\[
U_\gamma (W) = \frac{ W^{1-\gamma} -1 }{1-\gamma}
\]</span></p>
<p>The special case <span class="math inline">\(U(W) = \log (W )\)</span> for <span class="math inline">\(\gamma = 1\)</span>. This leads to a myopic Kelly criterion rule.</p>
</section>
<section id="unintuitive-nature-of-decision-making" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="unintuitive-nature-of-decision-making"><span class="header-section-number">4.2</span> Unintuitive Nature of Decision Making</h2>
<div id="exm-ellberg" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.4 (Ellsberg Paradox: Ambiguity Aversion)</strong></span> The Ellsberg paradox is a thought experiment that was first proposed by Daniel Ellsberg in 1961. It is a classic example of a situation where individuals exhibit ambiguity aversion, meaning that they prefer known risks over unknown risks. The paradox highlights the importance of considering ambiguity when making decisions under uncertainty.</p>
<p>There are two urns each containing 100 balls. It is known that urn A contains 50 red and 50 black, but urn B contains an unknown mix of red and black balls. The following bets are offered to a participant:</p>
<ul>
<li>Bet 1A: get $1 if red is drawn from urn A, $0 otherwise</li>
<li>Bet 2A: get $1 if black is drawn from urn A, $0 otherwise</li>
<li>Bet 1B: get $1 if red is drawn from urn B, $0 otherwise</li>
<li>Bet 2B: get $1 if black is drawn from urn B, $0 otherwise</li>
</ul>
</div>
<div id="exm-allias" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.5 (Allais Paradox: Independence Axiom)</strong></span> The Allais paradox is a choice problem designed by Maurice Allais to show an inconsistency of actual observed choices with the predictions of expected utility theory. The paradox is that the choices made in the second problem seem irrational, although they can be explained by the fact that the independence axiom of expected utility theory is violated.</p>
<p>We run two experiments. In each experiment a participant has to make a choice between two gambles.</p>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Experiment 1</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Gamble <span class="math inline">\({\cal G}_1\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gamble <span class="math inline">\({\cal G}_2\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Chance</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Chance</td>
</tr>
<tr class="odd">
<td style="text-align: center;">$25m</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$25m</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="even">
<td style="text-align: center;">$5m</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">$5m</td>
<td style="text-align: center;">0.89</td>
</tr>
<tr class="odd">
<td style="text-align: center;">$0m</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$0m</td>
<td style="text-align: center;">0.01</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Experiment 2</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Gamble <span class="math inline">\({\cal G}_3\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gamble <span class="math inline">\({\cal G}_4\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Chance</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Chance</td>
</tr>
<tr class="odd">
<td style="text-align: center;">$25</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$25m</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="even">
<td style="text-align: center;">$5</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">$5m</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">$0m</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">$0m</td>
<td style="text-align: center;">0.9</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>The difference in expected gains is identical in two experiments</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>E1 <span class="ot">=</span> <span class="dv">5</span><span class="sc">*</span><span class="dv">1</span> </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>E2 <span class="ot">=</span> <span class="dv">25</span><span class="sc">*</span><span class="fl">0.1</span> <span class="sc">+</span> <span class="dv">5</span><span class="sc">*</span><span class="fl">0.89</span> <span class="sc">+</span> <span class="dv">0</span><span class="sc">*</span><span class="fl">0.01</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>E3 <span class="ot">=</span> <span class="dv">5</span><span class="sc">*</span><span class="fl">0.11</span> <span class="sc">+</span> <span class="dv">0</span><span class="sc">*</span><span class="fl">0.89</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>E4 <span class="ot">=</span> <span class="dv">25</span><span class="sc">*</span><span class="fl">0.1</span> <span class="sc">+</span> <span class="dv">0</span><span class="sc">*</span><span class="fl">0.9</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">c</span>(E1<span class="sc">-</span>E2,E3<span class="sc">-</span>E4))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> -2 -2</code></pre>
</div>
</div>
<p>However, typically a person prefers <span class="math inline">\({\cal G}_1\)</span> to <span class="math inline">\({\cal G}_2\)</span> and <span class="math inline">\({\cal G}_4\)</span> to <span class="math inline">\({\cal G}_3\)</span>, we can conclude that the expected utilities of the preferred is greater than the expected utilities of the second choices. The fact is that if <span class="math inline">\({\cal G}_1 \geq {\cal G}_2\)</span> then <span class="math inline">\({\cal G}_3 \geq {\cal G}_4\)</span> and vice-versa.</p>
<p>Assuming the subjective probabilities <span class="math inline">\(P = ( p_1 , p_2 , p_3)\)</span>. The expected utility <span class="math inline">\(E ( U | P )\)</span> is <span class="math inline">\(u ( 0 ) = 0\)</span> and for the high prize set <span class="math inline">\(u ( \$ 25 \; \text{million} ) = 1\)</span>. Which leaves one free parameter <span class="math inline">\(u = u ( \$ 5 \; \text{million} )\)</span>.</p>
<p>Hence to compare gambles with probabilities <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> we look at the difference <span class="math display">\[
E ( u | P ) - E ( u | Q ) = ( p_2 - q_2 ) u + ( p_3 - q_3 )
\]</span></p>
<p>For comparing <span class="math inline">\({\cal G}_1\)</span> and <span class="math inline">\({\cal G}_2\)</span> we get <span class="math display">\[\begin{align*}
E ( u | {\cal G}_1 ) - E ( u | {\cal G}_2 ) &amp;= 0.11 u - 0.1 \\
E ( u | {\cal G}_3 ) - E ( u | {\cal G}_4 ) &amp;= 0.11 u - 0.1
\end{align*}\]</span> The order is the same, given your <span class="math inline">\(u\)</span>. If your utility satisfies <span class="math inline">\(u &lt; 0.1/0.11 = 0.909\)</span> you take the “riskier” gamble.</p>
</div>
<div id="exm-Curse" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.6 (Winner’s Curse)</strong></span> One of the interesting facts about expectation is that when you are in a competitive auctioning game then you shouldn’t value things based on pure expected value. You should take into consideration the event that you win <span class="math inline">\(W\)</span>. Really you should be calculating <span class="math inline">\(E(X\mid W)\)</span> rather than <span class="math inline">\(E(X)\)</span>.</p>
<p>The winner’s curse: given that you win, you should feel regret: <span class="math inline">\(E(X\mid W) &lt; E(X)\)</span>.</p>
<p>A good example is claiming racehorse whose value is uncertain.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Value</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>horse never wins</td>
</tr>
<tr class="even">
<td>50,000</td>
<td>horse improves</td>
</tr>
</tbody>
</table>
<p>Simple expected value tells you <span class="math display">\[
E(X) = \frac{1}{2} \cdot 0 + \frac{1}{2} \cdot 50,000 = \$25,000.
\]</span> In a $20,000 claiming race (you can buy the horse for this fixed fee ahead of time from the owner) it looks like a simple decision to claim the horse.</p>
<p>It’s not so simple! We need to calculate a conditional expectation. What’s <span class="math inline">\(E( X\mid W )\)</span>, given you win event (<span class="math inline">\(W\)</span>)? This is the expected value of the horse given that you win that is relevant to assessing your bid. In most situations <span class="math inline">\(E(X\mid W) &lt; 20,000\)</span>.</p>
<p>Another related feature of this problem is <em>asymmetric information</em>. The owner or trainer of the horse may know something that you don’t know. There’s a reason why they are entering the horse into a claiming race in the first place.</p>
<p>Winner’s curse implies that immediately after you have won, you should feel a little regret, as the object is less valuable to you after you have won! Or put another way, in an auction nobody else in the room is willing to offer more than you at that time.</p>
</div>
<div id="exm-hat" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.7 (The Hat Problem)</strong></span> There are <span class="math inline">\(N\)</span> prisoners in a forward facing line. Each guy is wearing a blue or red hat. Everyone can see all the hats in front of him, but cannot see his own hat. The hats can be in any combination of red and blue, from all red to all blue and every combination in between. The first guy doesn’t know his own hat.</p>
<p>A guard is going to walk down the line, starting in the back, and ask each prisoner what color hat they have on. They can only answer “blue” or “red.” If they answer incorrectly, or say anything else, they will be shot dead on the spot. If they answer correctly, they will be set free. Each prisoner can hear all of the other prisoners’ responses, as well as any gunshots that indicate an incorrect response. They can remember all of this information.</p>
<p>There is a rule that all can agree to follow such that the first guy makes a choice (“My hat is …”) and everyone after that, including the last guy, will get their color right with probability <span class="math inline">\(1\)</span>. You have a <span class="math inline">\(100\)</span>% chance of saving all but the last prisoner, and a <span class="math inline">\(50\)</span>% chance of saving that one. Here’s the strategy the prisoners have agreed on. The last prisoner counts the number of blue hats worn; if the number is even, the last prisoner yells “blue”, if odd, yells “red”. If the <span class="math inline">\(99\)</span>th prisoner hears “blue”, but counts an odd number of blue hats, then his hat must be blue so that the total number of blue hats is even. If he counts an even number of blue hats, then his hat must be red. If the last prisoner yells red, then 99 knows that there are an odd number of blue hats. So 99 counts the number of blue hats he can see. Again, if they are even, his hat is blue, if odd, his hat is red. The 99th prisoner then yells out the color of his hat and is spared. The next prisoner now knows whether the remaining number of blue hats, including his own, is odd or even, by taking into account whether 99 had a blue hat or not. Then by counting the number of blue hats he sees, he knows the color of his hat. So he yells out the color of his hat and is spared. This saves all but the last prisoner, and there is a <span class="math inline">\(50\)</span>% chance that his hat is the color he shouted out.</p>
<p>One hundred prisoners are too many to work with. Suppose there are two. The last person can save the guy in front of him by shouting out the color of his hat. OK, how about if there are three? The third prisoner can see 0,1, or 2 blue hats. There seem to be three possibilities but only two choices of things to say. But, two of the possibilities have something in common namely the number of blue hats is even. So if the last prisoner yells “blue” then he can tell 1 and 2 that he sees an even number of blue hats. Then the second prisoner, by looking ahead and counting the number of blue hats, knows his must be blue if he sees one blue hat, and red if he sees no blue hats. The last prisoner agrees to yell “red” if the number of blue hats seen is odd. Then if 2 sees a blue hat on 1, his must be red, and if 1 has a red hat, his must be blue. By shouting out the color of his hat, 1 also knows his hat color. Two “blues” or two “reds” in a row mean he wears blue, while one blue and one red means he wears red. OK. This looks like this always works, because there are always only two possibilities as far as the number of blue hats worn they are either even or odd. So, check as in the three-person case that using this strategy (“blue” for an even number of blue hats “red” for an odd number) tells 99 the color of his hat, and then each prisoner in turn can learn the color of his hat by taking into account the parity of the number of blue hats he can see, the parity of the number of blue hats 100 saw and the number of prisoners behind him wearing blue hats.</p>
</div>
<div id="exm-lemons" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.8 (Lemon’s Problem)</strong></span> The lemon problem is an interesting conditional probability puzzle and is a classic example of asymmetric information in economics. It was first proposed by George Akerlof in his 1970 paper “The Market for Lemons: Quality Uncertainty and the Market Mechanism.” The problem highlights the importance of information in markets and how it can lead to adverse selection, where the quality of goods or services is lower than expected.</p>
<p>The basic tenet of the lemons principle is that low-value cars force high-value cars out of the market because of the asymmetrical information available to the buyer and seller of a used car. This is primarily due to the fact that a seller does not know what the true value of a used car is and, therefore, is not willing to pay a premium on the chance that the car might be a lemon. Premium-car sellers are not willing to sell below the premium price so this results in only lemons being sold.</p>
<p>Suppose that a dealer pays $20K for a car and wants to sell for $25K. Some cars on the market are Lemons. The dealer knows whether a car is a lemon. A lemon is only worth $5K. There is asymmetric information as the customer doesn’t know if the particular new car is a lemon. S/he estimates the probability of lemons on the road by using the observed frequency of lemons. We will consider two separate cases:</p>
<ul>
<li>Let’s first suppose only 10% of cars are lemons.</li>
<li>We’ll then see what happens if 50% are lemons.</li>
</ul>
<p>The question is how does the market clear (i.e.&nbsp;at what price do car’s sell). Or put another way does the customer buy the car and if so what price is agreed on? This is very similar to winner’s curse: when computing an expected value what conditioning information should I be taking into account?</p>
<p>In the case where the customer thinks that <span class="math inline">\(p=0.10\)</span> of the car’s are lemons, they are willing to pay <span class="math display">\[
E (X)= \frac{9}{10} \cdot 25 + \frac{1}{10} \cdot 5 = \$ 23 K
\]</span> This is greater than the initial $20 that the dealer paid. The car then sells at $23K <span class="math inline">\(&lt;\)</span> $25K.</p>
<p>Of course, the dealer is disappointed that there are lemons on the road as he is not achieving the full value – missing $2000. Therefore, they should try and persuade the customer its not a lemon by offering a warranty for example.</p>
<p>The more interesting case is when <span class="math inline">\(p=0.5\)</span>. The customer now values the car at <span class="math display">\[
E (X)  = \frac{1}{2} \cdot 25 + \frac{1}{2} \cdot 5 = \$ 15K
\]</span> This is lower than the $20K – the reservation price that the dealer would have for a good car. Now what type of car and at what price do they sell?</p>
<p>The key point in asymmetric information is that the customer must condition on the fact that if the dealer still wants to sell the car, the customer must update his probability of the type of the car. We already know that if the car is not a lemon, the dealer won’t sell under his initial cost of $20K. So at $15K he is only willing to sell a lemon. But then if the customer computes a conditional expectation <span class="math inline">\(E( X \mid \mathrm{Lemon})\)</span> – conditioning on new information that the car is a lemon <span class="math inline">\(L\)</span> we get the valuation <span class="math display">\[
E ( X \mid L ) = 1 \cdot  5 = \$ 5K
\]</span> Therefore only lemons sell, at $ 5K, even if the dealer has a perfectly good car the customer is not willing to buy!</p>
<p>Again what should the dealer do? Try to raise the quality and decrease the frequency of lemons in the observable market. This type of modeling has all been used to understand credit markets and rationing in periods of loss of confidence.</p>
</div>
<div id="exm-envelope" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.9 (Envelope Paradox)</strong></span> The envelope paradox is a thought experiment or puzzle related to decision-making under uncertainty. It is also known as the “exchange paradox” or the “two-envelope paradox.” The paradox highlights the importance of carefully considering the information available when making decisions under uncertainty and the potential pitfalls of making assumptions about unknown quantities.</p>
<p>A swami puts <span class="math inline">\(m\)</span> dollars in one envelope and <span class="math inline">\(2 m\)</span> in another. He hands on envelope to you and one to your opponent. The amounts are placed randomly and so there is a probability of <span class="math inline">\(\frac{1}{2}\)</span> that you get either envelope.</p>
<p>You open your envelope and find <span class="math inline">\(x\)</span> dollars. Let <span class="math inline">\(y\)</span> be the amount in your opponent’s envelope. You know that <span class="math inline">\(y = \frac{1}{2} x\)</span> or <span class="math inline">\(y = 2 x\)</span>. You are thinking about whether you should switch your opened envelope for the unopened envelope of your friend. It is tempting to do an expected value calculation as follows <span class="math display">\[
E( y) = \frac{1}{2} \cdot  \frac{1}{2} x + \frac{1}{2} \cdot 2 x = \frac{5}{4} x &gt; x
\]</span> Therefore, it looks as if you should switch no matter what value of <span class="math inline">\(x\)</span> you see. A consequence of this, following the logic of backwards induction, that even if you didn’t open your envelope that you would want to switch! Where’s the flaw in this argument?</p>
<p>This is an open-ended problem, but it will not be very confusing if we well understand both the frequentist and bayesian approaches. Actually, this is a very good example to show how these two approaches are different and to check if we understand them correctly. There many conditions in this problem, so we cannot argue everything in this example; instead, we are going to focus on some interesting cases. First, assume we’re risk-neutral (although, we can simply change “money” with “utility” in this paradox, so it doesn’t matter). We will compare frequentist/bayesian, open/not open, and discrete/continuous. The finite, or bounded space, case will not be considered here since they are not very interesting.</p>
<p>If I DO NOT look in my envelope, in this case, even from a frequentist viewpoint, we can find a fallacy in this naive expectation reasoning <span class="math inline">\(E[trade] = 5X/4\)</span> . First, the right answer from a frequentist view is, loosely, as follows. If we switch the envelope, we can obtain <span class="math inline">\(m\)</span> (when <span class="math inline">\(X = m\)</span>) or lose <span class="math inline">\(m\)</span> (when <span class="math inline">\(X = 2m\)</span>) with the same probability <span class="math inline">\(1/2\)</span>. Thus, the value of a trade is zero, so that trading matters not for my expected wealth.</p>
<p>Instead, naive reasoning is confusing the property of variables <span class="math inline">\(x\)</span> and <span class="math inline">\(m\)</span>, <span class="math inline">\(x\)</span> is a random variable and <span class="math inline">\(m\)</span> is a fixed parameter which is constant (again, from a frequentist viewpoint). By trading, we can obtain <span class="math inline">\(x\)</span> or lose <span class="math inline">\(x/2\)</span> with the same probability. Here, the former <span class="math inline">\(x=m\)</span> is different from the latter <span class="math inline">\(X= 2m\)</span>. Thus, <span class="math inline">\(X \frac{1}{2} - \frac{X}{2} \frac{1}{2} = \frac{X}{4}\)</span> is the wrong expected value of trading. On the other hand, from a bayesian view, since we have no information, we are indifferent to either trading or not.</p>
<p>The second scenario is if I DO look in my envelope. As the Christensen &amp; Utts (1992) article said, the classical view cannot provide a completely reasonable resolution to this case. It is just ignoring the information revealed. Also, the arbitrary decision rule introduced at the end of the paper or the extension of it commented by Ross (1996) are not the results of reasoning from a classical approach. However, the bayesian approach provides a systematic way of finding an optimal decision rule using the given information.</p>
<p>We can use the Bayes rule to update the probabilities of which envelope your opponent has! Assume <span class="math inline">\(p(m)\)</span> of dollars to be placed in the envelope by the swami. Such an assumption then allows us to calculate an odds ratio <span class="math display">\[
\frac{ p \left ( y = \frac{1}{2} x | x \right ) }{ p \left ( y = 2 x | x \right ) }
\]</span> concerning the likelihood of which envelope your opponent has.</p>
<p>Then, the expected value is given by <span class="math display">\[
E(y\mid x) =  p \left ( y = \frac{1}{2} x \mid  x \right ) \cdot  \frac{1}{2} x +
  p \left ( y = 2 x | x \right ) \cdot 2 x
\]</span> and the condition <span class="math inline">\(E(y) &gt; x\)</span> becomes a decision rule.</p>
<p>Let <span class="math inline">\(g(m)\)</span> be the prior distribution of <span class="math inline">\(m\)</span>. Applying Bayes’ theorem, we have <span class="math display">\[
p(m = x \mid X = x) = \frac{p(X = x \mid m = x) g(x)}{p(X = x)} = \frac{g(x)}{g(x)+g(x/2)}.
\]</span> Similarly, we have <span class="math display">\[
p(m = x/2 \mid X = x) = \frac{p(X = x \mid m = x/2) g(x/2)}{p(X = x/2)} = \frac{g(x/2)}{g(x)+g(x/2)}.
\]</span> The Bayesian can now compute his expected winnings from the two actions. If he keeps the envelope he has, he wins <span class="math inline">\(x\)</span> dollars. If he trades envelopes, he wins <span class="math inline">\(x/2\)</span> if he currently has the envelope with <span class="math inline">\(2m\)</span> dollars, i.e., if <span class="math inline">\(m = x/2\)</span> and he wins <span class="math inline">\(2\)</span>x if he currently has the envelope with <span class="math inline">\(m\)</span> dollars, i.e., <span class="math inline">\(m = x\)</span>. His expected winnings from a trade are <span class="math display">\[
E(W\mid Trade) = E(Y\mid X = x) = \frac{g(x/2)}{g(x)+g(x/2)} \frac{x}{2} + \frac{g(x)}{g(x)+g(x/2)} 2x.
\]</span> It is easily seen that when <span class="math inline">\(g(x/2) = 2g(x)\)</span>, <span class="math inline">\(E(W\mid Trade) = x\)</span>. Therefore, if <span class="math inline">\(g(x/2) &gt; 2g(x)\)</span> it is optimal to keep the envelope and if <span class="math inline">\(g(x/2) &lt; 2g(x)\)</span> it is optimal to trade envelopes. For example, if your prior distribution on <span class="math inline">\(m\)</span> is exponential <span class="math inline">\(\lambda\)</span>, so that <span class="math inline">\(g(m) = \lambda e^{-\lambda m}\)</span>, then it is easily seen that it is optimal to keep your envelope if <span class="math inline">\(x &gt; 2\log(2)/\lambda\)</span>.</p>
<p>The intuitive value of the expected winnings when trading envelopes was shown to be <span class="math inline">\(5x/4\)</span>. This value can be obtained by assuming that <span class="math inline">\(g(x)/[g(x) + g(x/2)] =
1/2\)</span> for all <span class="math inline">\(x\)</span>. In particular, this implies that <span class="math inline">\(g(x) = g(x/2)\)</span> for all x, i.e., <span class="math inline">\(g(x)\)</span> is a constant function. In other words, the intuitive expected winnings assumes an improper “noninformative” uniform density on <span class="math inline">\([0, \infty)\)</span>. It is of interest to note that the improper noninformative prior for this problem gives a truly noninformative (maximum entropy) posterior distribution.</p>
<p>Most of the arguments in the Christensen &amp; Utts (1992) paper are right, but there is one serious error in the article which is corrected in Bachman-Christensen-Utts (1996) and discussed in Brams &amp; Kilgour (1995). The paper calculated the marginal density of <span class="math inline">\(X\)</span> like below. <span class="math display">\[\begin{align*}
p(X = x) &amp;= p(m = x)g(x) + p(2m = x)g(x/2) \\
&amp;= \frac{1}{2} g(x) + \frac{1}{2} g(x/2)
\end{align*}\]</span> where <span class="math inline">\(g(x)\)</span> is the prior distribution of <span class="math inline">\(m\)</span>. However, integrating <span class="math inline">\(p(X = x)\)</span> with respect to <span class="math inline">\(x\)</span> from <span class="math inline">\(0\)</span> to <span class="math inline">\(\infty\)</span> gives <span class="math inline">\(3/2\)</span> instead of <span class="math inline">\(1\)</span>. In fact, their calculation of <span class="math inline">\(p(X = x)\)</span> can hold only when the prior distribution <span class="math inline">\(g(x)\)</span> is discrete and <span class="math inline">\(p(X = x)\)</span>, <span class="math inline">\(g(m)\)</span>, <span class="math inline">\(g(m/2)\)</span> represent the probabilities that <span class="math inline">\(X = x\)</span>, <span class="math inline">\(m = m\)</span>, <span class="math inline">\(m = m/2\)</span>, respectively.</p>
<p>For the correct calculation of the continuous <span class="math inline">\(X\)</span> case, one needs to properly transform the distribution. That can be done by remembering to include the Jacobian term alongside the transformed PDF, or by working with the CDF of <span class="math inline">\(X\)</span> instead. The latter forces one to properly consider the transform, and we proceed with that method.</p>
<p>Let <span class="math inline">\(G(x)\)</span> be the CDF of the prior distribution of <span class="math inline">\(m\)</span> corresponding to <span class="math inline">\(g(x)\)</span>. <span class="math display">\[\begin{align*}
p(x &lt; X \leq x+dx) &amp;= p(m = x)dG(x)+ p(2m = x)dG(x/2) \\
&amp;= \frac{1}{2} \left( dG(x)+ dG(x/2) \right)
\end{align*}\]</span> where <span class="math inline">\(g(x) = dG(x)/dx\)</span>. Now, the PDF of <span class="math inline">\(X\)</span> is <span class="math display">\[\begin{align*}
f_X(x) &amp;= \frac{d}{dx} p(x &lt; X \leq x + dx) \\
&amp;= \frac{1}{2} \left(g(x) + \frac{1}{2} g(x/2) \right)
\end{align*}\]</span> We have an additional <span class="math inline">\(1/2\)</span> in the last term due to the chain rule, or the Jacobian in the change-in-variable formula. Therefore, the expected amount of a trade is <span class="math display">\[\begin{align*}
E(Y\mid X = x) &amp;= \frac{x}{2} p(2m = x\mid X = x) + 2 x \, p(m = x\mid X = x) \\
&amp;= \frac{x}{2} \frac{g(x)}{g(x) + g(x/2)/2} + 2 x \frac{g(x/2)/2}{g(x) + g(x/2)/2} \\
&amp;=  \frac{\frac{x}{2}g(x) + x g(x/2)}{g(x) + g(x/2)/2}
\end{align*}\]</span></p>
<p>Thus, for the continuous case, trading is advantageous whenever <span class="math inline">\(g(x/2) &lt; 4g(x)\)</span>, instead of the decision rule for the discrete case <span class="math inline">\(g(x/2) &lt; 2g(x)\)</span>.</p>
<p>Now, think about which prior will give you the same decision rule as the frequentist result. In the discrete case, <span class="math inline">\(g(x)\)</span> such that <span class="math inline">\(g(x/2) = 2g(x)\)</span>, and in the continuous case <span class="math inline">\(g(x)\)</span> such that <span class="math inline">\(g(x/2) = 4g(x)\)</span>. However, both do not look like useful, non-informative priors. Therefore, the frequentist approach does not always equal the Bayes approach with a non-informative prior. At the moment you start to treat <span class="math inline">\(x\)</span> as a given number, and consider <span class="math inline">\(p(m \mid X = x)\)</span> (or <span class="math inline">\(p(Y \mid X = x)\)</span>), you are thinking in a bayesian way, and need to understand the implications and assumptions in that context.</p>
</div>
</section>
<section id="decision-trees" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="decision-trees"><span class="header-section-number">4.3</span> Decision Trees</h2>
<p>Decision trees can effectively model and visualize conditional probabilities. They provide a structured way to break down complex scenarios into smaller, more manageable steps, allowing for clear calculations and interpretations of conditional probabilities.</p>
<p>Each node in a decision tree, including the root, represents an event or condition. The branches represent the possible outcomes of that condition. Along each branch, you’ll often see a probability. This is the chance of that outcome happening, given the condition at the node. As you move down the tree, you’re looking at more specific conditions and their probabilities. The leaves of the tree show the final probabilities of various outcomes, considering all the conditions along the path to that leaf. Thus, the probabilities of the leaves need to sum to 1.</p>
<div id="exm-medical" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.10 (Medical Testing)</strong></span> A patient goes to see a doctor. The doctor performs a test which is 95% sensitive – that is 95 percent of people who are sick test positive and 99% specific – that is 99 percent of the healthy people test negative. The doctor also knows that only 1 percent of the people in the country are sick. Now the question is: if the patient tests positive, what are the chances the patient is sick? The intuitive answer is 99 percent, but the correct answer is 66 percent.</p>
<p>Formally, we have two binary variables, <span class="math inline">\(D=1\)</span> that indicates you have a disease and <span class="math inline">\(T=1\)</span> that indicates that you test positive for it. The estimates we know already are given by <span class="math inline">\(P(D) = 0.02\)</span>, <span class="math inline">\(P(T\mid D) = 0.95\)</span>, and <span class="math inline">\(P(\bar T \mid \bar D) = 0.99\)</span>. Here we used shortcut notations, instead of writing <span class="math inline">\(P(D=1)\)</span> we used <span class="math inline">\(P(D)\)</span> and instead of <span class="math inline">\(P(D=0)\)</span> we wrote <span class="math inline">\(P(\bar D)\)</span>.</p>
<p>Sometimes it is more intuitive to describe probabilities using a tree rather than tables. The tree below shows the conditional distribution of <span class="math inline">\(D\)</span> and <span class="math inline">\(T\)</span>.</p>
<!-- https://www.mermaidchart.com/app/projects/ab5d5333-d1a5-42f8-ac1d-8e287a49d7b8/diagrams/30323a8e-087d-4321-b95e-7d89ad5d2f25/share/invite/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkb2N1bWVudElEIjoiMzAzMjNhOGUtMDg3ZC00MzIxLWI5NWUtN2Q4OWFkNWQyZjI1IiwiYWNjZXNzIjoiRWRpdCIsImlhdCI6MTc1MDIyMDQxMH0.-AGGtcpIEffJLsS6TEMPxpcZ-vMt9cu8MKU5ZB1hO2Q -->
<!-- ![Medical Diagnostics Decision Tree](fig/Medical-Diagnostics.svg){#fig-medtree} -->
<div class="cell" data-fig-width="4" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-medtree" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-medtree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<pre class="mermaid mermaid-js" data-label="fig-medtree">graph LR
    D --0.2--&gt; d1(D=1)
    D --0.98--&gt; d0(D=0)
    d1--0.95--&gt;t1(T=1)
    d1 --0.05--&gt; t0(T=0)
    d0--0.01--&gt;t10(T=1)
    d0 --0.99--&gt; t00(T=0)
</pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-medtree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1
</figcaption>
</figure>
</div>
</div>
</div>
<p>The result is not as intuitive as in the NBA example. Let’s think about this intuitively. Rather than relying on Bayesian math to help us with this, let us consider another illustration. Imagine that the above story takes place in a small town, with <span class="math inline">\(1,000\)</span> people. From the prior <span class="math inline">\(P(D)=0.02\)</span>, we know that 2 percent, or 20 people, are sick, and <span class="math inline">\(980\)</span> are healthy. If we administer the test to everyone, the most probable result is that 19 of the 20 sick people test positive. Since the test has a 1 percent error rate, however, it is also probable that 9.8 of the healthy people test positive, we round it to 10.</p>
<p>Now if the doctor sends everyone who tests positive to the national hospital, there will be 10 healthy and 19 sick patients. If you meet one, even though you are armed with the information that the patient tested positive, there is only a 66 percent chance this person is sick.</p>
<p>Let’s extend the example and add the utility of the test and the utility of the treatment. Then the decision problem is to treat <span class="math inline">\(a_T\)</span> or not to treat <span class="math inline">\(a_N\)</span>. The Q-function is the function of the state <span class="math inline">\(S \in \{D_0,D_1\}\)</span> and the action <span class="math inline">\(A \in \{a_T,a_N\}\)</span></p>
<table class="caption-top table">
<caption>Utility of the test and the treatment.</caption>
<thead>
<tr class="header">
<th>A/S</th>
<th><span class="math inline">\(a_T\)</span></th>
<th><span class="math inline">\(a_N\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(D_0\)</span></td>
<td>90</td>
<td>100</td>
</tr>
<tr class="even">
<td><span class="math inline">\(D_1\)</span></td>
<td>90</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Then expected utility of the treatment is 90 and no treatment is 98. A huge difference. Given our prior knowledge, we should not treat everyone.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fl">0.02</span><span class="sc">*</span><span class="dv">90</span> <span class="sc">+</span> <span class="fl">0.98</span><span class="sc">*</span><span class="dv">90</span>  <span class="co"># treat</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 90</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fl">0.02</span><span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> (<span class="dv">1</span><span class="fl">-0.02</span>)<span class="sc">*</span><span class="dv">100</span> <span class="co"># do not treat</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 98</code></pre>
</div>
</div>
<p>However, the expected utility will change when our probability of disease changes. Let’s say that we are in a country where the probability of disease is 0.1 or we performed a test and updated our prior probability of disease to some number <span class="math inline">\(p\)</span>. Then the expected utility of the treatment is <span class="math inline">\(E\left[U(a_T)\right]\)</span> is 90 and no treatment is <span class="math display">\[
E\left[U(a_N)\right] = 0\cdot p + 100 \cdot (1-p) = 100(1-p)
\]</span> When we are unsure about the value of <span class="math inline">\(p\)</span> we may want to explore how the optimal decision changes as we vary <span class="math inline">\(p\)</span></p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p, <span class="dv">100</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">xlab =</span> <span class="st">"p"</span>, <span class="at">ylab =</span> <span class="st">"E[U(a)]"</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">90</span>, <span class="at">col=</span><span class="st">"red"</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomleft"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="fu">TeX</span>(<span class="st">"$E[U(a_N)]$"</span>), </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">TeX</span>(<span class="st">"$E[U(a_T)]$"</span>)), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="st">"red"</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">bty=</span><span class="st">'n'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="04-dec_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Expected utility of the treatment and no treatment as a function of the prior probability of disease.</figcaption>
</figure>
</div>
</div>
</div>
<p>If our estimate at the crossover point, then we should be indifferent between treatment and no treatment, if on the left of the crossover point, we should treat, and if on the right, we should not treat. The crossover point is. <span class="math display">\[
100(1-p) = 90, ~p = 0.1
\]</span></p>
<p>The gap of <span class="math inline">\(90-100(1-p)\)</span> is the expected gain from treatment.</p>
<p>Now, let us calculate the value of test, e.g.&nbsp;the change in expected utility from the test. We will need to calculate the posterior probabilities</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(D | T = 0) = P(T = 0 | D) P(D) / P(T = 0)</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>pdt0 <span class="ot">=</span> <span class="fl">0.05</span><span class="sc">*</span><span class="fl">0.02</span><span class="sc">/</span>(<span class="fl">0.05</span><span class="sc">*</span><span class="fl">0.02</span> <span class="sc">+</span> <span class="fl">0.99</span><span class="sc">*</span><span class="fl">0.98</span>) </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pdt0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.001</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected utility given the test is negative </span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># E[U(a_N | T=0)]</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>UN0 <span class="ot">=</span> pdt0<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>pdt0)<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(UN0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 100</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># E[U(a_T | T=0)]</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>UT0 <span class="ot">=</span> pdt0<span class="sc">*</span><span class="dv">90</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>pdt0)<span class="sc">*</span><span class="dv">90</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(UT0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 90</code></pre>
</div>
</div>
<p>Given test is negative, our best action is not to treat. Our utility is 100. What if the test is positive?</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(D | T = 1) = P(T = 1 | D) P(D) / P(T = 1)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>pdt <span class="ot">=</span> <span class="fl">0.95</span><span class="sc">*</span><span class="fl">0.02</span><span class="sc">/</span>(<span class="fl">0.95</span><span class="sc">*</span><span class="fl">0.02</span> <span class="sc">+</span> <span class="fl">0.01</span><span class="sc">*</span><span class="fl">0.98</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pdt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.66</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># E[U(a_N | T=1)]</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>UN1 <span class="ot">=</span> pdt<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>pdt)<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(UN1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 34</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># E[U(a_T | T=1)]</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>UT1 <span class="ot">=</span> pdt<span class="sc">*</span><span class="dv">90</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>pdt)<span class="sc">*</span><span class="dv">90</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(UT1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 90</code></pre>
</div>
</div>
<p>The best option is to treat now! Given the test our strategy is to treat if the test is positive and not treat if the test is negative. Let’s calculate the expected utility of this strategy.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(T=1) = P(T=1 | D) P(D) + P(T=1 | D=0) P(D=0)</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>pt <span class="ot">=</span> <span class="fl">0.95</span><span class="sc">*</span><span class="fl">0.02</span> <span class="sc">+</span> <span class="fl">0.01</span><span class="sc">*</span><span class="fl">0.98</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.029</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(T=0) = P(T=0 | D) P(D) + P(T=0 | D=0) P(D=0)</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>pt0 <span class="ot">=</span> <span class="fl">0.05</span><span class="sc">*</span><span class="fl">0.02</span> <span class="sc">+</span> <span class="fl">0.99</span><span class="sc">*</span><span class="fl">0.98</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pt0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.97</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected utility of the strategy</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>pt<span class="sc">*</span>UT1 <span class="sc">+</span> pt0<span class="sc">*</span>UN0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 100</code></pre>
</div>
</div>
<p>The utility of our strategy of 100 is above the strategy prior to testing (98), this difference of 2 is called the <em>value of information</em>.</p>
</div>
<div id="exm-slide" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.11 (Mudslide)</strong></span> I live in a house that is at risk of being damaged by a mudslide. I can build a wall to protect it. The wall costs $10,000. If there is a mudslide, the wall will protect the house with probability <span class="math inline">\(0.95\)</span>. If there is no mudslide, the wall will not cause any damage. The prior probability of a mudslide is <span class="math inline">\(0.01\)</span>. If there is a mudslide and the wall does not protect the house, the damage will cost $100,0000. Should I build the wall?</p>
<p>Let’s formally solve this as follows:</p>
<ul>
<li>Build a decision tree.</li>
<li>The tree will list the probabilities at each node. It will also list any costs there are you going down a particular branch.</li>
<li>Finally, it will list the expected cost of going down each branch, so we can see which one has the better risk/reward characteristics.</li>
</ul>
<!-- https://www.mermaidchart.com/app/projects/ab5d5333-d1a5-42f8-ac1d-8e287a49d7b8/diagrams/30323a8e-087d-4321-b95e-7d89ad5d2f25/share/invite/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkb2N1bWVudElEIjoiMzAzMjNhOGUtMDg3ZC00MzIxLWI5NWUtN2Q4OWFkNWQyZjI1IiwiYWNjZXNzIjoiRWRpdCIsImlhdCI6MTc1MDIyMDUxMX0.LxikfdSRLuqd3w0a-x8ssYgMk1mUngIr8cIAW5dET8Y -->
<!-- ![](fig/mudslide.svg)
 -->
<div class="cell" data-fig-width="6.5" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-mudslide" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mudslide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<pre class="mermaid mermaid-js" data-label="fig-mudslide">graph LR
    B--"Build: $40, $40.5"--&gt;Y
    B--"Don't Build: $0, $10"--&gt;N
    Y--"Slide: $0, $90"--&gt;yy[Y]
    Y--"No slide $0, $40"--&gt;40
    N--"Slide: $1000, $1000"--&gt;1000
    N--"No slide $0, $0"--&gt;0
    yy --"Hold: $0, $40"--&gt;401[40]
    yy --"Not Hold: $1000, $1040"--&gt;1040
</pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-mudslide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2
</figcaption>
</figure>
</div>
</div>
</div>
<p>The first dollar value is the cost of the edge, e.g.&nbsp;the cost of building the wall is $10,000. The second dollar value is the expected cost of going down that branch. For example, if you build the wall and there is a mudslide, the expected cost is $15,000. If you build the wall and there is no mudslide, the expected cost is $10,000. The expected cost of building the wall is $10,050. The expected cost of not building the wall is $1,000. The expected cost of building the wall is greater than the expected cost of not building the wall, so you should not build the wall. The dollar value at the leaf nodes is the expected cost of going down that branch. For example, if you build the wall and there is a mudslide and the wall does not hold, the expected cost is $110,000.</p>
<p>There’s also the possibility of a further test to see if the wall will hold. Let’s include the geological testing option. The test costs $3000 and has the following accuracies. <span class="math display">\[
P( T  \mid  \mathrm{Slide} ) = 0.90 \; \; \mathrm{and } \; \; P( \mathrm{not~}T  \mid
\mathrm{No \; Slide} ) = 0.85
\]</span> If you choose the test, then should you build the wall?</p>
<p>Let’s use the Bayes rule. The initial prior probabilities are <span class="math display">\[
P( Slide ) = 0.01  \; \; \mathrm{and} \; \; P ( \mathrm{No \; Slide} ) = 0.99
\]</span></p>
<p><span class="math display">\[\begin{align*}
P( T) &amp; = P( T  \mid  \mathrm{Slide} ) P( \mathrm{Slide} ) +
P( T  \mid  \mathrm{No \;  Slide} ) P( \mathrm{No \; Slide} ) \\
P(T)&amp; = 0.90 \times 0.01 + 0.15 \times 0.99 = 0.1575
\end{align*}\]</span> We’ll use this to find our optimal course of action.</p>
<p>The posterior probability given a positive test is <span class="math display">\[\begin{align*}
P ( Slide  \mid  T ) &amp; = \frac{ P ( T  \mid  Slide ) P ( Slide )}{P(T)} \\
&amp; = \frac{ 0.90 \times 0.01}{ 0.1575} = 0.0571
\end{align*}\]</span></p>
<p>The posterior probability given a negative test is <span class="math display">\[\begin{align*}
P \left ( \mathrm{Slide}  \mid  \mathrm{not~}T \right ) &amp; = \frac{ P ( \mathrm{not~}T  \mid  \mathrm{Slide} ) P ( \mathrm{Slide} )}{P(\mathrm{not~}T)} \\
&amp; = \frac{0.1 \times 0.01 }{0.8425} \\
&amp; =0.001187
\end{align*}\]</span></p>
<p>Compare this to the initial base rate of a <span class="math inline">\(1\)</span>% chance of having a mud slide.</p>
<p>Given that you build the wall without testing, what is the probability that you’ll lose everything? With the given situation, there is one path (or sequence of events and decisions) that leads to losing everything:</p>
<ul>
<li>Build without testing (given) Slide (<span class="math inline">\(0.01\)</span>)</li>
<li>Doesn’t hold (<span class="math inline">\(0.05\)</span>) <span class="math display">\[
P ( \mathrm{losing} \; \mathrm{everything}  \mid  \mathrm{build} \; \mathrm{w/o} \;
\mathrm{testing} ) = 0.01 \times 0.05 = 0.0005
\]</span></li>
</ul>
<p>Given that you choose the test, what is the probability that you’ll lose everything? There are two paths that lead to losing everything:</p>
<ul>
<li><p>There are three things that have to happen to lose everything. Test +ve (<span class="math inline">\(P=0.1575\)</span>), Build, Slide (<span class="math inline">\(P= 0.0571\)</span>), Doesn’t Hold (<span class="math inline">\(P=0.05\)</span>)</p></li>
<li><p>Now you lose everything if Test -ve (<span class="math inline">\(P=0.8425\)</span>), Don’t Build, Slide given negative (<span class="math inline">\(P=0.001187\)</span>).</p></li>
</ul>
<p>The conditional probabilities for the first path <span class="math display">\[
P ( \mathrm{first} \; \mathrm{path} ) = 0.1575 \times 0.0571 \times 0.05
= 0.00045
\]</span></p>
<p>For the second path <span class="math display">\[
P ( \mathrm{second} \; \mathrm{path} ) = 0.8425 \times 0.001187 = 0.00101
\]</span></p>
<p>Hence putting it all together <span class="math display">\[
P ( \mathrm{losing} \; \mathrm{everything}  \mid  \mathrm{testing} ) = 0.00045 + 0.00101 = 0.00146
\]</span></p>
<p>Putting these three cases together we can build a risk/reward table</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Choice</th>
<th>Expected Cost</th>
<th>Risk</th>
<th>P</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Don’t Build</td>
<td>$1,000</td>
<td>0.01</td>
<td>1 in 100</td>
</tr>
<tr class="even">
<td>Build w/o testing</td>
<td>$10,050</td>
<td>0.0005</td>
<td>1 in 2000</td>
</tr>
<tr class="odd">
<td>Test</td>
<td>$4,693</td>
<td>0.00146</td>
<td>1 in 700</td>
</tr>
</tbody>
</table>
<p>The expected cost with the test is <span class="math inline">\(3000+10000\times 0.1575+100000\times 0.001187 = 4693\)</span></p>
<p>What do you choose?</p>
</div>
</section>
<section id="nash-equilibrium" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="nash-equilibrium"><span class="header-section-number">4.4</span> Nash Equilibrium</h2>
<p>When multiple decision makers interact with each other, meaning the decision of one player changes the state of the “world” and thus affects the decision of another player, then we need to consider the notion of equilibrium. It is a central concept in economics and game theory. The most widely used type of equilibrium is the Nash equilibrium, named after John Nash, who introduced it in his 1950 paper “Equilibrium Points in N-Person Games.” It was popularized by the 1994 film “A Beautiful Mind,” which depicted Nash’s life and work.</p>
<p>It is defined as a set of strategies where no player can improve their payoff by unilaterally changing their strategy, assuming others keep their strategies constant. In other words, a Nash equilibrium is a set of strategies where no player has an incentive to deviate from their current strategy, given the strategies of the other players.</p>
<p>Here are a few examples of Nash equilibria:</p>
<ul>
<li>Prisoner’s Dilemma: Two prisoners must decide whether to cooperate with each other or defect. The Nash equilibrium is for both to defect, even though they would be better off if they both cooperated.</li>
<li>Pricing Strategies: Firms in a market choose prices to maximize profits, taking into account their competitors’ pricing decisions. The equilibrium is the set of prices where no firm can increase profits by changing its price unilaterally.</li>
<li>Traffic Flow: Drivers choose routes to minimize travel time, based on their expectations of other drivers’ choices. The equilibrium is the pattern of traffic flow where no driver can reduce their travel time by choosing a different route.</li>
</ul>
<div id="exm-titfortat" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.12 (Marble Game)</strong></span> Here is a subtle marble game where players have to call out (or present) either red or blue with different payoffs according to how things match. Two players <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have both a red and a blue marble. They present one marble to each other. The payoff table is as follows:</p>
<ul>
<li>If both present red, <span class="math inline">\(A\)</span> wins $3.</li>
<li>If both present blue, <span class="math inline">\(A\)</span> wins $1.</li>
<li>If the colors do not match, <span class="math inline">\(B\)</span> wins $2</li>
</ul>
<p>The question is whether it is better to be <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> or does it matter? Moreover, what kind of strategy should you play? A lot depends on how much credit you give your opponent. A lot of empirical research has studying the <em>tit-for-tat</em> strategy, where you cooperate until your opponent defects. Then you match his last response.</p>
<p>Nash equilibrium will also allow us to study the concept of a <em>randomized strategy</em> (ie. picking a choice with a certain probability) which turns out to be optimal in many game theory problems.</p>
<p>First, assume that the players have a <span class="math inline">\(\frac{1}{2}\)</span> probability of playing Red or Blue. Thus each player has the same expected payoff <span class="math inline">\(E(A) = \$1\)</span> <span class="math display">\[\begin{align*}
    E(A) &amp;= \frac{1}{4} \cdot 3 + \frac{1}{4} \cdot 1 =1 \\
    E(B) &amp;= \frac{1}{4} \cdot 2 + \frac{1}{4} \cdot 2 =1
\end{align*}\]</span> We might go one step further and look at the risk (and measured by a standard deviation) and calculate the variances of each players payout <span class="math display">\[\begin{align*}
    Var (A) &amp; = (1-1)^2 \cdot \frac{1}{4} +(3-1)^2 \cdot \frac{1}{4} + (0-1)^2 \cdot \frac{1}{2} = 1.5 \\
    Var(B) &amp; = 1^2 \cdot \frac{1}{2} + (2-1)^2 \cdot \frac{1}{2} = 1
\end{align*}\]</span> Therefore, under this scenario, if you are risk averse, player <span class="math inline">\(B\)</span> position is favored.</p>
<p>The matrix of probabilities with equally likely choices is given by</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(A,B\)</span></th>
<th>Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P( red, red )\)</span></td>
<td>(1/2)(1/2)=1/4</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P( red, blue )\)</span></td>
<td>(1/2)(1/2)=1/4</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(P( blue, red )\)</span></td>
<td>(1/2)(1/2)=1/4</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P( blue, blue )\)</span></td>
<td>(1/2)(1/2)=1/4</td>
</tr>
</tbody>
</table>
<p>Now there is no reason to assume ahead of time that the players will decide to play <span class="math inline">\(50/50\)</span>. We will show that there’s a mixed strategy (randomized) that is a <em>Nash equilibrium</em> that is, both players won’t deviate from the strategy. We’ll prove that the following equilibrium happens:</p>
<ul>
<li><span class="math inline">\(A\)</span> plays Red with probability 1/2 and blue 1/2</li>
<li><span class="math inline">\(B\)</span> plays Red with probability 1/4 and blue 3/4</li>
</ul>
<p>In this case the expected payoff to playing Red equals that of playing Blue for each player. We can simply calculate: <span class="math inline">\(A\)</span>’s expected payoff is 3/4 and <span class="math inline">\(B\)</span>’s is $1 <span class="math display">\[
E(A) = \frac{1}{8} \cdot 3 + \frac{3}{8} \cdot 1 = \frac{3}{4}
\]</span> Moreover, <span class="math inline">\(E(B) =1\)</span>, thus <span class="math inline">\(E(B) &gt; E(A)\)</span>. We see that <span class="math inline">\(B\)</span> is the favored position. It is clear that if I know that you are going to play this strategy and vice-versa, neither of us will deviate from this strategy – hence the Nash equilibrium concept.</p>
<p>Nash equilibrium probabilities are: <span class="math inline">\(p=P( A \; red )= 1/2, p_1 = P( B \; red ) = 1/4\)</span> with payout matrix</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(A,B\)</span></th>
<th>Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P( red, red )\)</span></td>
<td>(1/2)(1/4)=1/8</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P( red, blue )\)</span></td>
<td>(1/2)(3/4)=3/8</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(P( blue, red )\)</span></td>
<td>(1/2)(1/4)=1/8</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P( blue, blue )\)</span></td>
<td>(1/2)(3/4)=3/8</td>
</tr>
</tbody>
</table>
<p>We have general payoff probabilities: <span class="math inline">\(p=P( A \; red ), p_1 = P( B \; red )\)</span></p>
<p><span class="math display">\[\begin{align*}
    f_A ( p , p_1 ) =&amp; 3 p p_1 + ( 1 -p ) ( 1 - p_1 ) \\
    f_B ( p , p_1 ) =&amp; 2 \{ p(1 - p_1) + ( 1 -p ) p_1 \}
\end{align*}\]</span></p>
<p>To find the equilibrium point <span class="math display">\[\begin{align*}
    ( \partial / \partial p ) f_A ( p , p_1 ) =&amp; 3 p_1 - ( 1 - p_1 ) = 4 p_1 -1 \; \; \mathrm{so} \; \; p_1= 1/4 \\
    ( \partial / \partial p_1 ) f_B ( p , p_1 ) =&amp; 2 ( 1 - 2p ) \; \; \mathrm{so} \; \; p= 1/2
\end{align*}\]</span></p>
<p>Much research has been directed to repeated games versus the one-shot game and is too large a topic to discuss further.</p>
</div>
<p>Equilibrium analysis helps predict the likely outcomes of strategic interactions, even when individuals are acting in their own self-interest. Further, we can use it to understand how markets function and how firms make pricing and production decisions or to design mechanisms (e.g., auctions, voting systems) that incentivize desired behavior and achieve efficient outcomes.</p>
<p>One major drawback is that equilibrium analysis relies on assumptions about rationality and common knowledge of preferences and strategies, which may not always hold in real-world situations. Furthermore, some games may have multiple equilibria, making it difficult to predict which one will be reached. The problem of dynamic strategies, when individuals may learn and adjust their strategies as they gain experience, is hard.</p>
</section>
<section id="statistical-decisions-and-risk" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="statistical-decisions-and-risk"><span class="header-section-number">4.5</span> Statistical Decisions and Risk</h2>
<p>The statistical decision making problem can be posed as follows. A decision maker (you) has to chose from a set of decisions or acts. The consequences of these decisions depend on an unknown state of the world. Let <span class="math inline">\(d\in\mathcal{D}\)</span> denote the decision and <span class="math inline">\(\theta\in\Theta\)</span> the state of the world. As an example, think of <span class="math inline">\(\theta\)</span> as the unknown parameter and the decision as choosing a parameter estimation or hypothesis testing procedure. To provide information about the parameter, the decision maker obtains a sample <span class="math inline">\(y\in\mathcal{Y}\)</span> that is generated from the likelihood function <span class="math inline">\(p\left(y|\theta\right)\)</span>. The resulting decision depends on the observed data, is denoted as <span class="math inline">\(d\left(  y\right)\)</span>, and is commonly called the decision rule.</p>
<p>To make the decision, the decision maker uses a “loss” function as a quantitative metric to assesses the consequences or performance of different decisions. For each state of the world <span class="math inline">\(\theta\)</span>, and decision <span class="math inline">\(d\)</span>, <span class="math inline">\(\mathcal{L}\left(  \theta,d\right)\)</span> quantifies the “loss” made by choosing <span class="math inline">\(d\)</span> when the state of the world is <span class="math inline">\(\theta.\)</span> Common loss functions include a quadratic loss, <span class="math inline">\(\mathcal{L}(\theta,d)=(\theta-d)^{2},\)</span> an absolute loss, <span class="math inline">\(\mathcal{L}(\theta,d)=|\theta-d|\)</span>, and a <span class="math inline">\(0-1\)</span> loss, <span class="math display">\[
\mathcal{L}(\theta,d)=L_{0}1_{\left[  \theta\in\Theta_{0}\right]  }+L_{1}1_{\left[  \theta\in\Theta_{1}\right]  }.
\]</span> For Bayesians, the utility function provides a natural loss function. Historically, decision theory was developed by classical statisticians, thus the development in terms of “objective” loss functions instead of “subjective” utility.</p>
<p>Classical decision theory takes a frequentist approach, treating parameters as “fixed but unknown” and evaluating decisions based on their population properties. Intuitively, this thought experiment entails drawing a dataset <span class="math inline">\(y\)</span> of given length and applying the same decision rule in a large number of repeated trials and averaging the resulting loss across those hypothetical samples. Formally, the classical risk function is defined as <span class="math display">\[
R(\theta,d)=\int_{\mathcal{Y}}\mathcal{L}\left[  \theta,d(y)\right]  p(y|\theta )dy=\mathbb{E}\left[  \mathcal{L}\left[  \theta,d(y)\right]  |\theta\right]  .
\]</span> Since the risk function integrates over the data, it does not depend on a given observed sample and is therefore an ex-ante or a-priori metric. In the case of quadratic loss, the risk function is the mean-squared error (MSE) and is <span class="math display">\[\begin{align*}
R(\theta,d)  &amp;  =\int_{\mathcal{Y}}\left[  \theta-d\left(  y\right)  \right]
^{2}p(y|\theta)dy\\
&amp;  =\mathbb{E}\left[  \left(  d\left(  y\right)  -E\left[  d\left(  y\right)
|\theta\right]  \right)  ^{2}|\theta\right]  +\mathbb{E}\left[  \left(
E\left[  d\left(  y\right)  |\theta\right]  -\theta\right)  ^{2}|\theta\right]
\\
&amp;  =Var\left(  d\left(  y\right)  |\theta\right)  +\left[  bias\left(
d\left(  y\right)  -\theta\right)  \right]  ^{2}%
\end{align*}\]</span> which can be interpreted as the bias of the decision/estimator plus the variance of the decision/estimator. Common frequentist estimators choose unbiased estimators so that the bias term is zero, which in most settings leads to unique estimators.</p>
<p>The goal of the decision maker is to minimize risk. Unfortunately, rarely is there a decision that minimizes risk uniformly for all parameter values. To see this, consider a simple example of <span class="math inline">\(y\sim N\left(  \theta,1\right)\)</span>, a quadratic loss, and two decision rules, <span class="math inline">\(d_{1}\left(  y\right)  =0\)</span> or <span class="math inline">\(d_{2}\left(  y\right)  =y\)</span>. Then, <span class="math inline">\(R\left(  \theta,d_{1}\right)  =\theta^{2}\)</span> and <span class="math inline">\(R\left(  \theta,d_{2}\right)  =1\)</span>. If <span class="math inline">\(\left\vert \theta\right\vert &lt;1\)</span>, then <span class="math inline">\(R\left(  \theta,d_{1}\right)  &lt;R\left(  \theta,d_{2}\right)\)</span>, with the ordering reversed for <span class="math inline">\(\left\vert \theta\right\vert &gt;1\)</span>. Thus, neither rule uniformly dominates the other.</p>
<p>One way to deal with the lack of uniform domination is to use the minimax principle:&nbsp;first maximize risk as function of <span class="math inline">\(\theta\)</span>, <span class="math display">\[
\theta^{\ast}=\underset{\theta\in\Theta}{\arg\max}R(\theta,d)\text{,}%
\]</span> and then minimize the resulting risk by choosing a decision:<br>
<span class="math display">\[
d_{m}^{\ast}=\underset{d\in\mathcal{D}}{\arg\min}\left[  R(\theta^{\ast },d)\right]  \text{.}%
\]</span> The resulting decision is known as a minimax decision rule. The motivation for minimax is game theory, with the idea that the statistician chooses the best decision rule against the other player, mother nature, who chooses the worst parameter.</p>
<p>The Bayesian approach treats parameters as random and specifies both a likelihood and prior distribution, denoted here by <span class="math inline">\(\pi\left(  \theta\right)\)</span>. The Bayesian decision maker recognizes that both the data and parameters are random, and accounts for both sources of uncertainty when calculating risk. The Bayes risk is defined as<br>
<span class="math display">\[\begin{align*}
r(\pi,d)  &amp;  =\int_{\mathcal{\Theta}}\int_{\mathcal{Y}}\mathcal{L}\left[  \theta ,d(y)\right]  p(y|\theta)\pi\left(  \theta\right)  dyd\theta\\
&amp;  =\int_{\mathcal{\Theta}}R(\theta,d)\pi\left(  \theta\right)  d\theta =\mathbb{E}_{\pi}\left[  R(\theta,d)\right]  ,
\end{align*}\]</span> and thus the Bayes risk is an average of the classical risk, with the expectation taken under the prior distribution. The Bayes decision rule minimizes expected risk:<br>
<span class="math display">\[
d_{\pi}^{\ast}=\underset{d\in\mathcal{D}}{\arg\min}\text{ }r(\pi,d)\text{.}%
\]</span> The classical risk of a Bayes decision rule is defined as <span class="math inline">\(R\left(
\theta,d_{\pi}^{\ast}\right)\)</span>, where <span class="math inline">\(d_{\pi}^{\ast}\)</span> does not depend on <span class="math inline">\(\theta\)</span> or <span class="math inline">\(y\)</span>. Minimizing expected risk is consistent with maximizing posterior expected utility or, in this case, minimizing expected loss. Expected posterior risk is <span class="math display">\[
r(\pi,d)=\int_{\mathcal{Y}}\left[  \int_{\mathcal{\Theta}}\mathcal{L}\left[
\theta,d(y)\right]  p(y|\theta)\pi\left(  \theta\right)  d\theta\right]  dy,
\]</span> where the term in the brackets is posterior expected loss. Minimizing posterior expected loss for every <span class="math inline">\(y\in\mathcal{Y},\)</span> is clearly equivalent to minimizing posterior expected risk, provided it is possibility to interchange the order of integration.</p>
<p>The previous definitions did not explicitly state that the prior distribution was proper, that is, that <span class="math inline">\(\int_{\mathcal{\Theta}}\pi\left(  \theta\right)d\theta=1\)</span>. In some applications and for some parameters, researchers may use priors that do not integrate, <span class="math inline">\(\int_{\Theta}\pi\left(  \theta\right)d\theta=\infty\)</span>, commonly called improper priors. A generalized Bayes rule is one that minimizes <span class="math inline">\(r(\pi,d),\)</span> where <span class="math inline">\(\pi\)</span> is not necessarily a distribution, if such a rule exists. If <span class="math inline">\(r(\pi,d)&lt;\infty\)</span>, then the mechanics of this rule is clear, although its meaning is less clear.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-kelly1956new" class="csl-entry" role="listitem">
Kelly, J. L. 1956. <span>“A <span>New Interpretation</span> of <span>Information Rate</span>.”</span> <em>Bell System Technical Journal</em> 35 (4): 917–26.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./03-bl.html" class="pagination-link" aria-label="Bayesian Learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./05-ab.html" class="pagination-link" aria-label="AB Testing">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">AB Testing</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>