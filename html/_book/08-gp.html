<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; Gaussian Processes – Bayes, AI and Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./09-rl.html" rel="next">
<link href="./07-sp.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-29e2c20b02301cfff04dc8050bf30c7e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7580570a2e354cd56757c689413fca0c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head><body class="nav-sidebar floating fullcontent"><div class="hidden">
<p><span class="math display">\[
\newcommand{\prob}[1]{\operatorname{P}\left(#1\right)}
\newcommand{\Var}[1]{\operatorname{Var}\left(#1\right)}
\newcommand{\sd}[1]{\operatorname{sd}\left(#1\right)}
\newcommand{\Cor}[1]{\operatorname{Corr}\left(#1\right)}
\newcommand{\Cov}[1]{\operatorname{Cov}\left(#1\right)}
\newcommand{\E}[1]{\operatorname{E}\left(#1\right)}
\newcommand{\defeq}{\overset{\text{\tiny def}}{=}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\mini}{minimize}
\]</span></p>
</div>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>





<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="./08-gp.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayes, AI and Deep Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Principles of Data Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-dec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-bl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Parameter Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-ab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">AB Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-hyp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-sp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-gp.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-rl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Unreasonable Effectiveness of Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-pattern.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Pattern Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Linear and Multiple Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Calssification: Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-theoryai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Theory of AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">RCT: Field vs Observational</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-select.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Tree Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-forecasting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Forecasting</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-dlopt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-arch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Image Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">showsln: false</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-prob.html">Bayes</a></li><li class="breadcrumb-item"><a href="./08-gp.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>A Gaussian Process (GP) is a collection of random variables, any finite number of which have a joint Gaussian distribution. It’s a powerful tool for modeling and predicting in various fields, particularly useful for regression and classification tasks in machine learning. A finite collection of <span class="math inline">\(n\)</span> points from Gaussian Process is completely specified by its <span class="math inline">\(n\)</span>-dimensional mean <span class="math inline">\(\mu\)</span> and covariance matrix <span class="math inline">\(\Sigma\)</span>. The index of the GP is a real number <span class="math inline">\(x\)</span> and values are also real numbers. The mean of the process (and a finite collection of points) is defined by function <span class="math inline">\(m(x)\)</span> and covariance is defined by function <span class="math inline">\(k(x, x')\)</span>, where <span class="math inline">\(x\)</span> and <span class="math inline">\(x'\)</span> are points in the index space. The mean function defines the average value of the function at point <span class="math inline">\(x\)</span>, and the covariance function, also known as the kernel, defines the extent to which the values of the function at two points <span class="math inline">\(x\)</span> and <span class="math inline">\(x'\)</span> are correlated.</p>
<p><span class="math inline">\(k(x, x')\)</span>, where <span class="math inline">\(x\)</span> and <span class="math inline">\(x'\)</span> are points in the input space. The mean function defines the average value of the function at point <span class="math inline">\(x\)</span>, and the covariance function, also known as the kernel, defines the extent to which the values of the function at two points <span class="math inline">\(x\)</span> and <span class="math inline">\(x'\)</span> are correlated. In other words, the kernel function is a measure of similarity between two input points. The covariance between two points is higher if they are similar, and lower if they are dissimilar. Thus Gaussian Process is completely specified by its mean function and covariance function and an instance of a one-dimensional GP is a function <span class="math inline">\(f(x): \mathbb{R} \rightarrow \mathbb{R}\)</span>, a typical notation is <span class="math display">\[
f(x) \sim \mathcal{GP}(m(x), k(x, x')).
\]</span> The mean function* <span class="math inline">\(m(x) = \mathbb{E}[f(x)]\)</span> is then represents the expected value of the function at point <span class="math inline">\(x\)</span>, and the <strong>covariance function</strong>: <span class="math inline">\(k(x, x') = \mathbb{E}[(f(x) - m(x))(f(x') - m(x'))]\)</span> describes the amount of dependence between the values of the function at two different points in the input space.</p>
<p>Typically the mean function is less important than the covariance function. Most of the time data scientists will use a zero mean function, <span class="math inline">\(m(x)=0\)</span>, and focus on the covariance function. The kernel function is often chosen to be a function of the distance between the two points <span class="math inline">\(|x-x'|\)</span> or <span class="math inline">\(\|x-x'\|_2\)</span> in higher dimensions. The most commonly used kernel function is the squared exponential kernel, which is a function of the squared distance between the two points. The squared exponential kernel is given by: <span class="math display">\[
k(x, x') = \sigma^2 \exp\left(-\frac{(x - x')^2}{2l^2}\right)
\]</span> where <span class="math inline">\(\sigma^2\)</span> is the variance parameter and <span class="math inline">\(l\)</span> is the length scale parameter. The variance parameter controls the vertical variation of the function (amplitude), and the length scale parameter controls the horizontal variation (number of “bumps”). The length scale parameter determines how far apart two points must be to be considered dissimilar. The larger the length scale, the smoother the function. The length scale parameter is also called the bandwidth parameter. In this case the covariance decays exponentially with the distance between the points. Observe, that <span class="math inline">\(k(x,x) = \sigma^2\)</span> and <span class="math inline">\(k(x,x') \rightarrow 0\)</span> as <span class="math inline">\(|x-x'| \rightarrow \infty\)</span>.</p>
<p>Let’s demonstrate GP using a simulated example. We start by generating a sequence 100 inputs (process indexes)</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">10</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and then define the mean function and the covariance function</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>mean <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">length</span>(x))</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>sqexpcov <span class="ot">=</span> <span class="cf">function</span>(x, x1, <span class="at">l=</span><span class="dv">1</span>, <span class="at">sigma=</span><span class="dv">1</span>) {</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(<span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> (x <span class="sc">-</span> x1)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> l<span class="sc">^</span><span class="dv">2</span>) <span class="sc">*</span> sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The covariance function is a function of the distance between the two points and not the actual values of the points. The squared exponential kernel is infinitely differentiable, which means that the GP is a very smooth function. The squared exponential kernel is also called the radial basis function (RBF) kernel. The covariance matrix is then defined as</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>cov_mat <span class="ot">=</span> <span class="fu">outer</span>(x, x, sqexpcov)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and we can generate a sample from the GP using the <code>mvrnorm</code> function from the <code>MASS</code> package and plot a sample</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">17</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> <span class="fu">mvrnorm</span>(<span class="dv">1</span>, mean, cov_mat)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, Y, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab=</span><span class="st">"y"</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>,<span class="dv">2</span>), <span class="at">lwd=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-gp-sample" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gp-sample-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="08-gp_files/figure-html/fig-gp-sample-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gp-sample-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.1: Sample from a Gaussian Process
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-gp-sample" class="quarto-xref">Figure&nbsp;<span>9.1</span></a> shows a collection of 100 points of function <span class="math inline">\(f(x)\)</span> sampled from a Gaussian Process with zero mean and squared exponential kernel for the set of 100 indexes <span class="math inline">\(x =(0,0.1,0.2,\ldots,10)\)</span>. By visually inspecting the finite realization in <a href="#fig-gp-sample" class="quarto-xref">Figure&nbsp;<span>9.1</span></a> of the GP, we can see that the sampled function is smooth, with most of its values between -2 and 2. Notice, that each element of the covariance matrix is less than 1. Thus, by properties of the normal 95% of points of <span class="math inline">\(Y\)</span> should be within 1.96 of the zero (the mean). We see a few bumps on the plot, because values of <span class="math inline">\(Y\)</span> with indexes close to each other are highly correlated.</p>
<p>Let’s generate a few more samples from the same GP and plot them together</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>Ys <span class="ot">=</span> <span class="fu">mvrnorm</span>(<span class="dv">3</span>, mean, cov_mat)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">matplot</span>(x, <span class="fu">t</span>(Ys), <span class="at">type=</span><span class="st">"l"</span>, <span class="at">ylab=</span><span class="st">"Y"</span>, <span class="at">lwd=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-gp-samples" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gp-samples-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="08-gp_files/figure-html/fig-gp-samples-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gp-samples-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.2: Samples from a Gaussian Process
</figcaption>
</figure>
</div>
</div>
</div>
<p>Each random finite collection is different than the next. They all have similar range, about the same number of bumps, and are smooth. That’s what it means to have function realizations under a GP prior: <span class="math inline">\(Y = f(x) \sim \mathcal{GP}(0, k(x, x'))\)</span></p>
<section id="making-predictions-with-gaussian-processes" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="making-predictions-with-gaussian-processes"><span class="header-section-number">9.1</span> Making Predictions with Gaussian Processes</h2>
<p>If we think that our observed data with input indexes <span class="math inline">\(X = (x_1,\ldots,x_n)\)</span> and outputs <span class="math inline">\(Y = (y_1,\ldots,y_n)\)</span> are a realization of a Gaussian Process, then we can use the GP to make predictions about the output values at new inputs <span class="math inline">\(x_* \in \mathbb{R}^q\)</span>. The joint distribution of the observed data <span class="math inline">\(Y\)</span> and the new data <span class="math inline">\(y_*\)</span> is given by <span class="math display">\[
\begin{bmatrix} Y \\ y_* \end{bmatrix} \sim \mathcal{N} \left ( \begin{bmatrix} \mu \\ \mu_* \end{bmatrix}, \begin{bmatrix} K &amp; K_* \\ K_*^T &amp; K_{**} \end{bmatrix} \right )
\]</span> where <span class="math inline">\(K = k(X, X)\in \mathbb{R}^{n\times n}\)</span>, <span class="math inline">\(K_* = k(X, x_*)\in \mathbb{R}^{n\times q}\)</span>, <span class="math inline">\(K_{**} = k(x_*, x_*) \in \mathbb{R}^{q\times q}\)</span>, <span class="math inline">\(\mu = \mathbb{E}[Y]\)</span>, and <span class="math inline">\(\mu_* = \mathbb{E}[y_*]\)</span>. The conditional distribution of <span class="math inline">\(y_*\)</span> given <span class="math inline">\(y\)</span> is then given by <span class="math display">\[
y_* \mid Y \sim \mathcal{N}(\mu_{\mathrm{post}}, \Sigma_{\mathrm{post}}).
% y_* \mid Y \sim \mathcal{N}(\mu_* + K_* K^{-1} (y - \mu), K_{**} - K_*^T K^{-1} K_*).
\]</span> The mean of the conditional distribution is given by <span id="eq-mupost"><span class="math display">\[
\mu_{\mathrm{post}} = \mu_* + K_*^TK^{-1} (Y - \mu)
\tag{9.1}\]</span></span> and the covariance is given by <span id="eq-Spost"><span class="math display">\[
\Sigma_{\mathrm{post}} = K_{**} - K_*^T K^{-1} K_*.
\tag{9.2}\]</span></span></p>
<p><a href="#eq-mupost" class="quarto-xref">Equation&nbsp;<span>9.1</span></a> and <a href="#eq-Spost" class="quarto-xref">Equation&nbsp;<span>9.2</span></a> are convenient properties of a <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">multivariate normal distribution</a>.</p>
<div id="exm-gpsin" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.1 (Gaussian Process for <span class="math inline">\(\sin\)</span> function)</strong></span> Let’s use the GP to make predictions about the output values at new inputs <span class="math inline">\(x_*\)</span>. We use <span class="math inline">\(x\)</span> in the [0,<span class="math inline">\(2\pi\)</span>] range and <span class="math inline">\(y\)</span> to be the <span class="math inline">\(y = \sin(x)\)</span>. We start by simulating the “observed” <span class="math inline">\(x\)</span>-<span class="math inline">\(y\)</span> pairs.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">8</span>; eps<span class="ot">=</span><span class="fl">1e-6</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length=</span>n), <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> <span class="fu">sin</span>(X)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>K <span class="ot">=</span> <span class="fu">outer</span>(X[,<span class="dv">1</span>],X[,<span class="dv">1</span>], sqexpcov) <span class="sc">+</span> <span class="fu">diag</span>(eps, n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The additive term <code>diag(eps, n)</code> <span class="math inline">\(=\epsilon I\)</span> adds a diagonal matrix with the small <span class="math inline">\(\epsilon\)</span> on the diagonal. This term shifts the spectrum of the resulting covariance matrix <span class="math inline">\(K\)</span> by <span class="math inline">\(\epsilon\)</span> to the right. This is done to add numerical stability in case one of the eigenvalues is close to zero. It simply gives us a guarantee that solving linear system (inverting) with matrix <span class="math inline">\(K\)</span> will be a numerically stable operation. In machine learning they call this term the jitter. Now we implement a function that calculates the mean and covariance of the posterior distribution of <span class="math inline">\(y_*\)</span> given <span class="math inline">\(Y\)</span>.</p>
<p>Now we generate a new set of inputs <span class="math inline">\(x_*\)</span> and calculate the covariance matrices <span class="math inline">\(K_*\)</span> and <span class="math inline">\(K_{**}\)</span>.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>q <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>XX <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="dv">2</span><span class="sc">*</span>pi <span class="sc">+</span> <span class="fl">0.5</span>, <span class="at">length=</span>q), <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>KX <span class="ot">=</span> <span class="fu">outer</span>(X[,<span class="dv">1</span>], XX[,<span class="dv">1</span>],sqexpcov)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>KXX <span class="ot">=</span> <span class="fu">outer</span>(XX[,<span class="dv">1</span>],XX[,<span class="dv">1</span>], sqexpcov) <span class="sc">+</span> <span class="fu">diag</span>(eps, q)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Notice, we did not add <span class="math inline">\(\epsilon I\)</span> to <span class="math inline">\(K_*\)</span> = <code>KX</code> matrix, but to add it to <span class="math inline">\(K_{**}\)</span> = <code>KXX</code> to guarantee that the resulting posterior covariance matrix is non-singular (invert able). Now we can calculate the mean and covariance of the posterior distribution of <span class="math inline">\(y_*\)</span> given <span class="math inline">\(Y\)</span>.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>Si <span class="ot">=</span> <span class="fu">solve</span>(K)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>mup <span class="ot">=</span> <span class="fu">t</span>(KX) <span class="sc">%*%</span> Si <span class="sc">%*%</span> Y <span class="co"># we assume mu is 0</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>Sigmap <span class="ot">=</span> KXX <span class="sc">-</span> <span class="fu">t</span>(KX) <span class="sc">%*%</span> Si <span class="sc">%*%</span> KX</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we can generate a sample from the posterior distribution over <span class="math inline">\(y_*\)</span>, given <span class="math inline">\(Y\)</span></p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>YY <span class="ot">=</span> <span class="fu">mvrnorm</span>(<span class="dv">100</span>, mup, Sigmap)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Using our convenience function <code>plot_gp</code> we can plot the posterior distribution over <span class="math inline">\(y_*\)</span>, given <span class="math inline">\(Y\)</span>.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>plot_gp <span class="ot">=</span> <span class="cf">function</span>(mup, Sigmap, X, Y, XX, YY){</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  q1 <span class="ot">=</span> mup <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.05</span>, <span class="dv">0</span>, <span class="fu">sqrt</span>(<span class="fu">diag</span>(Sigmap)))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  q2 <span class="ot">=</span> mup <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.95</span>, <span class="dv">0</span>, <span class="fu">sqrt</span>(<span class="fu">diag</span>(Sigmap)))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">matplot</span>(XX, <span class="fu">t</span>(YY), <span class="at">type=</span><span class="st">"l"</span>, <span class="at">col=</span><span class="st">"gray"</span>, <span class="at">lty=</span><span class="dv">1</span>, <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab=</span><span class="st">"y"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(X, Y, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">cex=</span><span class="dv">2</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(XX, <span class="fu">sin</span>(XX), <span class="at">col=</span><span class="st">"blue"</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(XX, mup, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(XX, q1, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="dv">2</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(XX, q2, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="dv">2</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_gp</span>(mup, Sigmap, X, Y, XX, YY)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-gp-sin" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gp-sin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="08-gp_files/figure-html/fig-gp-sin-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gp-sin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.3: Posterior distribution over <span class="math inline">\(y_*\)</span>, given <span class="math inline">\(Y\)</span>
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div id="exm-gp-sim" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.2 (Gaussian Process for Simulated Data using MLE)</strong></span> In previous example we assumed that the <span class="math inline">\(x\)</span>-<span class="math inline">\(y\)</span> relations are modeled by a GP with <span class="math inline">\(\sigma^2 = 1\)</span> and <span class="math inline">\(2l^2 = 1\)</span>. However, we can use the observed data to estimate those to parameters. In the context of GP models, they are call hyper-parameters. We will use Maximum Likelihood Estimation (MLE) procedure to estimate those hype-parameters. The likelihood of a data that follows multivariate normal distribution is given by <span class="math display">\[
p(Y \mid X, \sigma, l) = \frac{1}{(2\pi)^{n/2} |K|^{1/2}} \exp \left ( -\frac{1}{2} Y^T K^{-1} Y \right )
\]</span> where <span class="math inline">\(K = K(X,X)\)</span> is the covariance matrix. We assume mean is zero, to simplify the formulas. The log-likelihood is given by <span class="math display">\[
\log p(Y \mid X, \sigma, l) = -\frac{1}{2} \log |K| - \frac{1}{2} Y^T K^{-1} Y - \frac{n}{2} \log 2\pi.
\]</span></p>
<p>Let’s implement a function that calculates the log-likelihood of the data given the hyper-parameters <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(l\)</span> and use <code>optim</code> function to find the maximum of the log-likelihood function.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>loglik <span class="ot">=</span> <span class="cf">function</span>(par, X, Y) {</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">=</span> par[<span class="dv">1</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  l <span class="ot">=</span> par[<span class="dv">2</span>]</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  K <span class="ot">=</span> <span class="fu">outer</span>(X[,<span class="dv">1</span>],X[,<span class="dv">1</span>], sqexpcov,l,sigma) <span class="sc">+</span> <span class="fu">diag</span>(eps, n)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  Si <span class="ot">=</span> <span class="fu">solve</span>(K)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="sc">-</span>(<span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="fu">det</span>(K)) <span class="sc">-</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">t</span>(Y) <span class="sc">%*%</span> Si <span class="sc">%*%</span> Y <span class="sc">-</span> (n<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span><span class="sc">*</span>pi)))</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>par <span class="ot">=</span> <span class="fu">optim</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), loglik, <span class="at">X=</span>X, <span class="at">Y=</span>Y)<span class="sc">$</span>par</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(par)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 1.5 2.4</code></pre>
</div>
</div>
<p>The <code>optim</code> function returns the hyper-parameters that maximize the log-likelihood function. We can now use those hyper-parameters to make predictions about the output values at new inputs <span class="math inline">\(x_*\)</span>.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>l <span class="ot">=</span> par[<span class="dv">2</span>]; sigma <span class="ot">=</span> par[<span class="dv">1</span>]</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>predplot <span class="ot">=</span> <span class="cf">function</span>(X, Y, XX, YY, l, sigma) {</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  K <span class="ot">=</span> <span class="fu">outer</span>(X[,<span class="dv">1</span>],X[,<span class="dv">1</span>], sqexpcov,l,sigma) <span class="sc">+</span> <span class="fu">diag</span>(eps, n)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  KX <span class="ot">=</span> <span class="fu">outer</span>(X[,<span class="dv">1</span>], XX[,<span class="dv">1</span>],sqexpcov,l,sigma)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  KXX <span class="ot">=</span> <span class="fu">outer</span>(XX[,<span class="dv">1</span>],XX[,<span class="dv">1</span>], sqexpcov,l,sigma) <span class="sc">+</span> <span class="fu">diag</span>(eps, q)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  Si <span class="ot">=</span> <span class="fu">solve</span>(K)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  mup <span class="ot">=</span> <span class="fu">t</span>(KX) <span class="sc">%*%</span> Si <span class="sc">%*%</span> Y <span class="co"># we assume mu is 0</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  Sigmap <span class="ot">=</span> KXX <span class="sc">-</span> <span class="fu">t</span>(KX) <span class="sc">%*%</span> Si <span class="sc">%*%</span> KX</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  YY <span class="ot">=</span> <span class="fu">mvrnorm</span>(<span class="dv">100</span>, mup, Sigmap)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot_gp</span>(mup, Sigmap, X, Y, XX, YY)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="fu">predplot</span>(X, Y, XX, YY, l, sigma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="08-gp_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>We can see that our uncertainty is much “tighter”, the posterior distribution is much narrower. This is because we used the observed data to estimate the hyper-parameters. We can also see that the posterior mean is closer to the true function <span class="math inline">\(y = \sin(x)\)</span>. Although our initial guess of <span class="math inline">\(\sigma^2 = 1\)</span> and <span class="math inline">\(2l^2 = 1\)</span> was not too far off, the model fits the data much better when we use the estimated hyper-parameters.</p>
<p>The function <code>optim</code> we used above uses a derivative-based optimization algorithm and when derivative is not provided by the user, it uses a numerical approximation. Although we can use numerical methods to calculate the derivative of the log-likelihood function, it is faster and more accurate to use analytical derivatives, when possible. In the case of the GP’s log-likelihood, the derivative can be analytically calculated. To do it, we need a couple of facts from matrix calculus. If elements of matrix <span class="math inline">\(K\)</span> are functions of some parameter <span class="math inline">\(\theta\)</span>, then <span class="math display">\[
\frac{\partial  Y^T K^{-1} Y}{\partial \theta} =  Y^T \frac{\partial K^{-1}}{\partial \theta} Y.
\]</span> The derivative of the inverse matrix <span class="math display">\[
\frac{\partial K^{-1}}{\partial \theta} = -K^{-1} \frac{\partial K}{\partial \theta} K^{-1}.
\]</span> and the log of the determinant of a matrix <span class="math display">\[
\frac{\partial \log |K|}{\partial \theta} = \mathrm{tr} \left ( K^{-1} \frac{\partial K}{\partial \theta} \right ),
\]</span> we can calculate the derivative of the log-likelihood function with respect to <span class="math inline">\(\theta\)</span> <span class="math display">\[
\frac{\partial \log p(Y \mid X,\theta)}{\partial \theta} = -\frac{1}{2}\frac{\partial \log |K|}{\partial \theta}  + \frac{1}{2} Y^T \frac{\partial K^{-1}}{\partial \theta}  Y.
\]</span> Putting it all together, we get <span class="math display">\[
\frac{\partial \log p(Y \mid X,\theta)}{\partial \theta} = -\frac{1}{2} \mathrm{tr} \left ( K^{-1} \frac{\partial K}{\partial \theta} \right ) + \frac{1}{2} Y^T K^{-1} \frac{\partial K}{\partial \theta} K^{-1} Y.
\]</span> In the case of squared exponential kernel, the elements of the covariance matrix <span class="math inline">\(K\)</span> are given by <span class="math display">\[
K_{ij} = k(x_i, x_j) = \sigma^2 \exp \left ( -\frac{1}{2} \frac{(x_i - x_j)^2}{l^2} \right ).
\]</span> The derivative of the covariance matrix with respect to <span class="math inline">\(\sigma\)</span> is given by <span class="math display">\[
\frac{\partial K_{ij}}{\partial \sigma} = 2\sigma \exp \left ( -\frac{1}{2} \frac{(x_i - x_j)^2}{l^2} \right );~\frac{\partial K}{\partial \sigma} = \dfrac{2}{\sigma}K.
\]</span> The derivative of the covariance matrix with respect to <span class="math inline">\(l\)</span> is given by <span class="math display">\[
\frac{\partial K_{ij}}{\partial l} = \sigma^2 \exp \left ( -\frac{1}{2} \frac{(x_i - x_j)^2}{l^2} \right ) \frac{(x_i - x_j)^2}{l^3};~ \frac{\partial K}{\partial l}  = \frac{(x_i - x_j)^2}{l^3} K.
\]</span> Now we can implement a function that calculates the derivative of the log-likelihood function with respect to <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(l\)</span>.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Derivative of the log-likelihood function with respect to sigma</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>dloglik_sigma <span class="ot">=</span> <span class="cf">function</span>(par, X, Y) {</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">=</span> par[<span class="dv">1</span>]; l <span class="ot">=</span> par[<span class="dv">2</span>]</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  K <span class="ot">=</span> <span class="fu">outer</span>(X[,<span class="dv">1</span>],X[,<span class="dv">1</span>], sqexpcov,l,sigma) <span class="sc">+</span> <span class="fu">diag</span>(eps, n)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  Si <span class="ot">=</span> <span class="fu">solve</span>(K)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  dK <span class="ot">=</span> <span class="dv">2</span><span class="sc">*</span>K<span class="sc">/</span>sigma</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  tr <span class="ot">=</span> <span class="fu">sum</span>(<span class="fu">diag</span>(Si <span class="sc">%*%</span> dK))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="sc">-</span>(<span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> tr <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">t</span>(Y) <span class="sc">%*%</span> Si <span class="sc">%*%</span> dK <span class="sc">%*%</span> Si <span class="sc">%*%</span> Y))</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Derivative of the log-likelihood function with respect to l</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>dloglik_l <span class="ot">=</span> <span class="cf">function</span>(par, X, Y) {</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">=</span> par[<span class="dv">1</span>]; l <span class="ot">=</span> par[<span class="dv">2</span>]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  K <span class="ot">=</span> <span class="fu">outer</span>(X[,<span class="dv">1</span>],X[,<span class="dv">1</span>], sqexpcov ,l,sigma) <span class="sc">+</span> <span class="fu">diag</span>(eps, n)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>  Si <span class="ot">=</span> <span class="fu">solve</span>(K)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>  dK <span class="ot">=</span>   <span class="fu">outer</span>(X[,<span class="dv">1</span>],X[,<span class="dv">1</span>], <span class="cf">function</span>(x, x1) (x <span class="sc">-</span> x1)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>l<span class="sc">^</span><span class="dv">3</span> <span class="sc">*</span> K</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>  tr <span class="ot">=</span> <span class="fu">sum</span>(<span class="fu">diag</span>(Si <span class="sc">%*%</span> dK))</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="sc">-</span>(<span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> tr <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">t</span>(Y) <span class="sc">%*%</span> Si <span class="sc">%*%</span> dK <span class="sc">%*%</span> Si <span class="sc">%*%</span> Y))</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient function that returns a vector of derivatives</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>gnlg <span class="ot">=</span> <span class="cf">function</span>(par,X,Y) {</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(<span class="fu">dloglik_sigma</span>(par, X, Y), <span class="fu">dloglik_l</span>(par, X, Y)))</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can use the <code>optim</code> function to find the maximum of the log-likelihood function and provide the derivative function we just implemented.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>par1 <span class="ot">=</span> <span class="fu">optim</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">fn=</span>loglik, <span class="at">gr=</span>gnlg ,<span class="at">X=</span>X, <span class="at">Y=</span>Y,<span class="at">method=</span><span class="st">"BFGS"</span>)<span class="sc">$</span>par</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>l <span class="ot">=</span> par1[<span class="dv">2</span>]; sigma <span class="ot">=</span> par1[<span class="dv">1</span>]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(par1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 1.5 2.4</code></pre>
</div>
</div>
<p>The result is the same compared to when we called <code>optim</code> without the derivative function. Even execution time is the same for our small problem. However, at larger scale, the derivative-based optimization algorithm will be much faster.</p>
<p>Furthermore, incited of coding our own derivative functions, we can use an existing package, such as the <a href="https://cran.r-project.org/web/packages/laGP/index.html"><code>laGP</code></a> package, developed by Bobby Gramacy to estimate the hyper-parameters. The <code>laGP</code> package uses the same optimization algorithm as we used above, but it also provides better selection of the covariance functions and implements approximate GP inference algorithms for large scale problems, when <span class="math inline">\(n\)</span> becomes large and inversion of the covariance matrix <span class="math inline">\(K\)</span> is prohibitively expensive.</p>
<div class="cell" data-layout-align="center" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(laGP)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">=</span> <span class="fu">newGP</span>(X, Y, <span class="dv">1</span>, <span class="dv">0</span>, <span class="at">dK =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>res <span class="ot">=</span> <span class="fu">mleGP</span>(gp, <span class="at">tmax=</span><span class="dv">20</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>l.laGP <span class="ot">=</span> <span class="fu">sqrt</span>(res<span class="sc">$</span>d<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(l.laGP)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 2.4</code></pre>
</div>
</div>
<p>In the <code>newGP</code> function defines a Gaussian process with square exponential covariance function and assumes <span class="math inline">\(\sigma^2 = 1\)</span>, then <code>mleGP</code> function uses optimization algorithm to maximize the log-likelihood and returns the estimated hyper-parameters <code>d</code> = <span class="math inline">\(2l^2\)</span>, we can see that the length scale is close to the one we estimated above. We will use the <code>predplot</code> convenience function to calculate the predictions and plot the data vs fit.</p>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predplot</span>(X, Y, XX, YY, l, sigma)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predplot</span>(X, Y, XX, YY, l.laGP, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-gp-sin-mle" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gp-sin-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-gp-sin-mle" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-gp-sin-mle-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-gp-sin-mle-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="08-gp_files/figure-html/fig-gp-sin-mle-1.png" class="img-fluid figure-img" data-ref-parent="fig-gp-sin-mle" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-gp-sin-mle-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) MLE Fit
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-gp-sin-mle" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-gp-sin-mle-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-gp-sin-mle-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="08-gp_files/figure-html/fig-gp-sin-mle-2.png" class="img-fluid figure-img" data-ref-parent="fig-gp-sin-mle" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-gp-sin-mle-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) laGP Fit
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gp-sin-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.4: Posterior distribution over <span class="math inline">\(y_*\)</span>, given <span class="math inline">\(Y\)</span>
</figcaption>
</figure>
</div>
<p>We can see that there is visually no difference between the two fits. Thus, it seem irrelevant weather we keep sigma fixed <span class="math inline">\(\sigma=1\)</span> or estimate it using MLE. However, is other applications when uncertainty is larger, the choice of <span class="math inline">\(\sigma\)</span> is important when we use GP for regression and classification tasks. Even for our example, if we ask our model to extrapolate</p>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>XX1 <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">4</span><span class="sc">*</span>pi, <span class="dv">6</span><span class="sc">*</span>pi <span class="sc">+</span> <span class="fl">0.5</span>, <span class="at">length=</span>q), <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predplot</span>(X, Y, XX1, YY, l, sigma)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">predplot</span>(X, Y, XX1, YY, l.laGP, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell quarto-layout-panel" data-null_prefix="true" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08-gp_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>MLE Fit</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08-gp_files/figure-html/unnamed-chunk-15-2.png" class="img-fluid figure-img" width="576"></p>
<figcaption>laGP Fit</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p>Extrapolation: Posterior distribution over <span class="math inline">\(y_*\)</span>, given <span class="math inline">\(Y\)</span></p>
</div>
</div>
</div>
<p>We can see that outside of the range of the observed data, the model with <span class="math inline">\(\sigma=1\)</span> is more “confident” in its predictions.</p>
</div>
<p>Now, instead of using GP to fit a known function (<span class="math inline">\(\sin\)</span>), we will apply it to a real-world data set. We will use the motorcycle accident data set from the <code>MASS</code> package. The data set contains accelerator readings taken through time in a simulated experiment on the efficacy of crash helmets.</p>
<div id="exm-gp" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.3 (Gaussian Process for Motorcycle Accident Data)</strong></span> We first estimate the length scale parameter <span class="math inline">\(l\)</span> using the <code>laGP</code> package.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> mcycle<span class="sc">$</span>times</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> mcycle<span class="sc">$</span>accel</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">=</span> <span class="fu">newGP</span>(<span class="fu">matrix</span>(X), Y, <span class="dv">2</span>, <span class="fl">1e-6</span>, <span class="at">dK =</span> <span class="cn">TRUE</span>);</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mleGP</span>(gp, <span class="at">tmax=</span><span class="dv">10</span>);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we plot the data and the fit using the estimated length scale parameter <span class="math inline">\(l\)</span>.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>XX <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">seq</span>(<span class="fl">2.4</span>, <span class="dv">55</span>, <span class="at">length =</span> <span class="dv">499</span>), <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fu">predGP</span>(gp, XX)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>N <span class="ot">=</span> <span class="dv">499</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>q1 <span class="ot">=</span> <span class="fu">qnorm</span>(<span class="fl">0.05</span>, <span class="at">mean =</span> p<span class="sc">$</span>mean, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(p<span class="sc">$</span>Sigma)))</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>q2 <span class="ot">=</span> <span class="fu">qnorm</span>(<span class="fl">0.95</span>, <span class="at">mean =</span> p<span class="sc">$</span>mean, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(p<span class="sc">$</span>Sigma)))</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>q3 <span class="ot">=</span> <span class="fu">qnorm</span>(<span class="fl">0.5</span>, <span class="at">mean =</span> p<span class="sc">$</span>mean, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(p<span class="sc">$</span>Sigma)))</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>X,<span class="at">y=</span>Y)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>XX,<span class="at">y=</span>q3)) <span class="sc">+</span> <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">x=</span>XX,<span class="at">ymin=</span>q1, <span class="at">ymax=</span>q2), <span class="at">alpha=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08-gp_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Motorcycle Accident Data. Black line is the mean of the posterior distribution over <span class="math inline">\(y_*\)</span>, given <span class="math inline">\(Y\)</span>. Blue lines are the 95% confidence interval.</figcaption>
</figure>
</div>
</div>
</div>
<p>We can see that our model is more confident for time values between 10 and 30. The confidence interval is wider for time values between 0 and 10 and between 30 and less confident at the end close to the 60 mark. For some reason the acceleration values were not measure evenly, if we look at the histogram of time values, we can see that there are more data points in the middle of the time range.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08-gp_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Histogram of time values</figcaption>
</figure>
</div>
</div>
</div>
<p>The <span class="math inline">\(\sqrt{n}\)</span> decay in variance of the posterior distribution is a property of the squared exponential kernel.</p>
</div>
<p>In summary, Gaussian Processes provide a robust and flexible framework for modeling and predicting in situations where uncertainty and correlation among data points play a critical role. Their versatility and powerful predictive capabilities make them a popular choice in various scientific and engineering disciplines. GPs are considered non-parametric, which means they can model functions of arbitrary complexity. Through the choice of the kernel function, GPs can model a wide range of correlations between the data points. The mean and covariance functions can incorporate prior knowledge about the behavior of the function being modeled. There are many areas of applications for GP. The two main applications are: (i) predictive modeling, (ii) optimization, (iii) uncertainty quantification. We will focus on the first two applications in the later sections. In predictive modeling we can use GPs to predict the value of a function at new points, taking into account the uncertainty of the prediction. GPs are particular useful in spatial data analysis, where the correlation between data points is often related to their physical distance. Thus, GPs are quite often used for environmental modeling to analyze temperature or pollution levels, over geographical areas.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./07-sp.html" class="pagination-link" aria-label="Stochastic Processes">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./09-rl.html" class="pagination-link" aria-label="Reinforcement Learning">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>