<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>20&nbsp; Neural Networks – Bayes, AI and Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./20-dlopt.html" rel="next">
<link href="./18-forecasting.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-29e2c20b02301cfff04dc8050bf30c7e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7580570a2e354cd56757c689413fca0c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head><body class="nav-sidebar floating fullcontent"><div class="hidden">
<p><span class="math display">\[
\newcommand{\prob}[1]{\operatorname{P}\left(#1\right)}
\newcommand{\Var}[1]{\operatorname{Var}\left(#1\right)}
\newcommand{\sd}[1]{\operatorname{sd}\left(#1\right)}
\newcommand{\Cor}[1]{\operatorname{Corr}\left(#1\right)}
\newcommand{\Cov}[1]{\operatorname{Cov}\left(#1\right)}
\newcommand{\E}[1]{\operatorname{E}\left(#1\right)}
\newcommand{\defeq}{\overset{\text{\tiny def}}{=}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\mini}{minimize}
\]</span></p>
</div>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>





<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./19-nn.html">Deep Learning</a></li><li class="breadcrumb-item"><a href="./19-nn.html"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Neural Networks</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayes, AI and Deep Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Principles of Data Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability and Uncertainty</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-dec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Utility, Risk and Decisions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-bl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Parameter Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-ab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">AB Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-hyp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bayesian Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-sp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-rl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Unreasonable Effectiveness of Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-pattern.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Pattern Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Linear and Multiple Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Calssification: Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-theoryai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Theory of AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">RCT: Field vs Observational</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-select.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Tree Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-forecasting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Forecasting</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-nn.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-dlopt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-arch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Image Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">showsln: false</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./19-nn.html">Deep Learning</a></li><li class="breadcrumb-item"><a href="./19-nn.html"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Neural Networks</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Neural Networks</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The goal of this section paper is to provide an overview of of Deep Learning (DL) for statisticians. To do this, we have discussed the model estimation procedure and demonstrated that DL is an extension of a generalized linear model. One goal of statistics is to build predictive models along with uncertainty and to develop an understanding of the data generating mechanism. Data models are well studied in statistical literature, but often do not provide enough flexibility to learn the input-output relations. Closed box predictive rules, such as trees and neural networks, are more flexible learners. However, in high-dimensional problems, finding good models is challenging, and this is where deep learning methods shine. We can think of deterministic DL model as a transformation of high dimensional input and outputs. Hidden features lie on the transformed space, and are empirically learned as opposed to theoretically specified.</p>
<p>Although DL models have been almost exclusively used for problems of image analysis and natural language processing, more traditional data sets, which arise in finance, science and engineering, such as spatial and temporal data can be efficiently analyzed using deep learning. Thus, DL provides an alternative for applications where traditional statistical techniques apply. There are a number of areas of future research for Statisticians. In particular, uncertainty quantification and model selection, such as architecture design, as well as algorithmic improvements and Bayesian deep learning. We hope this review will make DL models accessible for statisticians.</p>
<p>In recent yeats neural networks and deep learning has re-emerged as a dominant technology for natural language processing (NLP), image analysis and reinforcement learning. The majority of applications use feed-forward neural network architectures such as convolutional neural networks and transformers. In this chapter we will focus on the feed-forward neural networks and their applications to regression and classification problems. We will also discuss the computational aspects of deep learning and its implementation in <code>R</code> and <code>Python</code>.</p>
<section id="introduction" class="level2" data-number="20.1">
<h2 data-number="20.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">20.1</span> Introduction</h2>
<p>Our goal is to provide a review of deep learning methods which provide insight into structured high-dimensional data. Rather than using shallow additive architectures common to most statistical models, deep learning uses layers of semi-affine input transformations to provide a predictive rule. Applying these layers of transformations leads to a set of attributes (or, features) to which probabilistic statistical methods can be applied. Thus, the best of both worlds can be achieved: scalable prediction rules fortified with uncertainty quantification, where sparse regularization finds the features.</p>
<p>Deep learning is one of the widely used machine learning method for analysis of large scale and high-dimensional data sets. Large-scale means that we have many samples (observations) and high dimensional means that each sample is a vector with many entries, usually hundreds and up.</p>
<p>Machine learning is the engineer’s version of statistical data analysis. Major difference between ML and statistics is that ML focuses on practical aspects, such as computational efficiency and ease of use of techniques. While statistical analysis is more concerned with rigorousness of the analysis and interpretability of the results.</p>
<p>Deep learning provides a powerful pattern matching tool suitable for many AI applications. Image recognition and text analysis are probably two of the deep learning’s most successful. From a computational perspective, you can think of an image or a text as a high dimensional matrices and vectors, respectively. The problem of recognizing objects in images or translating a text requires designing complex decision boundaries in the high dimensional space of inputs.</p>
<p>Although, image analysis and natural language processing are the applications where deep learning is the dominating approach, more traditional engineering and science applications, such as spatio-temporal and financial analysis is where DL also showed superior performance compared to traditional statistical learning techniques <span class="citation" data-cites="polson2021deep polson2017deep dixon2019deep heaton2017deep sokolov2017discussion bhadra2021merging bhadra2021merging behnia2021deep nareklishvili2022deep wang2022data nareklishvili2022feature polson2023generative nareklishvili2023generative polson2020deep">(<a href="references.html#ref-polson2021deep" role="doc-biblioref">N. Polson, Sokolov, and Xu 2021</a>; <a href="references.html#ref-polson2017deep" role="doc-biblioref">N. G. Polson and Sokolov 2017</a>, <a href="references.html#ref-polson2023generative" role="doc-biblioref">2023</a>; <a href="references.html#ref-dixon2019deep" role="doc-biblioref">Dixon, Polson, and Sokolov 2019</a>; <a href="references.html#ref-heaton2017deep" role="doc-biblioref">Heaton, Polson, and Witte 2017</a>; <a href="references.html#ref-sokolov2017discussion" role="doc-biblioref">Sokolov 2017</a>; <a href="references.html#ref-bhadra2021merging" role="doc-biblioref">Bhadra et al. 2021</a>, <a href="references.html#ref-bhadra2021merging" role="doc-biblioref">2021</a>; <a href="references.html#ref-behnia2021deep" role="doc-biblioref">Behnia, Karbowski, and Sokolov 2021</a>; <a href="references.html#ref-nareklishvili2022deep" role="doc-biblioref">Nareklishvili, Polson, and Sokolov 2022a</a>, <a href="references.html#ref-nareklishvili2022feature" role="doc-biblioref">2022b</a>, <a href="references.html#ref-nareklishvili2023generative" role="doc-biblioref">2023</a>; <a href="references.html#ref-wang2022data" role="doc-biblioref">Wang, Polson, and Sokolov 2022</a>; <a href="references.html#ref-polson2020deep" role="doc-biblioref">N. Polson and Sokolov 2020</a>)</span></p>
<p>There are several deep learning architectures exist - each has its own uses and purposes. Convolutional Neural Networks (CNN) deal with 2-dimensional input objects, i.e.&nbsp;images and were shown to outperform any other techniques. Recurrent Neural Networks (RNN) were shown the best performance on speech and text analysis tasks.</p>
<p>In general, a neural network can be described as follows. Let <span class="math inline">\(f_1 , \ldots , f_L\)</span> be given univariate activation functions for each of the <span class="math inline">\(L\)</span> layers. Activation functions are nonlinear transformations of weighted data. A semi-affine activation rule is then defined by <span class="math display">\[
f_l^{W,b} = f_l \left ( \sum_{j=1}^{N_l} W_{lj} X_j + b_l \right ) = f_l ( W_l X_l + b_l )\,,
\]</span> which implicitly needs the specification of the number of hidden units <span class="math inline">\(N_l\)</span>. Our deep predictor, given the number of layers <span class="math inline">\(L\)</span>, then becomes the composite map</p>
<p><span class="math display">\[
\hat{Y}(X) = F(X) = \left ( f_l^{W_1,b_1} \circ \ldots \circ f_L^{W_L,b_L} \right ) ( X)\,.
\]</span></p>
<p>The fact that DL forms a universal “basis” which we recognize in this formulation dates to Poincare and Hilbert is central. From a practical perspective, given a large enough data set of “test cases”, we can empirically learn an optimal predictor. Similar to a classic basis decomposition, the deep approach uses univariate activation functions to decompose a high dimensional <span class="math inline">\(X\)</span>.</p>
<p>Let <span class="math inline">\(Z^{(l)}\)</span> denote the <span class="math inline">\(l\)</span>th layer, and so <span class="math inline">\(X = Z^{(0)}\)</span>. The final output <span class="math inline">\(Y\)</span> can be numeric or categorical. The explicit structure of a deep prediction rule is then <span class="math display">\[
\begin{aligned}
\hat{Y} (X) &amp; = W^{(L)} Z^{(L)} + b^{(L)} \\
Z^{(1)} &amp; = f^{(1)} \left ( W^{(0)} X + b^{(0)} \right ) \\
Z^{(2)} &amp; = f^{(2)} \left ( W^{(1)} Z^{(1)} + b^{(1)} \right ) \\
\ldots  &amp; \\
Z^{(L)} &amp; = f^{(L)} \left ( W^{(L-1)} Z^{(L-1)} + b^{(L-1)} \right )\,.
\end{aligned}
\]</span> Here <span class="math inline">\(W^{(l)}\)</span> is a weight matrix and <span class="math inline">\(b^{(l)}\)</span> are threshold or activation levels. Designing a good predictor depends crucially on the choice of univariate activation functions <span class="math inline">\(f^{(l)}\)</span>. The <span class="math inline">\(Z^{(l)}\)</span> are hidden features which the algorithm will extract.</p>
<p>Put differently, the deep approach employs hierarchical predictors comprising of a series of <span class="math inline">\(L\)</span> nonlinear transformations applied to <span class="math inline">\(X\)</span>. Each of the <span class="math inline">\(L\)</span> transformations is referred to as a <strong>layer</strong>, where the original input is <span class="math inline">\(X\)</span>, the output of the first transformation is the first layer, and so on, with the output <span class="math inline">\(\hat Y\)</span> as the first layer. The layers <span class="math inline">\(1\)</span> to <span class="math inline">\(L\)</span> are called <strong>hidden layers</strong>. The number of layers <span class="math inline">\(L\)</span> represents the depth of our routine.</p>
</section>
<section id="motivating-example" class="level2" data-number="20.2">
<h2 data-number="20.2" class="anchored" data-anchor-id="motivating-example"><span class="header-section-number">20.2</span> Motivating Example</h2>
<p>We will start with applying a feed-forward neural network with one hidden layer to a problem of binary classification on a simulated data set. We start by generating a simple dataset shown in Figure below. The data is generated from a mixture of two distributions (Gaussian and truncated Gaussian). The red points are the positive class and the green points are the negative class. The goal is to find a model boundary that discriminates the two classes.</p>
<div class="cell" data-null_prefix="true">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="19-nn_files/figure-html/circle-data-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Let’s try to use a simple logistic regression model to separate the two classes.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a logistic regression model</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">glm</span>(label<span class="sc">~</span>x1<span class="sc">+</span>x2, <span class="at">data=</span><span class="fu">as.data.frame</span>(d), <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span><span class="st">'logit'</span>))</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the training dataset</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d[,<span class="dv">2</span>],d[,<span class="dv">3</span>], <span class="at">col=</span>d[,<span class="dv">1</span>]<span class="sc">+</span><span class="dv">2</span>, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">xlab=</span><span class="st">"x1"</span>, <span class="at">ylab=</span><span class="st">"x2"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>th <span class="ot">=</span> fit<span class="sc">$</span>coefficients</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the decision boundary</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="sc">-</span>th[<span class="dv">1</span>]<span class="sc">/</span>th[<span class="dv">3</span>], <span class="sc">-</span>th[<span class="dv">2</span>]<span class="sc">/</span>th[<span class="dv">3</span>], <span class="at">col=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="19-nn_files/figure-html/circle-lr-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>We can see that a logistic regression could not do it. It uses a single line to separate observations of two classes. We can see that the data is not linearly separable. However, we can use multiple lines to separate the data.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1<span class="sc">~</span>x2, <span class="at">data=</span>d,<span class="at">col=</span>d[,<span class="dv">1</span>]<span class="sc">+</span><span class="dv">2</span>, <span class="at">pch=</span><span class="dv">16</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot lines that separate once class (red) from another (green)</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x1, <span class="sc">-</span>x1 <span class="sc">-</span> <span class="dv">6</span>); <span class="fu">text</span>(<span class="sc">-</span><span class="dv">4</span>,<span class="sc">-</span><span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x1, <span class="sc">-</span>x1 <span class="sc">+</span> <span class="dv">6</span>); <span class="fu">text</span>(<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">2</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x1,  x1 <span class="sc">-</span> <span class="dv">6</span>); <span class="fu">text</span>(<span class="dv">4</span>,<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x1,  x1 <span class="sc">+</span> <span class="dv">6</span>); <span class="fu">text</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="19-nn_files/figure-html/sep-lines-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Now, we do the same thing as in simple logistic regression and apply logistic function to each of those lines</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define sigmoid function</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>sigmoid  <span class="ot">=</span> <span class="cf">function</span>(z) <span class="fu">exp</span>(z)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(z))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define hidden layer of our neural network</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>features <span class="ot">=</span> <span class="cf">function</span>(x1,x2) {</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  z1 <span class="ot">=</span>  <span class="dv">6</span> <span class="sc">+</span> x1 <span class="sc">+</span> x2; a1 <span class="ot">=</span> <span class="fu">sigmoid</span>(z1)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  z2 <span class="ot">=</span>  <span class="dv">6</span> <span class="sc">-</span> x1 <span class="sc">-</span> x2; a2 <span class="ot">=</span> <span class="fu">sigmoid</span>(z2)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  z3 <span class="ot">=</span>  <span class="dv">6</span> <span class="sc">-</span> x1 <span class="sc">+</span> x2; a3 <span class="ot">=</span> <span class="fu">sigmoid</span>(z3)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  z4 <span class="ot">=</span>  <span class="dv">6</span> <span class="sc">+</span> x1 <span class="sc">-</span> x2; a4 <span class="ot">=</span> <span class="fu">sigmoid</span>(z4)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(a1,a2,a3,a4))</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Using the matrix notaitons, we have <span class="math display">\[
z = \sigma(Wx + b), ~ W = \begin{bmatrix} 1 &amp; 1 \\ -1 &amp; -1 \\ -1 &amp; 1 \\ 1 &amp; -1 \end{bmatrix}, ~ b = \begin{bmatrix} 6 \\ 6 \\ 6 \\ 6 \end{bmatrix}, ~ \sigma(z) = \frac{1}{1+e^{-z}}
\]</span></p>
<p>The model shown above is the first layer of our neural network. It takes a two-dimensional input <span class="math inline">\(x\)</span> and produces a four-dimensional output <span class="math inline">\(z\)</span> which is a called a feature vector. The feature vector is then passed to the output layer, which applies simple logistic regression to the feature vector. <span class="math display">\[
\hat{y} = \sigma(w^Tz + b), ~ w = \begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \end{bmatrix}, ~ b = -3.1, ~ \sigma(z) = \frac{1}{1+e^{-z}}
\]</span></p>
<p>The output of the output layer is the probability of the positive class.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate prediction (classification) using our neural network</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>predict_prob <span class="ot">=</span> <span class="cf">function</span>(x){</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  x1 <span class="ot">=</span> x[<span class="dv">1</span>]; x2 <span class="ot">=</span> x[<span class="dv">2</span>]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  z <span class="ot">=</span> <span class="fu">features</span>(x1,x2)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print(z)</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">=</span> <span class="fu">sum</span>(z) <span class="sc">-</span> <span class="fl">3.1</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print(mu)</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sigmoid</span>(mu)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can use our model to do the predictions now</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the probability of the positive class for a given point</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict_prob</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.71</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict_prob</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.26</code></pre>
</div>
</div>
<p>The model generates sensible predictions, let’s plot the decision boundary to see how well it separates the data.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">11</span>,<span class="dv">11</span>,<span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">11</span>,<span class="dv">11</span>,<span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>gr <span class="ot">=</span> <span class="fu">as.matrix</span>(<span class="fu">expand.grid</span>(x1,x2));</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 10000     2</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">=</span> <span class="fu">apply</span>(gr,<span class="dv">1</span>,predict_prob)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 10000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(x1,x2,<span class="fu">matrix</span>(yhat,<span class="at">ncol =</span> <span class="dv">100</span>), <span class="at">col =</span> <span class="fu">heat.colors</span>(<span class="dv">20</span>,<span class="fl">0.7</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="19-nn_files/figure-html/circle-boundary-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>How about a regression model. We will use a one-layer neural network to fit a quadratic function. We simulate noisy data from the following model <span class="math display">\[
y = 0.5 + 0.3x^2 + \epsilon, ~ \epsilon \sim N(0,0.02^2)
\]</span> And use 3 hidden units in the first hidden layer and two units in the second hidden layer. The output layer is a single unit. We will use the hyperbolic tangent (<code>tanh</code>) activation function for all layers. The model is defined as follows</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>relu <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">max</span>(<span class="dv">0</span>,x)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>nn <span class="ot">=</span> <span class="cf">function</span>(W,<span class="at">f=</span>relu) {</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    b0 <span class="ot">=</span> W[<span class="dv">1</span>]; w0<span class="ot">=</span>W[<span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>];b1 <span class="ot">=</span> W[<span class="dv">5</span>]; w1 <span class="ot">=</span> W[<span class="dv">6</span><span class="sc">:</span><span class="dv">8</span>]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    z0 <span class="ot">=</span> <span class="fu">apply</span>(b0 <span class="sc">+</span> <span class="fu">outer</span>(x,w0,<span class="st">'*'</span>),<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,f)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    yhat <span class="ot">=</span> b1 <span class="sc">+</span> z0 <span class="sc">%*%</span> w1</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">yhat =</span> yhat[,<span class="dv">1</span>],<span class="at">z0=</span>z0))</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The hidden layer has three outputs (neurons) and uses the ReLu activation function. The output linear layer has a single output. Thus, the prediction <code>yhat</code> is generated as a linear model of the feature vector <code>z0</code>. The model has 8 parameters Let’s generate training data and fit the model. We will use the BFGS optimization algorithm to minimize the loss function (negative log-likelihood) of the model.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">99</span>) <span class="co">#gretzky</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>nl  <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">2</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>params <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">3</span>),<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">3</span>))</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="fl">0.02</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.3</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(x),<span class="dv">0</span>,<span class="fl">0.02</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>loss <span class="ot">=</span> <span class="cf">function</span>(W) <span class="fu">sum</span>((<span class="fu">nn</span>(W)<span class="sc">$</span>yhat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>res <span class="ot">=</span> <span class="fu">optim</span>(params, loss, <span class="at">method=</span><span class="st">'BFGS'</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>res<span class="sc">$</span>par</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> -0.24  1.39 -0.82  0.46  0.50  0.17  0.46  0.39</code></pre>
</div>
</div>
<p>The <a href="#fig-relu" class="quarto-xref">Figure&nbsp;<span>20.1</span></a> shows the quadratic function and the neural network model. The solid black line is the neural network model, and the dashed lines are the basis functions. The model fits the data well.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>o <span class="ot">=</span> <span class="fu">nn</span>(res<span class="sc">$</span>par)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y); <span class="fu">lines</span>(x,o<span class="sc">$</span>yhat, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">+</span>o<span class="sc">$</span>z0[,<span class="dv">1</span>],<span class="at">col=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>); <span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">+</span>o<span class="sc">$</span>z0[,<span class="dv">2</span>],<span class="at">col=</span><span class="dv">3</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>); <span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">+</span>o<span class="sc">$</span>z0[,<span class="dv">3</span>],<span class="at">col=</span><span class="dv">4</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-relu" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-relu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="19-nn_files/figure-html/fig-relu-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-relu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.1: Noisy quadratic function approximated by a neural network with ReLu activation function.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Let’s try the <span class="math inline">\(\tanh\)</span> function</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">8</span>) <span class="co">#gretzky</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>params <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">3</span>),<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">3</span>))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>loss <span class="ot">=</span> <span class="cf">function</span>(W) <span class="fu">mean</span>((<span class="fu">nn</span>(W,<span class="at">f=</span>tanh)<span class="sc">$</span>yhat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>res <span class="ot">=</span> <span class="fu">optim</span>(params, loss, <span class="at">method=</span><span class="st">'BFGS'</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>res<span class="sc">$</span>par</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> -0.98 -0.23  0.83 -1.14  0.84 -0.65  0.59  0.53</code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>o <span class="ot">=</span> <span class="fu">nn</span>(res<span class="sc">$</span>par, <span class="at">f=</span>tanh)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">0.4</span>,<span class="fl">0.95</span>)); <span class="fu">lines</span>(x,o<span class="sc">$</span>yhat, <span class="at">lwd=</span><span class="dv">2</span>);</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">*</span>o<span class="sc">$</span>z0[,<span class="dv">1</span>]<span class="sc">+</span><span class="fl">0.9</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="dv">2</span>); <span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">*</span>o<span class="sc">$</span>z0[,<span class="dv">2</span>]<span class="sc">+</span><span class="fl">0.9</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="dv">3</span>); <span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">*</span>o<span class="sc">$</span>z0[,<span class="dv">3</span>]<span class="sc">+</span><span class="fl">0.9</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="19-nn_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Noisy quadratic function approximated by a neural network with tanh activation function.</figcaption>
</figure>
</div>
</div>
</div>
<p>Notice that we did not have to explicitly specify that our model need to have a quadratic term, the model learned it from the data. This is the power of deep learning. The model is able to learn the structure of the data from the data itself.</p>
<p>We can apply the same approach to the interactions, say the true model for the data as follows <span class="math display">\[
y = 0.5 + 0.1x_1 + 0.2x_2  + 0.5x_1x_2+ \epsilon, ~ \epsilon \sim N(0,0.02^2)
\]</span> We can use the same model as above, but with two input variables. The model will learn the interaction term from the data.</p>
<div class="cell" data-null_prefix="true">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">99</span>) <span class="co">#ovi</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> x1</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.1</span><span class="sc">*</span>x1 <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>x2 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x1<span class="sc">*</span>x2 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(x1),<span class="dv">0</span>,<span class="fl">0.02</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"scatterplot3d"</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>s3d <span class="ot">=</span> <span class="fu">scatterplot3d</span>(x1,x2,y, <span class="at">pch=</span><span class="dv">16</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">cbind</span>(x1,x2)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>nn <span class="ot">=</span> <span class="cf">function</span>(W,<span class="at">f=</span>relu) {</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    b0 <span class="ot">=</span> W[<span class="dv">1</span>]; w0 <span class="ot">=</span> W[<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>]; b1 <span class="ot">=</span> W[<span class="dv">6</span>]; w1 <span class="ot">=</span> W[<span class="dv">7</span><span class="sc">:</span><span class="dv">8</span>]</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    w0 <span class="ot">=</span> <span class="fu">matrix</span>(w0,<span class="at">nrow=</span><span class="dv">2</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    z0 <span class="ot">=</span> <span class="fu">apply</span>(b0 <span class="sc">+</span> x<span class="sc">%*%</span>w0,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,f)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    yhat <span class="ot">=</span> b1 <span class="sc">+</span> z0 <span class="sc">%*%</span> w1</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">yhat =</span> yhat[,<span class="dv">1</span>],<span class="at">z0=</span>z0))</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>W <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">4</span>),<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">2</span>))</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>loss <span class="ot">=</span> <span class="cf">function</span>(W) <span class="fu">sum</span>((<span class="fu">nn</span>(W, <span class="at">f=</span>tanh)<span class="sc">$</span>yhat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>res <span class="ot">=</span> <span class="fu">optim</span>(W, <span class="at">fn=</span>loss, <span class="at">method=</span><span class="st">'BFGS'</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>res<span class="sc">$</span>par</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  0.78  0.50 -1.39  0.63 -0.94 -2.06 -2.88  6.78</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>o <span class="ot">=</span> <span class="fu">nn</span>(res<span class="sc">$</span>par, <span class="at">f=</span>tanh)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>s3d<span class="sc">$</span><span class="fu">points3d</span>(x1,x2,o<span class="sc">$</span>yhat, <span class="at">col=</span><span class="dv">2</span>, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">lwd=</span><span class="dv">5</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>s3d<span class="sc">$</span><span class="fu">points3d</span>(x1,x2,o<span class="sc">$</span>z0[,<span class="dv">1</span>], <span class="at">col=</span><span class="dv">3</span>, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">lwd=</span><span class="dv">5</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>s3d<span class="sc">$</span><span class="fu">points3d</span>(x1,x2,o<span class="sc">$</span>z0[,<span class="dv">2</span>], <span class="at">col=</span><span class="dv">4</span>, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">lwd=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="19-nn_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Effectively, you can think of the neural network as a flexible function approximator, equivalent to a nonparametric regression approach which learns the basis functions from data. The model can learn the structure of the data from the data itself. This is the power of deep learning.</p>
</section>
<section id="activation-functions" class="level2" data-number="20.3">
<h2 data-number="20.3" class="anchored" data-anchor-id="activation-functions"><span class="header-section-number">20.3</span> Activation Functions</h2>
<p>The last output layer of a neural network has sigmoid activation function for binary output variable (classification) and no activation function for continuous output variable regression. The hidden layers can have different activation functions. The most common activation functions are the hyperbolic tangent function and the rectified linear unit (ReLU) function.</p>
<p>A typical approach is to use the same activation function for all hidden layers. The hyperbolic tangent function is defined as <span class="math display">\[
\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
\]</span> Notice, that the hyperbolic tangent function is a scaled version of the sigmoid function, with <span class="math inline">\(\tanh(0) = 0\)</span>. It is a smooth function which is differentiable everywhere. However,</p>
<div>

</div>
<div class="cell quarto-layout-panel" data-layout-ncol="3" data-null_prefix="true">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="19-nn_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>tanh</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="19-nn_files/figure-html/unnamed-chunk-5-2.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Hard tanh</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="19-nn_files/figure-html/unnamed-chunk-5-3.png" class="img-fluid figure-img" width="576"></p>
<figcaption>softplus</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="19-nn_files/figure-html/unnamed-chunk-5-4.png" class="img-fluid figure-img" width="576"></p>
<figcaption>ReLU</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="19-nn_files/figure-html/unnamed-chunk-5-5.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Leaky ReLU</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="19-nn_files/figure-html/unnamed-chunk-5-6.png" class="img-fluid figure-img" width="576"></p>
<figcaption>sigmoid</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Typically <span class="math inline">\(\tanh\)</span> is preferred to the sigmoid function because it is zero-centered. The major drawback of sigmoid and <span class="math inline">\(\tanh\)</span> functions is that they saturate when the input is very large or very small. When we try to learn the weights of the network, the optimisation algorithms makes small steps in the space of the parameters and when the weights are large the small changes won’t effect the values of the layers’ outputs and optimisation will “stagnate”.</p>
<p>This means that the gradient of the function is very small, which makes learning slow. The ReLU function is defined as</p>
<p>The ReLU function is defined as <span class="math display">\[
\text{ReLU}(z) = \max(0,z)
\]</span> The ReLU function is a piecewise linear function which is computationally efficient and easy to optimize. The ReLU function is the most commonly used activation function in deep learning. The ReLU function is not differentiable at <span class="math inline">\(z=0\)</span>, but it is differentiable everywhere else. The derivative of the ReLU function is <span class="math display">\[
\text{ReLU}'(z) = \begin{cases} 0 &amp; \text{if } z &lt; 0 \\ 1 &amp; \text{if } z &gt; 0 \end{cases}
\]</span></p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-behnia2021deep" class="csl-entry" role="listitem">
Behnia, Farnaz, Dominik Karbowski, and Vadim Sokolov. 2021. <span>“Deep Generative Models for Vehicle Speed Trajectories.”</span> <em>arXiv Preprint arXiv:2112.08361</em>.
</div>
<div id="ref-bhadra2021merging" class="csl-entry" role="listitem">
Bhadra, Anindya, Jyotishka Datta, Nick Polson, Vadim Sokolov, and Jianeng Xu. 2021. <span>“Merging Two Cultures: Deep and Statistical Learning.”</span> <em>arXiv Preprint arXiv:2110.11561</em>.
</div>
<div id="ref-dixon2019deep" class="csl-entry" role="listitem">
Dixon, Matthew F, Nicholas G Polson, and Vadim O Sokolov. 2019. <span>“Deep Learning for Spatio-Temporal Modeling: Dynamic Traffic Flows and High Frequency Trading.”</span> <em>Applied Stochastic Models in Business and Industry</em> 35 (3): 788–807.
</div>
<div id="ref-heaton2017deep" class="csl-entry" role="listitem">
Heaton, JB, NG Polson, and Jan Hendrik Witte. 2017. <span>“Deep Learning for Finance: Deep Portfolios.”</span> <em>Applied Stochastic Models in Business and Industry</em> 33 (1): 3–12.
</div>
<div id="ref-nareklishvili2022deep" class="csl-entry" role="listitem">
Nareklishvili, Maria, Nicholas Polson, and Vadim Sokolov. 2022a. <span>“Deep Partial Least Squares for Iv Regression.”</span> <em>arXiv Preprint arXiv:2207.02612</em>.
</div>
<div id="ref-nareklishvili2022feature" class="csl-entry" role="listitem">
———. 2022b. <span>“Feature Selection for Personalized Policy Analysis.”</span> <em>arXiv Preprint arXiv:2301.00251</em>.
</div>
<div id="ref-nareklishvili2023generative" class="csl-entry" role="listitem">
———. 2023. <span>“Generative Causal Inference.”</span> <em>arXiv Preprint arXiv:2306.16096</em>.
</div>
<div id="ref-polson2017deep" class="csl-entry" role="listitem">
Polson, Nicholas G, and Vadim Sokolov. 2017. <span>“Deep Learning: A Bayesian Perspective.”</span>
</div>
<div id="ref-polson2023generative" class="csl-entry" role="listitem">
———. 2023. <span>“Generative AI for Bayesian Computation.”</span> <em>arXiv Preprint arXiv:2305.14972</em>.
</div>
<div id="ref-polson2020deep" class="csl-entry" role="listitem">
Polson, Nicholas, and Vadim Sokolov. 2020. <span>“Deep Learning: Computational Aspects.”</span> <em>Wiley Interdisciplinary Reviews: Computational Statistics</em> 12 (5): e1500.
</div>
<div id="ref-polson2021deep" class="csl-entry" role="listitem">
Polson, Nicholas, Vadim Sokolov, and Jianeng Xu. 2021. <span>“Deep Learning Partial Least Squares.”</span> <em>arXiv Preprint arXiv:2106.14085</em>.
</div>
<div id="ref-sokolov2017discussion" class="csl-entry" role="listitem">
Sokolov, Vadim. 2017. <span>“Discussion of ’Deep Learning for Finance: Deep Portfolios’.”</span> <em>Applied Stochastic Models in Business and Industry</em> 33 (1): 16–18.
</div>
<div id="ref-wang2022data" class="csl-entry" role="listitem">
Wang, Yuexi, Nicholas Polson, and Vadim O Sokolov. 2022. <span>“Data Augmentation for Bayesian Deep Learning.”</span> <em>Bayesian Analysis</em> 1 (1): 1–29.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./18-forecasting.html" class="pagination-link" aria-label="Forecasting">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Forecasting</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./20-dlopt.html" class="pagination-link" aria-label="Gradient Descent">
        <span class="nav-page-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>