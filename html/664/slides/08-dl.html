<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Vadim Sokolov   George Mason University   Spring 2025">
  <title>Bayes AI</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-bbe7401fe57d4b791b917637bb662036.css">
  <link rel="stylesheet" href="style.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="center">
  <h1 class="title" style="font-size:40px;">Bayes AI</h1>
  <p class="subtitle" style="color:blue;font-size:50px;">Unit 8: Bayesian Deep Learning</p>
<img style="height: 350px;" src="fig/page/09-quantilerl.jpg">
  <p class="author">Vadim Sokolov <br> George Mason University <br> Spring 2025</p>

<p style="font-size:10px;"> 
<a href="https://vsokolov.org/courses/664.html">Course Page</a>, <a href="https://vsokolov.org/html/664/slides/">Slides</a>
</p>


</section>
<section>
<section id="bayes-in-modern-ai" class="title-slide slide level1 center">
<h1>Bayes in Modern AI</h1>

</section>
<section id="deep-learning" class="slide level2">
<h2>Deep Learning</h2>
<ul>
<li>Rather than using shallow additive architectures common to most statistical models, deep learning uses layers of semi-affine input transformations to provide a predictive rule.</li>
<li>Applying these layers of transformations leads to a set of attributes (or, features) to which probabilistic statistical methods can be applied.</li>
<li>Deep learning is one of the widely used machine learning method for analysis of large scale and high-dimensional data sets.</li>
<li>There are several deep learning architectures exist - each has its own uses and purposes. Convolutional Neural Networks (CNN) deal with 2-dimensional input objects, i.e.&nbsp;images and were shown to outperform any other techniques. Recurrent Neural Networks (RNN) were shown the best performance on speech and text analysis tasks.</li>
</ul>
</section>
<section id="neural-network" class="slide level2">
<h2>Neural Network</h2>
<ul>
<li>Let <span class="math inline">\(f_1 , \ldots , f_L\)</span> be given univariate activation functions for each of the <span class="math inline">\(L\)</span> layers.</li>
<li>Activation functions are nonlinear transformations of weighted data.</li>
<li>A semi-affine activation rule is then defined by <span class="math display">\[
f_l^{W,b} = f_l \left ( \sum_{j=1}^{N_l} W_{lj} X_j + b_l \right ) = f_l ( W_l X_l + b_l )\,,
\]</span> which implicitly needs the specification of the number of hidden units <span class="math inline">\(N_l\)</span>. Our deep predictor, given the number of layers <span class="math inline">\(L\)</span>, then becomes the composite map</li>
</ul>
<p><span class="math display">\[
\hat{Y}(X) = F(X) = \left ( f_l^{W_1,b_1} \circ \ldots \circ f_L^{W_L,b_L} \right ) ( X)\,.
\]</span></p>
</section>
<section id="neural-network-1" class="slide level2">
<h2>Neural Network</h2>
<ul>
<li>The fact that DL forms a universal “basis” which we recognize in this formulation dates to Poincare and Hilbert is central.</li>
<li>From a practical perspective, given a large enough data set of “test cases”, we can empirically learn an optimal predictor.</li>
<li>Similar to a classic basis decomposition, the deep approach uses univariate activation functions to decompose a high dimensional <span class="math inline">\(X\)</span>.</li>
</ul>
<p>Let <span class="math inline">\(Z^{(l)}\)</span> denote the <span class="math inline">\(l\)</span>th layer, and so <span class="math inline">\(X = Z^{(0)}\)</span>. The final output <span class="math inline">\(Y\)</span> can be numeric or categorical. The explicit structure of a deep prediction rule is then <span class="math display">\[
\begin{aligned}
\hat{Y} (X) &amp; = W^{(L)} Z^{(L)} + b^{(L)} \\
Z^{(1)} &amp; = f^{(1)} \left ( W^{(0)} X + b^{(0)} \right ) \\
Z^{(2)} &amp; = f^{(2)} \left ( W^{(1)} Z^{(1)} + b^{(1)} \right ) \\
\ldots  &amp; \\
Z^{(L)} &amp; = f^{(L)} \left ( W^{(L-1)} Z^{(L-1)} + b^{(L-1)} \right )\,.
\end{aligned}
\]</span></p>
</section>
<section id="motivating-example" class="slide level2">
<h2>Motivating Example</h2>
<ul>
<li>Apply feed-forward neural network with one hidden layer to a problem of binary classification</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a></a>numSamples <span class="ot">=</span> <span class="dv">200</span> <span class="co"># total number of observations</span></span>
<span id="cb1-2"><a></a>radius <span class="ot">=</span> <span class="dv">10</span> <span class="co"># radius of the outer circle</span></span>
<span id="cb1-3"><a></a>noise <span class="ot">=</span> <span class="fl">0.0001</span> <span class="co"># amount of noise to be added to the data</span></span>
<span id="cb1-4"><a></a>d <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">nrow =</span> numSamples); <span class="co"># matrix to store our generated data</span></span>
<span id="cb1-5"><a></a></span>
<span id="cb1-6"><a></a><span class="co"># Generate positive points inside the circle.</span></span>
<span id="cb1-7"><a></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(numSamples<span class="sc">/</span><span class="dv">2</span>) ) {</span>
<span id="cb1-8"><a></a>  r <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>, radius <span class="sc">*</span> <span class="fl">0.4</span>);</span>
<span id="cb1-9"><a></a>  angle <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>, <span class="dv">2</span> <span class="sc">*</span> pi);</span>
<span id="cb1-10"><a></a>  x <span class="ot">=</span> r <span class="sc">*</span> <span class="fu">sin</span>(angle);</span>
<span id="cb1-11"><a></a>  y <span class="ot">=</span> r <span class="sc">*</span> <span class="fu">cos</span>(angle);</span>
<span id="cb1-12"><a></a>  noiseX <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="sc">-</span>radius, radius) <span class="sc">*</span> noise;</span>
<span id="cb1-13"><a></a>  noiseY <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="sc">-</span>radius, radius) <span class="sc">*</span> noise;</span>
<span id="cb1-14"><a></a>  d[i,] <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,x,y)</span>
<span id="cb1-15"><a></a>}</span>
<span id="cb1-16"><a></a></span>
<span id="cb1-17"><a></a><span class="co"># Generate negative points outside the circle.</span></span>
<span id="cb1-18"><a></a><span class="cf">for</span> (i <span class="cf">in</span> (numSamples<span class="sc">/</span><span class="dv">2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>numSamples ) {</span>
<span id="cb1-19"><a></a>  r <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,radius <span class="sc">*</span> <span class="fl">0.8</span>, radius);</span>
<span id="cb1-20"><a></a>  angle <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>, <span class="dv">2</span> <span class="sc">*</span> pi);</span>
<span id="cb1-21"><a></a>  x <span class="ot">=</span> r <span class="sc">*</span> <span class="fu">sin</span>(angle);</span>
<span id="cb1-22"><a></a>  y <span class="ot">=</span> r <span class="sc">*</span> <span class="fu">cos</span>(angle);</span>
<span id="cb1-23"><a></a>  noiseX <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="sc">-</span>radius, radius) <span class="sc">*</span> noise;</span>
<span id="cb1-24"><a></a>  noiseY <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1</span>,<span class="sc">-</span>radius, radius) <span class="sc">*</span> noise;</span>
<span id="cb1-25"><a></a>  d[i,] <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>,x,y)</span>
<span id="cb1-26"><a></a>}</span>
<span id="cb1-27"><a></a><span class="fu">colnames</span>(d) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"label"</span>, <span class="st">"x1"</span>, <span class="st">"x2"</span>)</span>
<span id="cb1-28"><a></a><span class="co"># Plot the training dataset</span></span>
<span id="cb1-29"><a></a><span class="fu">plot</span>(d[,<span class="dv">2</span>],d[,<span class="dv">3</span>], <span class="at">col=</span>d[,<span class="dv">1</span>]<span class="sc">+</span><span class="dv">2</span>, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">xlab=</span><span class="st">"x1"</span>, <span class="at">ylab=</span><span class="st">"x2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a></a><span class="co"># utils$save_pdf("~/papers/twocultures/fig/","nn-circle-2")</span></span>
<span id="cb2-2"><a></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">11</span>,<span class="dv">11</span>,<span class="at">length.out =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<img data-src="08-dl_files/figure-revealjs/circle-data-1.png" width="960" class="r-stretch"></section>
<section id="circle-example" class="slide level2">
<h2>Circle Example</h2>
<p>Let’s try to use a simple logistic regression model to separate the two classes.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a></a><span class="co"># Fit a logistic regression model</span></span>
<span id="cb3-2"><a></a>fit <span class="ot">=</span> <span class="fu">glm</span>(label<span class="sc">~</span>x1<span class="sc">+</span>x2, <span class="at">data=</span><span class="fu">as.data.frame</span>(d), <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span><span class="st">'logit'</span>))</span>
<span id="cb3-3"><a></a><span class="co"># Plot the training dataset</span></span>
<span id="cb3-4"><a></a><span class="fu">plot</span>(d[,<span class="dv">2</span>],d[,<span class="dv">3</span>], <span class="at">col=</span>d[,<span class="dv">1</span>]<span class="sc">+</span><span class="dv">2</span>, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">xlab=</span><span class="st">"x1"</span>, <span class="at">ylab=</span><span class="st">"x2"</span>)</span>
<span id="cb3-5"><a></a>th <span class="ot">=</span> fit<span class="sc">$</span>coefficients</span>
<span id="cb3-6"><a></a><span class="co"># Plot the decision boundary</span></span>
<span id="cb3-7"><a></a><span class="fu">abline</span>(<span class="sc">-</span>th[<span class="dv">1</span>]<span class="sc">/</span>th[<span class="dv">3</span>], <span class="sc">-</span>th[<span class="dv">2</span>]<span class="sc">/</span>th[<span class="dv">3</span>], <span class="at">col=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/circle-lr-1.png" width="960" class="r-stretch"><p>We can see that a logistic regression could not do it. It uses a single line to separate observations of two classes. We can see that the data is not linearly separable.</p>
</section>
<section id="circle-example-1" class="slide level2">
<h2>Circle Example</h2>
<p>However, we can use multiple lines to separate the data.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a></a><span class="fu">plot</span>(x1<span class="sc">~</span>x2, <span class="at">data=</span>d,<span class="at">col=</span>d[,<span class="dv">1</span>]<span class="sc">+</span><span class="dv">2</span>, <span class="at">pch=</span><span class="dv">16</span>)</span>
<span id="cb4-2"><a></a><span class="co"># Plot lines that separate once class (red) from another (green)</span></span>
<span id="cb4-3"><a></a><span class="fu">lines</span>(x1, <span class="sc">-</span>x1 <span class="sc">-</span> <span class="dv">6</span>); <span class="fu">text</span>(<span class="sc">-</span><span class="dv">4</span>,<span class="sc">-</span><span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb4-4"><a></a><span class="fu">lines</span>(x1, <span class="sc">-</span>x1 <span class="sc">+</span> <span class="dv">6</span>); <span class="fu">text</span>(<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">2</span>)</span>
<span id="cb4-5"><a></a><span class="fu">lines</span>(x1,  x1 <span class="sc">-</span> <span class="dv">6</span>); <span class="fu">text</span>(<span class="dv">4</span>,<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb4-6"><a></a><span class="fu">lines</span>(x1,  x1 <span class="sc">+</span> <span class="dv">6</span>); <span class="fu">text</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/sep-lines-1.png" width="960" class="r-stretch"></section>
<section id="circle-example-2" class="slide level2">
<h2>Circle Example</h2>
<p>Now, we do the same thing as in simple logistic regression and apply logistic function to each of those lines</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a></a><span class="co"># Define sigmoid function</span></span>
<span id="cb5-2"><a></a>sigmoid  <span class="ot">=</span> <span class="cf">function</span>(z) <span class="fu">exp</span>(z)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(z))</span>
<span id="cb5-3"><a></a></span>
<span id="cb5-4"><a></a><span class="co"># Define hidden layer of our neural network</span></span>
<span id="cb5-5"><a></a>features <span class="ot">=</span> <span class="cf">function</span>(x1,x2) {</span>
<span id="cb5-6"><a></a>  z1 <span class="ot">=</span>  <span class="dv">6</span> <span class="sc">+</span> x1 <span class="sc">+</span> x2; a1 <span class="ot">=</span> <span class="fu">sigmoid</span>(z1)</span>
<span id="cb5-7"><a></a>  z2 <span class="ot">=</span>  <span class="dv">6</span> <span class="sc">-</span> x1 <span class="sc">-</span> x2; a2 <span class="ot">=</span> <span class="fu">sigmoid</span>(z2)</span>
<span id="cb5-8"><a></a>  z3 <span class="ot">=</span>  <span class="dv">6</span> <span class="sc">-</span> x1 <span class="sc">+</span> x2; a3 <span class="ot">=</span> <span class="fu">sigmoid</span>(z3)</span>
<span id="cb5-9"><a></a>  z4 <span class="ot">=</span>  <span class="dv">6</span> <span class="sc">+</span> x1 <span class="sc">-</span> x2; a4 <span class="ot">=</span> <span class="fu">sigmoid</span>(z4)</span>
<span id="cb5-10"><a></a>  <span class="fu">return</span>(<span class="fu">c</span>(a1,a2,a3,a4))</span>
<span id="cb5-11"><a></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Using the matrix notaitons, we have <span class="math display">\[
z = \sigma(Wx + b), ~ W = \begin{bmatrix} 1 &amp; 1 \\ -1 &amp; -1 \\ -1 &amp; 1 \\ 1 &amp; -1 \end{bmatrix}, ~ b = \begin{bmatrix} 6 \\ 6 \\ 6 \\ 6 \end{bmatrix}, ~ \sigma(z) = \frac{1}{1+e^{-z}}
\]</span></p>
<p>First layer of our NN: <span class="math inline">\(R^2 \rightarrow R^4\)</span> output <span class="math inline">\(z\)</span> called a feature vector.</p>
</section>
<section id="circle-example-3" class="slide level2">
<h2>Circle Example</h2>
<p>The feature vector <span class="math inline">\(z\)</span> is then passed to the output layer, which applies simple logistic regression to the feature vector. <span class="math display">\[
\hat{y} = \sigma(w^Tz + b), ~ w = \begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \end{bmatrix}, ~ b = -3.1, ~ \sigma(z) = \frac{1}{1+e^{-z}}
\]</span></p>
<p>The output of the output layer is the probability of the positive class.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a></a><span class="co"># Calculate prediction (classification) using our neural network</span></span>
<span id="cb6-2"><a></a>predict_prob <span class="ot">=</span> <span class="cf">function</span>(x){</span>
<span id="cb6-3"><a></a>  x1 <span class="ot">=</span> x[<span class="dv">1</span>]; x2 <span class="ot">=</span> x[<span class="dv">2</span>]</span>
<span id="cb6-4"><a></a>  z <span class="ot">=</span> <span class="fu">features</span>(x1,x2)</span>
<span id="cb6-5"><a></a>  <span class="co"># print(z)</span></span>
<span id="cb6-6"><a></a>  mu <span class="ot">=</span> <span class="fu">sum</span>(z) <span class="sc">-</span> <span class="fl">3.1</span></span>
<span id="cb6-7"><a></a>  <span class="co"># print(mu)</span></span>
<span id="cb6-8"><a></a>  <span class="fu">sigmoid</span>(mu)</span>
<span id="cb6-9"><a></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="circle-example-4" class="slide level2">
<h2>Circle Example</h2>
<p>We can use our model to do the predictions now</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a></a><span class="co"># Predict the probability of the positive class for a given point</span></span>
<span id="cb7-2"><a></a><span class="fu">predict_prob</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7089128</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a></a><span class="fu">predict_prob</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2565405</code></pre>
</div>
</div>
</section>
<section id="circle-example-5" class="slide level2">
<h2>Circle Example</h2>
<p>The model generates sensible predictions, let’s plot the decision boundary to see how well it separates the data.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">11</span>,<span class="dv">11</span>,<span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb11-2"><a></a>x2 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">11</span>,<span class="dv">11</span>,<span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb11-3"><a></a>gr <span class="ot">=</span> <span class="fu">as.matrix</span>(<span class="fu">expand.grid</span>(x1,x2));</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10000     2</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a></a>yhat <span class="ot">=</span> <span class="fu">apply</span>(gr,<span class="dv">1</span>,predict_prob)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10000</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a></a><span class="fu">image</span>(x1,x2,<span class="fu">matrix</span>(yhat,<span class="at">ncol =</span> <span class="dv">100</span>), <span class="at">col =</span> <span class="fu">heat.colors</span>(<span class="dv">20</span>,<span class="fl">0.7</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/circle-boundary-1.png" width="960" class="r-stretch"></section>
<section id="regression" class="slide level2">
<h2>Regression</h2>
<p>How about a regression model. We will use a one-layer neural network to fit a quadratic function. We simulate noisy data from the following model <span class="math display">\[
y = 0.5 + 0.3x^2 + \epsilon, ~ \epsilon \sim N(0,0.02^2)
\]</span> - 3 hidden units in the first hidden - 2 units in the second hidden layer - output layer is a single unit - Use the hyperbolic tangent (<code>ReLU</code>) activation function for all layers. The model is defined as follows</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a></a>relu <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">max</span>(<span class="dv">0</span>,x)</span>
<span id="cb16-2"><a></a>nn <span class="ot">=</span> <span class="cf">function</span>(W,<span class="at">f=</span>relu) {</span>
<span id="cb16-3"><a></a>    b0 <span class="ot">=</span> W[<span class="dv">1</span>]; w0<span class="ot">=</span>W[<span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>];b1 <span class="ot">=</span> W[<span class="dv">5</span>]; w1 <span class="ot">=</span> W[<span class="dv">6</span><span class="sc">:</span><span class="dv">8</span>]</span>
<span id="cb16-4"><a></a>    z0 <span class="ot">=</span> <span class="fu">apply</span>(b0 <span class="sc">+</span> <span class="fu">outer</span>(x,w0,<span class="st">'*'</span>),<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,f)</span>
<span id="cb16-5"><a></a>    yhat <span class="ot">=</span> b1 <span class="sc">+</span> z0 <span class="sc">%*%</span> w1</span>
<span id="cb16-6"><a></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">yhat =</span> yhat[,<span class="dv">1</span>],<span class="at">z0=</span>z0))</span>
<span id="cb16-7"><a></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="regression-1" class="slide level2">
<h2>Regression</h2>
<ul>
<li>The output linear layer has a single output. Thus, the prediction <code>yhat</code> is generated as a linear model of the feature vector <code>z0</code>.</li>
<li>The model has 8 parameters<br>
</li>
<li>Let’s generate training data and fit the model</li>
<li>We will use the BFGS optimization algorithm to minimize the loss function (negative log-likelihood) of the model.</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a></a><span class="fu">set.seed</span>(<span class="dv">99</span>) <span class="co">#gretzky</span></span>
<span id="cb17-2"><a></a>nl  <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">2</span>)</span>
<span id="cb17-3"><a></a>params <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">3</span>),<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">3</span>))</span>
<span id="cb17-4"><a></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="fl">0.02</span>)</span>
<span id="cb17-5"><a></a>y <span class="ot">=</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.3</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(x),<span class="dv">0</span>,<span class="fl">0.02</span>)</span>
<span id="cb17-6"><a></a>loss <span class="ot">=</span> <span class="cf">function</span>(W) <span class="fu">sum</span>((<span class="fu">nn</span>(W)<span class="sc">$</span>yhat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb17-7"><a></a>res <span class="ot">=</span> <span class="fu">optim</span>(params, loss, <span class="at">method=</span><span class="st">'BFGS'</span>)</span>
<span id="cb17-8"><a></a>res<span class="sc">$</span>par</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.2369376  1.3898195 -0.8211064  0.4558352  0.4974205  0.1733447  0.4632991
[8]  0.3879388</code></pre>
</div>
</div>
</section>
<section id="regression-2" class="slide level2">
<h2>Regression</h2>
<p>The solid black line is the neural network model, and the dashed lines are the basis functions. The model fits the data well.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a></a>o <span class="ot">=</span> <span class="fu">nn</span>(res<span class="sc">$</span>par)</span>
<span id="cb19-2"><a></a><span class="fu">plot</span>(x,y); <span class="fu">lines</span>(x,o<span class="sc">$</span>yhat, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb19-3"><a></a><span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">+</span>o<span class="sc">$</span>z0[,<span class="dv">1</span>],<span class="at">col=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>); <span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">+</span>o<span class="sc">$</span>z0[,<span class="dv">2</span>],<span class="at">col=</span><span class="dv">3</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>); <span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">+</span>o<span class="sc">$</span>z0[,<span class="dv">3</span>],<span class="at">col=</span><span class="dv">4</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/fig-relu-1.png" width="960" class="r-stretch quarto-figure-center" id="fig-relu"><p class="caption">
Figure&nbsp;1: Noisy quadratic function approximated by a neural network with ReLu activation function.
</p></section>
<section id="regression-3" class="slide level2">
<h2>Regression</h2>
<p>Let’s try the <span class="math inline">\(\tanh\)</span> function</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a></a><span class="fu">set.seed</span>(<span class="dv">8</span>) <span class="co">#gretzky</span></span>
<span id="cb20-2"><a></a>params <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">3</span>),<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">3</span>))</span>
<span id="cb20-3"><a></a>loss <span class="ot">=</span> <span class="cf">function</span>(W) <span class="fu">mean</span>((<span class="fu">nn</span>(W,<span class="at">f=</span>tanh)<span class="sc">$</span>yhat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb20-4"><a></a>res <span class="ot">=</span> <span class="fu">optim</span>(params, loss, <span class="at">method=</span><span class="st">'BFGS'</span>)</span>
<span id="cb20-5"><a></a>res<span class="sc">$</span>par</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.9804458 -0.2331603  0.8336547 -1.1397178  0.8431593 -0.6489841  0.5880229
[8]  0.5269772</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a></a>o <span class="ot">=</span> <span class="fu">nn</span>(res<span class="sc">$</span>par, <span class="at">f=</span>tanh)</span>
<span id="cb22-2"><a></a><span class="fu">plot</span>(x,y, <span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">0.4</span>,<span class="fl">0.95</span>)); <span class="fu">lines</span>(x,o<span class="sc">$</span>yhat, <span class="at">lwd=</span><span class="dv">2</span>);</span>
<span id="cb22-3"><a></a><span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">*</span>o<span class="sc">$</span>z0[,<span class="dv">1</span>]<span class="sc">+</span><span class="fl">0.9</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="dv">2</span>); <span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">*</span>o<span class="sc">$</span>z0[,<span class="dv">2</span>]<span class="sc">+</span><span class="fl">0.9</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="dv">3</span>); <span class="fu">lines</span>(x,<span class="fl">0.5</span><span class="sc">*</span>o<span class="sc">$</span>z0[,<span class="dv">3</span>]<span class="sc">+</span><span class="fl">0.9</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-3-1.png" width="960" class="r-stretch quarto-figure-center"><p class="caption">Noisy quadratic function approximated by a neural network with tanh activation function.</p><p>Notice that we did not have to explicitly specify that our model need to have a quadratic term, the model learned it from the data. This is the power of deep learning. The model is able to learn the structure of the data from the data itself.</p>
</section>
<section id="regression-4" class="slide level2">
<h2>Regression</h2>
<p>We can apply the same approach to the interactions, say the true model for the data as follows <span class="math display">\[
y = 0.5 + 0.1x_1 + 0.2x_2  + 0.5x_1x_2+ \epsilon, ~ \epsilon \sim N(0,0.02^2)
\]</span> We can use the same model as above, but with two input variables. The model will learn the interaction term from the data.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a></a><span class="fu">set.seed</span>(<span class="dv">99</span>) <span class="co">#ovi</span></span>
<span id="cb23-2"><a></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb23-3"><a></a>x2 <span class="ot">=</span> x1</span>
<span id="cb23-4"><a></a>y <span class="ot">=</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.1</span><span class="sc">*</span>x1 <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>x2 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x1<span class="sc">*</span>x2 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(x1),<span class="dv">0</span>,<span class="fl">0.02</span>)</span>
<span id="cb23-5"><a></a><span class="fu">library</span>(<span class="st">"scatterplot3d"</span>)</span>
<span id="cb23-6"><a></a>s3d <span class="ot">=</span> <span class="fu">scatterplot3d</span>(x1,x2,y, <span class="at">pch=</span><span class="dv">16</span>)</span>
<span id="cb23-7"><a></a>x <span class="ot">=</span> <span class="fu">cbind</span>(x1,x2)</span>
<span id="cb23-8"><a></a>nn <span class="ot">=</span> <span class="cf">function</span>(W,<span class="at">f=</span>relu) {</span>
<span id="cb23-9"><a></a>    b0 <span class="ot">=</span> W[<span class="dv">1</span>]; w0 <span class="ot">=</span> W[<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>]; b1 <span class="ot">=</span> W[<span class="dv">6</span>]; w1 <span class="ot">=</span> W[<span class="dv">7</span><span class="sc">:</span><span class="dv">8</span>]</span>
<span id="cb23-10"><a></a>    w0 <span class="ot">=</span> <span class="fu">matrix</span>(w0,<span class="at">nrow=</span><span class="dv">2</span>)</span>
<span id="cb23-11"><a></a>    z0 <span class="ot">=</span> <span class="fu">apply</span>(b0 <span class="sc">+</span> x<span class="sc">%*%</span>w0,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,f)</span>
<span id="cb23-12"><a></a>    yhat <span class="ot">=</span> b1 <span class="sc">+</span> z0 <span class="sc">%*%</span> w1</span>
<span id="cb23-13"><a></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">yhat =</span> yhat[,<span class="dv">1</span>],<span class="at">z0=</span>z0))</span>
<span id="cb23-14"><a></a>}</span>
<span id="cb23-15"><a></a>W <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">4</span>),<span class="dv">0</span>,<span class="fu">rnorm</span>(<span class="dv">2</span>))</span>
<span id="cb23-16"><a></a>loss <span class="ot">=</span> <span class="cf">function</span>(W) <span class="fu">sum</span>((<span class="fu">nn</span>(W, <span class="at">f=</span>tanh)<span class="sc">$</span>yhat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb23-17"><a></a>res <span class="ot">=</span> <span class="fu">optim</span>(W, <span class="at">fn=</span>loss, <span class="at">method=</span><span class="st">'BFGS'</span>)</span>
<span id="cb23-18"><a></a>res<span class="sc">$</span>par</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  0.7821996  0.5035370 -1.3927522  0.6322621 -0.9379012 -2.0564351 -2.8841640
[8]  6.7772229</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a></a>o <span class="ot">=</span> <span class="fu">nn</span>(res<span class="sc">$</span>par, <span class="at">f=</span>tanh)</span>
<span id="cb25-2"><a></a>s3d<span class="sc">$</span><span class="fu">points3d</span>(x1,x2,o<span class="sc">$</span>yhat, <span class="at">col=</span><span class="dv">2</span>, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">lwd=</span><span class="dv">5</span>)</span>
<span id="cb25-3"><a></a>s3d<span class="sc">$</span><span class="fu">points3d</span>(x1,x2,o<span class="sc">$</span>z0[,<span class="dv">1</span>], <span class="at">col=</span><span class="dv">3</span>, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">lwd=</span><span class="dv">5</span>)</span>
<span id="cb25-4"><a></a>s3d<span class="sc">$</span><span class="fu">points3d</span>(x1,x2,o<span class="sc">$</span>z0[,<span class="dv">2</span>], <span class="at">col=</span><span class="dv">4</span>, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">lwd=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-4-1.png" width="960" class="r-stretch"></section>
<section id="activation-functions" class="slide level2">
<h2>Activation Functions</h2>
<ul>
<li>The last output layer of a neural network has sigmoid activation function for binary output variable (classification) and no activation function for continuous output variable regression.</li>
<li>The hidden layers can have different activation functions. The most common activation functions are the hyperbolic tangent function and the rectified linear unit (ReLU) function.</li>
</ul>
<p>A typical approach is to use the same activation function for all hidden layers. The hyperbolic tangent function is defined as <span class="math display">\[
\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
\]</span> Notice, that the hyperbolic tangent function is a scaled version of the sigmoid function, with <span class="math inline">\(\tanh(0) = 0\)</span>. It is a smooth function which is differentiable everywhere. However,</p>
</section>
<section id="activation-functions-1" class="slide level2">
<h2>Activation Functions</h2>
<div>

</div>
<div class="cell quarto-layout-panel" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="08-dl_files/figure-revealjs/unnamed-chunk-5-1.png" width="960"></p>
<figcaption>tanh</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="08-dl_files/figure-revealjs/unnamed-chunk-5-2.png" width="960"></p>
<figcaption>Hard tanh</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="08-dl_files/figure-revealjs/unnamed-chunk-5-3.png" width="960"></p>
<figcaption>softplus</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="08-dl_files/figure-revealjs/unnamed-chunk-5-4.png" width="960"></p>
<figcaption>ReLU</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="08-dl_files/figure-revealjs/unnamed-chunk-5-5.png" width="960"></p>
<figcaption>Leaky ReLU</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="08-dl_files/figure-revealjs/unnamed-chunk-5-6.png" width="960"></p>
<figcaption>sigmoid</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="activation-functions-2" class="slide level2">
<h2>Activation Functions</h2>
<ul>
<li>Typically <span class="math inline">\(\tanh\)</span> is preferred to the sigmoid function because it is zero-centered.</li>
<li>The major drawback of sigmoid and <span class="math inline">\(\tanh\)</span> functions is that they saturate when the input is very large or very small.<br>
</li>
<li>When we try to learn the weights of the network, the optimisation algorithms makes small steps in the space of the parameters and when the weights are large the small changes won’t effect the values of the layers’ outputs and optimisation will “stagnate”.</li>
<li>This means that the gradient of the function is very small, which makes learning slow. The ReLU function is defined as</li>
</ul>
</section>
<section id="activation-functions-3" class="slide level2">
<h2>Activation Functions</h2>
<p>The ReLU function is defined as <span class="math display">\[
\text{ReLU}(z) = \max(0,z)
\]</span> The ReLU function is a piecewise linear function which is computationally efficient and easy to optimize. The ReLU function is the most commonly used activation function in deep learning. The ReLU function is not differentiable at <span class="math inline">\(z=0\)</span>, but it is differentiable everywhere else. The derivative of the ReLU function is <span class="math display">\[
\text{ReLU}'(z) = \begin{cases} 0 &amp; \text{if } z &lt; 0 \\ 1 &amp; \text{if } z &gt; 0 \end{cases}
\]</span></p>
</section>
<section id="quantile-linear-regression" class="slide level2">
<h2>Quantile Linear Regression</h2>
<ul>
<li>Quantile regression is a statistical method that extends traditional linear regression</li>
<li>Models the relationship between predictor variables and specific quantiles of the response variable, rather than just the conditional mean.</li>
<li>Provides a more comprehensive view of the relationship between variables across different parts of the distribution.</li>
<li>Linear regression <span class="math display">\[
E(Y|X) = X\beta
\]</span></li>
</ul>
<p>vs quantile regression <span class="math display">\[
Q_Y(\tau|X) = X\beta(\tau)
\]</span> where <span class="math inline">\(\tau\)</span> is the quantile of interest (0 &lt; <span class="math inline">\(\tau\)</span> &lt; 1), and <span class="math inline">\(\beta(\tau)\)</span> are the regression coefficients for the <span class="math inline">\(\tau\)</span>th quantile.</p>
</section>
<section id="what-is-a-quantile" class="slide level2">
<h2>What is a Quantile?</h2>
<p>The distribution function (CDF) <span class="math display">\[
F(y) = P(Y \leq y) = \tau
\]</span> The <span class="math inline">\(\tau\)</span>th quantile of <span class="math inline">\(Y\)</span> is the value <span class="math inline">\(q\)</span> such that <span class="math display">\[
q = F^{-1}(\tau) = \inf \{y : F(y) \geq \tau\}
\]</span></p>
</section>
<section id="quantile-loss" class="slide level2">
<h2>Quantile loss</h2>
<ul>
<li>Sum of absolute differences between the predicted and actual values.</li>
<li>It is used for regression problems with continuous variables. <span class="math display">\[
\min_{\beta}\sum_{i=1}^n |y_i - f(x_i,\beta)|
\]</span> a.k.a. the quantile estimator with <span class="math inline">\(\tau=0.5\)</span></li>
</ul>
</section>
<section id="quantile-loss-1" class="slide level2">
<h2>Quantile loss</h2>
<p>Unconditional case: <span class="math display">\[
\frac{\mathrm{d} \left | x \right | }{\mathrm{d} x} = \operatorname{sign} \left( x \right)
\]</span> where <span class="math inline">\(\operatorname{sign} \left( x \right)\)</span> is the sign function. Hence, deriving the sum above yields <span class="math display">\[
\sum_{i=1}^n \operatorname{sign}(y_i - \beta).
\]</span> This equals to zero only when the number of positive items equals the number of negative which happens when <span class="math inline">\(\beta\)</span> is the median.</p>
</section>
<section id="quantile-loss-2" class="slide level2 smaller">
<h2>Quantile loss</h2>
<p>A more rigorous and non-calculus proof is due to Schwertman (1990).</p>
<p>Let <span class="math inline">\(y_1,\ldots,y_n\)</span> be the observed data and <span class="math inline">\(\hat{\beta}\)</span> be the least absolute deviations estimator. Then we have <span class="math display">\[
\sum_{i=1}^n |y_i - \hat{\beta}| \leq \sum_{i=1}^n |y_i - \beta|
\]</span> for any <span class="math inline">\(\beta\)</span>. Let <span class="math inline">\(y_{(1)},\ldots,y_{(n)}\)</span> be the ordered data. Then we have <span class="math display">\[
\sum_{i=1}^n |y_i - \hat{\beta}| \leq \sum_{i=1}^n |y_i - y_{(i)}|
\]</span> Let <span class="math inline">\(y_{(n/2)}\)</span> be the median of the data. Then we have <span class="math display">\[
\sum_{i=1}^n |y_i - \hat{\beta}| \leq \sum_{i=1}^n |y_i - y_{(n/2)}|
\]</span> which implies that <span class="math inline">\(\hat{\beta}\)</span> is the median of the data.</p>
</section>
<section id="quantile-loss-3" class="slide level2 smaller">
<h2>Quantile loss</h2>
<p>The generalization of the median estimator to the case of estimating value of quantile <span class="math inline">\(\tau\)</span> is as follows <span class="math display">\[
\min_{\beta}\sum_{i=1}^n \rho_{\tau}(y_i - \beta)
\]</span> where <span class="math inline">\(\rho_{\tau}(x) = x(\tau - \mathbb{I}(x &lt; 0))\)</span> is the quantile loss function. If we set <span class="math inline">\(\tau = 0.5\)</span>, the loss function becomes the absolute value function and we get the median estimator. The expected loss is <span class="math display">\[
E \rho_{\tau}(y - \beta) = (\tau-1)\int_{-\infty}^{\beta} (y-\beta)dF(y) + \tau\int_{\beta}^{\infty} (y-\beta)dF(y)
\]</span> Differentiating the expected loss function with respect to <span class="math inline">\(\beta\)</span> and setting it to zero gives the quantile estimator <span class="math display">\[
\hat{\beta}_{\tau} = F^{-1}(\tau)
\]</span></p>
</section>
<section id="bayesian-connection" class="slide level2">
<h2><strong>Bayesian Connection</strong></h2>
<p>Yu and Moyeed 2001</p>
<ul>
<li><p>Turn loss function <span class="math display">\[
\rho_{\tau}(x) = x(\tau - \mathbb{I}(x &lt; 0))
\]</span> into a likelihood function <span class="math display">\[
f(x\mid \tau) \propto \exp\left(-\rho_{\tau}(x)\right)
\]</span> <strong>asymmetric Laplace distribution</strong>!</p></li>
<li><p>Can add location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\sigma\)</span> parameters to the likelihood function <span class="math display">\[
f(x\mid \tau) = \frac{\tau(1 - \tau)}{\sigma} \exp\left(-\rho_\tau\left(\frac{x-\mu}{\sigma}\right)\right)
\]</span></p></li>
</ul>
</section>
<section id="estimation" class="slide level2">
<h2>Estimation</h2>
<p>Quantile regression estimates are obtained by minimizing the following objective function:</p>
<p><span class="math display">\[\min_{\beta} \sum_{i=1}^n \rho_\tau(y_i - x_i'\beta)\]</span></p>
<p>where <span class="math display">\[\rho_\tau(u) = u(\tau - I(u &lt; 0))\]</span> is the tilted absolute value function.</p>
</section>
<section id="advantages-and-applications" class="slide level2 scrollable">
<h2>Advantages and Applications</h2>
<ol type="1">
<li>Robustness to outliers</li>
<li>Ability to capture heterogeneous effects across the distribution</li>
<li>No assumptions about the distribution of the error terms</li>
</ol>
<p>Quantile regression is particularly useful in:</p>
<ul>
<li>Economics: Analyzing income disparities</li>
<li>Ecology: Studying species distributions</li>
<li>Healthcare: Developing growth charts</li>
<li>Finance: Assessing risk measures like Value at Risk (VaR)[4]</li>
</ul>
</section>
<section id="example-in-r" class="slide level2">
<h2>Example in R</h2>
<p>Let’s demonstrate quantile regression using the <code>mtcars</code> dataset in R:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a></a><span class="co"># Load required libraries</span></span>
<span id="cb26-2"><a></a><span class="fu">library</span>(quantreg)</span>
<span id="cb26-3"><a></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb26-4"><a></a></span>
<span id="cb26-5"><a></a><span class="co"># Load data</span></span>
<span id="cb26-6"><a></a><span class="fu">data</span>(mtcars)</span>
<span id="cb26-7"><a></a></span>
<span id="cb26-8"><a></a><span class="co"># Fit quantile regression models for different quantiles</span></span>
<span id="cb26-9"><a></a>quantiles <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.9</span>)</span>
<span id="cb26-10"><a></a>models <span class="ot">&lt;-</span> <span class="fu">lapply</span>(quantiles, <span class="cf">function</span>(q) <span class="fu">rq</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars, <span class="at">tau =</span> q))</span>
<span id="cb26-11"><a></a></span>
<span id="cb26-12"><a></a><span class="co"># Create a plot</span></span>
<span id="cb26-13"><a></a><span class="fu">ggplot</span>(mtcars, <span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> mpg)) <span class="sc">+</span></span>
<span id="cb26-14"><a></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb26-15"><a></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">coef</span>(<span class="fu">lm</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars))[<span class="dv">1</span>],</span>
<span id="cb26-16"><a></a>              <span class="at">slope =</span> <span class="fu">coef</span>(<span class="fu">lm</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars))[<span class="dv">2</span>],</span>
<span id="cb26-17"><a></a>              <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb26-18"><a></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">sapply</span>(models, <span class="cf">function</span>(m) <span class="fu">coef</span>(m)[<span class="dv">1</span>]),</span>
<span id="cb26-19"><a></a>              <span class="at">slope =</span> <span class="fu">sapply</span>(models, <span class="cf">function</span>(m) <span class="fu">coef</span>(m)[<span class="dv">2</span>]),</span>
<span id="cb26-20"><a></a>              <span class="at">color =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"green"</span>, <span class="st">"purple"</span>, <span class="st">"orange"</span>, <span class="st">"brown"</span>)) <span class="sc">+</span></span>
<span id="cb26-21"><a></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Quantile Regression: MPG vs Weight"</span>,</span>
<span id="cb26-22"><a></a>       <span class="at">x =</span> <span class="st">"Weight (1000 lbs)"</span>, <span class="at">y =</span> <span class="st">"Miles per Gallon"</span>) <span class="sc">+</span></span>
<span id="cb26-23"><a></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a></a><span class="co"># Print summary of median regression</span></span>
<span id="cb27-2"><a></a><span class="fu">summary</span>(models[[<span class="dv">3</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call: rq(formula = mpg ~ wt, tau = q, data = mtcars)

tau: [1] 0.5

Coefficients:
            coefficients lower bd upper bd
(Intercept) 34.23224     32.25029 39.74085
wt          -4.53947     -6.47553 -4.16390</code></pre>
</div>
</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-6-1.png" width="960" class="r-stretch"><p>This code fits quantile regression models for the 10th, 25th, 50th, 75th, and 90th percentiles of miles per gallon (mpg) based on car weight. The resulting plot shows how the relationship between weight and fuel efficiency varies across different quantiles of the mpg distribution.</p>
</section>
<section id="quantile-neural-network-for-synthetic-data" class="slide level2">
<h2>Quantile Neural Network for Synthetic Data</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-2"><a></a><span class="im">import</span> torch</span>
<span id="cb29-3"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-4"><a></a><span class="im">import</span> scipy.stats </span>
<span id="cb29-5"><a></a><span class="co"># Sin</span></span>
<span id="cb29-6"><a></a>n <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb29-7"><a></a><span class="co"># x = np.linspace(-1,1, n)</span></span>
<span id="cb29-8"><a></a>np.random.seed(<span class="dv">8</span>)</span>
<span id="cb29-9"><a></a>x <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,(n))</span>
<span id="cb29-10"><a></a>x <span class="op">=</span> np.sort(x)</span>
<span id="cb29-11"><a></a>eps <span class="op">=</span> np.random.normal(<span class="dv">0</span>,np.exp(<span class="dv">1</span><span class="op">-</span>x)<span class="op">/</span><span class="dv">10</span>)</span>
<span id="cb29-12"><a></a>mu <span class="op">=</span> np.sin(np.pi<span class="op">*</span>x)<span class="op">/</span>(np.pi<span class="op">*</span>x)</span>
<span id="cb29-13"><a></a>y  <span class="op">=</span> mu <span class="op">+</span> eps</span>
<span id="cb29-14"><a></a><span class="kw">def</span> truef(tau):</span>
<span id="cb29-15"><a></a>    <span class="cf">return</span> torch.sin(torch.pi<span class="op">*</span>x)<span class="op">/</span>(torch.pi<span class="op">*</span>x) <span class="op">+</span> torch.sqrt(torch.exp(<span class="dv">1</span><span class="op">-</span>x)<span class="op">/</span><span class="dv">10</span>)<span class="op">*</span>scipy.stats.norm.ppf(tau)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="convert-data-to-pytorch-tensors" class="slide level2">
<h2>Convert Data to PyTorch Tensors</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a></a>x  <span class="op">=</span> torch.as_tensor(x,dtype<span class="op">=</span>torch.float32).view(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb30-2"><a></a>y  <span class="op">=</span> torch.as_tensor(y,dtype<span class="op">=</span>torch.float32)</span>
<span id="cb30-3"><a></a>plt.scatter(x,y,s<span class="op">=</span><span class="dv">1</span>)    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-8-1.png" width="960" class="r-stretch"></section>
<section id="define-the-model" class="slide level2">
<h2>Define the Model</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb31-2"><a></a><span class="kw">class</span> QuantNet(nn.Module):</span>
<span id="cb31-3"><a></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, xsz<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb31-4"><a></a>        <span class="bu">super</span>(QuantNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb31-5"><a></a>        <span class="va">self</span>.nh <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb31-6"><a></a>        hsz <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb31-7"><a></a>        hsz1 <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb31-8"><a></a>        <span class="va">self</span>.fcx <span class="op">=</span> nn.Linear(xsz, hsz)</span>
<span id="cb31-9"><a></a>        <span class="va">self</span>.fctau <span class="op">=</span> nn.Linear(<span class="va">self</span>.nh, hsz)</span>
<span id="cb31-10"><a></a>        <span class="va">self</span>.fcxtau <span class="op">=</span> nn.Linear(hsz , hsz1)</span>
<span id="cb31-11"><a></a>        <span class="va">self</span>.fcxtau1 <span class="op">=</span> nn.Linear(hsz1 , hsz1)</span>
<span id="cb31-12"><a></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hsz1 , <span class="dv">2</span>)</span>
<span id="cb31-13"><a></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x,tau):</span>
<span id="cb31-14"><a></a>        tau <span class="op">=</span> torch.cos(torch.arange(start<span class="op">=</span><span class="dv">0</span>,end<span class="op">=</span><span class="va">self</span>.nh)<span class="op">*</span>torch.pi<span class="op">*</span>tau)</span>
<span id="cb31-15"><a></a>        tau <span class="op">=</span> torch.relu(<span class="va">self</span>.fctau(tau)) <span class="co"># function phi from paper </span></span>
<span id="cb31-16"><a></a>        x <span class="op">=</span> torch.relu(<span class="va">self</span>.fcx(x)) <span class="co"># function psi</span></span>
<span id="cb31-17"><a></a>        x <span class="op">=</span> torch.relu(<span class="va">self</span>.fcxtau(x<span class="op">*</span>tau)) <span class="co"># first layer of function g</span></span>
<span id="cb31-18"><a></a>        x <span class="op">=</span> torch.relu(<span class="va">self</span>.fcxtau1(x)) <span class="co"># second layer of function g</span></span>
<span id="cb31-19"><a></a>        x <span class="op">=</span> <span class="va">self</span>.fc(x) <span class="co"># third layer of function g</span></span>
<span id="cb31-20"><a></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="model-estimation-a.k.a.-training" class="slide level2">
<h2>Model Estimation (a.k.a. Training)</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a></a><span class="kw">def</span> train(model, x,y,optimizer,epochs):</span>
<span id="cb32-2"><a></a>    lv <span class="op">=</span> np.zeros(epochs)</span>
<span id="cb32-3"><a></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb32-4"><a></a>        tau <span class="op">=</span> torch.rand(<span class="dv">1</span>).item()</span>
<span id="cb32-5"><a></a>        f <span class="op">=</span> model(x,tau)</span>
<span id="cb32-6"><a></a>        e <span class="op">=</span> y.view(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">-</span>f</span>
<span id="cb32-7"><a></a>        loss <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>torch.mean(torch.square(e[:,<span class="dv">0</span>]))</span>
<span id="cb32-8"><a></a>        <span class="co"># loss = 0</span></span>
<span id="cb32-9"><a></a>        loss <span class="op">+=</span> torch.mean(torch.maximum(tau<span class="op">*</span>e[:,<span class="dv">1</span>],(tau<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>e[:,<span class="dv">1</span>]))</span>
<span id="cb32-10"><a></a>        optimizer.zero_grad()</span>
<span id="cb32-11"><a></a>        loss.backward()</span>
<span id="cb32-12"><a></a>        optimizer.step()</span>
<span id="cb32-13"><a></a>        lv[t] <span class="op">=</span> loss.item()</span>
<span id="cb32-14"><a></a>        <span class="cf">if</span> t <span class="op">%</span> <span class="dv">2000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb32-15"><a></a>            <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">: Loss = </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:&gt;7f}</span><span class="ss">"</span>)</span>
<span id="cb32-16"><a></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">: Loss = </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:&gt;7f}</span><span class="ss">"</span>)</span>
<span id="cb32-17"><a></a>    <span class="cf">return</span> lv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="create-model" class="slide level2">
<h2>Create Model</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a></a>torch.manual_seed(<span class="dv">8</span>) <span class="co"># ovi</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;torch._C.Generator object at 0x10935f190&gt;</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a></a><span class="kw">def</span> init_weights(m):</span>
<span id="cb35-2"><a></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(m, nn.Linear):</span>
<span id="cb35-3"><a></a>        torch.nn.init.xavier_uniform_(m.weight)</span>
<span id="cb35-4"><a></a></span>
<span id="cb35-5"><a></a>model <span class="op">=</span> QuantNet()</span>
<span id="cb35-6"><a></a>model.<span class="bu">apply</span>(init_weights)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>QuantNet(
  (fcx): Linear(in_features=1, out_features=32, bias=True)
  (fctau): Linear(in_features=64, out_features=32, bias=True)
  (fcxtau): Linear(in_features=32, out_features=32, bias=True)
  (fcxtau1): Linear(in_features=32, out_features=32, bias=True)
  (fc): Linear(in_features=32, out_features=2, bias=True)
)</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a></a>optimizer <span class="op">=</span> torch.optim.RMSprop(model.parameters())</span>
<span id="cb37-2"><a></a><span class="bu">print</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>QuantNet(
  (fcx): Linear(in_features=1, out_features=32, bias=True)
  (fctau): Linear(in_features=64, out_features=32, bias=True)
  (fcxtau): Linear(in_features=32, out_features=32, bias=True)
  (fcxtau1): Linear(in_features=32, out_features=32, bias=True)
  (fc): Linear(in_features=32, out_features=2, bias=True)
)</code></pre>
</div>
</div>
</section>
<section id="run-the-estimation-training" class="slide level2">
<h2>Run the Estimation (Training)</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a></a>lv <span class="op">=</span> train(model, x,y,optimizer,<span class="dv">1000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0: Loss = 0.382400
Epoch 999: Loss = 0.135881</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a></a>plt.plot(lv)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/training-3.png" width="960" class="r-stretch"></section>
<section id="make-predictions-and-plot" class="slide level2">
<h2>Make Predictions and Plot</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a></a>plt.scatter(x,y,s<span class="op">=</span><span class="dv">1</span>, label<span class="op">=</span><span class="st">'Data'</span>)<span class="op">;</span></span>
<span id="cb42-2"><a></a>plt.plot(x, model(x,<span class="fl">0.05</span>).detach().numpy()[:,<span class="dv">1</span>],<span class="st">'g-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'5% Percentile'</span>)<span class="op">;</span></span>
<span id="cb42-3"><a></a>plt.plot(x, truef(<span class="fl">0.05</span>),<span class="st">'g--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True 5% Percentile'</span>)<span class="op">;</span></span>
<span id="cb42-4"><a></a>plt.plot(x, model(x,<span class="fl">0.95</span>).detach().numpy()[:,<span class="dv">1</span>],<span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'95% Percentile'</span>)<span class="op">;</span></span>
<span id="cb42-5"><a></a>plt.plot(x, truef(<span class="fl">0.95</span>),<span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True 95% Percentile'</span>)<span class="op">;</span></span>
<span id="cb42-6"><a></a>plt.plot(x, model(x,<span class="fl">0.5</span>).detach().numpy()[:,<span class="dv">1</span>],<span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'50% Percentile'</span>)<span class="op">;</span></span>
<span id="cb42-7"><a></a>plt.plot(x, truef(<span class="fl">0.5</span>),<span class="st">'b--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True 50% Percentile'</span>)<span class="op">;</span></span>
<span id="cb42-8"><a></a>plt.legend(loc<span class="op">=</span><span class="st">'lower right'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-12-3.png" width="960" class="r-stretch"></section>
<section id="predict-at-a-specific-location" class="slide level2">
<h2>Predict at a specific location</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a></a>xn <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb43-2"><a></a><span class="bu">print</span>(np.exp(<span class="dv">1</span><span class="op">-</span>xn)<span class="op">/</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.1648721270700128</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a></a>ns <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb45-2"><a></a>tau <span class="op">=</span> torch.rand(ns)</span>
<span id="cb45-3"><a></a>yhat <span class="op">=</span> np.empty(ns)</span>
<span id="cb45-4"><a></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(ns):</span>
<span id="cb45-5"><a></a>    yhati  <span class="op">=</span> model(torch.as_tensor([xn],dtype<span class="op">=</span>torch.float32),tau[i])</span>
<span id="cb45-6"><a></a>    yhat[i] <span class="op">=</span> yhati[<span class="dv">1</span>].detach().numpy()</span>
<span id="cb45-7"><a></a><span class="bu">print</span>(np.std(yhat))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.059542930636527304</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a></a>plt.hist(yhat,bins<span class="op">=</span><span class="dv">50</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-13-5.png" width="960" class="r-stretch"></section>
<section id="fixed-quantile-neural-network" class="slide level2">
<h2>Fixed Quantile Neural Network</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a></a><span class="kw">class</span> FixedQuantNet(nn.Module):</span>
<span id="cb48-2"><a></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, xsz<span class="op">=</span><span class="dv">1</span>, tau <span class="op">=</span> [<span class="fl">0.5</span>]):</span>
<span id="cb48-3"><a></a>        <span class="bu">super</span>(FixedQuantNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb48-4"><a></a>        <span class="va">self</span>.nh <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb48-5"><a></a>        hsz <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb48-6"><a></a>        <span class="va">self</span>.fcx <span class="op">=</span> nn.Linear(xsz, hsz)</span>
<span id="cb48-7"><a></a>        <span class="va">self</span>.tau <span class="op">=</span> tau</span>
<span id="cb48-8"><a></a>        <span class="va">self</span>.nq <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.tau)</span>
<span id="cb48-9"><a></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hsz , <span class="va">self</span>.nq <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb48-10"><a></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb48-11"><a></a>        x <span class="op">=</span> torch.relu(<span class="va">self</span>.fcx(x))</span>
<span id="cb48-12"><a></a>        x <span class="op">=</span> <span class="va">self</span>.fc(x)</span>
<span id="cb48-13"><a></a>        <span class="cf">return</span> x</span>
<span id="cb48-14"><a></a>    <span class="kw">def</span> train(<span class="va">self</span>,x,y,optimizer,epochs):</span>
<span id="cb48-15"><a></a>        lv <span class="op">=</span> np.zeros(epochs)</span>
<span id="cb48-16"><a></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb48-17"><a></a>            f <span class="op">=</span> <span class="va">self</span>(x)</span>
<span id="cb48-18"><a></a>            e <span class="op">=</span> y.view(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">-</span>f</span>
<span id="cb48-19"><a></a>            loss <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>torch.mean(torch.square(e[:,<span class="dv">0</span>]))</span>
<span id="cb48-20"><a></a>            <span class="co"># loss = 0</span></span>
<span id="cb48-21"><a></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.nq):</span>
<span id="cb48-22"><a></a>                loss <span class="op">+=</span> torch.mean(torch.maximum(<span class="va">self</span>.tau[i]<span class="op">*</span>e[:,i<span class="op">+</span><span class="dv">1</span>],(<span class="va">self</span>.tau[i]<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>e[:,i<span class="op">+</span><span class="dv">1</span>]))</span>
<span id="cb48-23"><a></a>            optimizer.zero_grad()</span>
<span id="cb48-24"><a></a>            loss.backward()</span>
<span id="cb48-25"><a></a>            optimizer.step()</span>
<span id="cb48-26"><a></a>            lv[t] <span class="op">=</span> loss.item()</span>
<span id="cb48-27"><a></a>            <span class="cf">if</span> t <span class="op">%</span> <span class="dv">2000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb48-28"><a></a>                <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">: Loss = </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:&gt;7f}</span><span class="ss">"</span>)</span>
<span id="cb48-29"><a></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">: Loss = </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:&gt;7f}</span><span class="ss">"</span>)</span>
<span id="cb48-30"><a></a>        <span class="cf">return</span> lv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="train-the-model" class="slide level2">
<h2>Train the Model</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a></a>modelf <span class="op">=</span> FixedQuantNet(tau<span class="op">=</span>[<span class="fl">0.05</span>,<span class="fl">0.5</span>,<span class="fl">0.95</span>])</span>
<span id="cb49-2"><a></a>modelf.<span class="bu">apply</span>(init_weights)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>FixedQuantNet(
  (fcx): Linear(in_features=1, out_features=64, bias=True)
  (fc): Linear(in_features=64, out_features=4, bias=True)
)</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a></a>optimizer <span class="op">=</span> torch.optim.RMSprop(modelf.parameters())</span>
<span id="cb51-2"><a></a>lv <span class="op">=</span> modelf.train(x,y,optimizer,<span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0: Loss = 1.791370
Epoch 199: Loss = 0.221048</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a></a>yhat <span class="op">=</span> modelf(x).detach().numpy()</span>
<span id="cb53-2"><a></a>plt.plot(lv)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-15-7.png" width="960" class="r-stretch"></section>
<section id="plots" class="slide level2">
<h2>Plots</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a></a><span class="co"># model.train(x,y,optimizer,1000)</span></span>
<span id="cb54-2"><a></a>plt.scatter(x,y,s<span class="op">=</span><span class="dv">1</span>, label<span class="op">=</span><span class="st">'Data'</span>)<span class="op">;</span></span>
<span id="cb54-3"><a></a>plt.plot(x, yhat[:,<span class="dv">1</span>],<span class="st">'g-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'5% Percentile'</span>)<span class="op">;</span> plt.plot(x, truef(<span class="fl">0.05</span>),<span class="st">'g--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True 5% Percentile'</span>)<span class="op">;</span></span>
<span id="cb54-4"><a></a>plt.plot(x, yhat[:,<span class="dv">3</span>],<span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'95% Percentile'</span>)<span class="op">;</span> plt.plot(x, truef(<span class="fl">0.95</span>),<span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True 95% Percentile'</span>)<span class="op">;</span></span>
<span id="cb54-5"><a></a>plt.plot(x, yhat[:,<span class="dv">2</span>],<span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'50% Percentile'</span>)<span class="op">;</span> plt.plot(x, truef(<span class="fl">0.5</span>),<span class="st">'b--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True 50% Percentile'</span>)<span class="op">;</span></span>
<span id="cb54-6"><a></a>plt.legend(loc<span class="op">=</span><span class="st">'lower right'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-16-9.png" width="960" class="r-stretch"></section>
<section id="hierarchical-bayesian-model" class="slide level2">
<h2>Hierarchical Bayesian Model</h2>
<p>We consider the following model: <span class="math display">\[\begin{align*}
    \tau &amp;\sim \mathrm{Gamma}(0.5, 0.5) \\
    \lambda_d &amp;\sim \mathrm{Gamma}(0.5, 0.5) \\
    \beta_d &amp;\sim \mathcal{N}(0, 20) \\
    y_n &amp;\sim \mathrm{Bernoulli}(\sigma((\tau \lambda \odot \beta)^T x_n))),
\end{align*}\]</span> - <span class="math inline">\(\tau\)</span> is a scalar global coefficient scale - <span class="math inline">\(\lambda\)</span> is a vector of local scales - <span class="math inline">\(\beta\)</span> is the vector of unscaled coefficients,</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a></a><span class="im">import</span> tensorflow_probability.substrates.jax <span class="im">as</span> tfp</span>
<span id="cb55-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb55-3"><a></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb55-4"><a></a>tfd <span class="op">=</span> tfp.distributions</span>
<span id="cb55-5"><a></a><span class="im">import</span> jax</span>
<span id="cb55-6"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="apply-to-iris-data" class="slide level2">
<h2>Apply to Iris Data</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb56-2"><a></a>iris <span class="op">=</span> pd.read_csv(<span class="st">"data/iris.csv"</span>)</span>
<span id="cb56-3"><a></a><span class="bu">print</span>(iris.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(150, 5)</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a></a><span class="bu">print</span>(iris.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   sepal.length  sepal.width  petal.length  petal.width variety
0           5.1          3.5           1.4          0.2  Setosa
1           4.9          3.0           1.4          0.2  Setosa
2           4.7          3.2           1.3          0.2  Setosa
3           4.6          3.1           1.5          0.2  Setosa
4           5.0          3.6           1.4          0.2  Setosa</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a></a>y <span class="op">=</span> iris[<span class="st">'variety'</span>]<span class="op">==</span><span class="st">"Setosa"</span></span>
<span id="cb60-2"><a></a>x <span class="op">=</span> iris[<span class="st">"sepal.length"</span>].values</span>
<span id="cb60-3"><a></a>plt.scatter(x,y)</span>
<span id="cb60-4"><a></a>x <span class="op">=</span> np.c_[np.ones(<span class="dv">150</span>),x]</span>
<span id="cb60-5"><a></a><span class="bu">print</span>(x.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(150, 2)</code></pre>
</div>

</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-18-11.png" width="960" class="r-stretch"></section>
<section id="log-density-function" class="slide level2">
<h2>Log Density Function</h2>
<p>For Hamiltonian MC, we only need to evaluate the joint log-density pointwise</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a></a><span class="kw">def</span> joint_log_prob(x, y, tau, lamb, beta):</span>
<span id="cb62-2"><a></a>    lp <span class="op">=</span> tfd.Gamma(<span class="fl">0.5</span>, <span class="fl">0.5</span>).log_prob(tau)</span>
<span id="cb62-3"><a></a>    lp <span class="op">+=</span> tfd.Gamma(<span class="fl">0.5</span>, <span class="fl">0.5</span>).log_prob(lamb).<span class="bu">sum</span>() </span>
<span id="cb62-4"><a></a>    lp <span class="op">+=</span> tfd.Normal(<span class="fl">0.</span>, <span class="dv">20</span>).log_prob(beta).<span class="bu">sum</span>() </span>
<span id="cb62-5"><a></a>    logits <span class="op">=</span> x <span class="op">@</span> (tau <span class="op">*</span> lamb <span class="op">*</span> beta)</span>
<span id="cb62-6"><a></a>    lp <span class="op">+=</span> tfd.Bernoulli(logits).log_prob(y).<span class="bu">sum</span>() </span>
<span id="cb62-7"><a></a>    <span class="cf">return</span> lp   </span>
<span id="cb62-8"><a></a></span>
<span id="cb62-9"><a></a>tau <span class="op">=</span> np.random.rand(<span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb62-10"><a></a>lamb <span class="op">=</span> np.random.rand(<span class="dv">2</span>)</span>
<span id="cb62-11"><a></a>beta <span class="op">=</span> np.random.rand(<span class="dv">2</span>)</span>
<span id="cb62-12"><a></a>joint_log_prob(x, y, tau, lamb, beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Array(-126.7892, dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="change-of-variables" class="slide level2">
<h2>Change of Variables</h2>
<p><span class="math display">\[
z\triangleq T^{-1}(\theta),\qquad \pi(z) = \pi(\theta) \left| \frac{\partial T}{\partial z} (z) \right|,
\]</span></p>
<p>Taking the logarithm of both sides, we get <span class="math display">\[
\log \pi(z) = \log \pi(\theta) + \log \left| \frac{\partial T }{\partial z}(z) \right|
\]</span> Use <span class="math inline">\(T(z)=e^z\)</span>, and <span class="math inline">\(\log|\frac{\partial T}{\partial z}(z)| = z\)</span></p>
</section>
<section id="change-of-variables-in-code" class="slide level2">
<h2>Change of Variables in Code</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a></a><span class="kw">def</span> unconstrained_joint_log_prob(x, y, theta):</span>
<span id="cb64-2"><a></a>    ndims <span class="op">=</span> x.shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb64-3"><a></a>    unc_tau, unc_lamb, beta <span class="op">=</span> jnp.split(theta, [<span class="dv">1</span>, <span class="dv">1</span> <span class="op">+</span> ndims])</span>
<span id="cb64-4"><a></a>    unc_tau <span class="op">=</span> unc_tau.reshape([]) </span>
<span id="cb64-5"><a></a>    <span class="co"># Make unc_tau a scalar </span></span>
<span id="cb64-6"><a></a>    tau <span class="op">=</span> jnp.exp(unc_tau)</span>
<span id="cb64-7"><a></a>    ldj <span class="op">=</span> unc_tau</span>
<span id="cb64-8"><a></a>    lamb <span class="op">=</span> jnp.exp(unc_lamb)</span>
<span id="cb64-9"><a></a>    ldj <span class="op">+=</span> unc_lamb.<span class="bu">sum</span>()</span>
<span id="cb64-10"><a></a>    <span class="cf">return</span> joint_log_prob(x, y, tau, lamb, beta) <span class="op">+</span> ldj</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="lets-check-out-function" class="slide level2">
<h2>Let’s check out function</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a></a><span class="im">from</span> functools <span class="im">import</span> partial</span>
<span id="cb65-2"><a></a>target_log_prob <span class="op">=</span> partial(unconstrained_joint_log_prob, x, y)</span>
<span id="cb65-3"><a></a>theta <span class="op">=</span> np.r_[tau,lamb,beta]</span>
<span id="cb65-4"><a></a>target_log_prob(theta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Array(-530.62317, dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="automatic-differentiation" class="slide level2">
<h2>Automatic Differentiation</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a></a>target_log_prob_and_grad <span class="op">=</span> jax.value_and_grad(target_log_prob)</span>
<span id="cb67-2"><a></a>tlp, tlp_grad <span class="op">=</span> target_log_prob_and_grad(theta)</span>
<span id="cb67-3"><a></a><span class="bu">print</span>(tlp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>-530.62317</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a></a>tlp_grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Array([ -511.1795  ,   -95.032646,  -416.80698 ,  -185.95103 ,
       -1782.1393  ], dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="hamiltonian-monte-carlo" class="slide level2">
<h2>Hamiltonian Monte Carlo</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a></a><span class="kw">def</span> leapfrog_step(target_log_prob_and_grad, step_size, i, leapfrog_state):</span>
<span id="cb71-2"><a></a>    z, m, tlp, tlp_grad <span class="op">=</span> leapfrog_state</span>
<span id="cb71-3"><a></a>    m <span class="op">+=</span> <span class="fl">0.5</span> <span class="op">*</span> step_size <span class="op">*</span> tlp_grad</span>
<span id="cb71-4"><a></a>    z <span class="op">+=</span> step_size <span class="op">*</span> m</span>
<span id="cb71-5"><a></a>    tlp, tlp_grad <span class="op">=</span> target_log_prob_and_grad(z)</span>
<span id="cb71-6"><a></a>    m <span class="op">+=</span> <span class="fl">0.5</span> <span class="op">*</span> step_size <span class="op">*</span> tlp_grad</span>
<span id="cb71-7"><a></a>    <span class="cf">return</span> z, m, tlp, tlp_grad</span>
<span id="cb71-8"><a></a></span>
<span id="cb71-9"><a></a><span class="kw">def</span> hmc_step(target_log_prob_and_grad, num_leapfrog_steps, step_size, z, seed):</span>
<span id="cb71-10"><a></a>    m_seed, mh_seed <span class="op">=</span> jax.random.split(seed)</span>
<span id="cb71-11"><a></a>    tlp, tlp_grad <span class="op">=</span> target_log_prob_and_grad(z)</span>
<span id="cb71-12"><a></a>    m <span class="op">=</span> jax.random.normal(m_seed, z.shape)</span>
<span id="cb71-13"><a></a>    energy <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> jnp.square(m).<span class="bu">sum</span>() <span class="op">-</span> tlp</span>
<span id="cb71-14"><a></a>    new_z, new_m, new_tlp, _ <span class="op">=</span> jax.lax.fori_loop(</span>
<span id="cb71-15"><a></a>        <span class="dv">0</span>,</span>
<span id="cb71-16"><a></a>        num_leapfrog_steps,</span>
<span id="cb71-17"><a></a>        partial(leapfrog_step, target_log_prob_and_grad, step_size),</span>
<span id="cb71-18"><a></a>        (z, m, tlp, tlp_grad)) </span>
<span id="cb71-19"><a></a>    new_energy <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> jnp.square(new_m).<span class="bu">sum</span>() <span class="op">-</span> new_tlp</span>
<span id="cb71-20"><a></a>    log_accept_ratio <span class="op">=</span> energy <span class="op">-</span> new_energy</span>
<span id="cb71-21"><a></a>    is_accepted <span class="op">=</span> jnp.log(jax.random.uniform(mh_seed, [])) <span class="op">&lt;</span> log_accept_ratio</span>
<span id="cb71-22"><a></a>    <span class="co"># select the proposed state if accepted</span></span>
<span id="cb71-23"><a></a>    z <span class="op">=</span> jnp.where(is_accepted, new_z, z)</span>
<span id="cb71-24"><a></a>    hmc_output <span class="op">=</span> {<span class="st">"z"</span>: z,</span>
<span id="cb71-25"><a></a>                  <span class="st">"is_accepted"</span>: is_accepted,</span>
<span id="cb71-26"><a></a>                  <span class="st">"log_accept_ratio"</span>: log_accept_ratio}</span>
<span id="cb71-27"><a></a>    <span class="co"># hmc_output["z"] has shape [num_dimensions]</span></span>
<span id="cb71-28"><a></a>    <span class="cf">return</span> z, hmc_output</span>
<span id="cb71-29"><a></a></span>
<span id="cb71-30"><a></a><span class="kw">def</span> hmc(target_log_prob_and_grad, num_leapfrog_steps, step_size, num_steps, z,</span>
<span id="cb71-31"><a></a>        seed):</span>
<span id="cb71-32"><a></a>    <span class="co"># create a seed for each step</span></span>
<span id="cb71-33"><a></a>    seeds <span class="op">=</span> jax.random.split(seed, num_steps)</span>
<span id="cb71-34"><a></a>    <span class="co"># this will repeatedly run hmc_step and accumulate the outputs</span></span>
<span id="cb71-35"><a></a>    _, hmc_output <span class="op">=</span> jax.lax.scan(</span>
<span id="cb71-36"><a></a>        partial(hmc_step, target_log_prob_and_grad, num_leapfrog_steps, step_size),</span>
<span id="cb71-37"><a></a>        z, seeds)</span>
<span id="cb71-38"><a></a>    <span class="co"># hmc_output["z"] now has shape [num_steps, num_dimensions]</span></span>
<span id="cb71-39"><a></a>    <span class="cf">return</span> hmc_output</span>
<span id="cb71-40"><a></a></span>
<span id="cb71-41"><a></a><span class="kw">def</span> scan(f, state, xs):</span>
<span id="cb71-42"><a></a>  output <span class="op">=</span> []</span>
<span id="cb71-43"><a></a>  <span class="cf">for</span> x <span class="kw">in</span> xs:</span>
<span id="cb71-44"><a></a>    state, y <span class="op">=</span> f(state, x)</span>
<span id="cb71-45"><a></a>    output.append(y)</span>
<span id="cb71-46"><a></a>  <span class="cf">return</span> state, jnp.stack(output)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="hmc" class="slide level2">
<h2>HMC</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a></a>num_leapfrog_steps<span class="op">=</span><span class="dv">30</span></span>
<span id="cb72-2"><a></a>step_size <span class="op">=</span> <span class="fl">0.008</span></span>
<span id="cb72-3"><a></a><span class="im">from</span> jax <span class="im">import</span> random</span>
<span id="cb72-4"><a></a>seed <span class="op">=</span> random.PRNGKey(<span class="dv">92</span>)</span>
<span id="cb72-5"><a></a>num_samples<span class="op">=</span><span class="dv">10000</span></span>
<span id="cb72-6"><a></a>hmc_output <span class="op">=</span> hmc(target_log_prob_and_grad, num_leapfrog_steps, step_size,</span>
<span id="cb72-7"><a></a>    num_samples, theta, seed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="inspect-the-results" class="slide level2">
<h2>Inspect the results</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a></a>ndims <span class="op">=</span> x.shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb73-2"><a></a>thetap <span class="op">=</span> hmc_output[<span class="st">'z'</span>]</span>
<span id="cb73-3"><a></a>taup, lambp, betap <span class="op">=</span> jnp.split(thetap, [<span class="dv">1</span>, <span class="dv">1</span> <span class="op">+</span> ndims],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb73-4"><a></a>skip <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb73-5"><a></a>slope <span class="op">=</span> betap[skip:,<span class="dv">1</span>]</span>
<span id="cb73-6"><a></a>intercept <span class="op">=</span> betap[skip:,<span class="dv">0</span>]</span>
<span id="cb73-7"><a></a>plt.hist(slope,bins<span class="op">=</span><span class="dv">50</span>)<span class="op">;</span></span>
<span id="cb73-8"><a></a>plt.hist(intercept,bins<span class="op">=</span><span class="dv">50</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="08-dl_files/figure-revealjs/unnamed-chunk-25-13.png" width="960" class="r-stretch"></section>
<section id="inspect-the-results-1" class="slide level2">
<h2>Inspect the results</h2>
<div class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a></a><span class="bu">print</span>(np.quantile(slope,[<span class="fl">0.05</span>,<span class="fl">0.95</span>,<span class="fl">0.5</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[-14.40216732  -1.37361898  -5.5752933 ]</code></pre>
</div>
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a></a><span class="bu">print</span>(np.quantile(intercept,[<span class="fl">0.05</span>,<span class="fl">0.95</span>,<span class="fl">0.5</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[17.57117882 38.81280651 28.22325706]</code></pre>
</div>
</div>
</section>
<section id="some-applications-of-bayes-approaches-in-llms" class="slide level2">
<h2>Some Applications of Bayes Approaches in LLMs</h2>
<ul>
<li>Bayesian techniques are increasingly being used in the context of large language models (LLMs).</li>
<li>These developments highlight the growing synergy between Bayesian methods and large language models, offering improvements in model performance, uncertainty quantification, and interpretability.</li>
<li>Uncertainty Estimation: Bayesian Prompt Ensembles (<a href="https://www.amazon.science/publications/bayesian-prompt-ensembles-model-uncertainty-estimation-for-black-box-large-language-models">BayesPE</a>) have been proposed as a novel approach to obtain well-calibrated uncertainty estimates for black-box LLMs. This method uses a weighted ensemble of semantically equivalent prompts and applies Bayesian variational inference to estimate the weights.</li>
<li>Enhancing Bayesian Optimization: A new approach called <a href="https://arxiv.org/abs/2402.03921">LLAMBO</a> integrates LLMs within Bayesian optimization frameworks. This method frames the optimization problem in natural language, allowing LLMs to propose and evaluate solutions based on historical data. LLAMBO has shown promise in improving surrogate modeling and candidate sampling, especially in early stages of search.</li>
</ul>
</section>
<section id="some-applications-of-bayes-approaches-in-llms-1" class="slide level2">
<h2>Some Applications of Bayes Approaches in LLMs</h2>
<ul>
<li>Probability Estimation: The <a href="https://www.llmsresearch.com/p/llms-meet-bayesian-many-papers-published-uses-bayesian-prob-llms-performance-improvement">BIRD</a> framework incorporates abductive factors, LLM entailment, and learnable deductive Bayesian modeling to provide controllable and interpretable probability estimation for model decisions. This approach has demonstrated a 35% improvement over GPT-4 in aligning probability estimates with human judgments.</li>
<li>Natural Language Processing: Bayesian techniques have been applied to various NLP tasks, including word segmentation, syntax analysis, morphology, coreference resolution, and machine translation. These <a href="https://direct.mit.edu/coli/article/44/1/187/1585/Bayesian-Analysis-in-Natural-Language-Processing">methods</a> offer an elegant way to incorporate prior knowledge and manage uncertainty over parameters.</li>
<li>Deep Bayesian Learning: Researchers are exploring the integration of Bayesian principles with deep learning models for NLP applications. This includes the development of hierarchical Bayesian models, variational autoencoders, and (stochastic neural networks)[https://aclanthology.org/P19-4006/].</li>
<li>(Prompt Optimisation)[https://dl.acm.org/doi/10.1007/978-3-031-75623-8_28]</li>
</ul>
</section>
<section id="bayesian-optimization" class="slide level2">
<h2>Bayesian Optimization</h2>
<ul>
<li>Bayesian optimization is a powerful tool for optimizing expensive-to-evaluate functions</li>
<li><a href="https://www.run.ai/guides/hyperparameter-tuning/bayesian-hyperparameter-optimization">RunAI</a> was recently acquired by Nvidia for $700m</li>
<li>See <a href="https://www.dropbox.com/scl/fi/27qfoq8oueyqhfh5m44dh/bo-nn.ipynb?rlkey=nc295r6klf2kvdx8viarunsfv&amp;dl=0">bo-nn.ipynb</a> example</li>
</ul>
<!-- https://rlseminar.github.io/static/files/SP19-Slides/RL_seminars2019-0311hao_distributional_final.pdf -->
<!-- https://icml.cc/media/icml-2019/Slides/4534.pdf -->
<!-- https://storage.googleapis.com/deepmind-media/Era-of-Experience%20/The%20Era%20of%20Experience%20Paper.pdf -->
<!-- https://papers.nips.cc/paper_files/paper/2012/file/35051070e572e47d2c26c241ab88307f-Paper.pdf -->
</section>
<section id="distributional-reinforcement-learning" class="slide level2">
<h2>Distributional Reinforcement Learning</h2>
<p>Reading list:</p>
<ul>
<li><a href="https://arxiv.org/abs/1710.10044">Distributional Reinforcement Learning with Quantile Regression</a></li>
<li>Book on <a href="https://www.distributional-rl.org">Distributional Reinforcement Learning</a></li>
<li><a href="https://ewrl.wordpress.com/wp-content/uploads/2018/10/distributional_rl.pdf">Slides</a>, <a href="https://cs.uwaterloo.ca/~ppoupart/teaching/cs885-fall22/slides/cs885-lecture9.pdf">Slides</a></li>
</ul>
</section>
<section id="mixture-density-networks-mdns" class="slide level2">
<h2>Mixture Density Networks (MDNs)</h2>
<p>Mixture model head: Outputs parameters for: - Means (<span class="math inline">\(\mu_1,...,\mu_M\)</span>) - Variances (<span class="math inline">\(\sigma_1^2,...,\sigma_M^2\)</span>) - Mixing coefficients (<span class="math inline">\(\pi_1,...,\pi_M\)</span>)</p>
<p><span class="math display">\[
p(y\mid x) = \sum_{m=1}^M \pi_m \mathcal{N}(y\mid \mu_m, \sigma_m^2)
\]</span></p>
<p>Loss function: <span class="math display">\[
L(\theta) = -\frac{1}{N}\sum_{i=1}^N \log p(y_i\mid x_i, \theta)
\]</span> where <span class="math inline">\(\theta\)</span> are the parameters of the model.</p>
<p><a href="https://www.dropbox.com/scl/fi/0p99rehqdoo866nc4jxqv/mdn-nn.ipynb?rlkey=34uab15kxqm0y7xokl2shk00w&amp;dl=0">mdn-nn.ipynb</a></p>
</section>
<section id="more-direct-approaches" class="slide level2">
<h2>More Direct Approaches</h2>
<ul>
<li><a href="https://proceedings.mlr.press/v176/wilson22a/wilson22a.pdf">Evaluating Approximate Inference in Bayesian Deep Learning</a></li>
<li><a href="http://proceedings.mlr.press/v139/izmailov21a/izmailov21a.pdf">What Are Bayesian Neural Network Posteriors Really Like?</a></li>
</ul>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1300,

        height: 920,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>