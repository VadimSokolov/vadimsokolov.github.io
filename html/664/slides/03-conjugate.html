<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Vadim Sokolov   George Mason University   Spring 2025">
  <title>Bayes AI</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-bbe7401fe57d4b791b917637bb662036.css">
  <link rel="stylesheet" href="style.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="center">
  <h1 class="title" style="font-size:40px;">Bayes AI</h1>
  <p class="subtitle" style="color:blue;font-size:50px;">Unit 3: Bayesian Inference with Conjugate Pairs</p>
<img style="height: 350px;" src="fig/page/03-conjugate.jpg">
  <p class="author">Vadim Sokolov <br> George Mason University <br> Spring 2025</p>

<p style="font-size:10px;"> 
<a href="https://vsokolov.org/courses/664.html">Course Page</a>, <a href="https://vsokolov.org/html/664/slides/">Slides</a>
</p>


</section>
<section id="epl-odds" class="slide level2">
<h2>EPL Odds</h2>

<img data-src="figup/epl-odds.png" class="r-stretch"></section>
<section id="english-premier-league-epl" class="slide level2">
<h2>English Premier League: EPL</h2>
<p>Calculate <span style="color: red">Odds for the possible scores in a match?</span> <span class="math display">\[
0-0, \; 1-0, \; 0-1, \; 1-1, \; 2-0, \ldots
\]</span> Let <span class="math inline">\(X=\)</span> Goals scored by Arsenal</p>
<p><span class="math inline">\(Y=\)</span> Goals scored by Liverpool</p>
<p>What’s the odds of a <span style="color: blue">team winning?</span> <span class="math inline">\(\; \; \;  P \left ( X&gt; Y \right )\)</span> Odds of a <span style="color: blue">draw?</span> <span class="math inline">\(\; \; \;  P \left ( X = Y \right )\)</span></p>
<p>z1 = rpois(100,0.6) z2 = rpois(100,1.4) sum(z1&lt;z2)/100 # Team 2 wins sum(z1=z2)/100 # Draw</p>
</section>
<section id="chelsea-epl-2017" class="slide level2">
<h2>Chelsea EPL 2017</h2>
<p>Let’s take a historical set of data on scores Then estimate <span class="math inline">\(\lambda\)</span> with the sample mean of the home and away scores</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">home team</th>
<th style="text-align: left;">results</th>
<th></th>
<th style="text-align: left;">visit team</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Chelsea</td>
<td style="text-align: left;">2</td>
<td>1</td>
<td style="text-align: left;">West Ham</td>
</tr>
<tr class="even">
<td style="text-align: left;">Chelsea</td>
<td style="text-align: left;">5</td>
<td>1</td>
<td style="text-align: left;">Sunderland</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Watford</td>
<td style="text-align: left;">1</td>
<td>2</td>
<td style="text-align: left;">Chelsea</td>
</tr>
<tr class="even">
<td style="text-align: left;">Chelsea</td>
<td style="text-align: left;">3</td>
<td>0</td>
<td style="text-align: left;">Burnley</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\dots\)</span></td>
<td style="text-align: left;"></td>
<td></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
</section>
<section id="epl-chelsea" class="slide level2">
<h2>EPL Chelsea</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="fig/chelsea-against.svg"></p>
<figcaption>Chelsea against</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="fig/chelsea-for.svg"></p>
<figcaption>Chelsea for</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p><em>Our Poisson model fits the empirical data!!</em></p>
</section>
<section id="epl-attack-and-defence-strength" class="slide level2">
<h2>EPL: Attack and Defence Strength</h2>
<p>Each team gets an “attack” strength and “defence” weakness rating Adjust home and away average goal estimates</p>

<img data-src="figup/epl-table.jpg" style="width:80.0%" class="r-stretch"></section>
<section id="epl-hull-vs-manu-poisson-distribution" class="slide level2">
<h2>EPL: Hull vs ManU: Poisson Distribution</h2>
<p><span style="color: red">ManU</span> Average away goals <span class="math inline">\(=1.47\)</span>. Prediction: <span class="math inline">\(1.47 \times 1.46 \times 1.37 = 2.95\)</span></p>
<p>Attack strength times Hull’s defense weakness times average</p>
<p><span style="color: red">Hull</span> Average home goals <span class="math inline">\(=1.47\)</span>. Prediction: <span class="math inline">\(1.47 \times 0.85 \times 0.52 = 0.65\)</span>. Simulation</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Team</th>
<th style="text-align: left;">Expected Goals</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
<th style="text-align: left;">2</th>
<th style="text-align: left;">3</th>
<th style="text-align: left;">4</th>
<th style="text-align: left;">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Man U</td>
<td style="text-align: left;">2.95</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">22</td>
<td style="text-align: left;">26</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">13</td>
</tr>
<tr class="even">
<td style="text-align: left;">Hull City</td>
<td style="text-align: left;">0.65</td>
<td style="text-align: left;">49</td>
<td style="text-align: left;">41</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
</tbody>
</table>
</section>
<section id="epl-predictions" class="slide level2">
<h2>EPL Predictions</h2>
<p>A model is only <span style="color: blue">as good as its predictions</span></p>
<ul>
<li><p>In our simulation Man U wins 88 games out of 100, we should bet when odds ratio is below 88 to 100.</p></li>
<li><p>Most likely outcome is 0-3 (12 games out of 100)</p></li>
<li><p>The actual outcome was 0-1 (they played on August 27, 2016)</p></li>
<li><p>In out simulation 0-1 was the fourth most probable outcome (9 games out of 100)</p></li>
</ul>
</section>
<section>
<section id="hierarchical-distributions" class="title-slide slide level1 center">
<h1>Hierarchical Distributions</h1>

</section>
<section id="bayesian-methods" class="slide level2">
<h2>Bayesian Methods</h2>
<p>Modern Statistical/Machine Learning</p>
<ul>
<li>Bayes Rule and Probabilistic Learning</li>
<li>Computationally challenging: MCMC and Particle Filtering</li>
<li>Many applications in Finance:</li>
</ul>
<p>Asset pricing and corporate finance problems.</p>
<p>Lindley, D.V. <em>Making Decisions</em></p>
<p>Bernardo, J. and A.F.M. Smith <em>Bayesian Theory</em></p>
</section>
<section id="bayesian-books" class="slide level2">
<h2>Bayesian Books</h2>
<ul>
<li><p>Hierarchical Models and MCMC</p></li>
<li><p>Bayesian Nonparametrics</p></li>
</ul>
<p>Machine Learning</p>
<ul>
<li>Dynamic State Space Models <span class="math inline">\(\ldots\)</span></li>
</ul>

<img data-src="figup/bayes-book-paul.jpg" class="r-stretch"></section>
<section id="popular-books" class="slide level2">
<h2>Popular Books</h2>
<p>McGrayne (2012): The Theory that would not Die</p>
<ul>
<li><p>History of Bayes-Laplace</p></li>
<li><p>Code breaking</p></li>
<li><p>Bayes search: Air France <span class="math inline">\(\ldots\)</span></p></li>
</ul>

<img data-src="figup/bayes-book.jpg" class="r-stretch"></section>
<section id="nate-silver-538-and-nyt" class="slide level2">
<h2>Nate Silver: 538 and NYT</h2>
<p>Silver (2012): The Signal and The Noise</p>
<ul>
<li><p>Presidential Elections</p></li>
<li><p>Bayes dominant methodology</p></li>
<li><p>Predicting College Basketball/Oscars <span class="math inline">\(\ldots\)</span></p></li>
</ul>

<img data-src="fig/nate-silver-book.svg" class="r-stretch"></section>
<section id="things-to-know" class="slide level2">
<h2>Things to Know</h2>
<p>Explosion of Models and Algorithms starting in 1950s</p>
<ul>
<li><p>Bayesian Regularisation and Sparsity</p></li>
<li><p>Hierarchical Models and Shrinkage</p></li>
<li><p>Hidden Markov Models</p></li>
<li><p>Nonlinear Non-Gaussian State Space Models</p></li>
</ul>
<p>Algorithms</p>
<ul>
<li><p>Monte Carlo Method (von Neumann and Ulam, 1940s)</p></li>
<li><p>Metropolis-Hastings (Metropolis, 1950s)</p></li>
<li><p>Gibbs Sampling (Geman and Geman, Gelfand and Smith, 1980s)</p></li>
<li><p>Sequential Particle Filtering</p></li>
</ul>
</section>
<section id="probabilistic-reasoning" class="slide level2 scrollable">
<h2>Probabilistic Reasoning</h2>
<ul>
<li>Bayesian Probability (Ramsey, 1926, de Finetti, 1931)
<ol type="1">
<li>Beta-Binomial Learning: Black Swans</li>
<li>Elections: Nate Silver</li>
<li>Baseball: Kenny Lofton and Derek Jeter</li>
</ol></li>
<li>Monte Carlo (von Neumann and Ulam, Metropolis, 1940s)</li>
<li>Shrinkage Estimation (Lindley and Smith, Efron and Morris, 1970s)</li>
</ul>
</section>
<section id="bayesian-inference" class="slide level2 scrollable">
<h2>Bayesian Inference</h2>
<p><span style="color: red">Key Idea:</span> Explicit use of probability for summarizing uncertainty.</p>
<ol type="1">
<li><p>A <span style="color: blue">probability distribution</span> for data given parameters <span class="math display">\[
f(y| \theta ) \; \; \text{Likelihood}
\]</span></p></li>
<li><p>A <span style="color: blue">probability distribution</span> for unknown parameters <span class="math display">\[
p(\theta) \; \; \text{Prior}
\]</span></p></li>
<li><p>Inference for unknowns conditional on observed data</p></li>
</ol>
<p>Inverse probability (Bayes Theorem);</p>
<p>Formal decision making (Loss, Utility)</p>
</section>
<section id="posterior-inference" class="slide level2">
<h2>Posterior Inference</h2>
<p><span style="color: blue">Bayes theorem</span> to derive posterior distributions <span class="math display">\[
\begin{aligned}
p( \theta | y ) &amp; = \frac{p(y| \theta)p( \theta)}{p(y)} \\
p(y) &amp; = \int p(y| \theta)p( \theta)d \theta
\end{aligned}
\]</span> Allows you to make probability statements</p>
<ul>
<li>They can be very different from p-values!</li>
</ul>
<p>Hypothesis testing and Sequential problems</p>
<ul>
<li>Markov chain Monte Carlo (MCMC) and Filtering (PF)</li>
</ul>
</section>
<section id="coin-example" class="slide level2">
<h2>Coin Example</h2>
<ul>
<li>What if we gamble against unfair coin flips or the person who performs the flips is trained to get the side he wants?</li>
<li>In this case, we need to estimate the probability of heads <span class="math inline">\(\theta\)</span> from the data. Suppose we have observed 10 flips <span class="math display">\[
y = \{H, T, H, H, H, T, H, T, H, H\},
\]</span></li>
<li>The frequency-based answer would be <span class="math inline">\(\theta = 3/10 = 0.3\)</span>, but this is not a good estimate.</li>
</ul>
</section>
<section id="coin-example-1" class="slide level2">
<h2>Coin Example</h2>
<ul>
<li>Bayes approach gives us more flexibility.</li>
<li>Prior belief: the coin is fair, but we are not sure.</li>
<li>We can model this belief by a prior distribution, we discretize the variable</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a></a>theta <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb1-2"><a></a>prior <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.024</span>, <span class="fl">0.077</span>, <span class="fl">0.132</span>, <span class="fl">0.173</span>, <span class="fl">0.188</span>, <span class="fl">0.173</span>, <span class="fl">0.132</span>, <span class="fl">0.077</span>, <span class="fl">0.024</span>, <span class="dv">0</span>)</span>
<span id="cb1-3"><a></a><span class="fu">barplot</span>(prior, <span class="at">names.arg =</span> theta, <span class="at">xlab =</span> <span class="st">"theta"</span>, <span class="at">ylab =</span> <span class="st">"prior"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="03-conjugate_files/figure-revealjs/unnamed-chunk-1-1.png" width="960" class="r-stretch quarto-figure-center"><p class="caption">Prior distribution</p></section>
<section id="coin-example-2" class="slide level2">
<h2>Coin Example</h2>
<p>Use Bayes rule to update our prior belief. The posterior distribution is given by <span class="math display">\[
p(\theta \mid y) = \frac{p(y \mid \theta) p(\theta)}{p(y)}.
\]</span> The denominator is the marginal likelihood, which is given by <span class="math display">\[
p(y) = \sum_{\theta} p(y \mid \theta) p(\theta).
\]</span> The likelihood is given by the Binomial distribution <span class="math display">\[
p(y \mid \theta) \propto \theta^3 (1 - \theta)^7.
\]</span></p>
<p>Notice, that the posterior distribution depends only on the number of positive and negative cases. Those numbers are <strong>sufficient</strong> for the inference about <span class="math inline">\(\theta\)</span>. The posterior distribution is given by</p>
</section>
<section id="likelihood" class="slide level2">
<h2>Likelihood</h2>
<p>The likelihood is given by the Binomial distribution</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a></a>th <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">length=</span><span class="dv">100</span>)</span>
<span id="cb2-2"><a></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">bty=</span><span class="st">'n'</span>)</span>
<span id="cb2-3"><a></a>ll <span class="ot">=</span> th<span class="sc">^</span><span class="dv">30</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>th)<span class="sc">^</span><span class="dv">70</span>; ll <span class="ot">=</span> ll<span class="sc">/</span><span class="fu">sum</span>(ll)</span>
<span id="cb2-4"><a></a><span class="fu">plot</span>(th,ll, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">col=</span><span class="dv">1</span>, <span class="at">ylab=</span><span class="st">'likelihood'</span>, <span class="at">xlab=</span><span class="st">'theta'</span>)</span>
<span id="cb2-5"><a></a>ll <span class="ot">=</span> th<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>th)<span class="sc">^</span><span class="dv">7</span>; ll <span class="ot">=</span> ll<span class="sc">/</span><span class="fu">sum</span>(ll)</span>
<span id="cb2-6"><a></a><span class="fu">lines</span>(th,ll, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">col=</span><span class="dv">2</span>)</span>
<span id="cb2-7"><a></a>labels <span class="ot">=</span> <span class="fu">c</span>(<span class="st">'n=100'</span>, <span class="st">'n=10'</span>)</span>
<span id="cb2-8"><a></a><span class="fu">legend</span>(<span class="st">'topright'</span>, <span class="at">legend=</span>labels, <span class="at">col=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">1</span>,<span class="at">bty=</span><span class="st">'n'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="03-conjugate_files/figure-revealjs/unnamed-chunk-2-1.png" width="960" class="r-stretch"></section>
<section id="coin-example-3" class="slide level2">
<h2>Coin Example</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a></a>likelihood <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, n, Y) {</span>
<span id="cb3-2"><a></a>  theta<span class="sc">^</span>Y <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> theta)<span class="sc">^</span>(n <span class="sc">-</span> Y)</span>
<span id="cb3-3"><a></a>}</span>
<span id="cb3-4"><a></a>posterior <span class="ot">&lt;-</span> <span class="fu">likelihood</span>(theta, <span class="dv">10</span>,<span class="dv">3</span>) <span class="sc">*</span> prior</span>
<span id="cb3-5"><a></a>posterior <span class="ot">&lt;-</span> posterior <span class="sc">/</span> <span class="fu">sum</span>(posterior) <span class="co"># normalize</span></span>
<span id="cb3-6"><a></a><span class="fu">barplot</span>(posterior, <span class="at">names.arg =</span> theta, <span class="at">xlab =</span> <span class="st">"theta"</span>, <span class="at">ylab =</span> <span class="st">"posterior"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="03-conjugate_files/figure-revealjs/unnamed-chunk-3-1.png" width="960" class="r-stretch quarto-figure-center"><p class="caption">Posterior distribution</p></section>
<section id="coin-example-4" class="slide level2">
<h2>Coin Example</h2>
<p>If you are to keep collecting more observations and say observe a sequence of 100 flips, then the posterior distribution will be more concentrated around the value of <span class="math inline">\(\theta = 0.3\)</span>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a></a>posterior <span class="ot">&lt;-</span> <span class="fu">likelihood</span>(theta, <span class="dv">100</span>,<span class="dv">30</span>) <span class="sc">*</span> prior</span>
<span id="cb4-2"><a></a>posterior <span class="ot">&lt;-</span> posterior <span class="sc">/</span> <span class="fu">sum</span>(posterior) <span class="co"># normalize</span></span>
<span id="cb4-3"><a></a><span class="fu">barplot</span>(posterior, <span class="at">names.arg =</span> theta, <span class="at">xlab =</span> <span class="st">"theta"</span>, <span class="at">ylab =</span> <span class="st">"posterior"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="03-conjugate_files/figure-revealjs/unnamed-chunk-4-1.png" width="960" class="r-stretch quarto-figure-center"><p class="caption">Posterior distribution for n=100</p><p>This demonstrates that for large sample sizes, the frequentist approach and Bayes approach agree.</p>
</section>
<section id="conjugate-priors" class="slide level2">
<h2>Conjugate Priors</h2>
<ul>
<li><span style="color: blue">Definition:</span> Let <span class="math inline">\(F\)</span> denote the class of distributions <span class="math inline">\(f ( y | \theta )\)</span>.</li>
</ul>
<p>A class <span class="math inline">\(\Pi\)</span> of prior distributions is <span style="color: blue">conjugate</span> for <span class="math inline">\(F\)</span> if the posterior distribution is in the class <span class="math inline">\(\Pi\)</span> for all <span class="math inline">\(f \in F , \pi \in \Pi , y \in Y\)</span>.</p>
<ul>
<li><em>Example: Binomial/Beta:</em></li>
</ul>
<p>Suppose that <span class="math inline">\(Y_1 , \ldots , Y_n \sim Ber ( p )\)</span>.</p>
<p>Let <span class="math inline">\(p \sim Beta ( \alpha , \beta )\)</span> where <span class="math inline">\(( \alpha , \beta )\)</span> are known hyper-parameters.</p>
<p>The beta-family is very flexible</p>
<p>Prior mean <span class="math inline">\(E ( p ) = \frac{\alpha}{ \alpha + \beta }\)</span>.</p>
</section>
<section id="bayes-learning-beta-binomial" class="slide level2">
<h2>Bayes Learning: Beta-Binomial</h2>
<p><em>How do I update my beliefs about a coin toss?</em></p>
<p>Likelihood for Bernoulli <span class="math display">\[
p\left(  y|\theta\right)  =\prod_{t=1}^{T}p\left(  y_{t}|\theta\right)
=\theta^{\sum_{t=1}^{T}y_{t}}\left(  1-\theta\right)  ^{T-\sum_{t=1}^{T}y_{t}}.
\]</span> Initial prior distribution <span class="math inline">\(\theta\sim\mathcal{B}\left(  a,A\right)\)</span> given by <span class="math display">\[
p\left(  \theta|a,A\right)  =\frac{\theta^{a-1}\left(  1-\theta\right)
^{A-1}}{B\left(  a,A\right)  }
\]</span></p>
</section>
<section id="bayes-learning-beta-binomial-1" class="slide level2">
<h2>Bayes Learning: Beta-Binomial</h2>
<p>Updated posterior distribution is also Beta <span class="math display">\[
p\left(
\theta|y\right)  \sim\mathcal{B}\left(  a_{T},A_{T}\right)  \; {\rm and} \;
a_{T}=a+\sum_{t=1}^{T}y_{t} , A_{T}=A+T-\sum_{t=1}^{T}y_{t}
\]</span> The posterior mean and variance are <span class="math display">\[
E\left[  \theta|y\right]  =\frac{a_{T}}{a_{T}+A_{T}}\text{ and }var\left[
\theta|y\right]  =\frac{a_{T}A_{T}}{\left(  a_{T}+A_{T}\right)  ^{2}\left(
a_{T}+A_{T}+1\right)  }
\]</span></p>
</section>
<section id="binomial-beta" class="slide level2 smaller">
<h2>Binomial-Beta</h2>
<p><span class="math inline">\(p ( p | \bar{y} )\)</span> is the <span style="color: blue">posterior distribution</span> for <span class="math inline">\(p\)</span></p>
<p><span class="math inline">\(\bar{y}\)</span> is a sufficient statistic.</p>
<ul>
<li><p>Bayes theorem gives <span class="math display">\[
\begin{aligned}
p ( p | y )
&amp; \propto f ( y | p ) p ( p | \alpha , \beta )\\
&amp; \propto p^{\sum y_i} (1 - p )^{n - \sum y_i } \cdot p^{\alpha - 1} ( 1 - p )^{\beta - 1} \\
&amp; \propto p^{ \alpha + \sum y_i - 1 } ( 1 - p )^{ n - \sum y_i + \beta - 1} \\
&amp; \sim Beta ( \alpha + \sum y_i , \beta + n - \sum y_i )
\end{aligned}
\]</span></p></li>
<li><p>The posterior mean is a shrinkage estimator</p></li>
</ul>
<p>Combination of sample mean <span class="math inline">\(\bar{y}\)</span> and prior mean <span class="math inline">\(E( p )\)</span></p>
<p><span class="math display">\[
E(p|y) = \frac{\alpha + \sum_{i=1}^n y_i}{\alpha + \beta + n} = \frac{n}{n+ \alpha +\beta} \bar{y} + \frac{\alpha + \beta}{\alpha + \beta+n} \frac{\alpha}{\alpha+\beta}
\]</span></p>
</section>
<section id="binomial-beta-1" class="slide level2">
<h2>Binomial-Beta</h2>
<p>Let <span class="math inline">\(p_i\)</span> be the death rate proportion under treatment <span class="math inline">\(i\)</span>.</p>
<ul>
<li><p>To compare treatment <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span> directly compute <span class="math inline">\(P ( p_1 &gt; p_2 | D )\)</span>.</p></li>
<li><p>Prior <span class="math inline">\(beta ( \alpha , \beta )\)</span> with prior mean <span class="math inline">\(E ( p ) = \frac{\alpha}{\alpha + \beta }\)</span>.</p></li>
</ul>
<p>Posterior <span class="math inline">\(beta ( \alpha + \sum x_i , \beta + n - \sum x_i )\)</span></p>
<ul>
<li>For <span class="math inline">\(A\)</span>, <span class="math inline">\(beta ( 1 , 1 ) \rightarrow beta ( 8 , 94 )\)</span></li>
</ul>
<p>For <span class="math inline">\(B\)</span>, <span class="math inline">\(beta ( 1 , 1 ) \rightarrow beta ( 2 , 100 )\)</span></p>
<ul>
<li>Inference: <span class="math inline">\(P ( p_1 &gt; p_2 | D ) \approx 0.98\)</span></li>
</ul>
</section>
<section id="black-swans" class="slide level2">
<h2>Black Swans</h2>
<p><em>Taleb, The Black Swan: the Impact of the Highly Improbable</em></p>
<p>Suppose you’re only see a sequence of White Swans, having never seen a Black Swan.</p>
<p>What’s the Probability of Black Swan event <em>sometime</em> in the future?</p>
<p>Suppose that after <span class="math inline">\(T\)</span> trials you have only seen successes <span class="math inline">\(( y_1 , \ldots , y_T ) = ( 1 , \ldots , 1 )\)</span>. The next trial being a success has <span class="math display">\[
p( y_{T+1} =1 | y_1 , \ldots , y_T ) = \frac{T+1}{T+2}
\]</span> For large <span class="math inline">\(T\)</span> is almost certain. Here <span class="math inline">\(a=A=1\)</span>.</p>
</section>
<section id="black-swans-1" class="slide level2">
<h2>Black Swans</h2>
<p><em>Principle of Induction (Hume)</em></p>
<p>The probability of <span style="color: red">n</span>ever seeing a Black Swan is given by <span class="math display">\[
p( y_{T+1} =1 , \ldots ,  y_{T+n} = 1 | y_1 , \ldots , y_T ) = \frac{ T+1 }{ T+n+1 } \rightarrow 0
\]</span></p>
<p><span style="color: red">Black Swan</span> will eventually happen – don’t be surprised when it actually happens.</p>
</section>
<section id="bayesian-learning-poisson-gamma" class="slide level2">
<h2>Bayesian Learning: Poisson-Gamma</h2>
<p><em>Poisson/Gamma:</em> Suppose that <span class="math inline">\(Y_1 , \ldots , Y_n \mid \lambda \sim Poi ( \lambda )\)</span>.</p>
<p>Let <span class="math inline">\(\lambda \sim Gamma  ( \alpha , \beta )\)</span></p>
<p><span class="math inline">\(( \alpha , \beta )\)</span> are known hyper-parameters.</p>
<ul>
<li>The <span style="color: blue">posterior</span> distribution is</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
p ( \lambda | y ) &amp; \propto
\exp ( - n \lambda ) \lambda^{ \sum y_i } \lambda^{ \alpha - 1 } \exp ( - \beta \lambda ) \\
&amp; \sim Gamma ( \alpha + \sum y_i , n + \beta )
\end{aligned}
\]</span></p>
</section>
<section id="example-clinical-trials" class="slide level2 smaller">
<h2>Example: Clinical Trials</h2>
<p><a href="https://www.jstor.org/stable/pdf/2283139.pdf?casa_token=m_KOPpFmFWkAAAAA:wciAWITuEg35fTbLLoBaD_9Nj9t0OBH-kHuzHQzsFy-VAWzYsKHZwhr_j502Em4EcOPVfMLjjwJOs_lE7TfB4qQIiYzZeljGBz7slWzRbRQJ_X4cVrs">Novick and Grizzle</a>: A Bayesian Approach to the Analysis of Data from Clinical Trials</p>
<p>Four treatments for duodenal ulcers.</p>
<p>Doctors assess the state of the patient.</p>
<p>Sequential data</p>
<p>(<span class="math inline">\(\alpha\)</span>-spending function, can only look at prespecified times).</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Treat</th>
<th style="text-align: left;">Excellent</th>
<th style="text-align: left;">Fair</th>
<th style="text-align: left;">Death</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">A</td>
<td style="text-align: left;">76</td>
<td style="text-align: left;">17</td>
<td style="text-align: left;">7</td>
</tr>
<tr class="even">
<td style="text-align: left;">B</td>
<td style="text-align: left;">89</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">C</td>
<td style="text-align: left;">86</td>
<td style="text-align: left;">13</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">D</td>
<td style="text-align: left;">88</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">3</td>
</tr>
</tbody>
</table>
<p><span style="color: blue">Conclusion:</span> Cannot reject at the 5% level</p>
<p>Conjugate binomial/beta model+sensitivity analysis.</p>
</section>
<section id="sensitivity-analysis" class="slide level2 smaller">
<h2>Sensitivity Analysis</h2>
<p>Important to do a sensitivity analysis.</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Treat</th>
<th style="text-align: left;">Excellent</th>
<th style="text-align: left;">Fair</th>
<th style="text-align: left;">Death</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">A</td>
<td style="text-align: left;">76</td>
<td style="text-align: left;">17</td>
<td style="text-align: left;">7</td>
</tr>
<tr class="even">
<td style="text-align: left;">B</td>
<td style="text-align: left;">89</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">C</td>
<td style="text-align: left;">86</td>
<td style="text-align: left;">13</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">D</td>
<td style="text-align: left;">88</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">3</td>
</tr>
</tbody>
</table>
<p>Poisson-Gamma, prior <span class="math inline">\(\Gamma ( m , z)\)</span> and <span class="math inline">\(\lambda_i\)</span> be the expected death rate.</p>
<p>Compute <span class="math inline">\(P \left ( \frac{ \lambda_1 }{ \lambda_2 } &gt; c | D \right )\)</span></p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;">Prob</th>
<th style="text-align: left;">( 0 , 0 )</th>
<th style="text-align: center;">( 100, 2)</th>
<th style="text-align: right;">( 200 , 5)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(P \left ( \frac{ \lambda_1 }{ \lambda_2 } &gt; 1.3 | D \right )\)</span></td>
<td style="text-align: left;">0.95</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: right;">0.79</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(P \left ( \frac{ \lambda_1 }{ \lambda_2 } &gt; 1.6  | D \right )\)</span></td>
<td style="text-align: left;">0.91</td>
<td style="text-align: center;">0.80</td>
<td style="text-align: right;">0.64</td>
</tr>
</tbody>
</table>
</section>
<section id="bayesian-learning-normal-normal" class="slide level2 smaller">
<h2>Bayesian Learning: Normal-Normal</h2>
<p>Using <span style="color: red">Bayes rule</span> we get <span class="math display">\[
p( \mu | y ) \propto p( y| \mu ) p( \mu )
\]</span></p>
<ul>
<li><span style="color: blue">Posterior</span> is given by</li>
</ul>
<p><span class="math display">\[
p( \mu | y ) \propto \exp \left ( - \frac{1}{2 \sigma^2} \sum_{i=1}^n ( y_i - \mu )^2 -
\frac{1}{2 \tau^2} ( \mu - \mu_0 )^2 \right )
\]</span> Hence <span class="math inline">\(\mu | y \sim N \left ( \hat{\mu}_B , V_{\mu} \right )\)</span> where</p>
<p><span class="math display">\[
\hat{\mu}_B = \frac{ n / \sigma^2 }{ n / \sigma^2 + 1 / \tau^2 } \bar{y}
+  \frac{ 1 / \tau^2 }{ n / \sigma^2 + 1 / \tau^2 }\mu_0 \; \;
{\rm and} \; \;  V_{\mu}^{-1} = \frac{n}{ \sigma^2 } + \frac{1}{\tau^2}
\]</span> A shrinkage estimator.</p>
</section>
<section id="sat-scores" class="slide level2 smaller">
<h2>SAT Scores</h2>
<p>SAT (<span class="math inline">\(200-800\)</span>): 8 high schools and estimate effects.</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">School</th>
<th style="text-align: left;">Estimated <span class="math inline">\(y_j\)</span></th>
<th style="text-align: left;">St.&nbsp;Error <span class="math inline">\(\sigma_j\)</span></th>
<th style="text-align: left;">Average Treatment <span class="math inline">\(\theta_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">A</td>
<td style="text-align: left;">28</td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="even">
<td style="text-align: left;">B</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="odd">
<td style="text-align: left;">C</td>
<td style="text-align: left;">-3</td>
<td style="text-align: left;">16</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="even">
<td style="text-align: left;">D</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="odd">
<td style="text-align: left;">E</td>
<td style="text-align: left;">-1</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="even">
<td style="text-align: left;">F</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="odd">
<td style="text-align: left;">G</td>
<td style="text-align: left;">18</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">?</td>
</tr>
<tr class="even">
<td style="text-align: left;">H</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">18</td>
<td style="text-align: left;">?</td>
</tr>
</tbody>
</table>
<ul>
<li><p><span class="math inline">\(\theta_j\)</span> average effects of coaching programs</p></li>
<li><p><span class="math inline">\(y_j\)</span> estimated treatment effects, for school <span class="math inline">\(j\)</span>, standard error <span class="math inline">\(\sigma_j\)</span>.</p></li>
</ul>
</section>
<section id="estimates" class="slide level2">
<h2>Estimates</h2>
<p>Two programs appear to work (improvements of 18 and 28)</p>
<ul>
<li><p>Large standard errors. Overlapping Confidence Intervals?</p></li>
<li><p>Classical hypothesis test fails to reject the hypothesis that the <span class="math inline">\(\theta_j\)</span>’s are equal.</p></li>
<li><p>Pooled estimate has standard error of <span class="math inline">\(4.2\)</span> with</p></li>
</ul>
<p><span class="math display">\[
\hat{\theta} = \frac{  \sum_j ( y_j / \sigma_j^2 ) }{ \sum_j ( 1 / \sigma_j^2 ) } = 7.9
\]</span></p>
<ul>
<li>Neither separate or pooled seems sensible.</li>
</ul>
<p>Bayesian shrinkage!</p>
</section>
<section id="hierarchical-model" class="slide level2">
<h2>Hierarchical Model</h2>
<p>Hierarchical Model (<span class="math inline">\(\sigma_j^2\)</span> known) is given by <span class="math display">\[
\bar{y}_j | \theta_j \sim N ( \theta_j , \sigma_j^2 )
\]</span> Unequal variances–differential shrinkage.</p>
<ul>
<li>Prior Distribution: <span class="math inline">\(\theta_j \sim N ( \mu , \tau^2 )\)</span> for <span class="math inline">\(1 \leq j \leq 8\)</span>.</li>
</ul>
<p>Traditional random effects model.</p>
<p>Exchangeable prior for the treatment effects.</p>
<p>As <span class="math inline">\(\tau \rightarrow 0\)</span> (complete pooling) and as <span class="math inline">\(\tau \rightarrow \infty\)</span> (separate estimates).</p>
<ul>
<li>Hyper-prior Distribution: <span class="math inline">\(p( \mu , \tau^2 ) \propto 1 / \tau\)</span>.</li>
</ul>
<p>The posterior <span class="math inline">\(p( \mu , \tau^2 | y )\)</span> can be used to “estimate” <span class="math inline">\(( \mu , \tau^2 )\)</span>.</p>
</section>
<section id="posterior" class="slide level2">
<h2>Posterior</h2>
<p>Joint Posterior Distribution <span class="math inline">\(y = ( y_1 , \ldots , y_J )\)</span> <span class="math display">\[
p( \theta , \mu , \tau | y )
\propto  p( y| \theta )   p( \theta | \mu , \tau )p( \mu , \tau )
\]</span> <span class="math display">\[
\propto p( \mu , \tau^2)
\prod_{i=1}^8 N ( \theta_j | \mu , \tau^2 ) \prod_{j=1}^8
N ( y_j | \theta_j )
\]</span> <span class="math display">\[
\propto \tau^{-9} \exp \left ( - \frac{1}{2} \sum_j \frac{1}{\tau^2} ( \theta_j - \mu )^2 -
\frac{1}{2} \sum_j \frac{1}{\sigma_j^2} ( y_j - \theta_j )^2 \right )
\]</span> MCMC!</p>
</section>
<section id="posterior-inference-1" class="slide level2 smaller">
<h2>Posterior Inference</h2>
<p>Report posterior quantiles</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">School</th>
<th style="text-align: left;">2.5%</th>
<th style="text-align: left;">25%</th>
<th style="text-align: left;">50%</th>
<th style="text-align: left;">75%</th>
<th style="text-align: left;">97.5%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">A</td>
<td style="text-align: left;">-2</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">16</td>
<td style="text-align: left;">32</td>
</tr>
<tr class="even">
<td style="text-align: left;">B</td>
<td style="text-align: left;">-5</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">20</td>
</tr>
<tr class="odd">
<td style="text-align: left;">C</td>
<td style="text-align: left;">-12</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">22</td>
</tr>
<tr class="even">
<td style="text-align: left;">D</td>
<td style="text-align: left;">-6</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">21</td>
</tr>
<tr class="odd">
<td style="text-align: left;">E</td>
<td style="text-align: left;">-10</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">19</td>
</tr>
<tr class="even">
<td style="text-align: left;">F</td>
<td style="text-align: left;">-9</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">19</td>
</tr>
<tr class="odd">
<td style="text-align: left;">G</td>
<td style="text-align: left;">-1</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">27</td>
</tr>
<tr class="even">
<td style="text-align: left;">H</td>
<td style="text-align: left;">-7</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">13</td>
<td style="text-align: left;">23</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\mu\)</span></td>
<td style="text-align: left;">-2</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">18</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\tau\)</span></td>
<td style="text-align: left;">0.3</td>
<td style="text-align: left;">2.3</td>
<td style="text-align: left;">5.1</td>
<td style="text-align: left;">8.8</td>
<td style="text-align: left;">21</td>
</tr>
</tbody>
</table>
<p>Schools <span class="math inline">\(A\)</span> and <span class="math inline">\(G\)</span> are similar!</p>
</section>
<section id="bayesian-shrinkage" class="slide level2 scrollable">
<h2>Bayesian Shrinkage</h2>
<p>Bayesian shrinkage provides a way of modeling complex datasets.</p>
<ol type="1">
<li><p>Baseball batting averages: Stein’s Paradox</p></li>
<li><p>Batter-pitcher match-up: Kenny Lofton and Derek Jeter</p></li>
<li><p>Bayes Elections</p></li>
<li><p>Toxoplasmosis</p></li>
<li><p>Bayes MoneyBall</p></li>
<li><p>Bayes Portfolio Selection</p></li>
</ol>
</section>
<section id="example-baseball" class="slide level2">
<h2>Example: Baseball</h2>
<p>Batter-pitcher match-up?</p>
<p>Prior information on overall ability of a player.</p>
<p>Small sample size, pitcher variation.</p>
<ul>
<li>Let <span class="math inline">\(p_i\)</span> denote batter’s ability. Observed number of hits <span class="math inline">\(y_i\)</span></li>
</ul>
<p><span class="math display">\[
(y_i | p_i ) \sim Bin ( T_i , p_i ) \; \; {\rm with} \; \; p_i \sim Be ( \alpha , \beta )
\]</span> where <span class="math inline">\(T_i\)</span> is the number of at-bats against pitcher <span class="math inline">\(i\)</span>. A priori <span class="math inline">\(E( p_i ) = \alpha / (\alpha+\beta ) = \bar{p}_i\)</span>.</p>
<ul>
<li>The extra heterogeneity leads to a prior variance <span class="math inline">\(Var (p_i ) = \bar{p}_i (1 - \bar{p}_i ) \phi\)</span> where <span class="math inline">\(\phi = ( \alpha + \beta + 1 )^{-1}\)</span>.</li>
</ul>
</section>
<section id="sports-data-baseball" class="slide level2 smaller">
<h2>Sports Data: Baseball</h2>
<p>Kenny Lofton hitting versus individual pitchers.</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Pitcher</th>
<th style="text-align: left;">At-bats</th>
<th style="text-align: left;">Hits</th>
<th style="text-align: left;">ObsAvg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">J.C. Romero</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">.667</td>
</tr>
<tr class="even">
<td style="text-align: left;">S. Lewis</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">.600</td>
</tr>
<tr class="odd">
<td style="text-align: left;">B. Tomko</td>
<td style="text-align: left;">20</td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">.550</td>
</tr>
<tr class="even">
<td style="text-align: left;">T. Hoffman</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">.500</td>
</tr>
<tr class="odd">
<td style="text-align: left;">K. Tapani</td>
<td style="text-align: left;">45</td>
<td style="text-align: left;">22</td>
<td style="text-align: left;">.489</td>
</tr>
<tr class="even">
<td style="text-align: left;">A. Cook</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">.444</td>
</tr>
<tr class="odd">
<td style="text-align: left;">J. Abbott</td>
<td style="text-align: left;">34</td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">.412</td>
</tr>
<tr class="even">
<td style="text-align: left;">A.J. Burnett</td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">.400</td>
</tr>
<tr class="odd">
<td style="text-align: left;">K. Rogers</td>
<td style="text-align: left;">43</td>
<td style="text-align: left;">17</td>
<td style="text-align: left;">.395</td>
</tr>
<tr class="even">
<td style="text-align: left;">A. Harang</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">.333</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Pitcher</th>
<th style="text-align: left;">At-bats</th>
<th style="text-align: left;">Hits</th>
<th style="text-align: left;">ObsAvg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">K. Appier</td>
<td style="text-align: left;">49</td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">.306</td>
</tr>
<tr class="even">
<td style="text-align: left;">R. Clemens</td>
<td style="text-align: left;">62</td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">.226</td>
</tr>
<tr class="odd">
<td style="text-align: left;">C. Zambrano</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">.222</td>
</tr>
<tr class="even">
<td style="text-align: left;">N. Ryan</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">.200</td>
</tr>
<tr class="odd">
<td style="text-align: left;">E. Hanson</td>
<td style="text-align: left;">41</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">.171</td>
</tr>
<tr class="even">
<td style="text-align: left;">E. Milton</td>
<td style="text-align: left;">19</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">.056</td>
</tr>
<tr class="odd">
<td style="text-align: left;">M. Prior</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">M. Prior</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">.000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: left;">7630</td>
<td style="text-align: left;">2283</td>
<td style="text-align: left;">.299</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="baseball-kenny-lofton" class="slide level2">
<h2>Baseball: Kenny Lofton</h2>
<p>Kenny Lofton (career <span class="math inline">\(.299\)</span> average, and current <span class="math inline">\(.308\)</span> average for 2006 season) was facing the pitcher Milton (current record 1 for 19).</p>
<ul>
<li>Is putting in a weaker player really a better bet?</li>
<li>Over-reaction to bad luck?</li>
</ul>
<p><span class="math inline">\(\mathbb{P}\left ( \leq 1 \; {\rm hit \; in \; } 19 \; {\rm attempts} | p = 0.3 \right ) = 0.01\)</span></p>
<p>An unlikely 1-in-100 event.</p>
</section>
<section id="baseball-kenny-lofton-1" class="slide level2">
<h2>Baseball: Kenny Lofton</h2>
<p>Bayes solution: shrinkage. Borrow strength across pitchers</p>
<p>Bayes estimate: use the posterior mean</p>
<p>Lofton’s batting estimates that vary from <span class="math inline">\(.265\)</span> to <span class="math inline">\(.340\)</span>.</p>
<p>The lowest being against Milton.</p>
<p><span class="math inline">\(.265 &lt; .275\)</span></p>
<p>Conclusion: resting Lofton against Milton was justified!!</p>
</section>
<section id="bayes-batter-pitcher-match-up" class="slide level2">
<h2>Bayes Batter-pitcher match-up</h2>
<p>Here’s our model again ...</p>
<ul>
<li><p>Small sample sizes and pitcher variation.</p></li>
<li><p>Let <span class="math inline">\(p_i\)</span> denote Lofton’s ability. Observed number of hits <span class="math inline">\(y_i\)</span></p></li>
</ul>
<p><span class="math display">\[
(y_i | p_i ) \sim Bin ( T_i , p_i ) \; \; {\rm with} \; \; p_i \sim Be ( \alpha , \beta )
\]</span> where <span class="math inline">\(T_i\)</span> is the number of at-bats against pitcher <span class="math inline">\(i\)</span>.</p>
<p>Estimate <span class="math inline">\(( \alpha , \beta )\)</span></p>
</section>
<section id="example-derek-jeter" class="slide level2 smaller">
<h2>Example: Derek Jeter</h2>
<p>Derek Jeter 2006 season versus individual pitchers.</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Pitcher</th>
<th>At-bats</th>
<th>Hits</th>
<th>ObsAvg</th>
<th>EstAvg</th>
<th>95% Int</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>R. Mendoza</td>
<td>6</td>
<td>5</td>
<td>.833</td>
<td>.322</td>
<td>(.282, .394)</td>
</tr>
<tr class="even">
<td>H. Nomo</td>
<td>20</td>
<td>12</td>
<td>.600</td>
<td>.326</td>
<td>(.289, .407)</td>
</tr>
<tr class="odd">
<td>A.J.Burnett</td>
<td>5</td>
<td>3</td>
<td>.600</td>
<td>.320</td>
<td>(.275, .381)</td>
</tr>
<tr class="even">
<td>E. Milton</td>
<td>28</td>
<td>14</td>
<td>.500</td>
<td>.324</td>
<td>(.291, .397)</td>
</tr>
<tr class="odd">
<td>D. Cone</td>
<td>8</td>
<td>4</td>
<td>.500</td>
<td>.320</td>
<td>(.218, .381)</td>
</tr>
<tr class="even">
<td>R. Lopez</td>
<td>45</td>
<td>21</td>
<td>.467</td>
<td>.326</td>
<td>(.291, .401)</td>
</tr>
<tr class="odd">
<td>K. Escobar</td>
<td>39</td>
<td>16</td>
<td>.410</td>
<td>.322</td>
<td>(.281, .386)</td>
</tr>
<tr class="even">
<td>J. Wettland</td>
<td>5</td>
<td>2</td>
<td>.400</td>
<td>.318</td>
<td>(.275, .375)</td>
</tr>
</tbody>
</table>
</section>
<section id="example-derek-jeter-1" class="slide level2 smaller">
<h2>Example: Derek Jeter</h2>
<p>Derek Jeter 2006 season versus individual pitchers.</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Pitcher</th>
<th>At-bats</th>
<th>Hits</th>
<th>ObsAvg</th>
<th>EstAvg</th>
<th>95% Int</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>T. Wakefield</td>
<td>81</td>
<td>26</td>
<td>.321</td>
<td>.318</td>
<td>(.279, .364)</td>
</tr>
<tr class="even">
<td>P. Martinez</td>
<td>83</td>
<td>21</td>
<td>.253</td>
<td>.312</td>
<td>(.254, .347)</td>
</tr>
<tr class="odd">
<td>K. Benson</td>
<td>8</td>
<td>2</td>
<td>.250</td>
<td>.317</td>
<td>(.264, .368)</td>
</tr>
<tr class="even">
<td>T. Hudson</td>
<td>24</td>
<td>6</td>
<td>.250</td>
<td>.315</td>
<td>(.260, .362)</td>
</tr>
<tr class="odd">
<td>J. Smoltz</td>
<td>5</td>
<td>1</td>
<td>.200</td>
<td>.314</td>
<td>(.253, .355)</td>
</tr>
<tr class="even">
<td>F. Garcia</td>
<td>25</td>
<td>5</td>
<td>.200</td>
<td>.314</td>
<td>(.253, .355)</td>
</tr>
<tr class="odd">
<td>B. Radke</td>
<td>41</td>
<td>8</td>
<td>.195</td>
<td>.311</td>
<td>(.247, .347)</td>
</tr>
<tr class="even">
<td>D. Kolb</td>
<td>5</td>
<td>0</td>
<td>.000</td>
<td>.316</td>
<td>(.258, .363)</td>
</tr>
<tr class="odd">
<td>J. Julio</td>
<td>13</td>
<td>0</td>
<td>.000</td>
<td>.312</td>
<td>(.243, .350 )</td>
</tr>
<tr class="even">
<td>Total</td>
<td>6530</td>
<td>2061</td>
<td>.316</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="bayes-estimates" class="slide level2">
<h2>Bayes Estimates</h2>
<ul>
<li>Stern estimates <span class="math inline">\(\hat{\phi} = ( \alpha + \beta + 1 )^{-1} = 0.002\)</span> for Jeter</li>
<li>Doesn’t vary much across the population of pitchers.</li>
<li>The extremes are shrunk the most also matchups with the smallest sample sizes.</li>
<li>Jeter had a season <span class="math inline">\(.308\)</span> average.</li>
</ul>
<p>Bayes estimates vary from <span class="math inline">\(.311\)</span> to <span class="math inline">\(.327\)</span>–he’s very consistent.</p>
<p>If all players had a similar record then a constant batting average would make sense.</p>
</section>
<section id="bayes-elections-nate-silver-multinomial-dirichlet" class="slide level2">
<h2>Bayes Elections: Nate Silver: Multinomial-Dirichlet</h2>
<p>Predicting the Electoral Vote (EV)</p>
<ul>
<li>Multinomial-Dirichlet: <span class="math inline">\((\hat{p} | p) \sim Multi (p), ( p | \alpha ) \sim Dir (\alpha)\)</span></li>
</ul>
<p><span class="math display">\[
p_{Obama} = ( p_{1}, \ldots ,p_{51} | \hat{p}) \sim Dir \left ( \alpha + \hat{p} \right )
\]</span></p>
<ul>
<li>Flat uninformative prior <span class="math inline">\(\alpha\equiv 1\)</span>.</li>
</ul>
<p><code>http://www.electoral-vote.com/evp2012/Pres/prespolls.csv</code></p>
</section>
<section id="bayes-elections-nate-silver-simulation" class="slide level2">
<h2>Bayes Elections: Nate Silver: Simulation</h2>
<p>Calculate probabilities via simulation: <code>rdirichlet</code> <span class="math display">\[
p \left ( p_{j,O} | {\rm data} \right )  \;\; {\rm and} \;  \;
p \left ( EV &gt;270 | {\rm data} \right )
\]</span></p>
<p>The election vote prediction is given by the sum <span class="math display">\[
EV =\sum_{j=1}^{51} EV(j) \mathbb{E} \left ( p_{j} | {\rm data} \right )
\]</span> where <span class="math inline">\(EV(j)\)</span> are for individual states</p>
</section>
<section id="polling-data" class="slide level2 smaller">
<h2>Polling Data</h2>
<p>Electoral Vote (EV), <a href="electoral-vote.com">Polling Data</a>: Mitt and Obama percentages</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">State</th>
<th style="text-align: left;">M.pct</th>
<th style="text-align: left;">O.pct</th>
<th style="text-align: left;">EV</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Alabama</td>
<td style="text-align: left;">58</td>
<td style="text-align: left;">36</td>
<td style="text-align: left;">9</td>
</tr>
<tr class="even">
<td style="text-align: left;">Alaska</td>
<td style="text-align: left;">55</td>
<td style="text-align: left;">37</td>
<td style="text-align: left;">3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Arizona</td>
<td style="text-align: left;">50</td>
<td style="text-align: left;">46</td>
<td style="text-align: left;">10</td>
</tr>
<tr class="even">
<td style="text-align: left;">Arkansas</td>
<td style="text-align: left;">51</td>
<td style="text-align: left;">44</td>
<td style="text-align: left;">6</td>
</tr>
<tr class="odd">
<td style="text-align: left;">California</td>
<td style="text-align: left;">33</td>
<td style="text-align: left;">55</td>
<td style="text-align: left;">55</td>
</tr>
<tr class="even">
<td style="text-align: left;">Colorado</td>
<td style="text-align: left;">45</td>
<td style="text-align: left;">52</td>
<td style="text-align: left;">9</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Connecticut</td>
<td style="text-align: left;">31</td>
<td style="text-align: left;">56</td>
<td style="text-align: left;">7</td>
</tr>
<tr class="even">
<td style="text-align: left;">Delaware</td>
<td style="text-align: left;">38</td>
<td style="text-align: left;">56</td>
<td style="text-align: left;">3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">D.C.</td>
<td style="text-align: left;">13</td>
<td style="text-align: left;">82</td>
<td style="text-align: left;">3</td>
</tr>
<tr class="even">
<td style="text-align: left;">Florida</td>
<td style="text-align: left;">46</td>
<td style="text-align: left;">50</td>
<td style="text-align: left;">27</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Georgia</td>
<td style="text-align: left;">52</td>
<td style="text-align: left;">47</td>
<td style="text-align: left;">15</td>
</tr>
<tr class="even">
<td style="text-align: left;">Hawaii</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">63</td>
<td style="text-align: left;">4</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Idaho</td>
<td style="text-align: left;">68</td>
<td style="text-align: left;">26</td>
<td style="text-align: left;">4</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">State</th>
<th style="text-align: left;">M.pct</th>
<th style="text-align: left;">O.pct</th>
<th style="text-align: left;">EV</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Illinois</td>
<td style="text-align: left;">35</td>
<td style="text-align: left;">59</td>
<td style="text-align: left;">21</td>
</tr>
<tr class="even">
<td style="text-align: left;">Indiana</td>
<td style="text-align: left;">48</td>
<td style="text-align: left;">48</td>
<td style="text-align: left;">11</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Iowa</td>
<td style="text-align: left;">37</td>
<td style="text-align: left;">54</td>
<td style="text-align: left;">7</td>
</tr>
<tr class="even">
<td style="text-align: left;">Kansas</td>
<td style="text-align: left;">63</td>
<td style="text-align: left;">31</td>
<td style="text-align: left;">6</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Kentucky</td>
<td style="text-align: left;">51</td>
<td style="text-align: left;">42</td>
<td style="text-align: left;">8</td>
</tr>
<tr class="even">
<td style="text-align: left;">Louisiana</td>
<td style="text-align: left;">50</td>
<td style="text-align: left;">43</td>
<td style="text-align: left;">9</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Maine</td>
<td style="text-align: left;">35</td>
<td style="text-align: left;">56</td>
<td style="text-align: left;">4</td>
</tr>
<tr class="even">
<td style="text-align: left;">Maryland</td>
<td style="text-align: left;">39</td>
<td style="text-align: left;">54</td>
<td style="text-align: left;">10</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Massachusetts</td>
<td style="text-align: left;">34</td>
<td style="text-align: left;">53</td>
<td style="text-align: left;">12</td>
</tr>
<tr class="even">
<td style="text-align: left;">Michigan</td>
<td style="text-align: left;">37</td>
<td style="text-align: left;">53</td>
<td style="text-align: left;">17</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Minnesota</td>
<td style="text-align: left;">42</td>
<td style="text-align: left;">53</td>
<td style="text-align: left;">10</td>
</tr>
<tr class="even">
<td style="text-align: left;">Mississippi</td>
<td style="text-align: left;">46</td>
<td style="text-align: left;">33</td>
<td style="text-align: left;">6</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="polling-data-1" class="slide level2">
<h2>Polling Data:</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="fig/bayes-obama-2008.svg"></p>
<figcaption>Election 2008 Prediction. Obama 370</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="fig/bayes-obama-2012.svg"></p>
<figcaption>Election 2012 Prediction. Obama 332.</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="chicago-bears-2014-2015-season" class="slide level2">
<h2>Chicago Bears 2014-2015 Season</h2>
<p><span style="color: red">Bayes Learning:</span> Update our beliefs in light of <span style="color: blue">new information</span></p>
<ul>
<li>In the 2014-2015 season.</li>
</ul>
<p>The Bears suffered back-to-back 50-points defeats.</p>
<p>Partiots-Bears <span class="math inline">\(51-23\)</span></p>
<p>Packers-Bears <span class="math inline">\(55-14\)</span></p>
<ul>
<li>Their next game was at home against the Minnesota Vikings.</li>
</ul>
<p>Current line against the Vikings was <span style="color: red"><span class="math inline">\(-3.5\)</span> points</span>.</p>
<p>Slightly over a field goal</p>
<p><em>What’s the Bayes approach to learning the line?</em></p>
</section>
<section id="hierarchical-model-1" class="slide level2">
<h2>Hierarchical Model</h2>
<p>Hierarchical model for the current average win/lose this year <span class="math display">\[
\begin{aligned}
\bar{y} | \theta &amp; \sim N \left ( \theta , \frac{\sigma^2}{n} \right ) \sim N \left ( \theta , \frac{18.34^2}{9} \right )\\
\theta &amp; \sim N( 0 , \tau^2 )
\end{aligned}
\]</span> Here <span class="math inline">\(n =9\)</span> games so far. With <span class="math inline">\(s = 18.34\)</span> points</p>
<p>Pre-season prior mean <span class="math inline">\(\mu_0 = 0\)</span>, standard deviation <span class="math inline">\(\tau = 4\)</span>.</p>
<p>Record so-far. Data <span class="math inline">\(\bar{y} = -9.22\)</span>.</p>
</section>
<section id="chicago-bears" class="slide level2 smaller">
<h2>Chicago Bears</h2>
<p>Bayes Shrinkage estimator <span class="math display">\[
\mathbb{E} \left ( \theta | \bar{y} , \tau \right ) = \frac{ \tau^2 }{ \tau^2 + \frac{\sigma^2}{n} } \bar{y}
\]</span></p>
<p>The <span style="color: blue">Shrinkage factor</span> is <span class="math inline">\(0.3\)</span>!!</p>
<p>That’s quite a bit of shrinkage. <span style="color: red">Why?</span></p>
<ul>
<li>Our updated estimator is</li>
</ul>
<p><span class="math display">\[
\mathbb{E} \left ( \theta | \bar{y} , \tau \right ) = - 2.75 &gt; -.3.5
\]</span> where current line is <span class="math inline">\(-3.5\)</span>.</p>
<ul>
<li>Based on our hierarchical model this is an <span style="color: blue">over-reaction</span>.</li>
</ul>
<p>One point change on the line is about 3% on a probability scale.</p>
<p>Alternatively, calculate a <span style="color: blue">market-based <span class="math inline">\(\tau\)</span></span> given line <span class="math inline">\(=-3.5\)</span>.</p>
</section>
<section id="chicago-bears-1" class="slide level2">
<h2>Chicago Bears</h2>
<p>Last two defeats were 50 points scored by opponent (2014-15)</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a></a>bears<span class="ot">=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">8</span>,<span class="dv">8</span>,<span class="sc">-</span><span class="dv">21</span>,<span class="sc">-</span><span class="dv">7</span>,<span class="dv">14</span>,<span class="sc">-</span><span class="dv">13</span>,<span class="sc">-</span><span class="dv">28</span>,<span class="sc">-</span><span class="dv">41</span>)</span>
<span id="cb5-2"><a></a><span class="fu">mean</span>(bears)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -9.222222</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a></a><span class="fu">sd</span>(bears)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 18.34242</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a></a>tau<span class="ot">=</span><span class="dv">4</span></span>
<span id="cb9-2"><a></a>sig2<span class="ot">=</span><span class="fu">sd</span>(bears)<span class="sc">*</span><span class="fu">sd</span>(bears)<span class="sc">/</span><span class="dv">9</span></span>
<span id="cb9-3"><a></a>tau<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(sig2<span class="sc">+</span>tau<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2997225</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a></a><span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">2.76</span><span class="sc">/</span><span class="dv">18</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4390677</code></pre>
</div>
</div>
<p>Home advantage is worth 3 points. Vikings an average record.</p>
<p><span style="color: red">Result: Bears 21, Vikings 13</span></p>
</section>
<section id="steins-estimator" class="slide level2">
<h2>Stein’s Estimator</h2>
<ul>
<li>Popularized by Efron’s 1970 paper</li>
<li>Discovered by Charles Stein in 1956 and further developed with James in 1961 (James-Stein estimator)</li>
<li>Want to estimate <span class="math inline">\(p\)</span> means of several independent normal distributions <em>simultaneously</em>. <span class="math display">\[
\mu_1, \mu_2,\ldots,\mu_p
\]</span></li>
<li>MLE: <span class="math inline">\(\mu_i\)</span> is simply the sample observation <span class="math inline">\(x_i\)</span> from the i-th distribution, considering each mean <em>individually</em>.</li>
</ul>
</section>
<section id="the-shocking-result-stein-paradox" class="slide level2">
<h2>The Shocking Result (Stein Paradox)</h2>
<ul>
<li>When <span class="math inline">\(p&gt;3\)</span> there is <em>different</em> estimator that is <em>uniformly</em> better than using the individual sample means (<span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, …, <span class="math inline">\(x_p\)</span>) when you consider the <em>total</em> squared error risk across all means.</li>
<li>“Uniformly better” means it’s better for <em>all</em> possible true values of the means (<span class="math inline">\(\mu_1\)</span>, <span class="math inline">\(\mu_2\)</span>, …, <span class="math inline">\(\mu_p\)</span>).</li>
<li>The distributions are assumed to be independent.<br>
</li>
<li>Sample means are individually good estimators.</li>
</ul>
<p>Counterintuitive! How can we improve upon something that already seems so natural and optimal when considered in isolation?</p>
</section>
<section id="the-james-stein-estimator" class="slide level2">
<h2>The James-Stein Estimator</h2>
<p>The estimator that Stein and James proposed (often called the James-Stein estimator or shrinkage estimator) is of the form: <span class="math display">\[
\mu_{JS} = (1 - b)\hat x
\]</span> - <span class="math inline">\(b\)</span> is a “shrinkage factor” calculated based on the data, typically something like <span class="math inline">\(b = (p - 2) S^2 / ||x||^2\)</span>, where <span class="math inline">\(S^2\)</span> is the variance of the underlying distributions (often assumed to be known or estimated), and $||x||^2 = x_1^2 + x_2^2 + + <span class="math inline">\(x_p^2\)</span> is the squared Euclidean norm of x.</p>
</section>
<section id="what-does-this-estimator-do" class="slide level2">
<h2>What does this estimator do?</h2>
<ul>
<li>It <em>shrinks</em> the original estimate <span class="math inline">\(\mu\)</span> towards the origin (zero vector). The amount of shrinkage is determined by the data itself. If <span class="math inline">\(||x||^2\)</span> is large (observations are far from zero), the shrinkage factor <code>b</code> is smaller, and less shrinkage is applied. If <span class="math inline">\(||x||^2\)</span> is small, <span class="math inline">\(b\)</span> is larger, and more shrinkage is applied towards zero.</li>
<li>Brad Efron’s 1970 paper, “Stein’s Paradox in Statistics,” published in the <em>American Statistician</em>, simplified and clarified the paradox</li>
<li>Geometric Interpretation: Efron emphasized a geometric perspective on the Stein Paradox.</li>
<li>Risk Decomposition and Analysis: derivation cleverly decomposed the risk (expected squared error) of the estimators. This decomposition clearly showed how the James-Stein estimator reduces risk compared to the standard estimator, especially in higher dimensions.</li>
</ul>
</section>
<section id="risk-analysis-and-decomposition" class="slide level2">
<h2>Risk Analysis and Decomposition</h2>
<p><span class="math display">\[
Risk(\mu_{JS}) = E[ ||\mu_{JS}(x) - \mu||^2 ] = E[ \sum_{i=1}^p (\mu_{JS,i}(x) - \mu_i)^2 ]
\]</span> - Each component of <span class="math inline">\(x - \mu\)</span> has variance <span class="math inline">\(\sigma^2\)</span> (let’s assume for simplicity all distributions have the same known variance ^2).</p>
<p>Say <span class="math inline">\(\mu_{JS}(x) = x\)</span>, the risk becomes: <span class="math display">\[
Risk(x) = E[ ||x - \mu||^2 ] = E[ \sum_{i=1}^p (x_i - \mu_i)^2 ] = \sum_{i=1}^p Var(x) = p\sigma^2
\]</span> This is the risk of the standard MLE estimator. It scales linearly with the dimension <em>p</em>.</p>
</section>
<section id="risk-of-a-shrinkage-estimator" class="slide level2">
<h2>Risk of a Shrinkage Estimator</h2>
<p><span class="math display">\[
\mu_{JS} = (1 - b)x
\]</span> where <em>b</em> is a fixed constant between 0 and 1. Efron then analyzes the risk of this estimator: <span class="math display">\[
Risk(\mu_{JS}) = E[ ||(1 - b)x - \mu||^2 ] = E[ ||(1 - b)(x - \mu) - b\mu||^2 ]
\]</span> By expanding this using vector algebra and expectations, and making use of the independence and normality assumptions, Efron shows that you can decompose the risk into terms related to <em>b</em> and the dimension <em>p</em>.</p>
</section>
<section id="risk-of-a-shrinkage-estimator-1" class="slide level2">
<h2>Risk of a Shrinkage Estimator</h2>
<p>Approximately optimal fixed shrinkage constant <em>b</em> is around <span class="math display">\[
(p - 2) / E[||x||^2]
\]</span> or proportional to <span class="math inline">\((p-2) / ||x||^2\)</span> in the data-dependent version.</p>
</section>
<section id="random-effect-model" class="slide level2">
<h2>Random Effect Model</h2>

<img data-src="fig/randomeffects.png" style="width:100.0%" class="r-stretch"></section>
<section id="steins-paradox" class="slide level2 smaller">
<h2>Stein’s Paradox</h2>
<p><span style="color: blue">Stein paradox:</span> possible to make a <span style="color: red">uniform improvement</span> on the MLE in terms of MSE.</p>
<ul>
<li>Mistrust of the statistical interpretation of Stein’s result.</li>
</ul>
<p>In particular, the loss function.</p>
<ul>
<li><p>Difficulties in adapting the procedure to special cases</p></li>
<li><p>Long familiarity with good properties for the MLE</p></li>
</ul>
<p>Any gains from a “complicated” procedure could not be worth the extra trouble (Tukey, savings not more than 10 % in practice)</p>
<p>For <span class="math inline">\(k\ge 3\)</span>, we have the remarkable inequality <span class="math display">\[
MSE(\hat \theta_{JS},\theta) &lt; MSE(\bar y,\theta) \; \forall \theta
\]</span> Bias-variance explanation! Inadmissability of the classical stats.</p>
</section>
<section id="baseball-batting-averages" class="slide level2 smaller">
<h2>Baseball Batting Averages</h2>
<p>Data: 18 major-league players after 45 at bats (1970 season)</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Player</th>
<th style="text-align: left;"><span class="math inline">\(\bar{y}_i\)</span></th>
<th style="text-align: left;"><span class="math inline">\(E ( p_i | D )\)</span></th>
<th style="text-align: left;">average season</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Clemente</td>
<td style="text-align: left;">0.400</td>
<td style="text-align: left;">0.290</td>
<td style="text-align: left;">0.346</td>
</tr>
<tr class="even">
<td style="text-align: left;">Robinson</td>
<td style="text-align: left;">0.378</td>
<td style="text-align: left;">0.286</td>
<td style="text-align: left;">0.298</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Howard</td>
<td style="text-align: left;">0.356</td>
<td style="text-align: left;">0.281</td>
<td style="text-align: left;">0.276</td>
</tr>
<tr class="even">
<td style="text-align: left;">Johnstone</td>
<td style="text-align: left;">0.333</td>
<td style="text-align: left;">0.277</td>
<td style="text-align: left;">0.222</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Berry</td>
<td style="text-align: left;">0.311</td>
<td style="text-align: left;">0.273</td>
<td style="text-align: left;">0.273</td>
</tr>
<tr class="even">
<td style="text-align: left;">Spencer</td>
<td style="text-align: left;">0.311</td>
<td style="text-align: left;">0.273</td>
<td style="text-align: left;">0.270</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Kessinger</td>
<td style="text-align: left;">0.311</td>
<td style="text-align: left;">0.268</td>
<td style="text-align: left;">0.263</td>
</tr>
<tr class="even">
<td style="text-align: left;">Alvarado</td>
<td style="text-align: left;">0.267</td>
<td style="text-align: left;">0.264</td>
<td style="text-align: left;">0.210</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Santo</td>
<td style="text-align: left;">0.244</td>
<td style="text-align: left;">0.259</td>
<td style="text-align: left;">0.269</td>
</tr>
<tr class="even">
<td style="text-align: left;">Swoboda</td>
<td style="text-align: left;">0.244</td>
<td style="text-align: left;">0.259</td>
<td style="text-align: left;">0.230</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Unser</td>
<td style="text-align: left;">0.222</td>
<td style="text-align: left;">0.254</td>
<td style="text-align: left;">0.264</td>
</tr>
<tr class="even">
<td style="text-align: left;">Williams</td>
<td style="text-align: left;">0.222</td>
<td style="text-align: left;">0.254</td>
<td style="text-align: left;">0.256</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Scott</td>
<td style="text-align: left;">0.222</td>
<td style="text-align: left;">0.254</td>
<td style="text-align: left;">0.303</td>
</tr>
<tr class="even">
<td style="text-align: left;">Petrocelli</td>
<td style="text-align: left;">0.222</td>
<td style="text-align: left;">0.254</td>
<td style="text-align: left;">0.264</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Rodriguez</td>
<td style="text-align: left;">0.222</td>
<td style="text-align: left;">0.254</td>
<td style="text-align: left;">0.226</td>
</tr>
<tr class="even">
<td style="text-align: left;">Campanens</td>
<td style="text-align: left;">0.200</td>
<td style="text-align: left;">0.259</td>
<td style="text-align: left;">0.285</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Munson</td>
<td style="text-align: left;">0.178</td>
<td style="text-align: left;">0.244</td>
<td style="text-align: left;">0.316</td>
</tr>
<tr class="even">
<td style="text-align: left;">Alvis</td>
<td style="text-align: left;">0.156</td>
<td style="text-align: left;">0.239</td>
<td style="text-align: left;">0.200</td>
</tr>
</tbody>
</table>
</section>
<section id="baseball-data-first-shrinkage-estimator-efron-and-morris" class="slide level2">
<h2>Baseball Data: First Shrinkage Estimator: Efron and Morris</h2>

<img data-src="fig/efron-morris-baseball.svg" style="width:70.0%" class="r-stretch quarto-figure-center"><p class="caption">Baseball Shrinkage</p></section>
<section id="shrinkage" class="slide level2 smaller">
<h2>Shrinkage</h2>
<p>Let <span class="math inline">\(\theta_i\)</span> denote the end of season average</p>
<ul>
<li>Lindley: shrink to the overall grand mean</li>
</ul>
<p><span class="math display">\[
c = 1 - \frac{ ( k - 3 ) \sigma^2 }{ \sum ( \bar{y}_i - \bar{y} )^2 }
\]</span> where <span class="math inline">\(\bar{y}\)</span> is the overall grand mean and</p>
<p><span class="math display">\[
\hat{\theta} = c \bar{y}_i + ( 1 - c ) \bar{y}
\]</span></p>
<ul>
<li>Baseball data: <span class="math inline">\(c = 0.212\)</span> and <span class="math inline">\(\bar{y} = 0.265\)</span>.</li>
</ul>
<p>Compute <span class="math inline">\(\sum ( \hat{\theta}_i - \bar{y}^{obs}_i )^2\)</span> and see which is lower: <span class="math display">\[
MLE = 0.077 \; \; STEIN = 0.022
\]</span> That’s a factor of <span class="math inline">\(3.5\)</span> times better!</p>
</section>
<section id="batting-averages" class="slide level2">
<h2>Batting Averages</h2>

<img data-src="fig/efron-clemente.svg" style="width:90.0%" class="r-stretch"></section>
<section id="baseball-paradoxes" class="slide level2 smaller">
<h2>Baseball Paradoxes</h2>
<p><span style="color: blue">Shrinkage on Clemente</span> too severe: <span class="math inline">\(z_{Cl} = 0.265 + 0.212 ( 0.400 - 0.265) = 0.294\)</span>.</p>
<p>The <span class="math inline">\(0.212\)</span> seems a little severe</p>
<ul>
<li><p>Limited translation rules, maximum shrinkage eg. 80%</p></li>
<li><p>Not enough shrinkage eg O’Connor ( <span class="math inline">\(y = 1 , n = 2\)</span>). <span class="math inline">\(z_{O'C} = 0.265 + 0.212 ( 0.5  - 0.265 ) = 0.421\)</span>.</p></li>
</ul>
<p>Still better than Ted Williams <span class="math inline">\(0.406\)</span> in 1941.</p>
<ul>
<li><p>Foreign car sales (<span class="math inline">\(k = 19\)</span>) will further improve MSE performance! It will change the shrinkage factors.</p></li>
<li><p>Clearly an improvement over the Stein estimator is</p></li>
</ul>
<p><span class="math display">\[
\hat{\theta}_{S+} =
\max \left ( \left ( 1 - \frac{k-2}{ \sum \bar{Y}_i^2 } \right ) , 0 \right ) \bar{Y}_i
\]</span></p>
</section>
<section id="baseball-prior" class="slide level2">
<h2>Baseball Prior</h2>
<ul>
<li>Include extra prior knowledge</li>
<li>Empirical distribution of all major league players <span class="math display">\[
\theta_i \sim N ( 0.270 , 0.015 )
\]</span></li>
<li>The 0.270 provides another origin to shrink to and the prior variance 0.015 would give a different shrinkage factor.</li>
<li>To fully understand maybe we should build a probabilistic model and see what the posterior mean is as our estimator for the unknown parameters.</li>
</ul>
</section>
<section id="shrinkage-unequal-variances" class="slide level2">
<h2>Shrinkage: Unequal Variances</h2>
<p>Model <span class="math inline">\(Y_i | \theta_i  \sim N ( \theta_i , D_i )\)</span> where <span class="math inline">\(\theta_i \sim N ( \theta_0 , A ) \sim N ( 0.270 , 0.015 )\)</span>.</p>
<ul>
<li><p>The <span class="math inline">\(D_i\)</span> can be different – unequal variances</p></li>
<li><p>Bayes posterior means are given by</p></li>
</ul>
<p><span class="math display">\[
E ( \theta_i | Y ) = ( 1 - B_i ) Y_i \; \; {\rm where} \; \;
B_i = \frac{ D_i }{ D_i + A }
\]</span> where <span class="math inline">\(\hat{A}\)</span> is estimated from the data, see Efron and Morris (1975).</p>
<ul>
<li>Different shrinkage factors as different variances <span class="math inline">\(D_i\)</span>.</li>
</ul>
<p><span class="math inline">\(D_i \propto n_i^{-1}\)</span> and so smaller sample sizes are shrunk more.</p>
<p>Makes sense.</p>
</section>
<section id="example-toxoplasmosis-data" class="slide level2">
<h2>Example: Toxoplasmosis Data</h2>
<p>Disease of Blood that is endemic in tropical regions.</p>
<p>Data: 5000 people in El Salvador (varying sample sizes) from 36 cities.</p>
<ul>
<li><p>Estimate “true” prevalences <span class="math inline">\(\theta_i\)</span> for <span class="math inline">\(1 \leq i \leq 36\)</span></p></li>
<li><p>Allocation of Resources: should we spend funds on the city with the highest observed occurrence of the disease? Same shrinkage factors?</p></li>
<li><p>Shrinkage Procedure (Efron and Morris, p315) <span class="math display">\[
z_i = c_i y_i
\]</span> where <span class="math inline">\(y_i\)</span> are the observed relative rates (normalized so <span class="math inline">\(\bar{y} = 0\)</span> The smaller sample sizes will get shrunk more.</p></li>
</ul>
<p>The most gentle are in the range <span class="math inline">\(0.6 \rightarrow 0.9\)</span> but some are <span class="math inline">\(0.1 \rightarrow 0.3\)</span>.</p>
</section>
<section id="bayes-portfolio-selection" class="slide level2">
<h2>Bayes Portfolio Selection</h2>
<ul>
<li><p><span style="color: blue">de Finetti and Markowitz:</span> Mean-variance portfolio shrinkage: <span class="math inline">\(\frac{1}{\gamma} \Sigma^{-1} \mu\)</span></p></li>
<li><p>Different shrinkage factors for different history lengths.</p></li>
<li><p>Portfolio Allocation in the SP500 index</p></li>
<li><p>Entry/exit; splits; spin-offs etc. For example, 73 replacements to the SP500 index in period 1/1/94 to 12/31/96.</p></li>
<li><p><span style="color: blue">Advantage:</span> <span class="math inline">\(E ( \alpha | D_t ) = 0.39\)</span>, that is 39 bps per month which on an annual basis is <span class="math inline">\(\alpha = 468\)</span> bps.</p></li>
<li><p>The posterior mean for <span class="math inline">\(\beta\)</span> is <span class="math inline">\(p ( \beta | D_t ) = 0.745\)</span></p></li>
</ul>
<p><span class="math inline">\(\bar{x}_{M} = 12.25 \%\)</span> and <span class="math inline">\(\bar{x}_{PT} = 14.05 \%\)</span>.</p>
</section>
<section id="sp-composition" class="slide level2 smaller">
<h2>SP Composition</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Date</th>
<th>Symbol</th>
<th>6/96</th>
<th>12/89</th>
<th>12/79</th>
<th>12/69</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>General Electric</td>
<td>GE</td>
<td>2.800</td>
<td>2.485</td>
<td>1.640</td>
<td>1.569</td>
</tr>
<tr class="even">
<td>Coca Cola</td>
<td>KO</td>
<td>2.342</td>
<td>1.126</td>
<td>0.606</td>
<td>1.051</td>
</tr>
<tr class="odd">
<td>Exxon</td>
<td>XON</td>
<td>2.142</td>
<td>2.672</td>
<td>3.439</td>
<td>2.957</td>
</tr>
<tr class="even">
<td>ATT</td>
<td>T</td>
<td>2.030</td>
<td>2.090</td>
<td>5.197</td>
<td>5.948</td>
</tr>
<tr class="odd">
<td>Philip Morris</td>
<td>MO</td>
<td>1.678</td>
<td>1.649</td>
<td>0.637</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Royal Dutch</td>
<td>RD</td>
<td>1.636</td>
<td>1.774</td>
<td>1.191</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Merck</td>
<td>MRK</td>
<td>1.615</td>
<td>1.308</td>
<td>0.773</td>
<td>0.906</td>
</tr>
<tr class="even">
<td>Microsoft</td>
<td>MSFT</td>
<td>1.436</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Johnson/Johnson</td>
<td>JNJ</td>
<td>1.320</td>
<td>0.845</td>
<td>0.689</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Intel</td>
<td>INTC</td>
<td>1.262</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Procter and Gamble</td>
<td>PG</td>
<td>1.228</td>
<td>1.040</td>
<td>0.871</td>
<td>0.993</td>
</tr>
<tr class="even">
<td>Walmart</td>
<td>WMT</td>
<td>1.208</td>
<td>1.084</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>IBM</td>
<td>IBM</td>
<td>1.181</td>
<td>2.327</td>
<td>5.341</td>
<td>9.231</td>
</tr>
<tr class="even">
<td>Hewlett Packard</td>
<td>HWP</td>
<td>1.105</td>
<td>0.477</td>
<td>0.497</td>
<td>*****</td>
</tr>
</tbody>
</table>
</section>
<section id="sp-composition-1" class="slide level2 smaller">
<h2>SP Composition</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Date</th>
<th>Symbol</th>
<th>6/96</th>
<th>12/89</th>
<th>12/79</th>
<th>12/69</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pepsi</td>
<td>PEP</td>
<td>1.061</td>
<td>0.719</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Pfizer</td>
<td>PFE</td>
<td>0.918</td>
<td>0.491</td>
<td>0.408</td>
<td>0.486</td>
</tr>
<tr class="odd">
<td>Dupont</td>
<td>DD</td>
<td>0.910</td>
<td>1.229</td>
<td>0.837</td>
<td>1.101</td>
</tr>
<tr class="even">
<td>AIG</td>
<td>AIG</td>
<td>0.910</td>
<td>0.723</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Mobil</td>
<td>MOB</td>
<td>0.906</td>
<td>1.093</td>
<td>1.659</td>
<td>1.040</td>
</tr>
<tr class="even">
<td>Bristol Myers Squibb</td>
<td>BMY</td>
<td>0.878</td>
<td>1.247</td>
<td>*****</td>
<td>0.484</td>
</tr>
<tr class="odd">
<td>GTE</td>
<td>GTE</td>
<td>0.849</td>
<td>0.975</td>
<td>0.593</td>
<td>0.705</td>
</tr>
<tr class="even">
<td>General Motors</td>
<td>GM</td>
<td>0.848</td>
<td>1.086</td>
<td>2.079</td>
<td>4.399</td>
</tr>
<tr class="odd">
<td>Disney</td>
<td>DIS</td>
<td>0.839</td>
<td>0.644</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Citicorp</td>
<td>CCI</td>
<td>0.831</td>
<td>0.400</td>
<td>0.418</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>BellSouth</td>
<td>BLS</td>
<td>0.822</td>
<td>1.190</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Motorola</td>
<td>MOT</td>
<td>0.804</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Ford</td>
<td>F</td>
<td>0.798</td>
<td>0.883</td>
<td>0.485</td>
<td>0.640</td>
</tr>
<tr class="even">
<td>Chervon</td>
<td>CHV</td>
<td>0.794</td>
<td>0.990</td>
<td>1.370</td>
<td>0.966</td>
</tr>
</tbody>
</table>
</section>
<section id="sp-composition-2" class="slide level2 smaller">
<h2>SP Composition</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Date</th>
<th>Symbol</th>
<th>6/96</th>
<th>12/89</th>
<th>12/79</th>
<th>12/69</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Amoco</td>
<td>AN</td>
<td>0.733</td>
<td>1.198</td>
<td>1.673</td>
<td>0.758</td>
</tr>
<tr class="even">
<td>Eli Lilly</td>
<td>LLY</td>
<td>0.720</td>
<td>0.814</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Abbott Labs</td>
<td>ABT</td>
<td>0.690</td>
<td>0.654</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>AmerHome Products</td>
<td>AHP</td>
<td>0.686</td>
<td>0.716</td>
<td>0.606</td>
<td>0.793</td>
</tr>
<tr class="odd">
<td>FedNatlMortgage</td>
<td>FNM</td>
<td>0.686</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>McDonald’s</td>
<td>MCD</td>
<td>0.686</td>
<td>0.545</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Ameritech</td>
<td>AIT</td>
<td>0.639</td>
<td>0.782</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Cisco Systems</td>
<td>CSCO</td>
<td>0.633</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>CMB</td>
<td>CMB</td>
<td>0.621</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>SBC</td>
<td>SBC</td>
<td>0.612</td>
<td>0.819</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Boeing</td>
<td>BA</td>
<td>0.598</td>
<td>0.584</td>
<td>0.462</td>
<td>*****</td>
</tr>
<tr class="even">
<td>MMM</td>
<td>MMM</td>
<td>0.581</td>
<td>0.762</td>
<td>0.838</td>
<td>1.331</td>
</tr>
<tr class="odd">
<td>BankAmerica</td>
<td>BAC</td>
<td>0.560</td>
<td>*****</td>
<td>0.577</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Bell Atlantic</td>
<td>BEL</td>
<td>0.556</td>
<td>0.946</td>
<td>*****</td>
<td>*****</td>
</tr>
</tbody>
</table>
</section>
<section id="sp-composition-3" class="slide level2 smaller">
<h2>SP Composition</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Date</th>
<th>Symbol</th>
<th>6/96</th>
<th>12/89</th>
<th>12/79</th>
<th>12/69</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gillette</td>
<td>G</td>
<td>0.535</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Kodak</td>
<td>EK</td>
<td>0.524</td>
<td>0.570</td>
<td>1.106</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Chrysler</td>
<td>C</td>
<td>0.507</td>
<td>*****</td>
<td>*****</td>
<td>0.367</td>
</tr>
<tr class="even">
<td>Home Depot</td>
<td>HD</td>
<td>0.497</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Colgate</td>
<td>COL</td>
<td>0.489</td>
<td>0.499</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Wells Fargo</td>
<td>WFC</td>
<td>0.478</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="odd">
<td>Nations Bank</td>
<td>NB</td>
<td>0.453</td>
<td>*****</td>
<td>*****</td>
<td>*****</td>
</tr>
<tr class="even">
<td>Amer Express</td>
<td>AXP</td>
<td>0.450</td>
<td>0.621</td>
<td>*****</td>
<td>*****</td>
</tr>
</tbody>
</table>
</section>
<section id="keynes-versus-buffett-capm" class="slide level2 smaller">
<h2>Keynes versus Buffett: CAPM</h2>
<p>keynes = 15.08 + 1.83 market</p>
<p>buffett = 18.06 + 0.486 market</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Year</th>
<th style="text-align: left;">Keynes</th>
<th style="text-align: left;">Market</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1928</td>
<td style="text-align: left;">-3.4</td>
<td style="text-align: left;">7.9</td>
</tr>
<tr class="even">
<td style="text-align: left;">1929</td>
<td style="text-align: left;">0.8</td>
<td style="text-align: left;">6.6</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1930</td>
<td style="text-align: left;">-32.4</td>
<td style="text-align: left;">-20.3</td>
</tr>
<tr class="even">
<td style="text-align: left;">1931</td>
<td style="text-align: left;">-24.6</td>
<td style="text-align: left;">-25.0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1932</td>
<td style="text-align: left;">44.8</td>
<td style="text-align: left;">-5.8</td>
</tr>
<tr class="even">
<td style="text-align: left;">1933</td>
<td style="text-align: left;">35.1</td>
<td style="text-align: left;">21.5</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1934</td>
<td style="text-align: left;">33.1</td>
<td style="text-align: left;">-0.7</td>
</tr>
<tr class="even">
<td style="text-align: left;">1935</td>
<td style="text-align: left;">44.3</td>
<td style="text-align: left;">5.3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1936</td>
<td style="text-align: left;">56.0</td>
<td style="text-align: left;">10.2</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Year</th>
<th style="text-align: left;">Keynes</th>
<th style="text-align: left;">Market</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1937</td>
<td style="text-align: left;">8.5</td>
<td style="text-align: left;">-0.5</td>
</tr>
<tr class="even">
<td style="text-align: left;">1938</td>
<td style="text-align: left;">-40.1</td>
<td style="text-align: left;">-16.1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1939</td>
<td style="text-align: left;">12.9</td>
<td style="text-align: left;">-7.2</td>
</tr>
<tr class="even">
<td style="text-align: left;">1940</td>
<td style="text-align: left;">-15.6</td>
<td style="text-align: left;">-12.9</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1941</td>
<td style="text-align: left;">33.5</td>
<td style="text-align: left;">12.5</td>
</tr>
<tr class="even">
<td style="text-align: left;">1942</td>
<td style="text-align: left;">-0.9</td>
<td style="text-align: left;">0.8</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1943</td>
<td style="text-align: left;">53.9</td>
<td style="text-align: left;">15.6</td>
</tr>
<tr class="even">
<td style="text-align: left;">1944</td>
<td style="text-align: left;">14.5</td>
<td style="text-align: left;">5.4</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1945</td>
<td style="text-align: left;">14.6</td>
<td style="text-align: left;">0.8</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="kings-college-cambridge" class="slide level2">
<h2>King’s College Cambridge</h2>

<img data-src="fig/universal1-k.svg" class="r-stretch quarto-figure-center"><p class="caption">Keynes vs Cash</p></section>
<section id="superbowl-xlvii-ravens-vs-49ers" class="slide level2">
<h2>SuperBowl XLVII: Ravens vs 49ers</h2>
<p><code>TradeSports.com</code></p>

<img data-src="figup/hal-superbowl.png" style="width:80.0%" class="r-stretch quarto-figure-center"><p class="caption">SuperBowl XLVII</p></section>
<section id="super-bowl-xlvii-ravens-vs-49ers" class="slide level2">
<h2>Super Bowl XLVII: Ravens vs 49ers</h2>
<ul>
<li><p>Super Bowl XLVII was held at the Superdome in New Orleans on February 3, 2013.</p></li>
<li><p>We will track <span class="math inline">\(X(t)\)</span> which corresponds to the Raven’s lead over the 49ers at each point in time. Table 3 provides the score at the end of each quarter.</p></li>
</ul>
<p><span class="math display">\[
\begin{array}{c|ccccc}
t &amp; 0 &amp; \frac{1}{4} &amp; \frac{1}{2} &amp; \frac{3}{4} &amp; 1  \\\hline
Ravens &amp; 0 &amp; 7  &amp; 21 &amp; 28 &amp; 34 \\
49ers &amp; 0 &amp; 3 &amp; 6 &amp; 23 &amp; 31\\\hline
X(t) &amp; 0 &amp; 4 &amp; 15 &amp; 5 &amp; 3\\
\end{array}
\]</span> SuperBowl XLVII by Quarter</p>
</section>
<section id="initial-market" class="slide level2">
<h2>Initial Market</h2>
<ul>
<li>Initial <em>point spread</em> Ravens being a four point underdog, <span class="math inline">\(\mu=-4\)</span>. <span class="math display">\[
\mu = \mathbb{E} \left (X(1) \right )=-4 .
\]</span></li>
<li>The Ravens upset the 49ers by <span class="math inline">\(34-31\)</span> and <span class="math inline">\(X(1)= 34-31=3\)</span> with the point spread being beaten by 7 points.</li>
<li>To determine the markets’ assessment of the probability that the Ravens would win at the beginning of the game we use the <em>money-line</em> odds.</li>
</ul>
</section>
<section id="initial-market-1" class="slide level2">
<h2>Initial Market</h2>
<ul>
<li>San Francisco <span class="math inline">\(-175\)</span></li>
<li>Baltimore Ravens <span class="math inline">\(+155\)</span>.</li>
</ul>
<p>This implies that a bettor would have to place $175 to win $100 on the 49ers and a bet of $100 on the Ravens would lead to a win of $155.</p>
<p>Convert both of these money-lines to <em>implied probabilities</em> of the each team winning</p>
<p><span class="math display">\[
p_{SF} = \frac{175}{100+175} = 0.686 \; \; {\rm and} \; \; p_{Bal} = \frac{100}{100+155} = 0.392
\]</span></p>
</section>
<section id="probabilities-of-winning" class="slide level2 smaller">
<h2>Probabilities of Winning</h2>
<p>The probabilities do not sum to one. This "overound" probability is talso known as the bookmaker’s edge. <span class="math display">\[
p_{SF} + p_{Bal} = 0.686+0.392 = 1.078
\]</span> providing a <span class="math inline">\(7.8\)</span>% edge for the bookmakers.</p>
<p>the <em>"market vig"</em> is the implied probability of the bookie making money on the bet.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a></a>o <span class="ot">=</span> <span class="fl">1.078</span><span class="dv">-1</span></span>
<span id="cb13-2"><a></a>v <span class="ot">=</span> o<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span>o)</span>
<span id="cb13-3"><a></a>v</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.07235622</code></pre>
</div>
</div>
<p>We use the mid-point of the spread to determine <span class="math inline">\(p\)</span> implying that</p>
<p><span class="math display">\[
p = \frac{1}{2} p_{Bal} + \frac{1}{2} (1 - p_{SF} ) = 0.353
\]</span> From the Ravens perspective, we have <span class="math inline">\(p = \mathbb{P}(X(1)&gt;0) =0.353\)</span>.</p>
<p>Baltimore’s win probability started trading at <span class="math inline">\(p^{mkt}_0 =0.38\)</span></p>
</section>
<section id="half-time-analysis" class="slide level2">
<h2>Half Time Analysis</h2>
<p>The Ravens took a commanding <span class="math inline">\(21-6\)</span> lead at half time. Market was trading at <span class="math inline">\(p_{\frac{1}{2}}^{mkt}= 0.90\)</span>.</p>
<ul>
<li><p>During the 34 minute blackout 42760 contracts changed hands with Baltimore’s win probability ticking down from 95 to 94.</p></li>
<li><p>The win probability peak of 95% occurred after a third-quarter kickoff return for a touchdown.</p></li>
<li><p>At the end of the four quarter, however, when the 49ers nearly went into the lead with a touchdown, Baltimore’s win probability had dropped to 30%.</p></li>
</ul>
</section>
<section id="implied-volatility" class="slide level2 smaller">
<h2>Implied Volatility</h2>
<p>To calculate the implied volatility of the Superbowl we substitute the pair <span class="math inline">\((\mu,p) = (-4, .353)\)</span> into our definition and solve for <span class="math inline">\(\sigma_{IV}\)</span>. <span class="math display">\[
\sigma = \frac{\mu}{\Phi^{-1}(p)} \, ,
\]</span></p>
<ul>
<li>We obtain</li>
</ul>
<p><span class="math display">\[
\sigma_{IV} = \frac{\mu}{\Phi^{-1}(p)} = \frac{-4}{-0.377}  = 10.60
\]</span> where <span class="math inline">\(\Phi^{-1} ( p) = qnorm(0.353) = -0.377\)</span>. The 4 point advantage assessed for the 49ers is under a <span class="math inline">\(\frac{1}{2} \sigma\)</span> favorite.</p>
<ul>
<li>The outcome <span class="math inline">\(X(1)=3\)</span> was within one standard deviation of the pregame model which had an expectation of <span class="math inline">\(\mu=-4\)</span> and volatility of <span class="math inline">\(\sigma= 10.6\)</span>.</li>
</ul>
</section>
<section id="half-time-probabilities" class="slide level2">
<h2>Half Time Probabilities</h2>
<ul>
<li>What’s the probability of the Ravens winning given their lead at half time?</li>
<li>At half time Baltimore led by 15 points, 21 to 6.</li>
<li>The conditional mean for the final outcome is <span class="math inline">\(15 +  0.5*(-4) = 13\)</span> and the conditional volatility is <span class="math inline">\(10.6 \sqrt{1-t}.\)</span></li>
<li>These imply a probability of <span class="math inline">\(.96\)</span> for Baltimore to win the game.</li>
<li>A second estimate of the probability of winning given the half time lead can be obtained directly from the betting market.</li>
<li>From the online betting market we also have traded contracts on <code>TradeSports.com</code> that yield a half time probability of <span class="math inline">\(p_{\frac{1}{2}} = 0.90\)</span>.</li>
</ul>
</section>
<section id="whats-the-implied-volatility-for-the-second-half" class="slide level2">
<h2>What’s the implied volatility for the second half?</h2>
<ul>
<li><span class="math inline">\(p_t^{mkt}\)</span> reflects all available information</li>
<li>For example, at half-time <span class="math inline">\(t = \frac{1}{2}\)</span> we would update</li>
</ul>
<p><span class="math display">\[
\sigma_{IV,t=\frac{1}{2}} = \frac{ l + \mu ( 1-t ) }{ \Phi^{-1} ( p_t )  \sqrt{1-t}} = \frac{15-2}{ \Phi^{-1}(0.9) / \sqrt{2} } = 14
\]</span> where <span class="math inline">\(qnorm(0.9)=1.28\)</span>.</p>
<ul>
<li>As <span class="math inline">\(14&gt; 10.6\)</span>, the market was expecting a more volatile second half–possibly anticipating a comeback from the 49ers.</li>
</ul>
</section>
<section id="how-can-we-form-a-valid-betting-strategy" class="slide level2">
<h2>How can we form a valid betting strategy?</h2>
<p>Given the initial implied volatility <span class="math inline">\(\sigma=10.6\)</span>.</p>
<p>At half time with the Ravens having a <span class="math inline">\(l +\mu(1-t)=13\)</span> points edge</p>
<ul>
<li>We would assess with <span class="math inline">\(\sigma = 10.6\)</span></li>
</ul>
<p><span class="math display">\[
p_{\frac{1}{2}} = \Phi \left ( 13/ (10.6/\sqrt{2}) \right ) = 0.96
\]</span> probability of winning versus the <span class="math inline">\(p_{\frac{1}{2}}^{mkt} = 0.90\)</span> rate.</p>
<ul>
<li>To determine our optimal bet size, <span class="math inline">\(\omega_{bet}\)</span>, on the Ravens we might appeal to the Kelly criterion (Kelly, 1956) which yields</li>
</ul>
<p><span class="math display">\[
\omega_{bet} = p_{\frac{1}{2}} - \frac{q_{\frac{1}{2}}}{O^{mkt}} = 0.96 - \frac{0.1}{1/9} = 0.60
\]</span></p>
</section>
<section id="multivariate-normal" class="slide level2">
<h2>Multivariate Normal</h2>
<p>In the multivariate case, the normal-normal model is <span class="math display">\[
\theta \sim N(\mu_0,\Sigma_0), \quad y \mid \theta \sim N(\theta,\Sigma).
\]</span> The posterior distribution is <span class="math display">\[
\theta \mid y \sim N(\mu_1,\Sigma_1),
\]</span> where <span class="math display">\[
\Sigma_1 = (\Sigma_0^{-1} + \Sigma^{-1})^{-1}, \quad \mu_1 = \Sigma_1(\Sigma_0^{-1}\mu_0 + \Sigma^{-1}y).
\]</span> The predictive distribution is <span class="math display">\[
y_{new} \mid y \sim N(\mu_1,\Sigma_1 + \Sigma).
\]</span></p>
</section>
<section id="black-litterman" class="slide level2">
<h2>Black-Litterman</h2>
<ul>
<li><p>Black and Litterman (1991, 1992) work for combining investor views with market equilibrium.</p></li>
<li><p>In a multivariate returns setting the optimal allocation rule is <span class="math display">\[
\omega^\star = \frac{1}{\gamma} \Sigma^{-1} \mu
\]</span> The question is how to specify <span class="math inline">\((\mu, \Sigma)\)</span> pairs?</p></li>
<li><p>For example, given <span class="math inline">\(\hat{\Sigma}\)</span>, BL derive Bayesian inference for <span class="math inline">\(\mu\)</span> given market equilibrium model and <em>a priori</em> views on the returns of pre-specified portfolios which take the form <span class="math display">\[
( \hat{\mu} | \mu ) \sim \mathcal{N} \left ( \mu , \tau \hat{\Sigma} \right ) \; {\rm and} \;
( Q | \mu ) \sim \mathcal{N} \left ( P \mu , \hat{\Omega} \right ) \; .
\]</span></p></li>
</ul>
</section>
<section id="posterior-views" class="slide level2">
<h2>Posterior Views</h2>
<ul>
<li><p>Combining views, the implied posterior is <span class="math display">\[
( \mu | \hat{\mu} , Q ) \sim  \mathcal{N} \left ( B b , B \right )
\]</span></p></li>
<li><p>The mean and variance are specified by</p></li>
</ul>
<p><span class="math display">\[
B = ( \tau \hat{\Sigma} )^{-1} + P^\prime \hat{\Omega}^{-1} P \; {\rm and} \;    b = ( \tau \hat{\Sigma} )^{-1} \hat{\mu}
+ P^\prime \Omega^{-1} Q
\]</span> These posterior moments then define the optimal allocation rule.</p>
</section>
<section id="satya-nadella-ceo-of-microsoft" class="slide level2">
<h2>Satya Nadella: CEO of Microsoft</h2>
<ul>
<li>In 2014, Satya Nadella became the CEO of Microsoft.</li>
<li>The stock price of Microsoft has been on a steady rise since then.</li>
<li>Suppose that you are a portfolio manager and you are interested in analyzing the returns of Microsoft stock compared to the market.</li>
<li>Suppose you are managing a portfolio with two positions stock of Microsoft (MSFT) and an index fund that follows S&amp;P500 index and tracks overall market performance.</li>
<li>What is the mean returns of the positions in our portfolio?</li>
</ul>
</section>
<section id="satya-nadella-ceo-of-microsoft-1" class="slide level2">
<h2>Satya Nadella: CEO of Microsoft</h2>
<ul>
<li>Assume the prior for the mean returns is a bivariate normal distribution, let <span class="math inline">\(\mu_0 = (\mu_{M}, \mu_{S})\)</span> represent the prior mean returns for the stocks.</li>
<li>The covariance matrix <span class="math inline">\(\Sigma_0\)</span> captures your beliefs about the variability and the relationship between these stocks’ returns in the prior. <span class="math display">\[
\Sigma_0 = \begin{bmatrix} \sigma_{M}^2 &amp; \sigma_{MS} \\ \sigma_{MS} &amp; \sigma_{S}^2 \end{bmatrix},
\]</span></li>
</ul>
<p>We will use the sample mean and covariance matrix of the historical returns as the prior mean and covariance matrix.</p>
</section>
<section id="satya-nadella-ceo-of-microsoft-2" class="slide level2">
<h2>Satya Nadella: CEO of Microsoft</h2>
<ul>
<li>The likelihood of observing the data, given the mean returns, is also a bivariate normal distribution. <span class="math display">\[
\Sigma = \begin{bmatrix} \sigma_{M}^2 &amp; \sigma_{MS} \\ \sigma_{MS} &amp; \sigma_{S}^2 \end{bmatrix},
\]</span> where <span class="math inline">\(\sigma_{M}^2\)</span> and <span class="math inline">\(\sigma_{S}^2\)</span> are the sample variances of the observed returns of MSFT and SPY, respectively, and <span class="math inline">\(\sigma_{MS}\)</span> is the sample covariance of the observed returns of MSFT and SPY. The likelihood mean is given by <span class="math display">\[
\mu = \begin{bmatrix} \mu_{M} \\ \mu_{S} \end{bmatrix},
\]</span> where <span class="math inline">\(\mu_{M}\)</span> and <span class="math inline">\(\mu_{S}\)</span> are the sample means of the observed returns of MSFT and SPY, respectively.</li>
</ul>
</section>
<section id="satya-nadella-ceo-of-microsoft-3" class="slide level2">
<h2>Satya Nadella: CEO of Microsoft</h2>
<ul>
<li>You update your beliefs (prior) about the mean returns using the observed data (likelihood).</li>
<li>The posterior distribution, which combines your prior beliefs and the new information from the data, is also a bivariate normal distribution.</li>
<li>The mean <span class="math inline">\(\mu_{\text{post}}\)</span> and covariance <span class="math inline">\(\Sigma_{\text{post}}\)</span> of the posterior are calculated using Bayesian updating formulas, which involve <span class="math inline">\(\mu_0\)</span>, <span class="math inline">\(\Sigma_0\)</span>, <span class="math inline">\(\mu\)</span>, and <span class="math inline">\(\Sigma\)</span>.</li>
<li>We use observed returns prior to Nadella’s becoming CEO as our prior and analyze the returns post 2014.</li>
</ul>
</section>
<section id="satya-nadella-ceo-of-microsoft-4" class="slide level2">
<h2>Satya Nadella: CEO of Microsoft</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="fl">0.7</span>,<span class="fl">0.5</span>), <span class="at">bty=</span><span class="st">'n'</span>, <span class="at">cex.lab=</span><span class="fl">0.75</span>, <span class="at">cex.axis=</span><span class="fl">0.75</span>,<span class="at">cex.main=</span><span class="fl">0.75</span>)</span>
<span id="cb15-2"><a></a><span class="fu">library</span>(quantmod)</span>
<span id="cb15-3"><a></a><span class="fu">getSymbols</span>(<span class="fu">c</span>(<span class="st">"MSFT"</span>, <span class="st">"SPY"</span>), <span class="at">from =</span> <span class="st">"2001-01-01"</span>, <span class="at">to =</span> <span class="st">"2023-12-31"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "MSFT" "SPY" </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a></a>s <span class="ot">=</span> <span class="dv">3666</span> <span class="co"># 2015-07-30</span></span>
<span id="cb17-2"><a></a>prior <span class="ot">=</span> <span class="dv">1</span><span class="sc">:</span>s</span>
<span id="cb17-3"><a></a>obs <span class="ot">=</span> s<span class="sc">:</span><span class="fu">nrow</span>(MSFT) <span class="co"># post covid</span></span>
<span id="cb17-4"><a></a><span class="co"># obs = 5476:nrow(MSFT) # 2022-10-06 bull run if 22-23</span></span>
<span id="cb17-5"><a></a>a <span class="ot">=</span> <span class="fu">as.numeric</span>(<span class="fu">dailyReturn</span>(MSFT))</span>
<span id="cb17-6"><a></a>c <span class="ot">=</span> <span class="fu">as.numeric</span>(<span class="fu">dailyReturn</span>(SPY))</span>
<span id="cb17-7"><a></a><span class="co"># Prior</span></span>
<span id="cb17-8"><a></a>mu0 <span class="ot">=</span> <span class="fu">c</span>(<span class="fu">mean</span>(a[prior]), <span class="fu">mean</span>(c[prior]))</span>
<span id="cb17-9"><a></a>Sigma0 <span class="ot">=</span> <span class="fu">cov</span>(<span class="fu">data.frame</span>(<span class="at">a=</span>a[prior],<span class="at">c=</span>c[prior]))</span>
<span id="cb17-10"><a></a><span class="co"># Data</span></span>
<span id="cb17-11"><a></a>mu <span class="ot">=</span> <span class="fu">c</span>(<span class="fu">mean</span>(a[obs]), <span class="fu">mean</span>(c[obs]))</span>
<span id="cb17-12"><a></a>Sigma <span class="ot">=</span> <span class="fu">cov</span>(<span class="fu">data.frame</span>(<span class="at">a=</span>a,<span class="at">c=</span>c))</span>
<span id="cb17-13"><a></a><span class="co"># Posterior</span></span>
<span id="cb17-14"><a></a>SigmaPost <span class="ot">=</span> <span class="fu">solve</span>(<span class="fu">solve</span>(Sigma0) <span class="sc">+</span> <span class="fu">solve</span>(Sigma))</span>
<span id="cb17-15"><a></a>muPost <span class="ot">=</span> SigmaPost <span class="sc">%*%</span> (<span class="fu">solve</span>(Sigma0) <span class="sc">%*%</span> mu0 <span class="sc">+</span> <span class="fu">solve</span>(Sigma) <span class="sc">%*%</span> mu)</span>
<span id="cb17-16"><a></a><span class="co"># Plot</span></span>
<span id="cb17-17"><a></a><span class="fu">plot</span>(a[obs], c[obs], <span class="at">xlab=</span><span class="st">"MSFT"</span>, <span class="at">ylab=</span><span class="st">"SPY"</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.005</span>,<span class="fl">0.005</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.005</span>,<span class="fl">0.005</span>), <span class="at">pch=</span><span class="dv">16</span>, <span class="at">cex=</span><span class="fl">0.5</span>)</span>
<span id="cb17-18"><a></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">0</span>, <span class="at">h=</span><span class="dv">0</span>, <span class="at">col=</span><span class="st">"grey"</span>)</span>
<span id="cb17-19"><a></a><span class="fu">abline</span>(<span class="at">v=</span>mu0[<span class="dv">1</span>], <span class="at">h=</span>mu0[<span class="dv">2</span>], <span class="at">col=</span><span class="st">"blue"</span>,<span class="at">lwd=</span><span class="dv">3</span>) <span class="co">#prior</span></span>
<span id="cb17-20"><a></a><span class="fu">abline</span>(<span class="at">v=</span>mu[<span class="dv">1</span>], <span class="at">h=</span>mu[<span class="dv">2</span>], <span class="at">col=</span><span class="st">"red"</span>,<span class="at">lwd=</span><span class="dv">3</span>) <span class="co">#data</span></span>
<span id="cb17-21"><a></a><span class="fu">abline</span>(<span class="at">v=</span>muPost[<span class="dv">1</span>], <span class="at">h=</span>muPost[<span class="dv">2</span>], <span class="at">col=</span><span class="st">"green"</span>,<span class="at">lwd=</span><span class="dv">3</span>) <span class="co">#posterior</span></span>
<span id="cb17-22"><a></a><span class="fu">legend</span>(<span class="st">"bottomright"</span>, <span class="fu">c</span>(<span class="st">"Prior"</span>, <span class="st">"Likelihood"</span>, <span class="st">"Posterior"</span>), <span class="at">pch=</span><span class="dv">15</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>, <span class="st">"green"</span>), <span class="at">bty=</span><span class="st">"n"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="03-conjugate_files/figure-revealjs/unnamed-chunk-7-1.png" width="960" class="r-stretch"></section>
<section id="mixtures-of-conjugate-priors" class="slide level2">
<h2>Mixtures of Conjugate Priors</h2>
<ul>
<li>The mixture of conjugate priors is a powerful tool for modeling complex data. <span class="math display">\[
\theta \sim p(\theta) = \sum_{k=1}^K \pi_k p_k(\theta).
\]</span> Then the posterior is also a mixture of normal distributions, that is <span class="math display">\[
p(\theta\mid y) = p(y\mid \theta)\sum_{k=1}^K \pi_k p_k(\theta)/C.
\]</span></li>
</ul>
</section>
<section id="mixtures-of-conjugate-priors-1" class="slide level2 smaller">
<h2>Mixtures of Conjugate Priors</h2>
<p>We introduce a normalizing constant for each component <span class="math display">\[
C_k = \int p(y\mid \theta)p_k(\theta)d\theta.
\]</span> then <span class="math display">\[
p_k(\theta\mid y) =  p_k(\theta)p(y\mid \theta)/C_k
\]</span> is a proper distribution and our posterior is a mixture of these distributions <span class="math display">\[
p(\theta\mid y) = \sum_{k=1}^K \pi_k C_k p_k(\theta\mid y)/C.
\]</span> Meaning that we need to require <span class="math display">\[
\dfrac{\sum_{k=1}^K \pi_k C_k}{C} = 1.
\]</span> or <span class="math display">\[
C = \sum_{k=1}^K \pi_k C_k
\]</span></p>
</section>
<section id="mixture-of-two-normal-distributions" class="slide level2">
<h2>Mixture of two normal distributions</h2>
<p>The prior distribution is a mixture of two normal distributions, that is <span class="math display">\[
\mu \sim 0.5 N(0,1) + 0.5 N(5,1).
\]</span> The likelihood is a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance 1, that is <span class="math display">\[
y \mid \mu \sim N(\mu,1).
\]</span> The posterior distribution is a mixture of two normal distributions, that is <span class="math display">\[
p(\mu \mid y) \propto \phi(y\mid \mu,1) \left(0.5 \phi(\mu\mid 0,1) + 0.5 \phi(\mu\mid 5,1)\right),
\]</span> where <span class="math inline">\(\phi(x\mid \mu,\sigma^2)\)</span> is the normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.</p>
</section>
<section id="mixture-of-two-normal-distributions-1" class="slide level2">
<h2>Mixture of two normal distributions</h2>
<p>We can calculate it using property of a normal distribution <span class="math display">\[
\phi(x\mid \mu_1,\sigma_1^2)\phi(x\mid \mu_2,\sigma_2^2) = \phi(x\mid \mu_3,\sigma_3^2)\phi(\mu_1-\mu_2\mid 0,\sigma_1^2+\sigma_2^2)
\]</span> where <span class="math display">\[
\mu_3 = \dfrac{\mu_1/\sigma_2^2 + \mu_2/\sigma_1^2}{1/\sigma_1^2 + 1/\sigma_2^2}, \quad \sigma_3^2 = \dfrac{1}{1/\sigma_1^2 + 1/\sigma_2^2}.
\]</span></p>
</section>
<section id="mixture-of-two-normal-distributions-2" class="slide level2">
<h2>Mixture of two normal distributions</h2>
<p>Given, we observed <span class="math inline">\(y = 2\)</span>, we can calculate the posterior distribution for <span class="math inline">\(\mu\)</span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a></a>mu0 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">5</span>)</span>
<span id="cb18-2"><a></a>sigma02 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb18-3"><a></a>pi <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.5</span>)</span>
<span id="cb18-4"><a></a>y <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb18-5"><a></a>mu3 <span class="ot">=</span> (mu0<span class="sc">/</span>sigma02 <span class="sc">+</span> y) <span class="sc">/</span> (<span class="dv">1</span><span class="sc">/</span>sigma02 <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb18-6"><a></a>sigma3 <span class="ot">=</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">/</span>sigma02 <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb18-7"><a></a>C <span class="ot">=</span> <span class="fu">dnorm</span>(y<span class="sc">-</span>mu0,<span class="dv">0</span>,<span class="dv">1</span><span class="sc">+</span>sigma02)<span class="sc">*</span>pi</span>
<span id="cb18-8"><a></a>w <span class="ot">=</span> C<span class="sc">/</span><span class="fu">sum</span>(C)</span>
<span id="cb18-9"><a></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Component parameters:</span><span class="sc">\n</span><span class="st">Mean = (%1.1f,%2.1f)</span><span class="sc">\n</span><span class="st">Var = (%1.1f,%1.1f)</span><span class="sc">\n</span><span class="st">weights = (%1.2f,%1.2f)"</span>, mu3[<span class="dv">1</span>],mu3[<span class="dv">2</span>], sigma3[<span class="dv">1</span>],sigma3[<span class="dv">2</span>],w[<span class="dv">1</span>],w[<span class="dv">2</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Component parameters:
Mean = (1.0,3.5)
Var = (0.5,0.5)
weights = (0.65,0.35)</code></pre>
</div>
</div>
</section>
<section id="normal-with-unknown-variance" class="slide level2">
<h2>Normal With Unknown Variance</h2>
<p>Consider, another example, when mean <span class="math inline">\(\mu\)</span> is fixed and variance is a random variable which follows some distribution <span class="math inline">\(\sigma^2 \sim p(\sigma^2)\)</span>. Given an observed sample <span class="math inline">\(y\)</span>, we can update the distribution over variance using the Bayes rule <span class="math display">\[
p(\sigma^2 \mid  y) = \dfrac{p(y\mid \sigma^2 )p(\sigma^2)}{p(y)}.
\]</span> Now, the total probability in the denominator can be calculated as <span class="math display">\[
p(y) = \int p(y\mid \sigma^2 )p(\sigma^2) d\sigma^2.
\]</span></p>
</section>
<section id="normal-with-unknown-variance-1" class="slide level2">
<h2>Normal With Unknown Variance</h2>
<p>A conjugate prior that leads to analytically calculable integral for variance under the normal likelihood is the inverse Gamma. Thus, if <span class="math display">\[
\sigma^2 \mid  \alpha,\beta \sim IG(\alpha,\beta) = \dfrac{\beta^{\alpha}}{\Gamma(\alpha)}\sigma^{2(-\alpha-1)}\exp\left(-\dfrac{\beta}{\sigma^2}\right)
\]</span> and <span class="math display">\[
y \mid \mu,\sigma^2 \sim N(\mu,\sigma^2)
\]</span> Then the posterior distribution is another inverse Gamma <span class="math inline">\(IG(\alpha_{\mathrm{posterior}},\beta_{\mathrm{posterior}})\)</span>, with <span class="math display">\[
\alpha_{\mathrm{posterior}} = \alpha + 1/2, ~~\beta_{\mathrm{posterior}} = \beta + \dfrac{y-\mu}{2}.
\]</span></p>
</section>
<section id="normal-with-unknown-variance-2" class="slide level2">
<h2>Normal With Unknown Variance</h2>
<p>Now, the predictive distribution over <span class="math inline">\(y\)</span> can be calculated by <span class="math display">\[
p(y_{new}\mid y) = \int p(y_{new},\sigma^2\mid y)p(\sigma^2\mid y)d\sigma^2.
\]</span> Which happens to be a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(2\alpha_{\mathrm{posterior}}\)</span> degrees of freedom, mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\alpha_{\mathrm{posterior}}/\beta_{\mathrm{posterior}}\)</span>.</p>
</section>
<section id="the-normal-gamma-model" class="slide level2">
<h2>The Normal-Gamma Model</h2>
<ul>
<li>To simplify the formulas, we use precision <span class="math inline">\(\rho = 1/\sigma^2\)</span> instead of variance <span class="math inline">\(\sigma^2\)</span>. The normal-Gamma distribution is a conjugate prior for the normal distribution, when we do not know the precision and the mean. Given the observed data <span class="math inline">\(Y  = \{y_1,\ldots,y_n\}\)</span>, we assume normal likelihood <span class="math display">\[
y_i \mid \theta, \rho \sim N(\theta, 1/\rho)
\]</span></li>
</ul>
<p>The normal-gamma prior distribution is defined as <span class="math display">\[
\theta\mid \mu,\rho,\nu \sim N(\mu, 1/(\rho \nu)), \quad \rho \mid \alpha, \beta \sim \text{Gamma}(\alpha, \beta).
\]</span> - <span class="math inline">\(1/\rho\)</span> has inverse-Gamma distribution with parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. - Conditional on <span class="math inline">\(\rho\)</span>, the mean <span class="math inline">\(\theta\)</span> has normal distribution with mean <span class="math inline">\(\mu\)</span> and precision <span class="math inline">\(\nu\rho\)</span>.</p>
</section>
<section id="the-normal-gamma-model-1" class="slide level2">
<h2>The Normal-Gamma Model</h2>
<p><span class="math display">\[
\theta\mid \mu,\rho,\nu \sim N(\mu, 1/(\rho \nu)), \quad \rho \mid \alpha, \beta \sim \text{Gamma}(\alpha, \beta).
\]</span></p>
<ul>
<li>The mean <span class="math inline">\(\theta\)</span> and precision <span class="math inline">\(\rho\)</span> are not independent.</li>
<li>When the precision of observations <span class="math inline">\(\rho\)</span> is low, we are also less certain about the mean.</li>
<li>When <span class="math inline">\(\nu=0\)</span>, we have an improper uniform distribution over <span class="math inline">\(\theta\)</span>, that is independent of <span class="math inline">\(\rho\)</span>.</li>
<li>There is no conjugate distribution for <span class="math inline">\(\theta,\rho\)</span> in which <span class="math inline">\(\theta\)</span> is independent of <span class="math inline">\(\rho\)</span>.</li>
</ul>
</section>
<section id="the-normal-gamma-model-2" class="slide level2 smaller">
<h2>The Normal-Gamma Model</h2>
<p>Given the normal likelihood <span class="math display">\[
p(y\mid \theta, \rho) = \left(\dfrac{\rho}{2\pi}\right)^{1/2}\exp\left(-\dfrac{\rho}{2}\sum_{i=1}^n(y_i-\theta)^2\right)
\]</span> and the normal-gamma prior <span class="math display">\[
p(\theta, \rho \mid \mu,\nu,\alpha,\beta) = \dfrac{\beta^\alpha}{\Gamma(\alpha)}\nu\rho^{\alpha-1}\exp(-\beta\rho)\left(\dfrac{\nu\rho}{2\pi}\right)^{1/2}\exp\left(-\dfrac{\nu\rho}{2}(\theta-\mu)^2\right)
\]</span> the posterior distribution is given by <span class="math display">\[
p(\theta, \rho\mid y) \propto p(y\mid \theta, \rho)p(\theta, \rho).
\]</span> The posterior distribution is a normal-Gamma distribution with parameters <span class="math display">\[
\begin{aligned}
\mu_n &amp;= \dfrac{\nu\mu + n\bar{y}}{\nu+n},\\
\nu_n &amp;= \nu+n,\\
\alpha_n &amp;= \alpha + \dfrac{n}{2},\\
\beta_n &amp;= \beta + \dfrac{1}{2}\sum_{i=1}^n(y_i-\bar{y})^2 + \dfrac{n\nu}{2(\nu+n)}(\bar{y}-\mu)^2.
\end{aligned}
\]</span></p>
</section>
<section id="the-normal-gamma-model-3" class="slide level2">
<h2>The Normal-Gamma Model</h2>
<ul>
<li><span class="math inline">\(\bar{y} = n^{-1}\sum_{i=1}^n y_i\)</span> is the sample mean and <span class="math inline">\(n\)</span> is the sample size.</li>
<li>The posterior distribution is a normal-Gamma distribution with parameters <span class="math inline">\(\mu_n, \nu_n, \alpha_n, \beta_n\)</span>.</li>
</ul>
</section>
<section id="credible-intervals-for-normal-gamma-model-posterior-parameters" class="slide level2 smaller">
<h2>Credible Intervals for Normal-Gamma Model Posterior Parameters</h2>
<ul>
<li>The precission posterior follows a Gamma distribution with parameters <span class="math inline">\(\alpha_n, \beta_n\)</span>, thus we can use quantiles of the Gamma distribution to calculate credible intervals.</li>
<li>A symmetric <span class="math inline">\(100(1-c)%\)</span> credible interval <span class="math inline">\([g_{c/2},g_{1-c/2}]\)</span> is given by <span class="math inline">\(c/2\)</span> and <span class="math inline">\(1-c/2\)</span> quantiles of the gamma distrinution. To find credible intterval for the variance <span class="math inline">\(v = 1/\rho\)</span>, we simply use <span class="math display">\[
[1/g_{1-c/2},1/g_{c/2}].
\]</span> and for standard deviation <span class="math inline">\(s = \sqrt{v}\)</span> we use <span class="math display">\[
[\sqrt{1/g_{1-c/2}},\sqrt{1/g_{c/2}}].
\]</span></li>
</ul>
<p>To find credible interval over the mean <span class="math inline">\(\theta\)</span>, we need to integrate out the precision <span class="math inline">\(\rho\)</span> from the posterior distribution. The marginal distribution of <span class="math inline">\(\theta\)</span> is a Student’s t-distribution with parameters center at <span class="math inline">\(\mu_n\)</span>, variance <span class="math inline">\(\beta_n/(\nu_n\alpha_n)\)</span> and degrees of freedom <span class="math inline">\(2\alpha_n\)</span>.</p>
</section>
<section id="exponential-gamma-model" class="slide level2">
<h2>Exponential-Gamma Model</h2>
<ul>
<li>Waiting times between events: consecutive arrivals of a Poisson process is exponentially distributed with mean <span class="math inline">\(1/\lambda\)</span>. <span class="math display">\[
f(x;\lambda) =  \lambda e^{-\lambda x}, ~ x \geq 0
\]</span></li>
<li><span class="math inline">\(\lambda\)</span> is the rate parameter, which is the inverse of the mean</li>
<li>special case of the Gamma distribution with shape 1 and scale <span class="math inline">\(1/\lambda\)</span>.</li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;">Exponential Distribution</th>
<th style="text-align: center;">Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Expected value</td>
<td style="text-align: center;"><span class="math inline">\(\mu = E{X} = 1/\lambda\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">Variance</td>
<td style="text-align: center;"><span class="math inline">\(\sigma^2 = Var{X} = 1/\lambda^2\)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="exponential-model-examples" class="slide level2">
<h2>Exponential Model: Examples</h2>
<ul>
<li>Lifespan of Electronic Components: The exponential distribution can model the time until a component fails in systems where the failure rate is constant over time.</li>
<li>Time Between Arrivals: In a process where events (like customers arriving at a store or calls arriving at a call center) occur continuously and independently, the time between these events can often be modeled with an exponential distribution.</li>
<li>Radioactive Decay: The time until a radioactive atom decays is often modeled with an exponential distribution.</li>
</ul>
</section>
<section id="exponential-gamma-model-1" class="slide level2">
<h2>Exponential-Gamma Model</h2>
<p>The <em>Exponential-Gamma</em> model assumes that the data follows an exponential distribution (likelihood). - The Gamma distribution is a flexible two-parameter family of distributions and can model a wide range of shapes. <span class="math display">\[\begin{align*}
    \lambda &amp;\sim \text{Gamma}(\alpha, \beta) \\
    x_i &amp;\sim \text{Exponential}(\lambda)
\end{align*}\]</span></p>
<p>The posterior distribution of the rate parameter <span class="math inline">\(\lambda\)</span> is given by: <span class="math display">\[
p(\lambda\mid x_1, \ldots, x_n) \propto \lambda^{\alpha - 1} e^{-\beta\lambda} \prod_{i=1}^n \lambda e^{-\lambda x_i} = \lambda^{\alpha + n - 1} e^{-(\beta + \sum_{i=1}^n x_i)\lambda}
\]</span></p>
</section>
<section id="exponential-gamma-model-2" class="slide level2">
<h2>Exponential-Gamma Model</h2>
<p>Posterior is a Gamma distribution with shape parameter <span class="math inline">\(\alpha + n\)</span> and rate parameter <span class="math inline">\(\beta + \sum_{i=1}^n x_i\)</span>. The posterior mean and variance are given by: <span class="math display">\[
\mathbb{E}[\lambda|x_1, \ldots, x_n] = \frac{\alpha + n}{\beta + \sum_{i=1}^n x_i}, \quad \mathrm{Var}[\lambda|x_1, \ldots, x_n] = \frac{\alpha + n}{(\beta + \sum_{i=1}^n x_i)^2}.
\]</span> Notice, that <span class="math inline">\(\sum x_i\)</span> is the sufficient statistic for inference about parameter <span class="math inline">\(\lambda\)</span>!</p>
</section>
<section id="exponential-gamma-model-3" class="slide level2">
<h2>Exponential-Gamma Model</h2>
<ul>
<li>Reliability Engineering: In situations where the failure rate of components or systems may not be constant and can vary, the Exponential-Gamma model can be used to estimate the time until failure, incorporating uncertainty in the failure rate.</li>
<li>Medical Research: For modeling survival times of patients where the rate of mortality or disease progression is not constant and varies across a population. The variability in rates can be due to different factors like age, genetics, or environmental influences.</li>
<li>Ecology: In studying phenomena like the time between rare environmental events (e.g., extreme weather events), where the frequency of occurrence can vary due to changing climate conditions or other factors.</li>
</ul>
</section>
<section id="exploratory-data-analysis" class="slide level2 scrollable">
<h2>Exploratory Data Analysis</h2>
<p>Before deciding on a parametric model for a dataset. There are several tools that we use to choose the appropriate model. These include</p>
<ol type="1">
<li>Theoretical assumptions underlying the distribution (our prior knowledge about the data)</li>
<li>Exploratory data analysis</li>
<li>Formal goodness-of-fit tests</li>
</ol>
<p>The two most common tools for exploratory data analysis are Q-Q plot, scatter plots and bar plots/histograms.</p>
</section>
<section id="q-q-plot" class="slide level2">
<h2>Q-Q plot</h2>
<ul>
<li>Q-Q plot simply compares the quantiles of your data with the quantiles of a theoretical distribution (like normal, exponential, etc.).</li>
<li>Quantile is the fraction (or percent) of points below the given value.</li>
<li>That is, the <span class="math inline">\(i\)</span>-th quantile is the point <span class="math inline">\(x\)</span> for which <span class="math inline">\(i\)</span>% of the data lies below <span class="math inline">\(x\)</span>.</li>
<li>On a Q-Q plot, if the two data sets come from a population with the same distribution, we should see the points forming a line that’s roughly straight.</li>
</ul>
</section>
<section id="q-q-plot-1" class="slide level2">
<h2>Q-Q plot</h2>
<ul>
<li>If the two data sets <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> come from the same distribution, then the points <span class="math inline">\((x_{(i)}, y_{(i)})\)</span> should lie roughly on the line <span class="math inline">\(y = x\)</span>.</li>
<li>If <span class="math inline">\(y\)</span> comes from a distribution that’s linear in <span class="math inline">\(x\)</span>, then the points <span class="math inline">\((x_{(i)}, y_{(i)})\)</span> should lie roughly on a line, but not necessarily on the line <span class="math inline">\(y = x\)</span>.</li>
</ul>
</section>
<section id="noraml-q-q-plot" class="slide level2 smalller">
<h2>Noraml Q-Q plot</h2>
<p>Q-Q plot for the Data on birth weights of babies born in a Brisbane hospital on December 18, 1997. The data set contains 44 records. A more detailed description of the data set can be found in <a href="https://rdrr.io/cran/UsingR/man/babyboom.html"><code>UsingR manual</code></a>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a></a><span class="fu">require</span>(UsingR)</span>
<span id="cb20-2"><a></a><span class="fu">require</span>(dplyr) </span>
<span id="cb20-3"><a></a><span class="fu">data</span>(babyboom) </span>
<span id="cb20-4"><a></a><span class="fu">qqnorm</span>(babyboom<span class="sc">$</span>wt)</span>
<span id="cb20-5"><a></a><span class="fu">qqline</span>(babyboom<span class="sc">$</span>wt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="03-conjugate_files/figure-revealjs/fig-qqplot-1.png" id="fig-qqplot" width="960" class="r-stretch quarto-figure-center"><p class="caption">
Figure&nbsp;1
</p><p>Are Birth Weights Normally Distributed?</p>
</section>
<section id="noraml-q-q-plot-1" class="slide level2">
<h2>Noraml Q-Q plot</h2>
<p>The Q-Q plots look different if we split the data based on the gender</p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a></a>g <span class="ot">=</span> babyboom <span class="sc">%&gt;%</span> <span class="fu">filter</span>(gender<span class="sc">==</span><span class="st">"girl"</span>) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(wt) </span>
<span id="cb21-2"><a></a>b <span class="ot">=</span> babyboom <span class="sc">%&gt;%</span> <span class="fu">filter</span>(gender<span class="sc">==</span><span class="st">"boy"</span>)  <span class="sc">%&gt;%</span> <span class="fu">pull</span>(wt) </span>
<span id="cb21-3"><a></a><span class="fu">qqnorm</span>(g); <span class="fu">qqline</span>(g)</span>
<span id="cb21-4"><a></a><span class="fu">qqnorm</span>(b); <span class="fu">qqline</span>(b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="03-conjugate_files/figure-revealjs/unnamed-chunk-10-1.png" width="960"></p>
<figcaption>Girls</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="03-conjugate_files/figure-revealjs/unnamed-chunk-10-2.png" width="960"></p>
<figcaption>Boys</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p>Histogram of baby weights by gender</p>
</div>
</div>
</div>
</section>
<section id="noraml-q-q-plot-2" class="slide level2">
<h2>Noraml Q-Q plot</h2>
<p>How about the times in hours between births of babies?</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a></a>hr <span class="ot">=</span> <span class="fu">ceiling</span>(babyboom<span class="sc">$</span>running.time<span class="sc">/</span><span class="dv">60</span>)</span>
<span id="cb22-2"><a></a>BirthsByHour <span class="ot">=</span> <span class="fu">tabulate</span>(hr)</span>
<span id="cb22-3"><a></a><span class="co"># Number of hours with 0, 1, 2, 3, 4 births</span></span>
<span id="cb22-4"><a></a>ObservedCounts <span class="ot">=</span> <span class="fu">table</span>(BirthsByHour) </span>
<span id="cb22-5"><a></a><span class="co"># Average number of births per hour</span></span>
<span id="cb22-6"><a></a>BirthRate<span class="ot">=</span><span class="fu">sum</span>(BirthsByHour)<span class="sc">/</span><span class="dv">24</span>    </span>
<span id="cb22-7"><a></a><span class="co"># Expected counts for Poisson distribution</span></span>
<span id="cb22-8"><a></a>ExpectedCounts<span class="ot">=</span><span class="fu">dpois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>,BirthRate)<span class="sc">*</span><span class="dv">24</span>    </span>
<span id="cb22-9"><a></a><span class="co"># bind into matrix for plotting</span></span>
<span id="cb22-10"><a></a>ObsExp <span class="ot">&lt;-</span> <span class="fu">rbind</span>(ObservedCounts,ExpectedCounts) </span>
<span id="cb22-11"><a></a><span class="fu">barplot</span>(ObsExp,<span class="at">names=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">beside=</span><span class="cn">TRUE</span>,<span class="at">legend=</span><span class="fu">c</span>(<span class="st">"Observed"</span>,<span class="st">"Expected"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="03-conjugate_files/figure-revealjs/unnamed-chunk-11-1.png" width="960" class="r-stretch"></section>
<section id="exponential-q-q-plot" class="slide level2">
<h2>Exponential Q-Q plot</h2>
<p>What about the Q-Q plot?</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a></a><span class="co"># birth intervals</span></span>
<span id="cb23-2"><a></a>birthinterval<span class="ot">=</span><span class="fu">diff</span>(babyboom<span class="sc">$</span>running.time) </span>
<span id="cb23-3"><a></a> <span class="co"># quantiles of standard exponential distribution (rate=1)   </span></span>
<span id="cb23-4"><a></a>exponential.quantiles <span class="ot">=</span> <span class="fu">qexp</span>(<span class="fu">ppoints</span>(<span class="dv">43</span>)) </span>
<span id="cb23-5"><a></a><span class="fu">qqplot</span>(exponential.quantiles, birthinterval)</span>
<span id="cb23-6"><a></a>lmb<span class="ot">=</span><span class="fu">mean</span>(birthinterval)</span>
<span id="cb23-7"><a></a><span class="fu">lines</span>(exponential.quantiles,exponential.quantiles<span class="sc">*</span>lmb) <span class="co"># Overlay a line</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="03-conjugate_files/figure-revealjs/unnamed-chunk-12-1.png" width="960" class="r-stretch"><p>Here</p>
<ul>
<li><code>ppoints</code> function computes the sequence of probability points</li>
<li><code>qexp</code> function computes the quantiles of the exponential distribution</li>
<li><code>diff</code> function computes the difference between consecutive elements of a vector</li>
</ul>
</section>
<section id="brief-list-of-conjugate-models" class="slide level2">
<h2>Brief List of Conjugate Models</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Likelihood</th>
<th style="text-align: center;">Prior</th>
<th style="text-align: left;">Posterior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Binomial</td>
<td style="text-align: center;">Beta</td>
<td style="text-align: left;">Beta</td>
</tr>
<tr class="even">
<td style="text-align: left;">Negative</td>
<td style="text-align: center;">Binomial</td>
<td style="text-align: left;">Beta</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Poisson</td>
<td style="text-align: center;">Gamma</td>
<td style="text-align: left;">Gamma</td>
</tr>
<tr class="even">
<td style="text-align: left;">Geometric</td>
<td style="text-align: center;">Beta</td>
<td style="text-align: left;">Beta</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Exponential</td>
<td style="text-align: center;">Gamma</td>
<td style="text-align: left;">Gamma</td>
</tr>
<tr class="even">
<td style="text-align: left;">Normal (mean unknown)</td>
<td style="text-align: center;">Normal</td>
<td style="text-align: left;">Normal</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Normal (variance unknown)</td>
<td style="text-align: center;">Inverse Gamma</td>
<td style="text-align: left;">Inverse Gamma</td>
</tr>
<tr class="even">
<td style="text-align: left;">Normal (mean and variance unknown)</td>
<td style="text-align: center;">Normal/Gamma</td>
<td style="text-align: left;">Normal/Gamma</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Multinomial</td>
<td style="text-align: center;">Dirichlet</td>
<td style="text-align: left;">Dirichlet</td>
</tr>
</tbody>
</table>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1300,

        height: 920,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>